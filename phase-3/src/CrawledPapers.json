[{"id": "2981549002\n", "title": "Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes.", "abstract": "Wide neural networks with random weights and biases are Gaussian processes, as originally observed by Neal (1995) and more recently by Lee et al. (2018) and Matthews et al. (2018) for deep fully-connected networks, as well as by Novak et al. (2019) and Garriga-Alonso et al. (2019) for deep convolutional networks. We show that this Neural Network-Gaussian Process correspondence surprisingly extends to all modern feedforward or recurrent neural networks composed of multilayer perceptron, RNNs (e.g. LSTMs, GRUs), (nD or graph) convolution, pooling, skip connection, attention, batch normalization, and/or layer normalization. More generally, we introduce a language for expressing neural network computations, and our result encompasses all such expressible neural networks. This work serves as a tutorial on the *tensor programs* technique formulated in Yang (2019) and elucidates the Gaussian Process results obtained there. We provide open-source implementations of the Gaussian Process kernels of simple RNN, GRU, transformer, and batchnorm+ReLU network at this http URL.", "authors": ["Greg Yang"], "related_topics": ["147168706", "50644808", "179717631"], "citation_count": "27", "reference_count": "55", "references": ["2194775991", "2963403868", "1836465849", "2964308564", "2963446712", "1677182931", "2157331557", "2310919327", "2064675550", "1533861849"], "date": "2019"}, {"id": "2153579005\n", "title": "Distributed Representations of Words and Phrases and their Compositionality", "abstract": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.", "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "related_topics": ["2776461190", "2777462759", "70777604"], "citation_count": "25996", "reference_count": "19", "references": ["1614298861", "2117130368", "2141599568", "2132339004", "2158139315", "1423339008", "1498436455", "1662133657", "1889268436", "2131462252"], "date": "2013"}, {"id": "2117130368", "title": "A unified architecture for natural language processing: deep neural networks with multitask learning", "abstract": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.", "authors": ["Ronan Collobert", "Jason Weston"], "related_topics": ["28006648", "58973888", "129792486"], "citation_count": "5718", "reference_count": "24", "references": ["2310919327", "2132339004", "2130903752", "2158847908", "2107008379", "2914746235", "2173629880", "2885050925", "2158823144", "2163568299"], "date": "2008"}, {"id": "2141599568", "title": "Linguistic Regularities in Continuous Space Word Representations", "abstract": "Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, \u201cKing Man + Woman\u201d results in a vector very close to \u201cQueen.\u201d We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.", "authors": ["Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig"], "related_topics": ["60048249", "137293760", "521332185"], "citation_count": "3585", "reference_count": "22", "references": ["1614298861", "2100495367", "2117130368", "179875071", "2132339004", "2158139315", "2147152072", "1632114991", "2131462252", "1970689298"], "date": "2013"}, {"id": "1662133657", "title": "From frequency to meaning: vector space models of semantics", "abstract": "Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.", "authors": ["Peter D. Turney", "Patrick Pantel"], "related_topics": ["66974007", "2778828372", "124246873"], "citation_count": "3223", "reference_count": "178", "references": ["2173213060", "1880262756", "1532325895", "3013264884", "2038721957", "2117130368", "2024165284", "1660390307", "2166706824", "1992419399"], "date": "2009"}, {"id": "2132339004", "title": "A neural probabilistic language model", "abstract": "A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.", "authors": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Janvin"], "related_topics": ["137293760", "39608478", "2777462759"], "citation_count": "7596", "reference_count": "33", "references": ["2038721957", "2116064496", "2147152072", "1631260214", "2096175520", "2110485445", "1575350781", "2158195707", "2914484425", "2121227244"], "date": "2003"}, {"id": "2121227244", "title": "Class-based n -gram models of natural language", "abstract": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics.", "authors": ["Peter F. Brown", "Peter V. deSouza", "Robert L. Mercer", "Vincent J. Della Pietra", "Jenifer C. Lai"], "related_topics": ["117884012", "195324797", "90805587"], "citation_count": "4038", "reference_count": "12", "references": ["2049633694", "2097333193", "1966812932", "2142901448", "2751862591", "1597533204", "1575431606", "2007780422", "2016871293", "1628850721"], "date": "1992"}, {"id": "2194775991", "title": "Deep Residual Learning for Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.", "authors": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "related_topics": ["108583219", "155512373", "81363708"], "citation_count": "79410", "reference_count": "52", "references": ["2618530766", "2962835968", "2097117768", "639708223", "1836465849", "2102605133", "2117539524", "1903029394", "2155893237", "1536680647"], "date": "2016"}, {"id": "2038721957", "title": "WordNet : an electronic lexical database", "abstract": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet.", "authors": ["Christiane Fellbaum"], "related_topics": ["32206222", "2776139846", "157659113"], "citation_count": "20553", "reference_count": "0", "references": ["2108598243", "1861492603", "2031489346", "2097726431", "2110764733", "2132339004", "2160660844", "2952122856", "2145607950", "2022166150"], "date": "2000"}, {"id": "1614298861", "title": "Efficient Estimation of Word Representations in Vector Space", "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.", "authors": ["Tomas Mikolov", "Kai Chen", "Greg S. Corrado", "Jeffrey Dean"], "related_topics": ["2776461190", "2777462759", "61249035"], "citation_count": "17853", "reference_count": "0", "references": ["2153579005", "2250539671", "2271840356", "3104097132", "1895577753", "1888005072", "1486649854", "2964321699", "2100664567", "2123024445"], "date": "2013"}, {"id": "1861492603", "title": "Microsoft COCO: Common Objects in Context", "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.", "authors": ["Tsung-Yi Lin", "Michael Maire", "Serge J. Belongie", "James Hays", "Pietro Perona", "Deva Ramanan", "Piotr Doll\u00e1r", "C. Lawrence Zitnick"], "related_topics": ["2776151529", "64876066", "147037132"], "citation_count": "16319", "reference_count": "46", "references": ["2618530766", "2102605133", "2108598243", "2161969291", "2168356304", "2963542991", "3118608800", "2031489346", "2110158442", "2038721957"], "date": "2014"}, {"id": "2952122856", "title": "Microsoft COCO: Common Objects in Context", "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.", "authors": ["Tsung-Yi Lin", "Michael Maire", "Serge Belongie", "Lubomir Bourdev", "Ross Girshick", "James Hays", "Pietro Perona", "Deva Ramanan", "C. Lawrence Zitnick", "Piotr Doll\u00e1r"], "related_topics": ["64876066", "147037132", "89600930"], "citation_count": "5892", "reference_count": "39", "references": ["2102605133", "2108598243", "2161969291", "2168356304", "1861492603", "2963542991", "3118608800", "2031489346", "2110158442", "2038721957"], "date": "2014"}, {"id": "1880262756", "title": "Latent dirichlet allocation", "abstract": "We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.", "authors": ["David M. Blei", "Andrew Y. Ng", "Michael I. Jordan"], "related_topics": ["500882744", "181389423", "141318989"], "citation_count": "38976", "reference_count": "28", "references": ["2045656233", "2147152072", "2107743791", "2097089247", "1956559956", "1516111018", "1508165687", "1746680969", "2020842694", "2063392856"], "date": "2003"}, {"id": "1836465849", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.", "authors": ["Sergey Ioffe", "Christian Szegedy"], "related_topics": ["123832482", "114466953", "75294576"], "citation_count": "26211", "reference_count": "23", "references": ["2097117768", "2117539524", "2095705004", "1677182931", "2146502635", "2310919327", "1665214252", "2168231600", "1533861849", "104184427"], "date": "2015"}, {"id": "2097089247", "title": "Text Classification from Labeled and Unlabeled Documents using EM", "abstract": "This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents. This is important because in many text classification problems obtaining training labels is expensive, while large quantities of unlabeled documents are readily available. We introduce an algorithm for learning from labeled and unlabeled documents based on the combination of Expectation-Maximization (EM) and a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents. It then trains a new classifier using the labels for all the documents, and iterates to convergence. This basic EM procedure works well when the data conform to the generative assumptions of the model. However these assumptions are often violated in practice, and poor performance can result. We present two extensions to the algorithm that improve classification accuracy under these conditions: (1) a weighting factor to modulate the contribution of the unlabeled data, and (2) the use of multiple mixture components per class. Experimental results, obtained using text from three different real-world tasks, show that the use of unlabeled data reduces classification error by up to 30%.", "authors": ["Kamal Nigam", "Andrew Kachites McCallum", "Sebastian Thrun", "Tom Mitchell"], "related_topics": ["58973888", "2776959682", "52001869"], "citation_count": "3934", "reference_count": "47", "references": ["2099111195", "2149684865", "2049633694", "2435251607", "2048679005", "2117853077", "2114535528", "1550206324", "2138745909", "2140785063"], "date": "2000"}, {"id": "2618530766", "title": "ImageNet classification with deep convolutional neural networks", "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.", "authors": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "related_topics": ["81363708", "2776145597", "22019652"], "citation_count": "166585", "reference_count": "31", "references": ["2194775991", "2097117768", "2108598243", "2911964244", "3118608800", "1904365287", "1665214252", "2546302380", "2110764733", "2130325614"], "date": "2017"}, {"id": "2117539524", "title": "ImageNet Large Scale Visual Recognition Challenge", "abstract": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.", "authors": ["Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein", "Alexander C. Berg", "Li Fei-Fei"], "related_topics": ["2776151529", "64876066", "153180895"], "citation_count": "23640", "reference_count": "97", "references": ["2618530766", "2962835968", "2097117768", "2151103935", "2102605133", "1614298861", "2108598243", "2155893237", "2168356304", "1849277567"], "date": "2015"}, {"id": "2147152072", "title": "Indexing by Latent Semantic Analysis", "abstract": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.", "authors": ["Scott Deerwester", "Susan T. Dumais", "George W. Furnas", "Thomas K. Landauer", "Richard Harshman"], "related_topics": ["68841619", "170133592", "89686163"], "citation_count": "17287", "reference_count": "26", "references": ["1956559956", "1984565341", "1964262399", "2000215628", "2114804204", "2151561903", "3012395598", "1965061793", "2024683548", "2096411881"], "date": "1990"}, {"id": "1533861849", "title": "Understanding the difficulty of training deep feedforward neural networks", "abstract": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a \u201cbetter\u201d basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact).", "authors": ["Xavier Glorot", "Yoshua Bengio"], "related_topics": ["108583219", "2778149865", "114466953"], "citation_count": "13013", "reference_count": "17", "references": ["2136922672", "2310919327", "2072128103", "2117130368", "2025768430", "2110798204", "1498436455", "1994197834", "2131462252", "2172174689"], "date": "2010"}, {"id": "2110798204", "title": "Greedy Layer-Wise Training of Deep Networks", "abstract": "Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization.", "authors": ["Yoshua Bengio", "Pascal Lamblin", "Dan Popovici", "Hugo Larochelle"], "related_topics": ["97385483", "2777579346", "108583219"], "citation_count": "5558", "reference_count": "16", "references": ["2136922672", "2100495367", "2116064496", "2613634265", "2124914669", "1993845689", "2109779438", "2103626435", "2125569215", "2167967601"], "date": "2006"}, {"id": "2110764733", "title": "LabelMe: A Database and Web-Based Tool for Image Annotation", "abstract": "We seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.", "authors": ["Bryan C. Russell", "Antonio Torralba", "Kevin P. Murphy", "William T. Freeman"], "related_topics": ["1667742", "2779986562", "199579030"], "citation_count": "3313", "reference_count": "44", "references": ["2156909104", "2164598857", "2038721957", "2138451337", "2154422044", "2107034620", "1566135517", "2166049352", "2134557905", "2156598602"], "date": "2008"}, {"id": "2167967601", "title": "Convex Neural Networks", "abstract": "Convexity has recently received a lot of attention in the machine learning community, and the lack of convexity has been seen as a major disadvantage of many learning algorithms, such as multi-layer artificial neural networks. We show that training multi-layer neural networks in which the number of hidden units is learned can be viewed as a convex optimization problem. This problem involves an infinite number of variables, but can be solved by incrementally inserting a hidden unit at a time, each time finding a linear classifier that minimizes a weighted sum of errors.", "authors": ["Yoshua Bengio", "Nicolas L. Roux", "Pascal Vincent", "Olivier Delalleau", "Patrice Marcotte"], "related_topics": ["108583219", "157972887", "177973122"], "citation_count": "190", "reference_count": "16", "references": ["2135046866", "3124955340", "1678356000", "1498436455", "2151693816", "2091886411", "2504871398", "2108263314", "2109405055", "2075887074"], "date": "2005"}, {"id": "2160660844", "title": "Mining and summarizing customer reviews", "abstract": "Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative. We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization. Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results. This paper proposes several novel techniques to perform these tasks. Our experimental results using reviews of a number of products sold online demonstrate the effectiveness of the techniques.", "authors": ["Minqing Hu", "Bing Liu"], "related_topics": ["170858558", "135448495", "66402592"], "citation_count": "8447", "reference_count": "40", "references": ["2038721957", "2166706824", "1574901103", "3146306708", "1506285740", "2115023510", "2102381086", "1581485226", "2155328222", "2199803028"], "date": "2004"}, {"id": "2146502635", "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "abstract": "We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.", "authors": ["John Duchi", "Elad Hazan", "Yoram Singer"], "related_topics": ["158968445", "115903097", "107321475"], "citation_count": "8863", "reference_count": "48", "references": ["2296319761", "2108598243", "3120740533", "2798766386", "2610857016", "2150102617", "2167732364", "1992208280", "2160218441", "1978394996"], "date": "2011"}, {"id": "2108263314", "title": "Boosting Algorithms as Gradient Descent", "abstract": "We provide an abstract characterization of boosting algorithms as gradient decsent on cost-functionals in an inner-product function space. We prove convergence of these functional-gradient-descent algorithms under quite weak conditions. Following previous theoretical results bounding the generalization performance of convex combinations of classifiers in terms of general cost functions of the margin, we present a new algorithm (DOOM II) for performing a gradient descent optimization of such cost functions. Experiments on several data sets from the UC Irvine repository demonstrate that DOOM II generally outperforms AdaBoost, especially in high noise situations, and that the overfitting behaviour of AdaBoost is predicted by our cost functions.", "authors": ["Llew Mason", "Jonathan Baxter", "Peter L. Bartlett", "Marcus R. Frean"], "related_topics": ["206688291", "153258448", "46686674"], "citation_count": "873", "reference_count": "17", "references": ["3124955340", "2912934387", "2084812512", "2112076978", "2024046085", "1975846642", "1605688901", "2032210760", "1966280301", "2099968818"], "date": "1999"}, {"id": "2155893237", "title": "Caffe: Convolutional Architecture for Fast Feature Embedding", "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.", "authors": ["Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross Girshick", "Sergio Guadarrama", "Trevor Darrell"], "related_topics": ["108583219", "2776159882", "2778119891"], "citation_count": "14888", "reference_count": "10", "references": ["2618530766", "2102605133", "2963542991", "2088049833", "2155541015", "753012316", "1825604117", "2147414309", "1872489089", "2962883796"], "date": "2014"}, {"id": "1521626219", "title": "Natural Language Processing with Python", "abstract": "This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you: Extract information from unstructured text, either to guess the topic or identify \"named entities\" Analyze linguistic structure in text, including parsing and semantic analysis Access popular linguistic databases, including WordNet and treebanks Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages -- or if you're simply curious to have a programmer's perspective on how human language works -- you'll find Natural Language Processing with Python both fascinating and immensely useful.", "authors": ["Steven Bird", "Ewan Klein", "Edward Loper"], "related_topics": ["129792486", "67463725", "14919245"], "citation_count": "3107", "reference_count": "57", "references": ["1532325895", "1592805114", "2751318774", "2013833248", "1496357020", "2024228866", "2148212498", "2129765547", "1967461618", "1711163617"], "date": "2009"}, {"id": "2063392856", "title": "Latent semantic indexing: a probabilistic analysis", "abstract": "", "authors": ["Christos H. Papadimitriou", "Hisao Tamaki", "Prabhakar Raghavan", "Santosh Vempala"], "related_topics": ["112933361", "500882744", "68841619"], "citation_count": "1583", "reference_count": "20", "references": ["2138621811", "2798909945", "2147152072", "1956559956", "2072773380", "1979750072", "2013737143", "2983896310", "2058616517", "2106285343"], "date": "1998"}, {"id": "2096175520", "title": "A maximum entropy approach to natural language processing", "abstract": "The concept of maximum entropy can be traced back along multiple threads to Biblical times. Only recently, however, have computers become powerful enough to permit the widescale application of this concept to real world problems in statistical estimation and pattern recognition. In this paper, we describe a method for statistical modeling based on maximum entropy. We present a maximum-likelihood approach for automatically constructing maximum entropy models and describe how to implement this approach efficiently, using as examples several problems in natural language processing.", "authors": ["Adam L. Berger", "Vincent J. Della Pietra", "Stephen A. Della Pietra"], "related_topics": ["196956702", "9679016", "114289077"], "citation_count": "4846", "reference_count": "25", "references": ["2099111195", "2049633694", "2006969979", "2121227244", "2160842254", "2097333193", "1597533204", "2099345940", "2167434254", "1976241232"], "date": "1996"}, {"id": "2751318774", "title": "Introduction to Machine Learning", "abstract": "The goal of machine learning is to program computers to use example data or past experience to solve a given problem. Many successful applications of machine learning exist already, including systems that analyze past sales data to predict customer behavior, optimize robot behavior so that a task can be completed using minimum resources, and extract knowledge from bioinformatics data. Introduction to Machine Learning is a comprehensive textbook on the subject, covering a broad array of topics not usually included in introductory machine learning texts. In order to present a unified treatment of machine learning problems and solutions, it discusses many methods from different fields, including statistics, pattern recognition, neural networks, artificial intelligence, signal processing, control, and data mining. All learning algorithms are explained so that the student can easily move from the equations in the book to a computer program. The text covers such topics as supervised learning, Bayesian decision theory, parametric methods, multivariate methods, multilayer perceptrons, local models, hidden Markov models, assessing and comparing classification algorithms, and reinforcement learning. New to the second edition are chapters on kernel machines, graphical models, and Bayesian estimation; expanded coverage of statistical tests in a chapter on design and analysis of machine learning experiments; case studies available on the Web (with downloadable results for instructors); and many additional exercises. All chapters have been revised and updated. Introduction to Machine Learning can be used by advanced undergraduates and graduate students who have completed courses in computer programming, probability, calculus, and linear algebra. It will also be of interest to engineers in the field who are concerned with the application of machine learning methods. Adaptive Computation and Machine Learning series", "authors": ["Ethem Alpaydin"], "related_topics": ["77967617", "115903097", "50292564"], "citation_count": "5413", "reference_count": "0", "references": ["1521626219", "2167101736", "1560147776", "2436001372", "2278572312", "3011439212", "2343420905", "2163291889", "2038705219", "2104993419"], "date": "2004"}, {"id": "2131462252", "title": "A Scalable Hierarchical Distributed Language Model", "abstract": "Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the non-hierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models.", "authors": ["Andriy Mnih", "Geoffrey E. Hinton"], "related_topics": ["39608478", "137293760", "197855036"], "citation_count": "1132", "reference_count": "12", "references": ["2038721957", "2132339004", "36903255", "2091812280", "2158195707", "2121227244", "2127314673", "2056590938", "2111305191", "1558797106"], "date": "2008"}, {"id": "1849277567", "title": "Visualizing and Understanding Convolutional Networks", "abstract": "Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.", "authors": ["Matthew D. Zeiler", "Rob Fergus"], "related_topics": ["81363708", "188441871", "95623464"], "citation_count": "12388", "reference_count": "24", "references": ["2618530766", "2102605133", "2108598243", "2136922672", "1904365287", "2155541015", "2546302380", "2025768430", "2110798204", "2161381512"], "date": "2014"}, {"id": "1966812932", "title": "A Maximum Likelihood Approach to Continuous Speech Recognition", "abstract": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them.", "authors": ["Lalit R. Bahl", "Frederick Jelinek", "Robert L. Mercer"], "related_topics": ["61328038", "193969084", "57273362"], "citation_count": "1965", "reference_count": "17", "references": ["2142384583", "1597533204", "1575431606", "2341171179", "2163929346", "2157477135", "2029491572", "2035227369", "2137095888", "1989226853"], "date": "1983"}, {"id": "3013264884", "title": "The Anatomy of a Large-Scale Hypertextual Web Search Engine.", "abstract": "In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at http://google.stanford.edu/. To engineer a search engine is a challenging task. Search engines index tens to hundreds of millions of web pages involving a comparable number of distinct terms. They answer tens of millions of queries every day. Despite the importance of large-scale search engines on the web, very little academic research has been done on them. Furthermore, due to rapid advance in technology and web proliferation, creating a web search engine today is very different from three years ago. This paper provides an in-depth description of our large-scale web search engine -- the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better search results. This paper addresses this question of how to build a practical large-scale system which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want.", "authors": ["Sergey Brin", "Lawrence Page"], "related_topics": ["521815418", "21959979", "162215914"], "citation_count": "20969", "reference_count": "0", "references": ["2142827986", "2089554624", "2108278206", "2113112851", "1984250866", "2144629587", "2048562911", "2007541434", "2017333496", "1984137208"], "date": "1997"}, {"id": "2962883796", "title": "Recognizing Image Style.", "abstract": "The style of an image plays a significant role in how it is viewed, but style has received little attention in computer vision research. We describe an approach to predicting style of images, and perform a thorough evaluation of different image features for these tasks. We find that features learned in a multi-layer network generally perform best \u2013 even when trained with object class (not style) labels. Our large-scale learning methods results in the best published performance on an existing dataset of aesthetic ratings and photographic style annotations. We present two novel datasets: 80K Flickr photographs annotated with 20 curated style labels, and 85K paintings annotated with 25 style/genre labels. Our approach shows excellent classification performance on both datasets. We use the learned classifiers to extend traditional tag-based image search to consider stylistic constraints, and demonstrate cross-dataset understanding of style.", "authors": ["Sergey Karayev", "Matthew Trentacoste", "Helen Han", "Aseem Agarwala", "Trevor Darrell", "Aaron Hertzmann", "Holger Winnemoeller"], "related_topics": ["2781327548", "204321447", "41008148"], "citation_count": "396", "reference_count": "22", "references": ["2618530766", "2108598243", "2146502635", "2155541015", "1566135517", "2135957164", "1511924373", "2075456404", "2078807908", "2157462866"], "date": "2013"}, {"id": "2154422044", "title": "Object class recognition by unsupervised scale-invariant learning", "abstract": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).", "authors": ["R. Fergus", "P. Perona", "A. Zisserman"], "related_topics": ["20894473", "2780142956", "2776676872"], "citation_count": "3001", "reference_count": "19", "references": ["2164598857", "2217896605", "2049633694", "2119747362", "2109200236", "2159686933", "2155511848", "1949116567", "2160225842", "1699734612"], "date": "2003"}, {"id": "1978394996", "title": "Term Weighting Approaches in Automatic Text Retrieval", "abstract": "The experimental evidence accumulated over the past 20 years indicates that textindexing systems based on the assignment of appropriately weighted single terms produce retrieval results that are superior to those obtainable with other more elaborate text representations. These results depend crucially on the choice of effective term weighting systems. This paper summarizes the insights gained in automatic term weighting, and provides baseline single term indexing models with which other more elaborate content analysis procedures can be compared.", "authors": ["Gerard Salton", "Christopher Buckley"], "related_topics": ["22639730", "183115368", "61797465"], "citation_count": "11546", "reference_count": "48", "references": ["1956559956", "2043909051", "2083605078", "2068632118", "3090556797", "2095396650", "2075006521", "11171803", "3091372544", "1557757161"], "date": "1988"}, {"id": "2151693816", "title": "Matching pursuits with time-frequency dictionaries", "abstract": "The authors introduce an algorithm, called matching pursuit, that decomposes any signal into a linear expansion of waveforms that are selected from a redundant dictionary of functions. These waveforms are chosen in order to best match the signal structures. Matching pursuits are general procedures to compute adaptive signal representations. With a dictionary of Gabor functions a matching pursuit defines an adaptive time-frequency transform. They derive a signal energy distribution in the time-frequency plane, which does not include interference terms, unlike Wigner and Cohen class distributions. A matching pursuit isolates the signal structures that are coherent with respect to a given dictionary. An application to pattern extraction from noisy signals is described. They compare a matching pursuit decomposition with a signal expansion over an optimized wavepacket orthonormal basis, selected with the algorithm of Coifman and Wickerhauser see (IEEE Trans. Informat. Theory, vol. 38, Mar. 1992). >", "authors": ["S.G. Mallat", "Zhifeng Zhang"], "related_topics": ["156872377", "99217422", "154771677"], "citation_count": "11971", "reference_count": "13", "references": ["2062024414", "2798909945", "1996021349", "2156447271", "1970352604", "2165878107", "2913399920", "3132971798", "2091886411", "2080563952"], "date": "1993"}, {"id": "2911964244", "title": "Random Forests", "abstract": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, aaa, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.", "authors": ["Leo Breiman"], "related_topics": ["169258074", "138405894", "106135958"], "citation_count": "74907", "reference_count": "12", "references": ["2912934387", "2112076978", "1975846642", "2152761983", "2113242816", "1605688901", "2120240539", "2099968818", "2067885219", "1580948147"], "date": "2001"}, {"id": "2048679005", "title": "Combining labeled and unlabeled data with co-training", "abstract": "We consider the problem of using a large unlabeled sample to boost performance of a learning algorit,hrn when only a small set of labeled examples is available. In particular, we consider a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views. For example, the description of a web page can be partitioned into the words occurring on that page, and the words occurring in hyperlinks t,hat point to that page. We assume that either view of the example would be sufficient for learning if we had enough labeled data, but our goal is to use both views together to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples. Specifically, the presence of two distinct views of each example suggests strategies in which two learning algorithms are trained separately on each view, and then each algorithm\u2019s predictions on new unlabeled examples are used to enlarge the training set of the other. Our goal in this paper is to provide a PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data. We also provide empirical results on real web-page data indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice. *This research was supported in part by the DARPA HPKB program under contract F30602-97-1-0215 and by NSF National Young investigator grant CCR-9357793. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. TO copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. COLT 98 Madison WI USA Copyright ACM 1998 l-58113-057--0/98/ 7...%5.00 92 Tom Mitchell School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213-3891 mitchell+@cs.cmu.edu", "authors": ["Avrim Blum", "Tom Mitchell"], "related_topics": ["58973888", "2776959682", "21959979"], "citation_count": "6444", "reference_count": "14", "references": ["2049633694", "3017143921", "2101210369", "2167044614", "1995897489", "2128221272", "2103555337", "2150516767", "2020764470", "1550302919"], "date": "1998"}, {"id": "2110158442", "title": "Contour Detection and Hierarchical Image Segmentation", "abstract": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications.", "authors": ["P Arbela\u0301ez", "M Maire", "C Fowlkes", "J Malik"], "related_topics": ["65885262", "25694479", "124504099"], "citation_count": "4663", "reference_count": "76", "references": ["2121947440", "2067191022", "2116040950", "2124351162", "1999478155", "2145023731", "1578099820", "2169551590", "2121927366", "1528789833"], "date": "2011"}, {"id": "1536680647", "title": "Fast R-CNN", "abstract": "This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.", "authors": ["Ross Girshick"], "related_topics": ["2776151529", "519991488", "94176051"], "citation_count": "14493", "reference_count": "25", "references": ["2618530766", "2962835968", "2102605133", "2108598243", "2155893237", "2168356304", "1861492603", "2963542991", "2109255472", "2164598857"], "date": "2015"}, {"id": "2125569215", "title": "The Curse of Highly Variable Functions for Local Kernel Machines", "abstract": "We present a series of theoretical arguments supporting the claim that a large class of modern learning algorithms that rely solely on the smoothness prior - with similarity between examples expressed with a local kernel - are sensitive to the curse of dimensionality, or more precisely to the variability of the target. Our discussion covers supervised, semi-supervised and unsupervised learning algorithms. These algorithms are found to be local in the sense that crucial properties of the learned function at x depend mostly on the neighbors of x in the training set. This makes them sensitive to the curse of dimensionality, well studied for classical non-parametric statistical learning. We show in the case of the Gaussian kernel that when the function to be learned has many variations, these algorithms require a number of training examples proportional to the number of variations, which could be large even though there may exist short descriptions of the target function, i.e. their Kolmogorov complexity may be low. This suggests that there exist non-local learning algorithms that at least have the potential to learn about such structured but apparently complex functions (because locally they have many variations), while not using very specific prior domain knowledge.", "authors": ["Yoshua Bengio", "Olivier Delalleau", "Nicolas L. Roux"], "related_topics": ["58973888", "122280245", "134517425"], "citation_count": "224", "reference_count": "19", "references": ["2119821739", "2053186076", "2001141328", "2140095548", "2087347434", "2154455818", "2139823104", "1604938182", "3017143921", "2160167256"], "date": "2005"}, {"id": "2913399920", "title": "Vector quantization", "abstract": "A vector quantizer is a system for mapping a sequence of continuous or discrete vectors into a digital sequence suitable for communication over or storage in a digital channel. The goal of such a system is data compression: to reduce the bit rate so as to minimize communication channel capacity or digital storage memory requirements while maintaining the necessary fidelity of the data. The mapping for each vector may or may not have memory in the sense of depending on past actions of the coder, just as in well established scalar techniques such as PCM, which has no memory, and predictive quantization, which does. Even though information theory implies that one can always obtain better performance by coding vectors instead of scalars, scalar quantizers have remained by far the most common data compression system because of their simplicity and good performance when the communication rate is sufficiently large. In addition, relatively few design techniques have existed for vector quantizers. During the past few years several design algorithms have been developed for a variety of vector quantizers and the performance of these codes has been studied for speech waveforms, speech linear predictive parameter vectors, images, and several simulated random processes. It is the purpose of this article to survey some of these design techniques and their applications.", "authors": ["R. Gray"], "related_topics": ["199833920", "28855332", "13895895"], "citation_count": "4386", "reference_count": "44", "references": ["2134383396", "2127218421", "1995875735", "2583466288", "2142228262", "2021760654", "2164240509", "2150418026", "2119352491", "2040336387"], "date": "1984"}, {"id": "1665214252", "title": "Rectified Linear Units Improve Restricted Boltzmann Machines", "abstract": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.", "authors": ["Vinod Nair", "Geoffrey E. Hinton"], "related_topics": ["192576344", "48372109", "2778149865"], "citation_count": "13596", "reference_count": "21", "references": ["2136922672", "2100495367", "2546302380", "2116064496", "1782590233", "2134557905", "2099866409", "1994197834", "2536626143", "2157364932"], "date": "2010"}, {"id": "2124914669", "title": "Exponential Family Harmoniums with an Application to Information Retrieval", "abstract": "Directed graphical models with one layer of observed random variables and one or more layers of hidden random variables have been the dominant modelling paradigm in many research fields. Although this approach has met with considerable success, the causal semantics of these models can make it difficult to infer the posterior distribution over the hidden variables. In this paper we propose an alternative two-layer model based on exponential family distributions and the semantics of undirected models. Inference in these \"exponential family harmoniums\" is fast while learning is performed by minimizing contrastive divergence. A member of this family is then studied as an alternative probabilistic model for latent semantic indexing. In experiments it is shown that they perform well on document retrieval tasks and provide an elegant solution to searching with keywords.", "authors": ["Max Welling", "Michal Rosen-zvi", "Geoffrey E. Hinton"], "related_topics": ["30549945", "149189445", "155846161"], "citation_count": "573", "reference_count": "14", "references": ["1880262756", "2116064496", "2147152072", "1612003148", "2140124448", "1934021597", "2138448681", "145818128", "2109720450", "1813659000"], "date": "2004"}, {"id": "2025768430", "title": "Extracting and composing robust features with denoising autoencoders", "abstract": "Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.", "authors": ["Pascal Vincent", "Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "related_topics": ["97385483", "8038995", "167966045"], "citation_count": "5670", "reference_count": "23", "references": ["2136922672", "2100495367", "2072128103", "2110798204", "2153663612", "1652505363", "1498436455", "1994197834", "2293063825", "2172174689"], "date": "2008"}, {"id": "2087347434", "title": "A training algorithm for optimal margin classifiers", "abstract": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.", "authors": ["Bernhard E. Boser", "Isabelle M. Guyon", "Vladimir N. Vapnik"], "related_topics": ["774472", "42023084", "112972136"], "citation_count": "13591", "reference_count": "20", "references": ["3017143921", "2171277043", "2165758113", "2154579312", "2266946488", "1530699444", "2076118331", "2086472796", "2111494971", "1965770722"], "date": "1992"}, {"id": "2158195707", "title": "An empirical study of smoothing techniques for language modeling", "abstract": "We survey the most widely-used algorithms for smoothing models for language n -gram modeling. We then present an extensive empirical comparison of several of these smoothing techniques, including those described by Jelinek and Mercer (1980); Katz (1987); Bell, Cleary and Witten (1990); Ney, Essen and Kneser (1994), and Kneser and Ney (1995). We investigate how factors such as training data size, training corpus (e.g. Brown vs. Wall Street Journal), count cutoffs, and n -gram order (bigram vs. trigram) affect the relative performance of these methods, which is measured through the cross-entropy of test data. We find that these factors can significantly affect the relative performance of models, with the most significant factor being training data size. Since no previous comparisons have examined these factors systematically, this is the first thorough characterization of the relative performance of various algorithms. In addition, we introduce methodologies for analyzing smoothing algorithm efficacy in detail, and using these techniques we motivate a novel variation of Kneser?Ney smoothing that consistently outperforms all other algorithms evaluated. Finally, results showing that improved language model smoothing leads to improved speech recognition performance are presented.", "authors": ["Stanley F. Chen", "Joshua Goodman"], "related_topics": ["2778239037", "3770464", "108757681"], "citation_count": "3717", "reference_count": "23", "references": ["2170120409", "2158195707", "2121227244", "2099247782", "2097333193", "1966812932", "2611071497", "2166637769", "2134237567", "2075201173"], "date": "1999"}, {"id": "2168356304", "title": "Object Detection with Discriminatively Trained Part-Based Models", "abstract": "We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.", "authors": ["P F Felzenszwalb", "R B Girshick", "D McAllester", "D Ramanan"], "related_topics": ["112933361", "51167844", "182521987"], "citation_count": "10940", "reference_count": "46", "references": ["2151103935", "2161969291", "3097096317", "2154422044", "2120419212", "2152826865", "2145072179", "1576520375", "2030536784", "2115763357"], "date": "2010"}, {"id": "2160225842", "title": "Learning a Sparse Representation for Object Detection", "abstract": "We present an approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects. A vocabulary of information-rich object parts is automatically constructed from a set of sample images of the object class of interest. Images are then represented using parts from this vocabulary, along with spatial relations observed among them. Based on this representation, a feature-efficient learning algorithm is used to learn to detect instances of the object class. The framework developed can be applied to any object with distinguishable parts in a relatively fixed spatial configuration. We report experiments on images of side views of cars. Our experiments show that the method achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation.In addition, we discuss and offer solutions to several methodological issues that are significant for the research community to be able to evaluate object detection approaches.", "authors": ["Shivani Agarwal", "Dan Roth"], "related_topics": ["71681937", "2776151529", "182521987"], "citation_count": "767", "reference_count": "21", "references": ["2164598857", "2217896605", "2152473410", "2124087378", "2124351082", "2155511848", "1949116567", "1564419782", "2156406284", "2124722975"], "date": "2002"}, {"id": "2064675550", "title": "Long short-term memory", "abstract": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.", "authors": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "related_topics": ["2778149865", "2780005939", "147168706"], "citation_count": "49372", "reference_count": "34", "references": ["2107878631", "2128499899", "2007431958", "194249466", "2123716044", "2143503258", "2154890045", "2103452139", "2048060899", "1674799117"], "date": "1997"}, {"id": "3012395598", "title": "Data preprocessing and the extended PARAFAC model", "abstract": "", "authors": ["R. A. Harshman"], "related_topics": ["10551718", "178980831", "41008148"], "citation_count": "215", "reference_count": "0", "references": ["2024165284", "2147152072", "2119741678", "1539811621", "1986326495", "2155844971", "2089079408", "2085946009", "2172195418", "2001964924"], "date": "1983"}, {"id": "2024228866", "title": "The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data", "abstract": "1. Introduction to text mining 2. Core text mining operations 3. Text mining preprocessing techniques 4. Categorization 5. Clustering 6. Information extraction 7. Probabilistic models for Information extraction 8. Preprocessing applications using probabilistic and hybrid approaches 9. Presentation-layer considerations for browsing and query refinement 10. Visualization approaches 11. Link analysis 12. Text mining applications Appendix Bibliography.", "authors": ["Ronen Feldman", "James Sanger"], "related_topics": ["165141518", "176775163", "2781252014"], "citation_count": "3387", "reference_count": "500", "references": ["2156909104", "1880262756", "2099111195", "2147880316", "2038721957", "1660390307", "2125838338", "2166706824", "1679913846", "1992419399"], "date": "2006"}, {"id": "1736726159", "title": "Mining of Massive Datasets", "abstract": "The popularity of the Web and Internet commerce provides many extremely large datasets from which information can be gleaned by data mining. This book focuses on practical algorithms that have been used to solve key problems in data mining and which can be used on even the largest datasets. It begins with a discussion of the map-reduce framework, an important tool for parallelizing algorithms automatically. The authors explain the tricks of locality-sensitive hashing and stream processing algorithms for mining data that arrives too fast for exhaustive processing. The PageRank idea and related tricks for organizing the Web are covered next. Other chapters cover the problems of finding frequent itemsets and clustering. The final chapters cover two applications: recommendation systems and Web advertising, each vital in e-commerce. Written by two authorities in database and Web technologies, this book is essential reading for students and practitioners alike.", "authors": ["Anand Rajaraman", "Jeffrey David Ullman"], "related_topics": ["197046077", "110875604", "73555534"], "citation_count": "2206", "reference_count": "104", "references": ["2173213060", "1565377632", "1532325895", "3013264884", "2119821739", "2171960770", "1981420413", "2139212933", "2121947440", "2119565742"], "date": "2011"}, {"id": "2138745909", "title": "Data mining and knowledge discovery: making sense out of data", "abstract": "Current computing and storage technology is rapidly outstripping society's ability to make meaningful use of the torrent of available data. Without a concerted effort to develop knowledge discovery techniques, organizations stand to forfeit much of the value from the data they currently collect and store.", "authors": ["U.M. Feyyad"], "related_topics": ["120567893", "103520596", "135572916"], "citation_count": "7003", "reference_count": "14", "references": ["1553696291", "3017143921", "1523293200", "1601529450", "1610836425", "1520252399", "3162744413", "1547515408", "1602329118", "1513282898"], "date": "1996"}, {"id": "2169551590", "title": "Interactive graph cuts for optimal boundary & region segmentation of objects in N-D images", "abstract": "In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both \"object\" and \"background\" segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm.", "authors": ["Y.Y. Boykov", "M.-P. Jolly"], "related_topics": ["65885262", "25694479", "124504099"], "citation_count": "6159", "reference_count": "21", "references": ["2121947440", "2104095591", "2113137767", "1991113069", "1564419782", "2098152234", "2086921140", "2096139825", "1987983010", "2132603077"], "date": "2001"}, {"id": "2089079408", "title": "The Multilinear Engine\u2014A Table-Driven, Least Squares Program for Solving Multilinear Problems, Including the n-Way Parallel Factor Analysis Model", "abstract": "Abstract A technique for fitting multilinear and quasi-multilinear mathematical expressions or models to two-, three-, and many-dimensional data arrays is described. Principal component analysis and three-way PARAFAC factor analysis are examples of bilinear and trilinear least squares fit. This work presents a technique for specifying the problem in a structured way so that one program (the Multilinear Engine) may be used for solving widely different multilinear problems. The multilinear equations to be solved are specified as a large table of integer code values. The end user creates this table by using a small preprocessing program. For each different case, an individual structure table is needed. The solution is computed by using the conjugate gradient algorithm. Non-negativity constraints are implemented by using the well-known technique of preconditioning in opposite way for slowing down changes of variables that are about to become negative. The iteration converges to a minimum that may be local or ...", "authors": ["Pentti Paatero"], "related_topics": ["84392682", "91352546", "26689484"], "citation_count": "884", "reference_count": "19", "references": ["2798909945", "2075665712", "2056857971", "2098098075", "2000215628", "1974403130", "3012395598", "2022242697", "2121739212", "1963826206"], "date": "1999"}, {"id": "2108598243", "title": "ImageNet: A large-scale hierarchical image database", "abstract": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.", "authors": ["Jia Deng", "Wei Dong", "Richard Socher", "Li-Jia Li", "Kai Li", "Li Fei-Fei"], "related_topics": ["157659113", "1667742", "75294576"], "citation_count": "28822", "reference_count": "24", "references": ["2151103935", "2038721957", "2128017662", "2110764733", "1782590233", "1576445103", "2145607950", "2141282920", "2115733720", "1528789833"], "date": "2009"}, {"id": "2115733720", "title": "One-shot learning of object categories", "abstract": "Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by maximum likelihood (ML) and maximum a posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.", "authors": ["Li Fei-Fei", "R. Fergus", "P. Perona"], "related_topics": ["2778034222", "136389625", "9810830"], "citation_count": "2041", "reference_count": "44", "references": ["2164598857", "2310919327", "2124386111", "2217896605", "2154422044", "2045656233", "2166049352", "2134557905", "2130416410", "2030536784"], "date": "2006"}, {"id": "2171960770", "title": "Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions", "abstract": "This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. These extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multicriteria ratings, and a provision of more flexible and less intrusive types of recommendations.", "authors": ["G. Adomavicius", "A. Tuzhilin"], "related_topics": ["557471498", "21569690", "44263959"], "citation_count": "12663", "reference_count": "108", "references": ["1660390307", "2042281163", "1971040550", "2110325612", "2159094788", "3121531027", "2085937320", "2124591829", "1966553486", "1999047234"], "date": "2005"}, {"id": "1971040550", "title": "Evaluating collaborative filtering recommender systems", "abstract": "Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated.", "authors": ["Jonathan L. Herlocker", "Joseph A. Konstan", "Loren G. Terveen", "John T. Riedl"], "related_topics": ["557471498", "21569690", "2780213525"], "citation_count": "6980", "reference_count": "63", "references": ["1660390307", "2042281163", "2110325612", "2342091124", "3121531027", "2085937320", "2124591829", "1966553486", "1999047234", "2042123098"], "date": "2003"}, {"id": "104184427", "title": "On the importance of initialization and momentum in deep learning", "abstract": "Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.", "authors": ["Ilya Sutskever", "James Martens", "George Dahl", "Geoffrey Hinton"], "related_topics": ["114466953", "206688291", "147168706"], "citation_count": "3619", "reference_count": "28", "references": ["2618530766", "2136922672", "2100495367", "2064675550", "1533861849", "2147768505", "2110798204", "1993882792", "3141595720", "2184045248"], "date": "2013"}, {"id": "2962965405", "title": "A Neural Attention Model for Abstractive Sentence Summarization", "abstract": "Summarization based on text extraction is inherently limited, but generation-style abstractive methods have proven challenging to build. In this work, we propose a fully data-driven approach to abstractive sentence summarization. Our method utilizes a local attention-based model that generates each word of the summary conditioned on the input sentence. While the model is structurally simple, it can easily be trained end-to-end and scales to a large amount of training data. The model shows significant performance gains on the DUC-2004 shared task compared with several strong baselines.", "authors": ["Alexander M. Rush", "Sumit Chopra", "Jason Weston"], "related_topics": ["170858558", "2777530160", "204321447"], "citation_count": "1862", "reference_count": "25", "references": ["2964308564", "2130942839", "2157331557", "1904365287", "1532325895", "2123442489", "2132339004", "1753482797", "2124807415", "2118434577"], "date": "2015"}, {"id": "2138451337", "title": "Eigenfaces for recognition", "abstract": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture.", "authors": ["Matthew Turk", "Alex Pentland"], "related_topics": ["104906051", "88799230", "191070858"], "citation_count": "20218", "reference_count": "23", "references": ["2135463994", "2125848778", "2130259898", "2055712799", "2125999363", "1509703770", "1526492552", "1507699566", "2032361618", "1986450498"], "date": "1990"}, {"id": "2130903752", "title": "A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data", "abstract": "One of the most important issues in machine learning is whether one can improve the performance of a supervised learning algorithm by including unlabeled data. Methods that use both labeled and unlabeled data are generally referred to as semi-supervised learning. Although a number of such methods are proposed, at the current stage, we still don't have a complete understanding of their effectiveness. This paper investigates a closely related problem, which leads to a novel approach to semi-supervised learning. Specifically we consider learning predictive structures on hypothesis spaces (that is, what kind of classifiers have good predictive power) from multiple learning tasks. We present a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data. Under this framework, algorithms for structural learning will be proposed, and computational issues will be investigated. Experiments will be given to demonstrate the effectiveness of the proposed algorithms in the semi-supervised learning setting.", "authors": ["Rie Kubota Ando", "Tong Zhang"], "related_topics": ["58973888", "8038995", "24138899"], "citation_count": "1518", "reference_count": "26", "references": ["2148603752", "1480376833", "2154455818", "2139823104", "2048679005", "2097089247", "2107008379", "2914746235", "2010353172", "2101210369"], "date": "2005"}, {"id": "2136542423", "title": "A Study of Smoothing Methods for Language Models Applied to Ad Hoc Information Retrieval", "abstract": "Language modeling approaches to information retrieval are attractive and promising because they connect the problem of retrieval with that of language model estimation, which has been studied extensively in other application areas such as speech recognition. The basic idea of these approaches is to estimate a language model for each document, and then rank documents by the likelihood of the query according to the estimated language model. A core problem in language model estimation is smoothing, which adjusts the maximum likelihood estimator so as to correct the inaccuracy due to data sparseness. In this paper, we study the problem of language model smoothing and its influence on retrieval performance. We examine the sensitivity of retrieval performance to the smoothing parameters and compare several popular smoothing methods on different test collections.", "authors": ["Chengxiang Zhai", "John Lafferty"], "related_topics": ["137293760", "3770464", "100853971"], "citation_count": "1854", "reference_count": "29", "references": ["1978394996", "2093390569", "2169213601", "2158195707", "1482214997", "2000672666", "2068905009", "2062270497", "2000569744", "2134237567"], "date": "2001"}, {"id": "1631260214", "title": "SRILM \u2013 An Extensible Language Modeling Toolkit", "abstract": "", "authors": ["Andreas Stolcke"], "related_topics": ["179603123", "19024347", "41008148"], "citation_count": "5423", "reference_count": "19", "references": ["2158195707", "2121227244", "1904457459", "2594610113", "1549285799", "2100506586", "1797288984", "2097978681", "1528470941", "2127836646"], "date": "2001"}, {"id": "2165758113", "title": "What Size Net Gives Valid Generalization", "abstract": "We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < e \u2264 1/8. We show that if m \u2265 O(W/e log N/e) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 - e/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 - e of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than \u03a9(W/e) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 - e fraction of the future test examples.", "authors": ["Eric B. Baum", "David Haussler"], "related_topics": ["149441793", "101561427", "177148314"], "citation_count": "2218", "reference_count": "32", "references": ["2147800946", "3017143921", "1530699444", "2019363670", "3036751298", "2176028050", "2154952480", "2129113961", "2010029425", "2020246210"], "date": "1987"}, {"id": "2097117768", "title": "Going deeper with convolutions", "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.", "authors": ["Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich"], "related_topics": ["81363708", "50644808", "75294576"], "citation_count": "31038", "reference_count": "21", "references": ["2618530766", "2102605133", "1849277567", "2963542991", "2310919327", "1904365287", "2963911037", "2168231600", "2068730032", "104184427"], "date": "2015"}, {"id": "1903029394", "title": "Fully convolutional networks for semantic segmentation", "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.", "authors": ["Jonathan Long", "Evan Shelhamer", "Trevor Darrell"], "related_topics": ["65885262", "89600930", "2776214188"], "citation_count": "23343", "reference_count": "42", "references": ["2618530766", "2962835968", "2097117768", "2102605133", "2155893237", "1663973292", "1849277567", "2963542991", "2109255472", "2155541015"], "date": "2015"}, {"id": "2167434254", "title": "Towards History-based Grammars: Using Richer Models for Probabilistic Parsing", "abstract": "We describe a generative probabilistic model of natural language, which we call HBG, that takes advantage of detailed linguistic information to resolve ambiguity. HBG incorporates lexical, syntactic, semantic, and structural information from the parse tree into the disambiguation process in a novel way. We use a corpus of bracketed sentences, called a Treebank, in combination with decision tree building to tease out the relevant aspects of a parse tree that will determine the correct parse of a sentence. This stands in contrast to the usual approach of further grammar tailoring via the usual linguistic introspection in the hope of generating the correct parse. In head-to-head tests against one of the best existing robust probabilistic parsing models, which we call P-CFG, the HBG model significantly outperforms P-CFG, increasing the parsing accuracy rate from 60% to 75%, a 37% reduction in error.", "authors": ["Ezra Black", "Fred Jelinek", "John Lafrerty", "David M. Magerman", "Robert Mercer", "Salim Roukos"], "related_topics": ["2781466058", "42560504", "186644900"], "citation_count": "227", "reference_count": "12", "references": ["2121227244", "2099247782", "1859173823", "2012837062", "1535681052", "2021758792", "2029825515", "2127009519", "1973021928", "2008506796"], "date": "1993"}, {"id": "2112076978", "title": "Experiments with a new boosting algorithm", "abstract": "In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem.", "authors": ["Yoav Freund", "Robert E. Schapire"], "related_topics": ["31912584", "46686674", "70153297"], "citation_count": "10889", "reference_count": "19", "references": ["3124955340", "2912934387", "2125055259", "1504694836", "1670263352", "1966280301", "2093717447", "2132166479", "2070534370", "2137291015"], "date": "1996"}, {"id": "2101210369", "title": "UNSUPERVISED WORD SENSE DISAMBIGUATION RIVALING SUPERVISED METHODS", "abstract": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints---that words tend to have one sense per discourse and one sense per collocation---exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%.", "authors": ["David Yarowsky"], "related_topics": ["44572571", "8038995", "76283291"], "citation_count": "2982", "reference_count": "23", "references": ["2049633694", "2102381086", "2099247782", "2040004971", "1971220772", "1977182536", "2129139611", "2428981601", "1554031433", "2156202195"], "date": "1995"}, {"id": "2000672666", "title": "Improving Retrieval Performance by Relevance Feedback", "abstract": "Relevance feedback is an automatic process, introduced over 20 years ago, designed to produce query formulations following an initial retrieval operation. The principal relevance feedback methods described over the years are examined briefly, and evaluation data are included to demonstrate the effectiveness of the various methods. Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback.", "authors": ["Gerard Salton", "Chris Buckley"], "related_topics": ["2779532271", "87546605", "161156560"], "citation_count": "2226", "reference_count": "17", "references": ["1978394996", "2043909051", "2019087979", "2164547069", "2026937586", "120261275", "2053039612", "2030350774", "2174678383", "1555286071"], "date": "1997"}, {"id": "2040004971", "title": "Word-sense disambiguation using statistical models of Roget's categories trained on large corpora", "abstract": "This paper describes a program that disambiguates English word senses in unrestricted text using statistical models of the major Roget's Thesaurus categories. Roget's categories serve as approximations of conceptual classes. The categories listed for a word in Roget's index tend to correspond to sense distinctions; thus selecting the most likely category provides a useful level of sense disambiguation. The selection of categories is accomplished by identifying and weighting words that are indicative of each category when seen in context, using a Bayesian theoretical framework.Other statistical approaches have required special corpora or hand-labeled training examples for much of the lexicon. Our use of class models overcomes this knowledge acquisition bottleneck, enabling training on unrestricted monolingual text without human intervention. Applied to the 10 million word Grolier's Encyclopedia, the system correctly disambiguated 92% of the instances of 12 polysemous words that have been previously studied in the literature.", "authors": ["David Yarowsky"], "related_topics": ["2778698081", "2778121359", "2780049985"], "citation_count": "1159", "reference_count": "23", "references": ["2102381086", "2121227244", "2099247782", "1570542661", "1971220772", "1977182536", "2129139611", "1548013757", "1550769831", "2137638032"], "date": "1992"}, {"id": "1944615693", "title": "Action recognition with trajectory-pooled deep-convolutional descriptors", "abstract": "Visual features are of vital importance for human action understanding in videos. This paper presents a new video representation, called trajectory-pooled deep-convolutional descriptor (TDD), which shares the merits of both hand-crafted features [31] and deep-learned features [24]. Specifically, we utilize deep architectures to learn discriminative convolutional feature maps, and conduct trajectory-constrained pooling to aggregate these convolutional features into effective descriptors. To enhance the robustness of TDDs, we design two normalization methods to transform convolutional feature maps, namely spatiotemporal normalization and channel normalization. The advantages of our features come from (i) TDDs are automatically learned and contain high discriminative capacity compared with those hand-crafted features; (ii) TDDs take account of the intrinsic characteristics of temporal dimension and introduce the strategies of trajectory-constrained sampling and pooling for aggregating deep-learned features. We conduct experiments on two challenging datasets: HMD-B51 and UCF101. Experimental results show that TDDs outperform previous hand-crafted features [31] and deep-learned features [24]. Our method also achieves superior performance to the state of the art on these datasets.", "authors": ["Limin Wang", "Yu Qiao", "Xiaoou Tang"], "related_topics": ["123832482", "195653225", "97931131"], "citation_count": "3123", "reference_count": "41", "references": ["2618530766", "2962835968", "2097117768", "2151103935", "2108598243", "2161969291", "2155893237", "1849277567", "2310919327", "1677409904"], "date": "2015"}, {"id": "2950893734\n", "title": "Self-Attention Generative Adversarial Networks", "abstract": "In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.", "authors": ["Han Zhang", "Ian Goodfellow", "Dimitris Metaxas", "Augustus Odena"], "related_topics": ["46686674", "36464697", "123832482"], "citation_count": "1558", "reference_count": "51", "references": ["2964121744", "2963403868", "2117539524", "2099471712", "2964308564", "2963073614", "2962793481", "2963684088", "2963373786", "2963470893"], "date": "2018"}, {"id": "1991113069", "title": "Fronts propagating with curvature-dependent speed: algorithms based on Hamilton-Jacobi formulations", "abstract": "Abstract We devise new numerical algorithms, called PSC algorithms, for following fronts propagating with curvature-dependent speed. The speed may be an arbitrary function of curvature, and the front also can be passively advected by an underlying flow. These algorithms approximate the equations of motion, which resemble Hamilton-Jacobi equations with parabolic right-hand sides, by using techniques from hyperbolic conservation laws. Non-oscillatory schemes of various orders of accuracy are used to solve the equations, providing methods that accurately capture the formation of sharp gradients and cusps in the moving fronts. The algorithms handle topological merging and breaking naturally, work in any number of space dimensions, and do not require that the moving surface be written as a function. The methods can be also used for more general Hamilton-Jacobi-type problems. We demonstrate our algorithms by computing the solution to a variety of surface motion problems.", "authors": ["Stanley Osher", "James A. Sethian"], "related_topics": ["14037181", "195065555", "2778860007"], "citation_count": "17912", "reference_count": "31", "references": ["1973481688", "2054662916", "3010292040", "1553761880", "1491650242", "1498500832", "2080477605", "2006134838", "2147963686", "1967575591"], "date": "1988"}, {"id": "2248026759", "title": "Framing image description as a ranking task: data, models and evaluation metrics", "abstract": "In [Hodosh et al., 2013], we establish a ranking-based framework for sentence-based image description and retrieval. We introduce a new dataset of images paired with multiple descriptive captions that was specifically designed for these tasks. We also present strong KCCA-based baseline systems for description and search, and perform an in-depth study of evaluation metrics for these two tasks. Our results indicate that automatic evaluation metrics for our ranking-based tasks are more accurate and robust than those proposed for generation-based image description.", "authors": ["Micah Hodosh", "Peter Young", "Julia Hockenmaier"], "related_topics": ["197927960", "67186912", "2777530160"], "citation_count": "932", "reference_count": "33", "references": ["2962835968", "2151103935", "2064675550", "2101105183", "1895577753", "2481240925", "2066941820", "2248026759", "2185175083", "2006969979"], "date": "2015"}, {"id": "2022242697", "title": "A weighted non-negative least squares algorithm for three-way \u2018PARAFAC\u2019 factor analysis", "abstract": "Abstract A time-efficient algorithm PMF3 is presented for solving the three-way PARAFAC (CANDECOMP) factor analytic model. In contrast to the usual alternating least squares, the PMF3 algorithm computes changes to all three modes simultaneously. This typically leads to convergence in 40\u2013100 iteration steps. The equations of the weighted multilinear least squares fit are given. The optional non-negativity is achieved by imposing a logarithmic penalty function. The algorithm contains a possibility for dynamical reweighting of the data during the iteration, allowing a robust analysis of outlier-containing data. The problems typical of PARAFAC models are discussed (but not solved): multiple local solutions, degenerate solutions, non-identifiable solutions. The question of how to verify the solution is discussed at length. The program PMF3 is available for 486-Pentium based PC computers.", "authors": ["Pentti Paatero"], "related_topics": ["2776730065", "45923927", "6180225"], "citation_count": "409", "reference_count": "13", "references": ["2059745395", "2075665712", "2056857971", "2341059552", "2012470056", "2057503509", "137381930", "2172253872", "1579320743", "2764595897"], "date": "1997"}, {"id": "2164019165", "title": "Improving Word Representations via Global Context and Multiple Word Prototypes", "abstract": "Unsupervised word representations are very useful in NLP tasks both as inputs to learning algorithms and as extra word features in NLP systems. However, most of these models are built with only local context and one representation per word. This is problematic because words are often polysemous and global context can also provide useful information for learning word meanings. We present a new neural network architecture which 1) learns word embeddings that better capture the semantics of words by incorporating both local and global document context, and 2) accounts for homonymy and polysemy by learning multiple embeddings per word. We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outperforms competitive baselines and other neural language models.", "authors": ["Eric Huang", "Richard Socher", "Christopher Manning", "Andrew Ng"], "related_topics": ["175293574", "61249035", "137293760"], "citation_count": "1370", "reference_count": "36", "references": ["1532325895", "2117130368", "2132339004", "2118020653", "2158139315", "1423339008", "71795751", "2081580037", "1970381522", "2131462252"], "date": "2012"}, {"id": "2049633694", "title": "Maximum likelihood from incomplete data via the EM algorithm", "abstract": "", "authors": ["Arthur P. Dempster", "Nan M. Laird", "Donald B. Rubin"], "related_topics": ["191462741", "182081679", "2780047678"], "citation_count": "66114", "reference_count": "74", "references": ["2100358124", "2327022120", "2074673068", "2403035479", "1982585616", "1575431606", "2086699924", "2144578442", "2000084758", "2121493622"], "date": "1977"}, {"id": "1888005072", "title": "LINE: Large-scale Information Network Embedding", "abstract": "This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,'' which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\footnote{\\url{https://github.com/tangjianpku/LINE}}.", "authors": ["Jian Tang", "Meng Qu", "Mingzhe Wang", "Ming Zhang", "Jun Yan", "Qiaozhu Mei"], "related_topics": ["75564084", "41608201", "46135064"], "citation_count": "3345", "reference_count": "23", "references": ["2153579005", "1614298861", "2187089797", "2131744502", "1532325895", "2053186076", "3104097132", "2001141328", "1854214752", "2156718197"], "date": "2015"}, {"id": "2109720450", "title": "The multiple multiplicative factor model for collaborative filtering", "abstract": "We describe a class of causal, discrete latent variable models called Multiple Multiplicative Factor models (MMFs). A data vector is represented in the latent space as a vector of factors that have discrete, non-negative expression levels. Each factor proposes a distribution over the data vector. The distinguishing feature of MMFs is that they combine the factors' proposed distributions multiplicatively, taking into account factor expression levels. The product formulation of MMFs allow factors to specialize to a subset of the items, while the causal generative semantics mean MMFs can readily accommodate missing data. This makes MMFs distinct from both directed models with mixture semantics and undirected product models. In this paper we present empirical results from the collaborative filtering domain showing that a binary/multinomial MMF model matches the performance of the best existing models while learning an interesting latent space description of the users.", "authors": ["Benjamin Marlin", "Richard S. Zemel"], "related_topics": ["21569690", "51167844", "70727504"], "citation_count": "97", "reference_count": "11", "references": ["2116064496", "2110325612", "3121531027", "1669104078", "2567948266", "2070786785", "2151052953", "2118079529", "1806731464", "2148124601"], "date": "2004"}, {"id": "1992419399", "title": "Data clustering: a review", "abstract": "Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.", "authors": ["A. K. Jain", "M. N. Murty", "P. J. Flynn"], "related_topics": ["73555534", "94641424", "22648726"], "citation_count": "18126", "reference_count": "191", "references": ["2912565176", "1639032689", "1497256448", "2581275558", "2152150600", "2049633694", "2133671888", "1971784203", "2095897464", "2138745909"], "date": "1999"}, {"id": "2173213060", "title": "MapReduce: simplified data processing on large clusters", "abstract": "MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.", "authors": ["Jeffrey Dean", "Sanjay Ghemawat"], "related_topics": ["76831024", "2780870223", "2778362760"], "citation_count": "30307", "reference_count": "19", "references": ["2173213060", "2119565742", "2148317584", "2073965851", "2109722477", "2104644701", "1510543252", "2044534358", "1988243929", "2045271686"], "date": "2007"}, {"id": "1511924373", "title": "Studying aesthetics in photographic images using a computational approach", "abstract": "Aesthetics, in the world of art and photography, refers to the principles of the nature and appreciation of beauty. Judging beauty and other aesthetic qualities of photographs is a highly subjective task. Hence, there is no unanimously agreed standard for measuring aesthetic value. In spite of the lack of firm rules, certain features in photographic images are believed, by many, to please humans more than certain others. In this paper, we treat the challenge of automatically inferring aesthetic quality of pictures using their visual content as a machine learning problem, with a peer-rated online photo sharing Website as data source. We extract certain visual features based on the intuition that they can discriminate between aesthetically pleasing and displeasing images. Automated classifiers are built using support vector machines and classification trees. Linear regression on polynomial terms of the features is also applied to infer numerical aesthetics ratings. The work attempts to explore the relationship between emotions which pictures arouse in people, and their low-level content. Potential applications include content-based image retrieval and digital photography.", "authors": ["Ritendra Datta", "Dhiraj Joshi", "Jia Li", "James Z. Wang"], "related_topics": ["119657128", "2780620123", "194387008"], "citation_count": "1226", "reference_count": "25", "references": ["2156909104", "2062024414", "1594031697", "2130660124", "740415", "2125148312", "2143668817", "2137471889", "2109868644", "2135705692"], "date": "2006"}, {"id": "1970689298", "title": "Continuous space language models", "abstract": "This paper describes the use of a neural network language model for large vocabulary continuous speech recognition. The underlying idea of this approach is to attack the data sparseness problem by performing the language model probability estimation in a continuous space. Highly efficient learning algorithms are described that enable the use of training corpora of several hundred million words. It is also shown that this approach can be incorporated into a large vocabulary continuous speech recognizer using a lattice rescoring framework at a very low additional processing time. The neural network language model was thoroughly evaluated in a state-of-the-art large vocabulary continuous speech recognizer for several international benchmark tasks, in particular the Nist evaluations on broadcast news and conversational speech recognition. The new approach is compared to four-gram back-off language models trained with modified Kneser-Ney smoothing which has often been reported to be the best known smoothing method. Usually the neural network language model is interpolated with the back-off language model. In that way, consistent word error rate reductions for all considered tasks and languages were achieved, ranging from 0.4% to almost 1% absolute.", "authors": ["Holger Schwenk"], "related_topics": ["39608478", "137293760", "2777601683"], "citation_count": "606", "reference_count": "63", "references": ["2148603752", "1554663460", "2912934387", "2132339004", "2147152072", "1631260214", "2096175520", "2110485445", "36903255", "2158195707"], "date": "2007"}, {"id": "1570448133", "title": "Data Mining: Practical Machine Learning Tools and Techniques", "abstract": "Data Mining: Practical Machine Learning Tools and Techniques offers a thorough grounding in machine learning concepts as well as practical advice on applying machine learning tools and techniques in real-world data mining situations. This highly anticipated third edition of the most acclaimed work on data mining and machine learning will teach you everything you need to know about preparing inputs, interpreting outputs, evaluating results, and the algorithmic methods at the heart of successful data mining. Thorough updates reflect the technical changes and modernizations that have taken place in the field since the last edition, including new material on Data Transformations, Ensemble Learning, Massive Data Sets, Multi-instance Learning, plus a new version of the popular Weka machine learning software developed by the authors. Witten, Frank, and Hall include both tried-and-true techniques of today as well as methods at the leading edge of contemporary research. *Provides a thorough grounding in machine learning concepts as well as practical advice on applying the tools and techniques to your data mining projects *Offers concrete tips and techniques for performance improvement that work by transforming the input or output in machine learning methods *Includes downloadable Weka software toolkit, a collection of machine learning algorithms for data mining tasks-in an updated, interactive interface. Algorithms in toolkit cover: data pre-processing, classification, regression, clustering, association rules, visualization", "authors": ["Ian H. Witten", "Eibe Frank", "Mark A. Hall"], "related_topics": ["77967617", "24138899", "32254414"], "citation_count": "37112", "reference_count": "202", "references": ["2156909104", "2140190241", "1995945562", "1639032689", "1554663460", "3013264884", "2119821739", "2139212933", "2912934387", "2138621811"], "date": "1999"}, {"id": "1516111018", "title": "An introduction to variational methods for graphical models", "abstract": "This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.", "authors": ["Michael I. Jordan", "Zoubin Ghahramani", "Tommi S. Jaakkola", "Lawrence K. Saul"], "related_topics": ["155846161", "2777590308", "13778685"], "citation_count": "3111", "reference_count": "59", "references": ["2099111195", "2159080219", "1573186872", "2049633694", "2171265988", "2982720039", "1746680969", "2567948266", "2397866408", "1993845689"], "date": "1999"}, {"id": "2964308564", "title": "Neural Machine Translation by Jointly Learning to Align and Translate", "abstract": "Abstract: Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.", "authors": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "related_topics": ["203005215", "50644808", "2776224158"], "citation_count": "17608", "reference_count": "25", "references": ["2157331557", "2064675550", "6908809", "2132339004", "1753482797", "2294059674", "1810943226", "2964199361", "1815076433", "2153653739"], "date": "2014"}, {"id": "1506285740", "title": "Fast Algorithms for Mining Association Rules in Large Databases", "abstract": "", "authors": ["Rakesh Agrawal", "Ramakrishnan Srikant"], "related_topics": ["193524817", "81440476", "160468390"], "citation_count": "17398", "reference_count": "17", "references": ["2166559705", "2159080219", "1594031697", "2100406636", "1601529450", "1499049447", "1556507321", "1487801850", "1787564306", "20184837"], "date": "1994"}, {"id": "2031489346", "title": "The Pascal Visual Object Classes (VOC) Challenge", "abstract": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection. This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.", "authors": ["Mark Everingham", "Luc Gool", "Christopher K. Williams", "John Winn", "Andrew Zisserman"], "related_topics": ["2776151529", "64876066", "94176051"], "citation_count": "11341", "reference_count": "57", "references": ["2151103935", "2161969291", "3097096317", "2162915993", "2038721957", "2131846894", "2110764733", "2104974755", "1576445103", "1565746575"], "date": "2010"}, {"id": "1971784203", "title": "Algorithms for clustering data", "abstract": "", "authors": ["Anil K. Jain", "Richard C. Dubes"], "related_topics": ["73555534", "94641424", "33704608"], "citation_count": "15559", "reference_count": "16", "references": ["2913066018", "1975152892", "2118587067", "1572134371", "1576534100", "1533790012", "2018388286", "2086943813", "1978616828", "2120636855"], "date": "1987"}, {"id": "2119741678", "title": "PARAFAC. Tutorial and applications", "abstract": "Abstract This paper explains the multi-way decomposition method PARAFAC and its use in chemometrics. PARAFAC is a generalization of PCA to higher order arrays, but some of the characteristics of the method are quite different from the ordinary two-way case. There is no rotation problem in PARAFAC, and e.g., pure spectra can be recovered from multi-way spectral data. One cannot as in PCA estimate components successively as this will give a model with poorer fit, than if the simultaneous solution is estimated. Finally scaling and centering is not as straightforward in the multi-way case as in the two-way case. An important advantage of using multi-way methods instead of unfolding methods is that the estimated models are very simple in a mathematical sense, and therefore more robust and easier to interpret. All these aspects plus more are explained in this tutorial and an implementation in Matlab code is available, that contains most of the features explained in the text. Three examples show how PARAFAC can be used for specific problems. The applications include subjects as: Analysis of variance by PARAFAC, a five-way application of PARAFAC, PARAFAC with half the elements missing, PARAFAC constrained to positive solutions and PARAFAC for regression as in principal component regression.", "authors": ["Rasmus Bro"], "related_topics": ["151304367", "74887250", "177148314"], "citation_count": "2813", "reference_count": "58", "references": ["2075665712", "2145147745", "2155639125", "2089317757", "2000215628", "1974403130", "3012395598", "2033693394", "2057503509", "137381930"], "date": "1997"}, {"id": "2481240925", "title": "Deep Visual-Semantic Alignments for Generating Image Descriptions", "abstract": "We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks (RNN) over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions outperform retrieval baselines on both full images and on a new dataset of region-level annotations. Finally, we conduct large-scale analysis of our RNN language model on the Visual Genome dataset of 4.1 million captions and highlight the differences between image and region-level caption statistics.", "authors": ["Andrej Karpathy", "Li Fei-Fei"], "related_topics": ["137293760", "81363708", "147168706"], "citation_count": "4269", "reference_count": "65", "references": ["2618530766", "2962835968", "2097117768", "2102605133", "2117539524", "2153579005", "2250539671", "2108598243", "2310919327", "2031489346"], "date": "2017"}, {"id": "2748207967", "title": "Method implemented by portable data processing (pdp) device", "abstract": "PROBLEM TO BE SOLVED: To provide a method implemented by a portable data processing (PDP) device for reducing power consumption and blocking unnecessary data input.SOLUTION: A method comprises: receiving proximity data, indicative of location of a user relative to a PDP device, from a proximity sensor of the PDP device; receiving input data from an input device of the PDP device; controlling a power setting of a display of the PDP device; and determining whether to change both a state of processing of the input data regarding receipt of user inputs and the power setting of the display in response to a change in the proximity data.", "authors": ["\u30d5\u30c3\u30d4\u30fc\uff0c\u30d6\u30e9\u30a4\u30a2\u30f3", "Huppi Brian", "\u30d5\u30a1\u30c7\u30eb\uff0c\u30a2\u30f3\u30bd\u30cb\u30fc\u30fb\u30a8\u30e0", "M Fadell Anthony", "\u30d0\u30ec\u30f3\u30bf\u30a4\u30f3\uff0c\u30c7\u30ec\u30af", "Barrentine Derek", "\u30d5\u30ea\u30fc\u30de\u30f3\uff0c\u30c0\u30cb\u30a8\u30eb", "Freeman Daniel"], "related_topics": ["121449826", "135403697", "138827492"], "citation_count": "1305", "reference_count": "19", "references": ["2854904947", "2872185899", "2759162363", "2744606555", "3141088976", "2745934694", "3150482329", "3146866156", "2751003026", "3145335152"], "date": "2015"}, {"id": "2159686933", "title": "Example-based learning for view-based human face detection", "abstract": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system.", "authors": ["K.-K. Sung", "T. Poggio"], "related_topics": ["83665646", "4641261", "2776151529"], "citation_count": "2887", "reference_count": "17", "references": ["2138451337", "3017143921", "2098947662", "2113341759", "2135463994", "2125848778", "2104671481", "1554705102", "1532977286", "1571461735"], "date": "1997"}, {"id": "2155639125", "title": "Multiway calibration. Multilinear PLS", "abstract": "A new multiway regression method called N-way partial least squares (N-PLS) is presented. The emphasis is on the three-way PLS version (tri-PLS), but it is shown how to extend the algorithm to higher orders. The developed algorithm is superior to unfolding methods, primarily owing to a stabilization of the decomposition. This stabilization potentially gives increased interpretability and better predictions. The algorithm is fast compared with e.g. PARAFAC, because it consists of solving eigenvalue problems. An example of the developed algorithm taken from the sugar industry is shown and compared with unfold-PLS. Fluorescence excitation\u2014emission matrices (EEMs) are measured on white sugar solutions and used to predict the ash content of the sugar. The predictions are comparable by the two methods, but there is a clear difference in the interpretability of the two solutions. Also shown is a simulated example of EEMs with very noisy measurements and a low relative signal from the analyte of interest. The predictions from unfold-PLS are almost twice as bad as from tri-PLS despite the large number of samples (125) used in the calibration. The algorithms are available from World Wide Web: hhtp:\\\\newton.foodsci.kvl.dk\\foodtech.", "authors": ["Rasmus Bro"], "related_topics": ["22354355", "2994048982", "2781067378"], "citation_count": "824", "reference_count": "0", "references": ["2000651380", "2119412403", "2119741678", "1539811621", "2042901969", "2479654458", "3105824255", "2140862024", "2008114373", "1582645007"], "date": "1995"}, {"id": "2147859400", "title": "User modeling via stereotypes", "abstract": "This paper addresses the problems that must be considered if computers are going to treat their users as individuals with distinct personalities, goals, and so forth. It first outlines the issues, and then proposes stereotypes as a useful mechanism for building models of individual users on the basis of a small amount of information about them. In order to build user models quickly, a large amount of uncertain knowledge must be incorporated into the models. The issue of how to resolve the conflicts that will arise among such inferences is discussed. A system, Grundy, is described that builds models of its users, with the aid of stereotypes, and then exploits those models to guide it in its task, suggesting novels that people may find interesting. If stereotypes are to be useful to Grundy, they must accurately characterize the users of the system. Some techniques to modify stereotypes on the basis of experience are discussed. An analysis of Grundy's performance shows that its user models are effective in guiding its performance.", "authors": ["Elaine Rich"], "related_topics": ["67712803", "107457646", "165696696"], "citation_count": "1362", "reference_count": "12", "references": ["2164558494", "2121773050", "2037417965", "1480687347", "2324258411", "2109206786", "1496962241", "1602312040", "2059915827", "1966506925"], "date": "1998"}, {"id": "2546302380", "title": "What is the best multi-stage architecture for object recognition?", "abstract": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\u226b 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%).", "authors": ["Kevin Jarrett", "Koray Kavukcuoglu", "Marc'Aurelio Ranzato", "Yann LeCun"], "related_topics": ["52622490", "40608802", "8038995"], "citation_count": "2435", "reference_count": "54", "references": ["2151103935", "2161969291", "2310919327", "2100495367", "2162915993", "2110798204", "2130325614", "2097018403", "2166049352", "2134557905"], "date": "2009"}, {"id": "2042281163", "title": "Item-based collaborative filtering recommendation algorithms", "abstract": "Recommender systems apply knowledge discovery techniques to the problem of making personalized recommendations for information, products or services during a live interaction. These systems, especially the k-nearest neighbor collaborative ltering based ones, are achieving widespread success on the Web. The tremendous growth in the amount of available information and the number of visitors to Web sites in recent years poses some key challenges for recommender systems. These are: producing high quality recommendations, performing many recommendations per second for millions of users and items and achieving high coverage in the face of data sparsity. In traditional collaborative ltering systems the amount of work increases with the number of participants in the system. New recommender system technologies are needed that can quickly produce high quality recommendations, even for very large-scale problems. To address these issues we have explored item-based collaborative ltering techniques. Item-based techniques rst analyze the user-item matrix to identify relationships between di erent items, and then use these relationships to indirectly compute recommendations for users. In this paper we analyze di erent item-based recommendation generation algorithms. We look into di erent techniques for computing item-item similarities (e.g., item-item correlation vs. cosine similarities between item vectors) and di erent techniques for obtaining recommendations from them (e.g., weighted sum vs. regression model). Finally, we experimentally evaluate our results and compare them to the basic k-nearest neighbor approach. Our experiments suggest that item-based algorithms provide dramatically better performance than user-based algorithms, while at the same time providing better quality than the best available userbased algorithms.", "authors": ["Badrul Sarwar", "George Karypis", "Joseph Konstan", "John Riedl"], "related_topics": ["21569690", "557471498", "2780213525"], "citation_count": "10204", "reference_count": "28", "references": ["2110325612", "2147152072", "3121531027", "2085937320", "2124591829", "1966553486", "1999047234", "2341865734", "1832221731", "1996283866"], "date": "2001"}, {"id": "2266946488", "title": "Linear and nonlinear programming", "abstract": "This new edition covers the central concepts of practical optimization techniques, with an emphasis on methods that are both state-of-the-art and popular. One major insight is the connection between the purely analytical character of an optimization problem and the behavior of algorithms used to solve a problem. This was a major theme of the first edition of this book and the fourth edition expands and further illustrates this relationship. As in the earlier editions, the material in this fourth edition is organized into three separate parts. Part I is a self-contained introduction to linear programming. The presentation in this part is fairly conventional, covering the main elements of the underlying theory of linear programming, many of the most effective numerical algorithms, and many of its important special applications. Part II, which is independent of Part I, covers the theory of unconstrained optimization, including both derivations of the appropriate optimality conditions and an introduction to basic algorithms. This part of the book explores the general properties of algorithms and defines various notions of convergence. Part III extends the concepts developed in the second part to constrained optimization problems. Except for a few isolated sections, this part is also independent of Part I. It is possible to go directly into Parts II and III omitting Part I, and, in fact, the book has been used in this way in many universities.New to this edition is a chapter devoted to Conic Linear Programming, a powerful generalization of Linear Programming. Indeed, many conic structures are possible and useful in a variety of applications. It must be recognized, however, that conic linear programming is an advanced topic, requiring special study. Another important topic is an accelerated steepest descent method that exhibits superior convergence properties, and for this reason, has become quite popular. The proof of the convergence property for both standard and accelerated steepest descent methods are presented in Chapter 8. As in previous editions, end-of-chapter exercises appear for all chapters.From the reviews of the Third Edition: this very well-written book is a classic textbook in Optimization. It should be present in the bookcase of each student, researcher, and specialist from the host of disciplines from which practical optimization applications are drawn. (Jean-Jacques Strodiot, Zentralblatt MATH, Vol. 1207, 2011)", "authors": ["David G. Luenberger", "Yinyu Ye"], "related_topics": ["115527620", "41045048", "137836250"], "citation_count": "8333", "reference_count": "0", "references": ["2049981393", "2087347434", "2167485994", "2162409952", "3144673228", "2159687282", "2141870784", "2099968818", "1883186006", "2003949305"], "date": "1983"}, {"id": "3121531027", "title": "GroupLens: An Open Architecture for Collaborative Filtering of Netnews", "abstract": "Collaborative filers help people make choices based on the opinions of other people. GroupLens is a system for collaborative filtering of netnews, to help people find articles they will like in the huge stream of available articles. News reader clients display predicted scores and make it easy for users to rate articles after they read them. Rating servers, called Better Bit Bureaus, gather and disseminate the ratings. The rating servers predict scores based on the heuristic that people who agreed in the past will probably agree again. Users can protect their privacy by entering ratings under a pseudonym, without reducing the effectiveness of the score prediction. The entire architecture is open: alternative software for news clients and Better Bit Bureaus can be developed independently and can interoperate with the components we have developed.", "authors": ["Paul Resnick", "Neophytos Iacovou", "Mitesh Suchak", "Peter Bergstrom", "John Riedl"], "related_topics": ["93996380", "21569690", "180505990"], "citation_count": "7783", "reference_count": "0", "references": ["3121531027", "1557657228", "2051650632", "2166528748", "2749904967", "2611873958", "4548461", "2783472765", "2408262139", "2749253217"], "date": "1994"}, {"id": "2000651380", "title": "Data-driven Soft Sensors in the process industry", "abstract": "In the last two decades Soft Sensors established themselves as a valuable alternative to the traditional means for the acquisition of critical process variables, process monitoring and other tasks which are related to process control. This paper discusses characteristics of the process industry data which are critical for the development of data-driven Soft Sensors. These characteristics are common to a large number of process industry fields, like the chemical industry, bioprocess industry, steel industry, etc. The focus of this work is put on the data-driven Soft Sensors because of their growing popularity, already demonstrated usefulness and huge, though yet not completely realised, potential. A comprehensive selection of case studies covering the three most important Soft Sensor application fields, a general introduction to the most popular Soft Sensor modelling techniques as well as a discussion of some open issues in the Soft Sensor development and maintenance and their possible solutions are the main contributions of this work.", "authors": ["Petr Kadlec", "Bogdan Gabrys", "Sibylle Strandt"], "related_topics": ["115575686", "4279774", "155386361"], "citation_count": "1379", "reference_count": "160", "references": ["2912565176", "2148603752", "1554944419", "1554663460", "3124955340", "2912934387", "2119479037", "1679913846", "2148694408", "2156267802"], "date": "2009"}, {"id": "2051650632", "title": "Follow the reader: filtering comments on slashdot", "abstract": "Large-scale online communities need to manage the tension between critical mass and information overload. Slashdot is a news and discussion site that has used comment rating to allow massive participation while providing a mechanism for users to filter content. By default, comments with low ratings are hidden. Of users who changed the defaults, more than three times as many chose to use ratings for filtering or sorting as chose to suppress the use of comment ratings. Nearly half of registered users, however, never strayed from the default filtering settings, suggesting that the costs of exploring and selecting custom filter settings exceeds the expected benefit for many users. We recommend leveraging the efforts of the users that actively choose filter settings to reduce the cost of changing settings for all other users. One strategy is to create static schemas that capture the filtering preferences of different groups of readers. Another strategy is to dynamically set filtering thresholds for each conversation thread, based in part on the choices of previous readers. For predicting later readers' choices, the choices of previous readers are far more useful than content features such as the number of comments or the ratings of those comments.", "authors": ["Cliff A.C. Lampe", "Erik Johnston", "Paul Resnick"], "related_topics": ["186625053", "183003079", "2780656832"], "citation_count": "152", "reference_count": "24", "references": ["3121531027", "1966553486", "2152284345", "2111122424", "1569545823", "2091579301", "2098874414", "2053522862", "2024888488", "2110636172"], "date": "2007"}, {"id": "2154455818", "title": "Learning with Local and Global Consistency", "abstract": "We consider the general problem of learning from labeled and unlabeled data, which is often called semi-supervised learning or transductive inference. A principled approach to semi-supervised learning is to design a classifying function which is sufficiently smooth with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. We present a simple algorithm to obtain such a smooth solution. Our method yields encouraging experimental results on a number of classification problems and demonstrates effective use of unlabeled data.", "authors": ["Dengyong Zhou", "Olivier Bousquet", "Thomas N. Lal", "Jason Weston", "Bernhard Sch\u00f6lkopf"], "related_topics": ["58973888", "8038995", "119857082"], "citation_count": "4414", "reference_count": "19", "references": ["2148603752", "2053186076", "2001141328", "2165874743", "1578099820", "2139823104", "1708874574", "2159737176", "1966949944", "2122837498"], "date": "2003"}, {"id": "2102605133", "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.", "authors": ["Ross Girshick", "Jeff Donahue", "Trevor Darrell", "Jitendra Malik"], "related_topics": ["2776151529", "7374053", "81363708"], "citation_count": "19676", "reference_count": "46", "references": ["2618530766", "2151103935", "2108598243", "2161969291", "2168356304", "3118608800", "2310919327", "2031489346", "2088049833", "2155541015"], "date": "2014"}, {"id": "120261275", "title": "Extending the boolean and vector space models of information retrieval with p-norm queries and multiple concept types", "abstract": "Information retrieval systems accept user queries and respond by identifying documents presumed to be relevant to those queries. Boolean logic is commonly employed as the query language, but an alternate scheme based on the vector space model has been investigated. Automatic indexing methods allow questions and documents to be represented by weighted vectors, and searching yields a ranked list of documents in decreasing order of query-document similarity. Both the Boolean logic and vector space approaches are special cases of the very general p-norm model developed by Wu. In this thesis, analytical results help explain the ranking behavior of p-norm queries. Four experimental test collections are employed to prove that interpreting Boolean queries with p-norm techniques leads to substantial improvements in retrieval effectiveness. Several procedures are described to automatically construct Boolean queries from short lists of words. An algorithm based on probability theory which utilizes relevance feedback information to produce even more effective Boolean or p-norm queries is also specified and validated by experimental tests; one of the essential innovations is to control query construction by allowing the searcher to specify the desired number of retrieved documents. The vector space model is extended to allow separate handling of other types of concepts beyond those derived from textual words or assigned descriptors. Citation, cocitation, and bibliographic coupling data as well as factual information normally handled by database management systems are easily incorporated. Clustered search and feedback processes are improved by utilizing combinations of these concept types, as shown by preliminary experimental studies with collections in computer and information science. P-norm queries and multiple concept types are both handled by an updated SMART system implemented using relational database and statistical processing packages. This integrated system should facilitate further research as well as be adaptable to retrieval applications for office and bibliographic information.", "authors": ["Edward Alan Fox"], "related_topics": ["68481662", "89686163", "192028432"], "citation_count": "202", "reference_count": "0", "references": ["2000672666", "1934947680", "2087739686", "2002306339", "2105106523", "2078396654", "2004276548", "2134895902", "2140354722", "1552863221"], "date": "1982"}, {"id": "2055846397", "title": "Retrieval of misspelled names in an airlines passenger record system", "abstract": "", "authors": ["Leon Davidson"], "related_topics": ["41008148", "23123220", "44154836"], "citation_count": "104", "reference_count": "0", "references": ["2010595692", "2008819433", "2111192396", "2010392031", "2117084652", "2075880254", "2058929792", "2124936621", "1494632860", "1233737202"], "date": "1962"}, {"id": "1982585616", "title": "Maximum Likelihood Approaches to Variance Component Estimation and to Related Problems", "abstract": "Abstract Recent developments promise to increase greatly the popularity of maximum likelihood (ml) as a technique for estimating variance components. Patterson and Thompson (1971) proposed a restricted maximum likelihood (reml) approach which takes into account the loss in degrees of freedom resulting from estimating fixed effects. Miller (1973) developed a satisfactory asymptotic theory for ml estimators of variance components. There are many iterative algorithms that can be considered for computing the ml or reml estimates. The computations on each iteration of these algorithms are those associated with computing estimates of fixed and random effects for given values of the variance components.", "authors": ["David A. Harville"], "related_topics": ["61420037", "183931610", "167928553"], "citation_count": "3274", "reference_count": "69", "references": ["2986444355", "2403035479", "2798510847", "2000084758", "1982126198", "128740895", "2013866489", "21072975", "2072857774", "2334647599"], "date": "1977"}, {"id": "2053039612", "title": "Applications of the Connection Machine", "abstract": "The Connection Machine development effort was initiated in the belief that parallel processing and artificial intelligence could together accelerate the rate of progress toward truly intelligent machines. This progress is the result of the ease with which the machine can be programmed and the dramatic increase in compute power that the machine can bring to bear. The authors have been able to run many trials of experiments in instances where previously, running just one would have been considered an achievement and no further experimentation would have been done. This has enabled exploring a great many more hypotheses and to work on much larger problems that had been possible on previous-generation artificial intelligence workstations. The ease of programming is in part the result of a decision to use existing serial machines (the Symbolics 3600 or Digital Equipment Corporation VAX), thus leaving unchanged the operating systems, editors, file systems, debuggers, network communications systems, and so on, so as to provide familiar programming environments. The Connection Machine is programmed in conservative extensions of Common Lisp and C. Users familiar with these languages and with front-end computer systems have been able to produce results on the Connection Machine on the first day that theymore \u00bb use it.\u00ab less", "authors": ["Waltz"], "related_topics": ["190883126", "2779353305", "67953723"], "citation_count": "191", "reference_count": "10", "references": ["2178806388", "2004131797", "1505652865", "2083605078", "1967810725", "2019087979", "2035032881", "2081721258", "2136066653", "2165377302"], "date": "1986"}, {"id": "2102381086", "title": "Introduction to WordNet: An On-line Lexical Database", "abstract": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list. Unfortunately, there is no obvious alternative, no other simple way for lexicographers to keep track of what has been done or for readers to find the word they are looking for. But a frequent objection to this solution is that finding things on an alphabetical list can be tedious and time-consuming. Many people who would like to refer to a dictionary decide not to bother with it because finding the information would interrupt their work and break their train of thought.", "authors": ["George A. Miller", "Richard Beckwith", "Christiane Fellbaum", "Derek Gross", "Katherine J. Miller"], "related_topics": ["2780403423", "157659113", "32206222"], "citation_count": "6807", "reference_count": "81", "references": ["1933657216", "2103318667", "2090626368", "1483126227", "2017668967", "2123987305", "2040300040", "2013596317", "2052262800", "2059799772"], "date": "1990"}, {"id": "2159094788", "title": "Amazon.com recommendations: item-to-item collaborative filtering", "abstract": "Recommendation algorithms are best known for their use on e-commerce Web sites, where they use input about a customer's interests to generate a list of recommended items. Many applications use only the items that customers purchase and explicitly rate to represent their interests, but they can also use other attributes, including items viewed, demographic data, subject interests, and favorite artists. At Amazon.com, we use recommendation algorithms to personalize the online store for each customer. The store radically changes based on customer interests, showing programming titles to a software engineer and baby toys to a new mother. There are three common approaches to solving the recommendation problem: traditional collaborative filtering, cluster models, and search-based methods. Here, we compare these methods with our algorithm, which we call item-to-item collaborative filtering. Unlike traditional collaborative filtering, our algorithm's online computation scales independently of the number of customers and number of items in the product catalog. Our algorithm produces recommendations in real-time, scales to massive data sets, and generates high quality recommendations.", "authors": ["G. Linden", "B. Smith", "J. York"], "related_topics": ["2780213525", "21569690", "557471498"], "citation_count": "7431", "reference_count": "11", "references": ["2042281163", "2110325612", "3121531027", "2043403353", "1996283866", "2117354486", "1570159982", "1955441067", "147860157", "1629473008"], "date": "2002"}, {"id": "2963073614", "title": "Image-to-Image Translation with Conditional Adversarial Networks", "abstract": "We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without handengineering our loss functions either.", "authors": ["Phillip Isola", "Jun-Yan Zhu", "Tinghui Zhou", "Alexei A. Efros"], "related_topics": ["2779757391", "115961682", "119857082"], "citation_count": "9243", "reference_count": "52", "references": ["2964121744", "1836465849", "1901129140", "2117539524", "1903029394", "2099471712", "2133665775", "2963684088", "2100495367", "2340897893"], "date": "2017"}, {"id": "2150341604", "title": "Deep Learning: Methods and Applications", "abstract": "This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.", "authors": ["Li Deng", "Dong Yu"], "related_topics": ["8038995", "28006648", "108583219"], "citation_count": "3282", "reference_count": "430", "references": ["2618530766", "2102605133", "2153579005", "1614298861", "2136922672", "1849277567", "2310919327", "2100495367", "1904365287", "2064675550"], "date": "2014"}, {"id": "2147555786", "title": "Integrated proximity sensor and light sensor", "abstract": "Apparatuses and methods to sense proximity and to detect light. In one embodiment, an apparatus includes an emitter of electromagnetic radiation and a detector of electromagnetic radiation; the detector has a sensor to detect electromagnetic radiation from the emitter when sensing proximity, and to detect electromagnetic radiation from a source other than the emitter when sensing visible light. The emitter may be disabled at least temporarily to allow the detector to detect electromagnetic radiation from a source other than the emitter, such as ambient light. In one implementation, the ambient light is measured by measuring infrared wavelengths. Also, a fence having a non-IR transmissive material disposed between the emitter and the detector to remove electromagnetic radiation emitted by the emitter. Other apparatuses and methods and data processing systems and machine readable media are also described.", "authors": ["Anthony M. Fadell", "Achim Pantfoerder"], "related_topics": ["135403697", "46918542", "23125352"], "citation_count": "622", "reference_count": "125", "references": ["1930456798", "1584397650", "1893940590", "1901544345", "2164252468", "2748207967", "1948825421", "1893741530", "1849545308", "2169287257"], "date": "2007"}, {"id": "3124955340", "title": "A Decision Theoretic Generalization of On-Line Learning and an Application to Boosting", "abstract": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line.", "authors": ["Y. Freund", "R. Schapire"], "related_topics": ["46686674", "177148314", "34388435"], "citation_count": "27437", "reference_count": "0", "references": ["2122005484", "2132511032", "2109826612", "2114839088", "2115781554", "2120520366", "2132827378", "1984194948", "2070277296", "2031910487"], "date": "2010"}, {"id": "1746819321", "title": "Gaussian Processes for Machine Learning", "abstract": "A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach to learning in kernel machines. Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.", "authors": ["Carl Edward Rasmussen", "Christopher K I Williams"], "related_topics": ["77967617", "58973888", "24138899"], "citation_count": "23786", "reference_count": "180", "references": ["2296319761", "2156909104", "2148603752", "2170120409", "1554663460", "2117812871", "3140968660", "3023786531", "2798909945", "2078206416"], "date": "2005"}, {"id": "2155541015", "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition", "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.", "authors": ["Jeff Donahue", "Yangqing Jia", "Oriol Vinyals", "Judy Hoffman", "Ning Zhang", "Eric Tzeng", "Trevor Darrell"], "related_topics": ["40608802", "64876066", "119857082"], "citation_count": "4386", "reference_count": "46", "references": ["2618530766", "2108598243", "2161969291", "2168356304", "2310919327", "2100495367", "1904365287", "2187089797", "1677409904", "2546302380"], "date": "2014"}, {"id": "2127314673", "title": "DISTRIBUTIONAL CLUSTERING OF ENGLISH WORDS", "abstract": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data.", "authors": ["Fernando Pereira", "Naftali Tishby", "Lillian Lee"], "related_topics": ["22648726", "23822008", "94641424"], "citation_count": "1464", "reference_count": "11", "references": ["2099111195", "2049633694", "3017143921", "2121227244", "2099247782", "2123084125", "2025887562", "2059800182", "2016001305", "1982944197"], "date": "1993"}, {"id": "2037417965", "title": "Traits as prototypes: Effects on recognition memory.", "abstract": "", "authors": ["Nancy Cantor", "Walter Mischel"], "related_topics": ["169900460", "127816348", "2865642"], "citation_count": "841", "reference_count": "25", "references": ["158727920", "1989314580", "2121773050", "2135255848", "1555806226", "1996443718", "1969486542", "2141545068", "2157646826", "2018507693"], "date": "1976"}, {"id": "2135705692", "title": "Blobworld: image segmentation using expectation-maximization and its application to image querying", "abstract": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. We present a new image representation that provides a transformation from the raw pixel data to a small set of image regions that are coherent in color and texture. This \"Blobworld\" representation is created by clustering pixels in a joint color-texture-position feature space. The segmentation algorithm is fully automatic and has been run on a collection of 10,000 natural images. We describe a system that uses the Blobworld representation to retrieve images from this collection. An important aspect of the system is that the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, query results from these systems can be inexplicable, despite the availability of knobs for adjusting the similarity metrics. By finding image regions that roughly correspond to objects, we allow querying at the level of objects rather than global image properties. We present results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects.", "authors": ["C. Carson", "S. Belongie", "H. Greenspan", "J. Malik"], "related_topics": ["63099799", "124504099", "126422989"], "citation_count": "2016", "reference_count": "49", "references": ["2049633694", "2914885528", "2160066518", "2103414828", "2168175751", "1991605728", "2008297189", "1917380066", "2162630772", "2049694710"], "date": "2002"}, {"id": "2125148312", "title": "Texture features for browsing and retrieval of image data", "abstract": "Image content based retrieval is emerging as an important research area with application to digital libraries and multimedia databases. The focus of this paper is on the image processing aspects and in particular using texture information for browsing and retrieval of large image data. We propose the use of Gabor wavelet features for texture analysis and provide a comprehensive experimental evaluation. Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy. An application to browsing large air photos is illustrated.", "authors": ["B.S. Manjunath", "W.Y. Ma"], "related_topics": ["63099799", "2780052074", "189391414"], "citation_count": "5360", "reference_count": "20", "references": ["1996021349", "2102796633", "2095757522", "2093191240", "2008297189", "2138313032", "2168977926", "2103384342", "2171181782", "2021751319"], "date": "1996"}, {"id": "2114535528", "title": "An Evaluation of Statistical Approaches to Text Categorization", "abstract": "This paper focuses on a comparative evaluation of a wide-range of text categorization methods, including previously published results on the Reuters corpus and new results of additional experiments. A controlled study using three classifiers, kNN, LLSF and WORD, was conducted to examine the impact of configuration variations in five versions of Reuters on the observed performance of classifiers. Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable confusions in the literature. Using the results evaluated on the other versions of Reuters which exclude the unlabelled documents, the performance of twelve methods are compared directly or indirectly. For indirect compararions, kNN, LLSF and WORD were used as baselines, since they were evaluated on all versions of Reuters that exclude the unlabelled documents. As a global observation, kNN, LLSF and a neural network method had the best performances except for a Naive Bayes approach, the other learning algorithms also performed relatively well.", "authors": ["Yiming Yang"], "related_topics": ["52001869", "2779500292", "204321447"], "citation_count": "3130", "reference_count": "21", "references": ["2149706766", "2435251607", "1956559956", "1833785989", "1969572066", "2060216474", "2063198646", "1983078185", "1986913017", "2071664212"], "date": "1999"}, {"id": "2145962650", "title": "Robust principal component analysis", "abstract": "This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individuallyq We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the e1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.", "authors": ["Emmanuel J. Cand\u00e8s", "Xiaodong Li", "Yi Ma", "John Wright"], "related_topics": ["2777749129", "24252448", "124066611"], "citation_count": "7478", "reference_count": "54", "references": ["2145096794", "2100556411", "2001141328", "2124608575", "2078204800", "2102625004", "2103972604", "2097308346", "2147152072", "2148694408"], "date": "2011"}, {"id": "2123442489", "title": "The Stanford CoreNLP Natural Language Processing Toolkit", "abstract": "We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.", "authors": ["Christopher Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven Bethard", "David McClosky"], "related_topics": ["43521106", "41008148", "204321447"], "citation_count": "6528", "reference_count": "14", "references": ["2251939518", "1521626219", "2096765155", "1508977358", "1996430422", "2096797897", "2147218300", "2250789336", "2251758222", "2167072947"], "date": "2014"}, {"id": "2085937320", "title": "An algorithmic framework for performing collaborative filtering", "abstract": "", "authors": ["Jonathan L. Herlocker", "Joseph A. Konstan", "Al Borchers", "John Riedl"], "related_topics": ["2780213525", "21569690", "2776156558"], "citation_count": "4091", "reference_count": "22", "references": ["2110325612", "2147152072", "3121531027", "3004157836", "2124591829", "1966553486", "1999047234", "2043403353", "1978394996", "175500210"], "date": "1999"}, {"id": "2121773050", "title": "A framework for representing knowledge", "abstract": "Abstract : A partial theory is presented of thinking, combining a number of classical and modern concepts from psychology, linguistics, and AI. In a new situation one selects from memory a structure called a frame: a remembered framework to be adapted to fit reality by changing details as necessary, and a data-structure for representing a stereotyped situation. Attached to each frame are several kinds of information -- how to use the frame, what one can expect to happen next, and what to do if these expectations are not confirmed. The report discusses collections of related frames that are linked together into frame-systems.", "authors": ["Marvin Minsky"], "related_topics": ["120114321", "195324797", "87868495"], "citation_count": "9850", "reference_count": "21", "references": ["2065343501", "1488252886", "2134199742", "2108729336", "2042119491", "2098181550", "2142565826", "1559427309", "2145714134", "1819699930"], "date": "1974"}, {"id": "1806731464", "title": "Learning What People (Don't) Want", "abstract": "Recommender systems make use of a database of user ratings to generate personalized recommendations and help people to find relevant products, items, or documents. In this paper, we present a probabilistic, model-based framework for user ratings based on a novel collaborative filtering technique that performs an automatic decomposition of user preferences. Our approach has several benefits, including highly accurate predictions, task-optimized model learning, mining of interest groups and patterns, as well as a highly efficient and scalable computation of predictions and recommendation lists.", "authors": ["Thomas Hofmann"], "related_topics": ["557471498", "21569690", "88330836"], "citation_count": "67", "reference_count": "13", "references": ["2110325612", "3121531027", "2107743791", "2085937320", "2124591829", "1966553486", "1999047234", "1612003148", "1629473008", "2109992782"], "date": "2001"}, {"id": "2164598857", "title": "Rapid object detection using a boosted cascade of simple features", "abstract": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.", "authors": ["P. Viola", "M. Jones"], "related_topics": ["2776151529", "71681937", "182521987"], "citation_count": "23874", "reference_count": "18", "references": ["3124955340", "2128272608", "2217896605", "2115763357", "1975846642", "2124351082", "2159686933", "2155511848", "2101522199", "3146003712"], "date": "2001"}, {"id": "1509703770", "title": "Parallel Models of Associative Memory", "abstract": "Contents: G.E. Hinton, J.A. Anderson, Introduction to the Updated Edition. D.E. Rumelhart, D.A. Norman, Introduction. J.A. Anderson, G.E. Hinton, Models of Information Processing in the Brain. J.A. Feldman, A Connectionist Model of Visual Memory. D. Willshaw, Holography, Associative Memory, and Inductive Generalization. T. Kohonen, E. Oja, P. Lehtio, Storage and Processing of Information in Distributed Associative Memory Systems. S.E. Fahlman, Representing Implicit Knowledge. G.E. Hinton, Implementing Semantic Networks in Parallel Hardware. T.J. Sejnowski, Skeleton Filters in the Brain. J.A. Anderson, M.C. Mozer, Categorization and Selective Neurons. S. Geman, Notes on a Self-Organizing Machine. R. Ratcliff, Parallel-Processing Mechanisms and Processing of Organized Information in Human Memory.", "authors": ["Geoffrey E. Hinton", "James A. Anderson"], "related_topics": ["53442348", "178278151", "8521452"], "citation_count": "1263", "reference_count": "0", "references": ["2072128103", "2138451337", "1507849272", "3036751298", "2047057213", "2176028050", "2004417889", "2070862086", "2062104878", "2161070585"], "date": "1988"}, {"id": "2166049352", "title": "Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories", "abstract": "Current computational approaches to learning visual object categories require thousands of training images, are slow, cannot learn in an incremental manner and cannot incorporate prior information into the learning process. In addition, no algorithm presented in the literature has been tested on more than a handful of object categories. We present an method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We test it on a dataset composed of images of objects belonging to 101 widely varied categories. Our proposed method is based on making use of prior information, assembled from (unrelated) object categories which were previously learnt. A generative probabilistic model is used, which represents the shape and appearance of a constellation of features belonging to the object. The parameters of the model are learnt incrementally in a Bayesian manner. Our incremental algorithm is compared experimentally to an earlier batch Bayesian algorithm, as well as to one based on maximum likelihood. The incremental and batch versions have comparable classification performance on small training sets, but incremental learning is significantly faster, making real-time learning feasible. Both Bayesian methods outperform maximum likelihood on small training sets.", "authors": ["Li Fei-Fei", "Rob Fergus", "Pietro Perona"], "related_topics": ["167966045", "2779542340", "2777018310"], "citation_count": "8261", "reference_count": "18", "references": ["2164598857", "2124386111", "2154422044", "2124087378", "2155511848", "1516111018", "1949116567", "1746680969", "2567948266", "1699734612"], "date": "2007"}, {"id": "2749253217", "title": "Classification and Applications of Social Recommender Systems", "abstract": "The rapid growth of internet has paved the way for recommender systems as users are inundated with a variety of choices. A computer system that provides recommendations/suggestions to the users is called Recommender Systems (RS). These systems are a subclass of information filtering systems that provides suitable recommendations to users about a product, movie, song, mobile applications etc. RS are being widely used in social networking sites like Facebook, Twitter, LinkedIn etc. to help users choose product/friend/job from the various recommendations. These systems analyze patterns of user interest in posting information, sharing posts or joining a new group to provide personalized recommendations that suit user\u2019s taste. RS are popular in many areas especially for predicting/suggesting what the users want in advance and thus help in reducing search costs. Recommendations are done using either collaborative, Content-based filtering or hybrid approach. Content-based recommendation system recommends based on user profile created by analyzing the items the user has liked/rated in the past. A collaborative recommendation system, on the other hand, does suggestions based on the preferences/ratings of our previous collaborators (users whose liking was similar to ours). The popularity of social networking sites is increasing with more number of users being added daily. This paper discusses the various classification and applications of RS in some of the popular networking sites.", "authors": ["V. R. Revathy", "Anitha S. Pillai"], "related_topics": ["557471498", "21569690", "2780150774"], "citation_count": "1", "reference_count": "23", "references": ["1980202081", "2155048531", "2136664839", "1967507014", "1993897382", "290370860", "2155959613", "1976859382", "151400537", "1996320586"], "date": "2016"}, {"id": "2159737176", "title": "Training Invariant Support Vector Machines", "abstract": "Practical experience has shown that in order to obtain the best possible performance, prior knowledge about invariances of a classification problem at hand ought to be incorporated into the training procedure. We describe and review all known methods for doing so in support vector machines, provide experimental results, and discuss their respective merits. One of the significant new results reported in this work is our recent achievement of the lowest reported test error on the well-known MNIST digit recognition benchmark task, with SVM training times that are also significantly faster than previous SVM methods.", "authors": ["Dennis Decoste", "Bernhard Sch\u00f6lkopf"], "related_topics": ["10719679", "125168437", "145828037"], "citation_count": "775", "reference_count": "38", "references": ["2156909104", "2148603752", "2310919327", "2119821739", "2140095548", "1512098439", "2087347434", "1604938182", "2147800946", "2151040995"], "date": "2002"}, {"id": "1612003148", "title": "Probabilistic latent semantic analysis", "abstract": "Probabilistic Latent Semantic Analysis is a novel statistical technique for the analysis of two-mode and co-occurrence data, which has applications in information retrieval and filtering, natural language processing, machine learning from text, and in related areas. Compared to standard Latent Semantic Analysis which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed method is based on a mixture decomposition derived from a latent class model. This results in a more principled approach which has a solid foundation in statistics. In order to avoid overfitting, we propose a widely applicable generalization of maximum likelihood model fitting by tempered EM. Our approach yields substantial and consistent improvements over Latent Semantic Analysis in a number of experiments.", "authors": ["Thomas Hofmann"], "related_topics": ["112933361", "170133592", "68841619"], "citation_count": "3044", "reference_count": "13", "references": ["2147152072", "2107743791", "2049633694", "1956559956", "1983578042", "2134731454", "2127314673", "2056029990", "2143144851", "2140842551"], "date": "1999"}, {"id": "2157331557", "title": "Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation", "abstract": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.", "authors": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio", "", ""], "related_topics": ["118505674", "147168706", "50644808"], "citation_count": "13086", "reference_count": "31", "references": ["2618530766", "2153579005", "2064675550", "2147768505", "6908809", "2132339004", "1753482797", "2294059674", "2156387975", "2963504252"], "date": "2013"}, {"id": "2117354486", "title": "Eigentaste: A Constant Time Collaborative Filtering Algorithm", "abstract": "Eigentaste is a collaborative filtering algorithm that uses i>universal queries to elicit real-valued user ratings on a common set of items and applies principal component analysis (PCA) to the resulting dense subset of the ratings matrix. PCA facilitates dimensionality reduction for offline clustering of users and rapid computation of recommendations. For a database of i>n users, standard nearest-neighbor techniques require i>O(i>n) processing time to compute recommendations, whereas Eigentaste requires i>O(1) (constant) time. We compare Eigentaste to alternative algorithms using data from i>Jester, an online joke recommending system. Jester has collected approximately 2,500,000 ratings from 57,000 users. We use the Normalized Mean Absolute Error (NMAE) measure to compare performance of different algorithms. In the Appendix we use Uniform and Normal distribution models to derive analytic estimates of NMAE when predictions are random. On the Jester dataset, Eigentaste computes recommendations two orders of magnitude faster with no loss of accuracy. Jester is online at: http://eigentaste.berkeley.edu", "authors": ["Ken Goldberg", "Theresa Roeder", "Dhruv Gupta", "Chris Perkins"], "related_topics": ["21569690", "557471498", "70518039"], "citation_count": "1977", "reference_count": "30", "references": ["2110325612", "2147152072", "3121531027", "2107743791", "2085937320", "2124591829", "1966553486", "1999047234", "2341865734", "1832221731"], "date": "2001"}, {"id": "2147768505", "title": "Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition", "abstract": "We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.", "authors": ["G. E. Dahl", "Dong Yu", "Li Deng", "A. Acero"], "related_topics": ["97385483", "23224414", "40969351"], "citation_count": "3179", "reference_count": "84", "references": ["2136922672", "2100495367", "1533861849", "2072128103", "2546302380", "2116064496", "2117130368", "2025768430", "1993882792", "1498436455"], "date": "2011"}, {"id": "2099471712", "title": "Generative Adversarial Nets", "abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.", "authors": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "related_topics": ["167966045", "97931131", "2777472644"], "citation_count": "27297", "reference_count": "34", "references": ["2618530766", "2136922672", "1959608418", "3118608800", "2310919327", "1904365287", "2964153729", "2072128103", "2546302380", "2025768430"], "date": "2014"}, {"id": "2165874743", "title": "On Spectral Clustering: Analysis and an algorithm", "abstract": "Despite many empirical successes of spectral clustering methods\u2014 algorithms that cluster points using eigenvectors of matrices derived from the data\u2014there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.", "authors": ["Andrew Y. Ng", "Michael I. Jordan", "Yair Weiss"], "related_topics": ["73555534", "94641424", "17212007"], "citation_count": "9863", "reference_count": "13", "references": ["2140095548", "1578099820", "2141376824", "2160167256", "658559791", "2130891992", "2067976091", "2171009857", "2123320529", "1981193610"], "date": "2001"}, {"id": "137381930", "title": "Rank, decomposition, and uniqueness for 3-way and n -way arrays", "abstract": "", "authors": ["J. B. Kruskal"], "related_topics": ["1026927", "2777021972", "144911616"], "citation_count": "319", "reference_count": "0", "references": ["2024165284", "2013912476", "2404400936", "2132267493", "2119741678", "2113055885", "2043571470", "2039748980", "1539811621", "2108138101"], "date": "1989"}, {"id": "2120520366", "title": "Ensembling Rule Based Classifiers for Detecting Network Intrusions", "abstract": "An intrusion is defined as a violation of the security policy of the system, and hence, intrusion detection mainly refers to the mechanisms that are developed to detect violations of system security policy. Recently, data mining techniques have gained importance in providing the valuable information which in turn can help to enhance the decision on identifying the intrusions (attacks). In this paper; we evaluate the performance of various rule based classifiers like: JRip, RIDOR, NNge and Decision Table using ensemble approach in order to build an efficient network intrusion detection system. We use KDDCup\u201999, intrusion detection benchmark dataset (which is a part of DARPA evaluation program) for our experimentation. It can be observed from the results that the proposed approach is accurate in detecting network intrusions, provides low false positive rate, simple, reliable and faster in building an efficient network intrusion system.", "authors": ["Mrutyunjaya Panda", "Manas Ranjan Patra"], "related_topics": ["137524506", "35525427", "149271511"], "citation_count": "24", "reference_count": "16", "references": ["3124955340", "1670263352", "2019363670", "1520252399", "2130802299", "2160598920", "1630964756", "1574164692", "2146257637", "2037768235"], "date": "2009"}, {"id": "1949116567", "title": "Unsupervised Learning of Models for Recognition", "abstract": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars.", "authors": ["Markus Weber", "Max Welling", "Pietro Perona", ""], "related_topics": ["2776676872", "8038995", "73555534"], "citation_count": "947", "reference_count": "16", "references": ["2049633694", "3017143921", "1564419782", "2095757522", "1958762911", "2124722975", "2117138270", "2125791971", "2029727948", "1628541567"], "date": "2000"}, {"id": "2140862024", "title": "Unsupervised Multiway Data Analysis: A Literature Survey", "abstract": "Two-way arrays or matrices are often not enough to represent all the information in the data and standard two-way analysis techniques commonly applied on matrices may fail to find the underlying structures in multi-modal datasets. Multiway data analysis has recently become popular as an exploratory analysis tool in discovering the structures in higher-order datasets, where data have more than two modes. We provide a review of significant contributions in the literature on multiway models, algorithms as well as their applications in diverse disciplines including chemometrics, neuroscience, social network analysis, text mining and computer vision.", "authors": ["E. Acar", "B. Yener"], "related_topics": ["3017831414", "162319229", "114713312"], "citation_count": "480", "reference_count": "95", "references": ["2024165284", "2798909945", "1510073064", "2102544846", "2013912476", "2113722075", "2027559251", "2119741678", "2113055885", "2611015177"], "date": "2008"}, {"id": "2160167256", "title": "Segmentation using eigenvectors: a unifying view", "abstract": "Automatic grouping and segmentation of images remains a challenging problem in computer vision. Recently, a number of authors have demonstrated good performance on this task using methods that are based on eigenvectors of the affinity matrix. These approaches are extremely attractive in that they are based on simple eigendecomposition algorithms whose stability is well understood. Nevertheless, the use of eigendecompositions in the context of segmentation is far from well understood. In this paper we give a unified treatment of these algorithms, and show the close connections between them while highlighting their distinguishing features. We then prove results on eigenvectors of block matrices that allow us to analyze the performance of these algorithms in simple grouping settings. Finally, we use our analysis to motivate a variation on the existing methods that combines aspects from different eigenvector segmentation algorithms. We illustrate our analysis with results on real and synthetic images.", "authors": ["Y. Weiss"], "related_topics": ["65885262", "124504099", "89600930"], "citation_count": "1066", "reference_count": "10", "references": ["2121947440", "2049633694", "1640070940", "2136120429", "2143920871", "2083761303", "1576344349", "1731063510", "2151869980", "2127123593"], "date": "1999"}, {"id": "2172174689", "title": "Efficient Learning of Sparse Representations with an Energy-Based Model", "abstract": "We describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces \"stroke detectors\" when trained on handwritten numerals, and Gabor-like filters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the first layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical filter maps.", "authors": ["Marc'aurelio Ranzato", "Christopher Poultney", "Sumit Chopra", "Yann L. Cun"], "related_topics": ["118505674", "124066611", "190502265"], "citation_count": "1552", "reference_count": "14", "references": ["2136922672", "2310919327", "2116064496", "1902027874", "2156163116", "2105464873", "1802356529", "2075187489", "2102409316", "11828546"], "date": "2006"}, {"id": "2090626368", "title": "Language typology and syntactic description", "abstract": "", "authors": ["Timothy Shopen"], "related_topics": ["1701360", "61577278", "60048249"], "citation_count": "1633", "reference_count": "40", "references": ["239563548", "2153190547", "2075166633", "2020822911", "2237495196", "277336407", "2093483153", "1492367142", "1822002357", "2097219834"], "date": "2006"}, {"id": "2168977926", "title": "Texture analysis and classification with tree-structured wavelet transform", "abstract": "A multiresolution approach based on a modified wavelet transform called the tree-structured wavelet transform or wavelet packets is proposed. The development of this transform is motivated by the observation that a large class of natural textures can be modeled as quasi-periodic signals whose dominant frequencies are located in the middle frequency channels. With the transform, it is possible to zoom into any desired frequency channels for further decomposition. In contrast, the conventional pyramid-structured wavelet transform performs further decomposition in low-frequency channels. A progressive texture classification algorithm which is not only computationally attractive but also has excellent performance is developed. The performance of the present method is compared with that of several other methods. >", "authors": ["T. Chang", "C.-C.J. Kuo"], "related_topics": ["155777637", "73339587", "46286280"], "citation_count": "2218", "reference_count": "52", "references": ["2132984323", "2098914003", "1997063559", "2100115174", "1996021349", "2156447271", "1970352604", "2165878107", "1980149518", "2044465660"], "date": "1993"}, {"id": "2125838338", "title": "A tutorial on hidden Markov models and selected applications in speech recognition", "abstract": "This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described. >", "authors": ["L.R. Rabiner"], "related_topics": ["2776777365", "64939953", "2778673898"], "citation_count": "31278", "reference_count": "62", "references": ["2049633694", "2105594594", "1966812932", "2142384583", "2022554507", "2002182716", "1966264494", "2171850596", "1991133427", "1877570817"], "date": "1989"}, {"id": "2075456404", "title": "Large-scale visual sentiment ontology and detectors using adjective noun pairs", "abstract": "We address the challenge of sentiment analysis from visual content. In contrast to existing methods which infer sentiment or emotion directly from visual low-level features, we propose a novel approach based on understanding of the visual concepts that are strongly related to sentiments. Our key contribution is two-fold: first, we present a method built upon psychological theories and web mining to automatically construct a large-scale Visual Sentiment Ontology (VSO) consisting of more than 3,000 Adjective Noun Pairs (ANP). Second, we propose SentiBank, a novel visual concept detector library that can be used to detect the presence of 1,200 ANPs in an image. The VSO and SentiBank are distinct from existing work and will open a gate towards various applications enabled by automatic sentiment analysis. Experiments on detecting sentiment of image tweets demonstrate significant improvement in detection accuracy when comparing the proposed SentiBank based predictors with the text-based approaches. The effort also leads to a large publicly available resource consisting of a visual sentiment ontology, a large detector library, and the training/testing benchmark for visual sentiment analysis.", "authors": ["Damian Borth", "Rongrong Ji", "Tao Chen", "Thomas Breuel", "Shih-Fu Chang"], "related_topics": ["66402592", "166724064", "197046077"], "citation_count": "604", "reference_count": "47", "references": ["2108598243", "2031489346", "2097726431", "2171468534", "1566135517", "1590495275", "2022204871", "2122369144", "38739846", "2139043937"], "date": "2013"}, {"id": "2136066653", "title": "CIS: a massively concurrent rule-based system", "abstract": "Recently researchers have suggested several computational models in which, one programs by specifying large networks of simple devices. Such models are interesting because they go to the roots of concurrency - the circuit level. A problem with the models is that it is unclear how to program large systems and expensive to implement many features that are taken for granted in symbolic programming languages. This paper describes the Concurrent Inference System (CIS), and its implementation on a massively concurrent network model of computation. It shows how much of the functionality of current rule-based systems can be implemented in a straightforward manner within such models. Unlike conventional implementations of rule-based systems in which the inference engine and rule sets are clearly divided at run time. CIS compiles the rules into a large static concurrent network of very simple devices. In this network the rules and inference engine are no longer distinct. The Thinking Machines Corporation, Connection Machine - a 65,536 processor SIMD computer - is then used to run the network. On the current implementation, real time user system interaction is possible with up to 100,000 rules.", "authors": ["Guy E. Blelloch"], "related_topics": ["149271511", "193702766", "46743427"], "citation_count": "55", "reference_count": "18", "references": ["1652505363", "1507849272", "2112325651", "2033755422", "2060482235", "2096620062", "2407038694", "35024350", "83940682", "3147718583"], "date": "1986"}, {"id": "1976859382", "title": "Automatic tag recommendation algorithms for social recommender systems", "abstract": "The emergence of Web 2.0 and the consequent success of social network Web sites such as Del.icio.us and Flickr introduce us to a new concept called social bookmarking, or tagging. Tagging is the action of connecting a relevant user-defined keyword to a document, image, or video, which helps the user to better organize and share their collections of interesting stuff. With the rapid growth of Web 2.0, tagged data is becoming more and more abundant on the social network Web sites. An interesting problem is how to automate the process of making tag recommendations to users when a new resource becomes available.In this article, we address the issue of tag recommendation from a machine learning perspective. From our empirical observation of two large-scale datasets, we first argue that the user-centered approach for tag recommendation is not very effective in practice. Consequently, we propose two novel document-centered approaches that are capable of making effective and efficient tag recommendations in real scenarios. The first, graph-based, method represents the tagged data in two bipartite graphs, (document, tag) and (document, word), then finds document topics by leveraging graph partitioning algorithms. The second, prototype-based, method aims at finding the most representative documents within the data collections and advocates a sparse multiclass Gaussian process classifier for efficient document classification. For both methods, tags are ranked within each topic cluster/class by a novel ranking method. Recommendations are performed by first classifying a new document into one or more topic clusters/classes, and then selecting the most relevant tags from those clusters/classes as machine-recommended tags.Experiments on real-world data from Del.icio.us, CiteULike, and BibSonomy examine the quality of tag recommendation as well as the efficiency of our recommendation algorithms. The results suggest that our document-centered models can substantially improve the performance of tag recommendations when compared to the user-centered methods, as well as topic models LDA and SVM classifiers.", "authors": ["Yang Song", "Lu Zhang", "C. Lee Giles"], "related_topics": ["75003639", "2780479914", "171686336"], "citation_count": "212", "reference_count": "31", "references": ["1880262756", "1746819321", "1563088657", "2110325612", "2049633694", "1981745143", "2102775690", "2146241755", "2015245929", "1549874165"], "date": "2011"}, {"id": "1507849272", "title": "A learning algorithm for Boltzmann machines", "abstract": "The computational power of massively parallel networks of simple processing elements resides in the communication bandwidth provided by the hardware connections between elements. These connections can allow a significant fraction of the knowledge of the system to be applied to an instance of a problem in a very short time. One kind of computation for which massively parallel networks appear to be well suited is large constraint satisfaction searches, but to use the connections efficiently two conditions must be met: First, a search technique that is suitable for parallel networks must be found. Second, there must be some way of choosing internal representations which allow the preexisting hardware connections to be used efficiently for encoding the constraints in the domain being searched. We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connection strengths so as to incorporate knowledge about a task domain in an efficient way. We describe some simple examples in which the learning algorithm creates internal representations that are demonstrably the most efficient way of using the preexisting connectivity structure.", "authors": ["David H. Ackley", "Geoffrey E. Hinton", "Terrence J. Sejnowski"], "related_topics": ["190475519", "2779127903", "44616089"], "citation_count": "4821", "reference_count": "10", "references": ["2581275558", "1997063559", "2293063825", "2112325651", "2056760934", "2157629899", "2098205603", "1597474747", "1980658026", "807785616"], "date": "1987"}, {"id": "2053772216", "title": "ACM president's letter: electronic junk", "abstract": "", "authors": ["Peter J. Denning"], "related_topics": ["41008148"], "citation_count": "354", "reference_count": "0", "references": ["1966553486", "1982428762", "2118079529", "2165990684", "2057826272", "2545577367", "2115186087", "2147261473", "2025172185", "1977281680"], "date": "1982"}, {"id": "2128221272", "title": "Supervised learning from incomplete data via an EM approach", "abstract": "Real-world learning tasks may involve high-dimensional data sets with arbitrary patterns of missing data. In this paper we present a framework based on maximum likelihood density estimation for learning from such data set.s. We use mixture models for the density estimates and make two distinct appeals to the Expectation-Maximization (EM) principle (Dempster et al., 1977) in deriving a learning algorithm--EM is used both for the estimation of mixture components and for coping with missing data. The resulting algorithm is applicable to a wide range of supervised as well as unsupervised learning problems. Results from a classification benchmark--the iris data set--are presented.", "authors": ["Zoubin Ghahramani", "Michael I. Jordan"], "related_topics": ["58973888", "8038995", "136389625"], "citation_count": "764", "reference_count": "13", "references": ["1594031697", "2049633694", "2044758663", "2102201073", "3017143921", "2150884987", "2025653905", "2149723649", "1992402718", "1580495158"], "date": "1993"}, {"id": "382421368", "title": "Language, Usage and Cognition", "abstract": "Language demonstrates structure while also showing considerable variation at all levels: languages differ from one another while still being shaped by the same principles; utterances within a language differ from one another while exhibiting the same structural patterns; languages change over time, but in fairly regular ways. This book focuses on the dynamic processes that create languages and give them their structure and variance. It outlines a theory of language that addresses the nature of grammar, taking into account its variance and gradience, and seeks explanation in terms of the recurrent processes that operate in language use. The evidence is based on the study of large corpora of spoken and written language, what we know about how languages change, as well as the results of experiments with language users. The result is an integrated theory of language use and language change which has implications for cognitive processing and language evolution.", "authors": ["Joan L. Bybee"], "related_topics": ["2780790391", "2776095024", "2778946008"], "citation_count": "3008", "reference_count": "281", "references": ["1652505363", "2013833248", "2970460809", "2168488947", "1550933260", "2055460448", "1558866924", "2796493717", "3140196993", "1872053182"], "date": "2010"}, {"id": "2098874414", "title": "Membership Size, Communication Activity, and Sustainability: A Resource-Based Model of Online Social Structures", "abstract": "As telecommunication networks become more common, there is an increasing interest in the factors underlying the development of online social structures. It has been proposed that these structures are new forms of organizing which are not subject to the same constraints as traditional social structures. However, from anecdotal evidence and case studies it is difficult to evaluate whether online social structures are subject to the same problems as traditional social structures. Drawing from prior studies of traditional social structures and empirical analyses of longitudinal data from a sample of Internet-based groups, this exploratory work considers the role of size and communication activity in sustainable online social structures.A resource-based theory of sustainable social structures is presented. Members contribute time, energy, and other resources, enabling a social structure to provide benefits for individuals. These benefits, which include information, influence, and social support, are the basis for a social structure's ability to attract and retain members. This model focuses on the system of opposing forces that link membership size as a component of resource availability and communication activity as an aspect of benefit provision to the sustainability of an online social structure. Analyses of data from a random sample of e-mail-based Internet social structures (listservs) indicate that communication activity and size have both positive and negative effects on a structure's sustainability. These results suggest that while the use of networked communication technologies may alter the form of communication, balancing the opposing impacts of membership size and communication activity in order to maintain resource availability and provide benefits for current members remains a fundamental problem underlying the development of sustainable online social structures.", "authors": ["Brian S. Butler"], "related_topics": ["86256295", "137405303", "9701087"], "citation_count": "1119", "reference_count": "81", "references": ["1971440513", "2175723801", "2576297379", "2124990143", "1994373531", "2024372407", "1581423510", "2090530117", "2798960802", "2564226227"], "date": "2001"}, {"id": "2142384583", "title": "The viterbi algorithm", "abstract": "The Viterbi algorithm (VA) is a recursive optimal solution to the problem of estimating the state sequence of a discrete-time finite-state Markov process observed in memoryless noise. Many problems in areas such as digital communications can be cast in this form. This paper gives a tutorial exposition of the algorithm and of how it is implemented and analyzed. Applications to date are reviewed. Increasing use of the algorithm in a widening variety of areas is foreseen.", "authors": ["Jr. G.D. Forney"], "related_topics": ["130319729", "113638808", "60582962"], "citation_count": "7958", "reference_count": "38", "references": ["1562979145", "2045407304", "1991133427", "2131086249", "2122683098", "2106185713", "2153810958", "2035227369", "2161457263", "2134360027"], "date": "1973"}, {"id": "1670263352", "title": "Fast effective rule induction", "abstract": "Abstract Many existing rule learning systems are computationally expensive on large noisy datasets. In this paper we evaluate the recently-proposed rule learning algorithm IREP on a large and diverse collection of benchmark problems. We show that while IREP is extremely efficient, it frequently gives error rates higher than those of C4.5 and C4.5rules. We then propose a number of modifications resulting in an algorithm RIPPERk that is very competitive with C4.5rules with respect to error rates, but much more efficient on large samples. RIPPERk obtains error rates lower than or equivalent to C4.5rules on 22 of 37 benchmark problems, scales nearly linearly with the number of training examples, and can efficiently process noisy datasets containing hundreds of thousands of examples.", "authors": ["William W. Cohen"], "related_topics": ["2776780472", "137955351", "119857082"], "citation_count": "5263", "reference_count": "16", "references": ["2128420091", "1999138184", "1604329830", "1531743498", "2111746072", "2089967664", "146100937", "2037689320", "1510806966", "165133269"], "date": "1995"}, {"id": "2149684865", "title": "Text Categorization with Suport Vector Machines: Learning with Many Relevant Features", "abstract": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning.", "authors": ["Thorsten Joachims"], "related_topics": ["12267149", "94124525", "119857082"], "citation_count": "11689", "reference_count": "12", "references": ["2156909104", "2119821739", "2125055259", "2435251607", "740415", "1504694836", "2114535528", "1978394996", "2096152098", "2087614174"], "date": "1998"}, {"id": "2013596317", "title": "How children learn words.", "abstract": "", "authors": ["George A. Miller", "Patricia M. Gildea"], "related_topics": ["2983335612", "2777601683", "150856459"], "citation_count": "566", "reference_count": "0", "references": ["2164599981", "2102381086", "3121300207", "2074350771", "3104747894", "2144020833", "1826683621", "2017668967", "2113307054", "2152215838"], "date": "1987"}, {"id": "2134383396", "title": "An Algorithm for Vector Quantizer Design", "abstract": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data. The basic properties of the algorithm are discussed and demonstrated by examples. Quite general distortion measures and long blocklengths are allowed, as exemplified by the design of parameter vector quantizers of ten-dimensional vectors arising in Linear Predictive Coded (LPC) speech compression with a complicated distortion measure arising in LPC analysis that does not depend only on the error vector.", "authors": ["Y. Linde", "A. Buzo", "R. Gray"], "related_topics": ["93372532", "199833920", "40567965"], "citation_count": "10841", "reference_count": "16", "references": ["2127218421", "2137089646", "2142228262", "1973387369", "2109808436", "1489608363", "1968191505", "2145838167", "1628049834", "1631408262"], "date": "1979"}, {"id": "2109405055", "title": "Efficient Non-Parametric Function Induction in Semi-Supervised Learning", "abstract": "There has been an increase of interest for semi-supervised learning recently, because of the many datasets with large amounts of unlabeled examples and only a few labeled ones. This paper follows up on proposed non-parametric algorithms which provide an estimated continuous label for the given unlabeled examples. It extends them to function induction algorithms that correspond to the minimization of a regularization criterion applied to an out-of-sample example, and happens to have the form of a Parzen windows regressor. The advantage of the extension is that it allows predicting the label for a new example without having to solve again a linear system of dimension n (the number of unlabeled and labeled training examples), which can cost O(n 3 ). Experiments show that the extension works well, in the sense of predicting a label close to the one that would have been obtained if the test example had been included in the unlabeled set. This relatively efficient function induction procedure can also be used when n is large to approximate the solution by writing it only in terms of a kernel expansion with m n terms, and reducing the linear system to m equations in m unknowns.", "authors": ["Yoshua Bengio", "Olivier Delalleau", "Nicolas Le Roux"], "related_topics": ["58973888", "6802819", "8398441"], "citation_count": "230", "reference_count": "17", "references": ["2165874743", "2154455818", "2139823104", "2520931985", "2112545207", "2122837498", "2113592823", "1491300635", "1574877594", "1514707997"], "date": "2003"}, {"id": "2103452139", "title": "Learning long-term dependencies in NARX recurrent neural networks", "abstract": "It has previously been shown that gradient-descent learning algorithms for recurrent neural networks can perform poorly on tasks that involve long-term dependencies, i.e. those problems for which the desired output depends on inputs presented at times far in the past. We show that the long-term dependencies problem is lessened for a class of architectures called nonlinear autoregressive models with exogenous (NARX) recurrent neural networks, which have powerful representational capabilities. We have previously reported that gradient descent learning can be more effective in NARX networks than in recurrent neural network architectures that have \"hidden states\" on problems including grammatical inference and nonlinear system identification. Typically, the network converges much faster and generalizes better than other networks. The results in this paper are consistent with this phenomenon. We present some experimental results which show that NARX networks can often retain information for two to three times as long as conventional recurrent neural networks. We show that although NARX networks do not circumvent the problem of long-term dependencies, they can greatly improve performance on long-term dependency problems. We also describe in detail some of the assumptions regarding what it means to latch information robustly and suggest possible ways to loosen these assumptions.", "authors": ["Tsungnan Lin", "B.G. Horne", "P. Tino", "C.L. Giles"], "related_topics": ["147168706", "50644808", "22157029"], "citation_count": "702", "reference_count": "32", "references": ["2064675550", "2154642048", "2138484437", "2110485445", "2107878631", "2798813531", "2128499899", "2123716044", "1674799117", "2098398123"], "date": "1996"}, {"id": "2157629899", "title": "OPTIMAL PERCEPTUAL INFERENCE", "abstract": "When a vision system creates an interpretation of some input datn, it assigns truth values or probabilities to intcrnal hypothcses about the world. We present a non-dctcrministic method for assigning truth values that avoids many of the problcms encountered by existing relaxation methods. Instead of rcprcscnting probabilitics with realnumbers, we usc a more dircct encoding in which thc probability \\ associated with a hypotlmis is rcprcscntcd by the probability hat it is in one of two states, true or false. Wc give a particular nondeterministic operator, based on statistical mechanics, for updating the truth values of hypothcses. The operator ensures that the probability of discovering a particular combination of hypothcscs is a simplc function of how good that combination is. Wc show that thcrc is a simple relationship bctween this operator and Bayesian inference, and we describe a learning rule which allows a parallel system to converge on a set ofweights that optimizes its perccptt~al inferences.", "authors": ["Geoffrey E. Hinton", "J. Sejnowski"], "related_topics": ["160234255", "162376815", "101112237"], "citation_count": "722", "reference_count": "11", "references": ["2581275558", "2293063825", "2048330959", "2046425638", "2080250034", "1965044325", "1581975000", "179212727", "2002010034", "1548470819"], "date": "1982"}, {"id": "2158139315", "title": "Word Representations: A Simple and General Method for Semi-Supervised Learning", "abstract": "If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/", "authors": ["Joseph Turian", "Lev-Arie Ratinov", "Yoshua Bengio"], "related_topics": ["61249035", "58973888", "203357204"], "citation_count": "2502", "reference_count": "47", "references": ["1880262756", "2117130368", "2132339004", "1662133657", "168564468", "2131462252", "2296073425", "2158997610", "2004763266", "2156515921"], "date": "2010"}, {"id": "2070862086", "title": "Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors", "abstract": "The 1990s saw the emergence of cognitive models that depend on very high dimensionality and randomness. They include Holographic Reduced Representations, Spatter Code, Semantic Vectors, Latent Semantic Analysis, Context-Dependent Thinning, and Vector-Symbolic Architecture. They represent things in high-dimensional vectors that are manipulated by operations that produce new high-dimensional vectors in the style of traditional computing, in what is called here hyperdimensional computing on account of the very high dimensionality. The paper presents the main ideas behind these models, written as a tutorial essay in hopes of making the ideas accessible and even provocative. A sketch of how we have arrived at these models, with references and pointers to further reading, is given at the end. The thesis of the paper is that hyperdimensional representation has much to offer to students of cognitive science, theoretical neuroscience, computer science and engineering, and mathematics.", "authors": ["Pentti Kanerva"], "related_topics": ["2780291827", "170133592", "2779231336"], "citation_count": "554", "reference_count": "23", "references": ["2293063825", "1983578042", "1991848143", "2063392856", "1986707196", "2135508918", "1573706465", "1509703770", "1584739173", "1538369587"], "date": "2009"}, {"id": "2098914003", "title": "Orthonormal bases of compactly supported wavelets", "abstract": "We construct orthonormal bases of compactly supported wavelets, with arbitrarily high regularity. The order of regularity increases linearly with the support width. We start by reviewing the concept of multiresolution analysis as well as several algorithms in vision decomposition and reconstruction. The construction then follows from a synthesis of these different approaches.", "authors": ["Ingrid Daubechies"], "related_topics": ["5806529", "2777946946", "123769847"], "citation_count": "12275", "reference_count": "25", "references": ["2103504761", "1980149518", "2096684483", "2043583598", "2087377426", "2013987111", "1975474302", "2039942287", "2153709524", "1989491465"], "date": "1988"}, {"id": "2096192494", "title": "On the quantitative analysis of deep belief networks", "abstract": "Deep Belief Networks (DBN's) are generative models that contain many layers of hidden variables. Efficient greedy algorithms for learning and approximate inference have allowed these models to be applied successfully in many application domains. The main building block of a DBN is a bipartite undirected graphical model called a restricted Boltzmann machine (RBM). Due to the presence of the partition function, model selection, complexity control, and exact maximum likelihood learning in RBM's are intractable. We show that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and we present a novel AIS scheme for comparing RBM's with different architectures. We further show how an AIS estimator, along with approximate inference, can be used to estimate a lower bound on the log-probability that a DBN model with multiple hidden layers assigns to the test data. This is, to our knowledge, the first step towards obtaining quantitative results that would allow us to directly assess the performance of Deep Belief Networks as generative models of data.", "authors": ["Ruslan Salakhutdinov", "Iain Murray"], "related_topics": ["97385483", "199354608", "2777472644"], "citation_count": "493", "reference_count": "14", "references": ["2136922672", "2100495367", "2116064496", "2099866409", "2169415915", "2158164339", "66838807", "2064630666", "1513873506", "2135094946"], "date": "2008"}, {"id": "2030536784", "title": "Pictorial Structures for Object Recognition", "abstract": "In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images.", "authors": ["Pedro F. Felzenszwalb", "Daniel P. Huttenlocher"], "related_topics": ["14551309", "20894473", "512554520"], "citation_count": "2824", "reference_count": "43", "references": ["3145128584", "2138451337", "2752885492", "2143516773", "2159080219", "1560013842", "1997063559", "301824129", "2123977795", "2085261163"], "date": "2004"}, {"id": "2085946009", "title": "Centering and scaling in component analysis", "abstract": "In this paper the purpose and use of centering and scaling are discussed in depth. The main focus is on two-way bilinear data analysis, but the results can easily be generalized to multiway data analysis. In fact, one of the scopes of this paper is to show that if two-way centering and scaling are understood, then multiway centering and scaling is quite straightforward. In the literature it is often stated that preprocessing of multiway arrays is difficult, but here it is shown that most of the difficulties do not pertain to three- and higher-way modeling in particular. It is shown that centering is most conveniently seen as a projection step, where the data are projected onto certain well-defined spaces within a given mode. This view of centering helps to explain why, for example, centering data with missing elements is likely to be suboptimal if there are many missing elements. Building a model for data consists of two parts: postulating a structural model and using a method to estimate the parameters. Centering has to do with the first part: when centering, a model including offsets is postulated. Scaling has to do with the second part: when scaling, another way of fitting the model is employed. It is shown that centering is simply a convenient technique to estimate model parameters for models with certain offsets, but this does not work for all types of offsets. It is also shown that scaling is a way to fit models with a weighted least squares loss function and that sometimes this change in objective function cannot be performed by a simple scaling step. Further practical. aspects of and alternatives to centering and scaling are discussed, and examples are used throughout to show that the conclusions in the paper are not only of theoretical interest but can have an impact on practical data analysis. Copyright (C) 2003 John Wiley Sons, Ltd", "authors": ["Rasmus Bro", "Age K. Smilde"], "related_topics": ["99844830", "9357733", "175291020"], "citation_count": "425", "reference_count": "27", "references": ["2044758663", "2059745395", "2037430361", "2087964979", "2016090370", "1986326495", "3012395598", "2022242697", "2085059189", "2094382594"], "date": "2002"}, {"id": "2125791971", "title": "Finding faces in cluttered scenes using random labeled graph matching", "abstract": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented. The algorithm works by coupling a set of local feature detectors with a statistical model of the mutual distances between facial features it is invariant with respect to translation, rotation (in the plane), and scale and can handle partial occlusions of the face. On a challenging database with complicated and varied backgrounds, the algorithm achieved a correct localization rate of 95% in images where the face appeared quasi-frontally. >", "authors": ["T.K. Leung", "M.C. Burl", "P. Perona"], "related_topics": ["31510193", "205068", "52622490"], "citation_count": "613", "reference_count": "17", "references": ["2138451337", "3017143921", "2113341759", "2135346934", "2084844503", "2293807537", "2014102379", "2090196588", "1964156667", "8853611"], "date": "1995"}, {"id": "1652505363", "title": "Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations", "abstract": "The fundamental principles, basic mechanisms, and formal analyses involved in the development of parallel distributed processing (PDP) systems are presented in individual chapters contributed by leading experts. Topics examined include distributed representations, PDP models and general issues in cognitive science, feature discovery by competitive learning, the foundations of harmony theory, learning and relearning in Boltzmann machines, and learning internal representations by error propagation. Consideration is given to linear algebra in PDP, the logic of additive functions, resource requirements of standard and programmable nets, and the P3 parallel-network simulating system.", "authors": ["David E. Rumelhart", "James L. McClelland"], "related_topics": ["120822770", "8521452", "2776867014"], "citation_count": "23606", "reference_count": "0", "references": ["1614298861", "2145339207", "2076063813", "2072128103", "2116064496", "2025768430", "2145094598", "2107941094", "2154642048", "1498436455"], "date": "1986"}, {"id": "1560013842", "title": "Fundamentals of speech recognition", "abstract": "1. Fundamentals of Speech Recognition. 2. The Speech Signal: Production, Perception, and Acoustic-Phonetic Characterization. 3. Signal Processing and Analysis Methods for Speech Recognition. 4. Pattern Comparison Techniques. 5. Speech Recognition System Design and Implementation Issues. 6. Theory and Implementation of Hidden Markov Models. 7. Speech Recognition Based on Connected Word Models. 8. Large Vocabulary Continuous Speech Recognition. 9. Task-Oriented Applications of Automatic Speech Recognition.", "authors": ["Lawrence Rabiner", "Biing-Hwang Juang"], "related_topics": ["61328038", "204201278", "91863865"], "citation_count": "13109", "reference_count": "0", "references": ["2519091744", "2121601095", "2030536784", "2120340025", "2161406034", "2133824856", "2081681829", "2470139095", "2099019320", "2074788634"], "date": "1992"}, {"id": "1999478155", "title": "Efficient Graph-Based Image Segmentation", "abstract": "This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.", "authors": ["Pedro F. Felzenszwalb", "Daniel P. Huttenlocher"], "related_topics": ["25694479", "124504099", "67561299"], "citation_count": "7281", "reference_count": "17", "references": ["2121947440", "2752885492", "1971784203", "1964443764", "2160167256", "2137560895", "2167077256", "2132603077", "1640070940", "2109562068"], "date": "2004"}, {"id": "36903255", "title": "Hierarchical Probabilistic Neural Network Language Model.", "abstract": "In recent years, variants of a neural network architecture for statistical language modeling have been proposed and successfully applied, e.g. in the language modeling component of speech recognizers. The main advantage of these architectures is that they learn an embedding for words (or other symbols) in a continuous space that helps to smooth the language model and provide good generalization even when the number of training examples is insufficient. However, these models are extremely slow in comparison to the more commonly used n-gram models, both for training and recognition. As an alternative to an importance sampling method proposed to speed-up training, we introduce a hierarchical decomposition of the conditional probabilities that yields a speed-up of about 200 both during training and recognition. The hierarchical decomposition is a binary hierarchical clustering constrained by the prior knowledge extracted from the WordNet semantic hierarchy.", "authors": ["Frederic Morin", "Yoshua Bengio"], "related_topics": ["64900535", "137293760", "175202392"], "citation_count": "1120", "reference_count": "27", "references": ["2038721957", "2116064496", "2132339004", "2147152072", "1631260214", "2096175520", "2110485445", "1978394996", "2121227244", "2127314673"], "date": "2004"}, {"id": "2171850596", "title": "An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition", "abstract": "In this paper we present several of the salient theoretical and practical issues associated with modeling a speech signal as a probabilistic function of a (hidden) Markov chain. First we give a concise review of the literature with emphasis on the Baum-Welch algorithm. This is followed by a detailed discussion of three issues not treated in the literature: alternatives to the Baum-Welch algorithm; critical facets of the implementation of the algorithms, with emphasis on their numerical properties; and behavior of Markov models on certain artificial but realistic problems. Special attention is given to a particular class of Markov models, which we call \u201cleft-to-right\u201d models. This class of models is especially appropriate for isolated word recognition. The results of the application of these methods to an isolated word, speaker-independent speech recognition experiment are given in a companion paper.", "authors": ["S. E. Levinson", "L. R. Rabiner", "M. M. Sondhi"], "related_topics": ["163836022", "98763669", "159886148"], "citation_count": "1443", "reference_count": "20", "references": ["2022772618", "1575431606", "1990005915", "2086699924", "2021760654", "1980800561", "2163929346", "2057833190", "2007321142", "2077574412"], "date": "1983"}, {"id": "2408262139", "title": "Building Rich User Profiles for Personalized News Recommendation.", "abstract": "Nowadays, more and more people are using online news platforms as their main source of information about daily life events. Users of such platforms have access to an increasing amount of articles of different topics, stories, and view points. Thus, a news personalization service is needed to filter the flow of available information and satisfy users needs. To this end, it is crucial to understand and build accurate profiles for both users and news articles. In this paper, we propose a new approach that exploits users comments to recommend articles. We build the profile of each user based on (1) the set of entities he talked about it in his comments, (2) and the set of aspects related to those entities. The same information is extracted from the content of each news article to create its profile. These profiles are then matched for the purpose of recommendation. We have used a collection based on real users activities in four news web sites, namely The Independent, The Telegraph, CNN and ALJazeera. The first results show that our approach outperforms baseline approaches achieving high accuracy.", "authors": ["Youssef Meguebli", "Mouna Kacimi", "Bich-Li\u00ean Doan", "Fabrice Popineau"], "related_topics": ["136764020", "23123220", "50201147"], "citation_count": "4", "reference_count": "11", "references": ["2076219102", "2063904635", "2127785456", "2019177758", "2116235440", "2151451758", "2028593080", "2040107208", "2121017700", "2107214735"], "date": "2013"}, {"id": "2035032881", "title": "Transition network grammars for natural language analysis", "abstract": "The use of augmented transition network grammars for the analysis of natural language sentences is described. Structure-building actions associated with the arcs of the grammar network allow for the reordering, restructuring, and copying of constituents necessary to produce deep-structure representations of the type normally obtained from a transformational analysis, and conditions on the arcs allow for a powerful selectivity which can rule out meaningless analyses and take advantage of semantic information to guide the parsing. The advantages of this model for natural language analysis are discussed in detail and illustrated by examples. An implementation of an experimental parsing system for transition network grammars is briefly described.", "authors": ["W. A. Woods"], "related_topics": ["67621940", "97212296", "125950753"], "citation_count": "1844", "reference_count": "21", "references": ["2170716495", "2134199742", "2148224873", "2134495021", "3003374142", "2064490449", "1991570511", "2129414328", "1601555688", "2152907450"], "date": "1970"}, {"id": "1832221731", "title": "Application of Dimensionality Reduction in Recommender System - A Case Study", "abstract": "Abstract : We investigate the use of dimensionality reduction to improve performance for a new class of data analysis software called \"recommender systems\" Recommender systems apply knowledge discovery techniques to the problem of making product recommendations during a live customer interaction. These systems are achieving widespread success in E-commerce nowadays, especially with the advent of the Internet. The tremendous growth of customers and products poses three key challenges for recommender systems in the E-commerce domain. These are: producing high quality recommendations, performing many recommendations per second for millions of customers and products, and achieving high coverage in the face of data sparsity. One successful recommender system technology is collaborative filtering, which works by matching customer preferences to other customers in making recommendations. Collaborative filtering has been shown to produce high quality recommendations, but the performance degrades with the number of customers and products. New recommender system technologies are needed that can quickly produce high quality recommendations, even for very largescale problems. This paper presents two different experiments where we have explored one technology called Singular Value Decomposition (SVD) to reduce the dimensionality of recommender system databases. Each experiment compares the quality of a recommender system using SVD with the quality of a recommender system using collaborative filtering. The first experiment compares the effectiveness of the two recommender systems at predicting consumer preferences based on a database of explicit ratings of products. The second experiment compares the effectiveness of the two recommender systems at producing Top-N lists based on a real-life customer purchase database from an E-Commerce site. Our experience suggests that SVD has the potential to meet many of the challenges of recommender systems, under certain conditions.", "authors": ["Badrul Sarwar", "George Karypis", "Joseph Konstan", "John Riedl"], "related_topics": ["557471498", "21569690", "2779483712"], "citation_count": "2017", "reference_count": "19", "references": ["2147152072", "3121531027", "2085937320", "2124591829", "1966553486", "2005422315", "2030144199", "2072773380", "1997136459", "1673941785"], "date": "2000"}, {"id": "1956559956", "title": "Introduction to Modern Information Retrieval", "abstract": "", "authors": ["Gerard Salton", "Michael J. McGill"], "related_topics": ["90288658", "22639730", "89686163"], "citation_count": "15135", "reference_count": "0", "references": ["1880262756", "2140190241", "2031489346", "2037227137", "1902027874", "2031454541", "2110325612", "2147152072", "2158266063", "2100235918"], "date": "1983"}, {"id": "2029727948", "title": "Recognizing surfaces using three-dimensional textons", "abstract": "We study the recognition of surfaces made from different materials such as concrete, rug, marble or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions. Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions.", "authors": ["T. Leung", "J. Malik"], "related_topics": ["2779934759", "63099799", "2779862385"], "citation_count": "286", "reference_count": "20", "references": ["2170120409", "2130416410", "1997063559", "1634005169", "3017143921", "1490632837", "2000123870", "1506013575", "2115738369", "1528775006"], "date": "1999"}, {"id": "1753482797", "title": "Recurrent Continuous Translation Models", "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.", "authors": ["Nal Kalchbrenner", "Phil Blunsom"], "related_topics": ["53893814", "130597682", "98199350"], "citation_count": "1282", "reference_count": "18", "references": ["2146502635", "2117130368", "179875071", "2132339004", "1889268436", "2171928131", "2251222643", "2103305545", "2006969979", "196214544"], "date": "2013"}, {"id": "2145072179", "title": "PCA-SIFT: a more distinctive representation for local image descriptors", "abstract": "Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.", "authors": ["Yan Ke", "R. Sukthankar"], "related_topics": ["186926958", "126422989", "52779249"], "citation_count": "4922", "reference_count": "17", "references": ["2151103935", "2124386111", "2177274842", "1902027874", "2154422044", "2148694408", "2119747362", "2111308925", "2098693229", "1541642243"], "date": "2004"}, {"id": "2153791616", "title": "Whatever next? Predictive brains, situated agents, and the future of cognitive science", "abstract": "Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this \"hierarchical prediction machine\" approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.", "authors": ["Andy Clark"], "related_topics": ["2778032263", "2780891288", "26760741"], "citation_count": "3932", "reference_count": "350", "references": ["2136922672", "2100495367", "2072128103", "2116064496", "1652505363", "2049633694", "2029949252", "2085529605", "2145889472", "1983578042"], "date": "2013"}, {"id": "1986913017", "title": "An example-based mapping method for text categorization and retrieval", "abstract": "A unified model for text categorization and text retrieval is introduced. We use a training set of manually categorized documents to learn word-category associations, and use these associations to predict the categories of arbitrary documents. Similarly, we use a training set of queries and their related documents to obtain empirical associations between query words and indexing terms of documents, and use these associations to predict the related documents of arbitrary queries. A Linear Least Squares Fit (LLSF) technique is employed to estimate the likelihood of these associations. Document collections from the MEDLINE database and Mayo patient records are used for studies on the effectiveness of our approach, and on how much the effectiveness depends on the choices of training data, indexing language, word-weighting scheme, and morphological canonicalization. Alternative methods are also tested on these data collections for comparison. It is evident that the LLSF approach uses the relevance information effectively within human decisions of categorization and retrieval, and achieves a semantic mapping of free texts to their representations in an indexing language. Such a semantic mapping lead to a significant improvement in categorization and retrieval, compared to alternative approaches.", "authors": ["Yiming Yang", "Christopher G. Chute"], "related_topics": ["2775955345", "87546605", "94124525"], "citation_count": "714", "reference_count": "18", "references": ["2798909945", "2147152072", "1833785989", "2000672666", "2075665712", "133977063", "2071106922", "1520963883", "2028962062", "2090756040"], "date": "1994"}, {"id": "2100406636", "title": "Database mining: a performance perspective", "abstract": "The authors' perspective of database mining as the confluence of machine learning techniques and the performance emphasis of database technology is presented. Three classes of database mining problems involving classification, associations, and sequences are described. It is argued that these problems can be uniformly viewed as requiring discovery of rules embedded in massive amounts of data. A model and some basic operations for the process of rule discovery are described. It is shown how the database mining problems considered map to this model, and how they can be solved by using the basic operations proposed. An example is given of an algorithm for classification obtained by combining the basic rule discovery operations. This algorithm is efficient in discovering classification rules and has accuracy comparable to ID3, one of the best current classifiers. >", "authors": ["R. Agrawal", "T. Imielinski", "A. Swami"], "related_topics": ["148840519", "30775581", "120567893"], "citation_count": "2314", "reference_count": "16", "references": ["1594031697", "2149706766", "2042264548", "1601529450", "1556507321", "1487801850", "1787564306", "2128420091", "1992810975", "1893597428"], "date": "1993"}, {"id": "2141870784", "title": "Numerical solution of saddle point problems", "abstract": "Large linear systems of saddle point type arise in a wide variety of applications throughout computational science and engineering. Due to their indefiniteness and often poor spectral properties, such linear systems represent a significant challenge for solver developers. In recent years there has been a surge of interest in saddle point problems, and numerous solution techniques have been proposed for this type of system. The aim of this paper is to present and discuss a large selection of solution methods for linear systems in saddle point form, with an emphasis on iterative methods for large and sparse problems.", "authors": ["Michele Benzi", "Gene H. Golub", "J\u00f6rg Liesen"], "related_topics": ["2681867", "94766913", "2778770139"], "citation_count": "2466", "reference_count": "484", "references": ["3029645440", "2798909945", "2610857016", "2124192278", "1669104078", "2077658674", "1852082788", "2010315317", "1967011851", "1548589512"], "date": "2005"}, {"id": "2151795416", "title": "On the achievable throughput of a multiantenna Gaussian broadcast channel", "abstract": "A Gaussian broadcast channel (GBC) with r single-antenna receivers and t antennas at the transmitter is considered. Both transmitter and receivers have perfect knowledge of the channel. Despite its apparent simplicity, this model is, in general, a nondegraded broadcast channel (BC), for which the capacity region is not fully known. For the two-user case, we find a special case of Marton's (1979) region that achieves optimal sum-rate (throughput). In brief, the transmitter decomposes the channel into two interference channels, where interference is caused by the other user signal. Users are successively encoded, such that encoding of the second user is based on the noncausal knowledge of the interference caused by the first user. The crosstalk parameters are optimized such that the overall throughput is maximum and, surprisingly, this is shown to be optimal over all possible strategies (not only with respect to Marton's achievable region). For the case of r>2 users, we find a somewhat simpler choice of Marton's region based on ordering and successively encoding the users. For each user i in the given ordering, the interference caused by users j>i is eliminated by zero forcing at the transmitter, while interference caused by users j<i is taken into account by coding for noncausally known interference. Under certain mild conditions, this scheme is found to be throughput-wise asymptotically optimal for both high and low signal-to-noise ratio (SNR). We conclude by providing some numerical results for the ergodic throughput of the simplified zero-forcing scheme in independent Rayleigh fading.", "authors": ["G. Caire", "S. Shamai"], "related_topics": ["2780186295", "97744766", "56985126"], "citation_count": "2947", "reference_count": "48", "references": ["2137775453", "2130509920", "2099111195", "2610857016", "2161872841", "1989225545", "2098257210", "2116485279", "391578156", "2111992817"], "date": "2003"}, {"id": "2090756040", "title": "An application of least squares fit mapping to text information retrieval", "abstract": "This paper describes a unique example-based mapping method for document retrieval. We discovered that the knowledge about relevance among queries and documents can be used to obtain empirical connections between query terms and the canonical concepts which are used for indexing the content of documents. These connections do not depend on whether there are shared terms among the queries and documents; therefore, they are especially effective for a mapping from queries to the documents where the concepts are relevant but the terms used by article authors happen to be different from the terms of database users. We employ a Linear Least Squares Fit (LLSF) technique to compute such connections from a collection of queries and documents where the relevance is assigned by humans, and then use these connections in the retrieval of documents where the relevance is unknown. We tested this method on both retrieval and indexing with a set of MEDLINE documents which has been used by other information retrieval systems for evaluations. The effectiveness of the LLSF mapping and the significant improvement over alternative approaches was evident in the tests.", "authors": ["Yiming Yang", "Christopher G. Chute"], "related_topics": ["87546605", "189430467", "89686163"], "citation_count": "76", "reference_count": "10", "references": ["2075665712", "133977063", "2071106922", "2092616252", "111308826", "1858816702", "2028250954", "873522368", "1805475080", "1558785097"], "date": "1993"}, {"id": "2118434577", "title": "Addressing the Rare Word Problem in Neural Machine Translation", "abstract": "Neural Machine Translation (NMT) is a new approach to machine translation that has shown promising results that are comparable to traditional approaches. A significant weakness in conventional NMT systems is their inability to correctly translate very rare words: end-to-end NMTs tend to have relatively small vocabularies with a single unk symbol that represents every possible out-of-vocabulary (OOV) word. In this paper, we propose and implement an effective technique to address this problem. We train an NMT system on data that is augmented by the output of a word alignment algorithm, allowing the NMT system to emit, for each OOV word in the target sentence, the position of its corresponding word in the source sentence. This information is later utilized in a post-processing step that translates every OOV word using a dictionary. Our experiments on the WMT\u201914 English to French translation task show that this method provides a substantial improvement of up to 2.8 BLEU points over an equivalent NMT system that does not use this technique. With 37.5 BLEU points, our NMT system is the first to surpass the best result achieved on a WMT\u201914 contest task.", "authors": ["Thang Luong", "Ilya Sutskever", "Quoc Le", "Oriol Vinyals", "Wojciech Zaremba"], "related_topics": ["203005215", "90988201", "61249035"], "citation_count": "711", "reference_count": "18", "references": ["2964308564", "2130942839", "2157331557", "2101105183", "1753482797", "1810943226", "2124807415", "1815076433", "2153653739", "2100664567"], "date": "2015"}, {"id": "2110325612", "title": "Empirical analysis of predictive algorithms for collaborative filtering", "abstract": "Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods. We compare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evaluation metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second estimates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommendation in an ordered list. Experiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metr rics for the various algorithms. Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector-similarity methods. Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other considerations include the size of database, speed of predictions, and learning time.", "authors": ["John S. Breese", "David Heckerman", "Carl Kadie"], "related_topics": ["557471498", "21569690", "2780213525"], "citation_count": "6364", "reference_count": "11", "references": ["3121531027", "2049633694", "1956559956", "2341865734", "1524704912", "2066590388", "1567331820", "1864566053", "2031636842", "1557657228"], "date": "1998"}, {"id": "2103626435", "title": "Practical Issues in Temporal Difference Learning", "abstract": "This paper examines whether temporal difference methods for training connectionist networks, such as Sutton's TD(\u03bb) algorithm, can be successfully applied to complex real-world problems. A number of important practical issues are identified and discussed from a general theoretical perspective. These practical issues are then examined in the context of a case study in which TD(\u03bb) is applied to learning the game of backgammon from the outcome of self-play. This is apparently the first application of this algorithm to a complex non-trivial task. It is found that, with zero knowledge built in, the network is able to learn from scratch to play the entire game at a fairly strong intermediate level of performance, which is clearly better than conventional commercial programs, and which in fact surpasses comparable networks trained on a massive human expert data set. This indicates that TD learning may work better in practice than one would expect based on current theory, and it suggests that further analysis of TD methods, as well as applications in other complex domains, may be worth investigating.", "authors": ["Gerald Tesauro"], "related_topics": ["196340769", "148220186", "2780049985"], "citation_count": "1569", "reference_count": "28", "references": ["2154642048", "1652505363", "2137983211", "3146803896", "2100677568", "2178806388", "1583833196", "2154952480", "2159047538", "1569296262"], "date": "1992"}, {"id": "1996283866", "title": "Analysis of recommendation algorithms for e-commerce", "abstract": "ABSTRACT Re ommender systems apply statisti al and knowledge disovery te hniques to the problem of making produ t re ommendations during a live ustomer intera tion and they are a hieving widespread su ess in E-Commer e nowadays. In this paper, we investigate several te hniques for analyzing large-s ale pur hase and preferen e data for the purpose of produ ing useful re ommendations to ustomers. In parti ular, we apply a olle tion of algorithms su h as traditional data mining, nearest-neighbor ollaborative ltering, and dimensionality redu tion on two di erent data sets. The rst data set was derived from the web-pur hasing transa tion of a large Eommer e ompany whereas the se ond data set was olle ted from MovieLens movie re ommendation site. For the experimental purpose, we divide the re ommendation generation pro ess into three sub pro esses{ representation of input data, neighborhood formation, and re ommendation generation. We devise di erent te hniques for di erent sub pro esses and apply their ombinations on our data sets to ompare for re ommendation quality and performan e.", "authors": ["Badrul Sarwar", "George Karypis", "Joseph Konstan", "John Riedl"], "related_topics": ["2776156558", "78597825", "41008148"], "citation_count": "2809", "reference_count": "30", "references": ["1484413656", "2110325612", "2064853889", "1506285740", "2147152072", "3121531027", "2085937320", "2124591829", "1966553486", "1999047234"], "date": "2000"}, {"id": "2133665775", "title": "Image quality assessment: from error visibility to structural similarity", "abstract": "Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.", "authors": ["Zhou Wang", "A.C. Bovik", "H.R. Sheikh", "E.P. Simoncelli"], "related_topics": ["55020928", "114227958", "160086991"], "citation_count": "33167", "reference_count": "53", "references": ["2159269332", "2142276208", "2118217749", "2053691921", "2153777140", "2912116903", "2107790757", "2158564760", "2124731682", "2115838129"], "date": "2004"}, {"id": "1981420413", "title": "Bigtable: A Distributed Storage System for Structured Data", "abstract": "Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Finance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this article, we describe the simple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we describe the design and implementation of Bigtable.", "authors": ["Fay Chang", "Jeffrey Dean", "Sanjay Ghemawat", "Wilson C. Hsieh", "Deborah A. Wallach", "Mike Burrows", "Tushar Chandra", "Andrew Fikes", "Robert E. Gruber"], "related_topics": ["24885549", "133501362", "2779599972"], "citation_count": "9792", "reference_count": "37", "references": ["2173213060", "2158049821", "1981420413", "2119565742", "2167898414", "2163059190", "1650675509", "2119714163", "3138367763", "3021428210"], "date": "2008"}, {"id": "2102201073", "title": "Multivariate Adaptive Regression Splines", "abstract": "A new method is presented for flexible regression modeling of high dimensional data. The model takes the form of an expansion in product spline basis functions, where the number of basis functions as well as the parameters associated with each one (product degree and knot locations) are automatically determined by the data. This procedure is motivated by the recursive partitioning approach to regression and shares its attractive properties. Unlike recursive partitioning, however, this method produces continuous models with continuous derivatives. It has more power and flexibility to model relationships that are nearly additive or involve interactions in at most a few variables. In addition, the model can be represented in a form that separately identifies the additive contributions and those associated with the different multivariable interactions.", "authors": ["Jerome H. Friedman"], "related_topics": ["44882253", "74127309", "137345334"], "citation_count": "9131", "reference_count": "31", "references": ["2798909945", "1594031697", "2146766088", "2162870748", "2017977879", "133977063", "2091886411", "2040615655", "3000332379", "2082102453"], "date": "1991"}, {"id": "2119747362", "title": "Indexing based on scale invariant interest points", "abstract": "This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images.", "authors": ["K. Mikolajczyk", "C. Schmid"], "related_topics": ["6408098", "27434737", "99102927"], "citation_count": "1792", "reference_count": "14", "references": ["2124386111", "2124087378", "2109200236", "2165497495", "1991605728", "2109863423", "2132332894", "2143753158", "134171312", "1494702534"], "date": "2001"}, {"id": "2217896605", "title": "Neural network-based face detection", "abstract": "We present a neural network-based upright frontal face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We present a straightforward procedure for aligning positive face examples for training. To collect negative examples, we use a bootstrap algorithm, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting nonface training examples, which must be chosen to span the entire space of nonface images. Simple heuristics, such as using the fact that faces rarely overlap in images, can further improve the accuracy. Comparisons with several other state-of-the-art face detection systems are presented, showing that our system has comparable performance in terms of detection and false-positive rates.", "authors": ["H.A. Rowley", "S. Baluja", "T. Kanade"], "related_topics": ["4641261", "71681937", "31510193"], "citation_count": "6478", "reference_count": "46", "references": ["2139212933", "2981264952", "2133671888", "2124351082", "2147800946", "2098947662", "1997011019", "2173629880", "2042371054", "2159173611"], "date": "1997"}, {"id": "1965770722", "title": "Consistent inference of probabilities in layered networks: predictions and generalizations", "abstract": "The problem of learning a general input-output relation using a layered neural network is discussed in a statistical framework. By imposing the consistency condition that the error minimization be equivalent to a likelihood maximization for training the network, the authors arrive at a Gibbs distribution on a canonical ensemble of networks with the same architecture. This statistical description enables them to evaluate the probability of a correct prediction of an independent example, after training the network on a given training set. The prediction probability is highly correlated with the generalization ability of the network, as measured outside the training set. This suggests a general and practical criterion for training layered networks by minimizing prediction errors. The authors demonstrate the utility of this criterion for selecting the optimal architecture in the continuity problem. As a theoretical application of the statistical formalism, they discuss the question of learning curves and estimate the sufficient training size needed for correct generalization, in a simple example. >", "authors": ["Tishby", "Levin", "Solla"], "related_topics": ["136389625", "177148314", "50644808"], "citation_count": "202", "reference_count": "12", "references": ["2581275558", "2293063825", "1593125407", "56903235", "1968908999", "2012903341", "2123838014", "2043014754", "2476694670", "2161278885"], "date": "1988"}, {"id": "2913535645", "title": "Proximal Algorithms", "abstract": "This monograph is about a class of optimization algorithms called proximal algorithms. Much like Newton's method is a standard tool for solving unconstrained smooth optimization problems of modest size, proximal algorithms can be viewed as an analogous tool for nonsmooth, constrained, large-scale, or distributed versions of these problems. They are very generally applicable, but are especially well-suited to problems of substantial recent interest involving large or high-dimensional datasets. Proximal methods sit at a higher level of abstraction than classical algorithms like Newton's method: the base operation is evaluating the proximal operator of a function, which itself involves solving a small convex optimization problem. These subproblems, which generalize the problem of projecting a point onto a convex set, often admit closed-form solutions or can be solved very quickly with standard or simple specialized methods. Here, we discuss the many different interpretations of proximal operators and algorithms, describe their connections to many other topics in optimization and applied mathematics, survey some popular algorithms, and provide a large number of examples of proximal operators that commonly arise in practice.", "authors": ["Neal Parikh", "Stephen Boyd"], "related_topics": ["137836250", "157972887", "49870271"], "citation_count": "3496", "reference_count": "182", "references": ["2296319761", "2164278908", "3029645440", "2100556411", "2135046866", "2122825543", "2078204800", "3141595720", "2103972604", "2138019504"], "date": "2013"}, {"id": "2171277043", "title": "Fast learning in networks of locally-tuned processing units", "abstract": "We propose a network architecture which uses a single internal layer of locally-tuned processing units to learn both classification tasks and real-valued function approximations (Moody and Darken 1988). We consider training such networks in a completely supervised manner, but abandon this approach in favor of a more computationally efficient hybrid learning method which combines self-organized and supervised learning. Our networks learn faster than backpropagation for two reasons: the local representations ensure that only a few units respond to any given input, thus reducing computational overhead, and the hybrid learning rules are linear rather than nonlinear, thus leading to faster convergence. Unlike many existing methods for data analysis, our network architecture and learning rules are truly adaptive and are thus appropriate for real-time use.", "authors": ["John Moody", "Christian J. Darken"], "related_topics": ["58973888", "8038995", "120822770"], "citation_count": "6337", "reference_count": "20", "references": ["2042264548", "2143956139", "2150593711", "23758216", "2084544490", "1524100745", "2127218421", "2034099719", "2072773743", "2007700211"], "date": "1989"}, {"id": "2134557905", "title": "Learning methods for generic object recognition with invariance to pose and lighting", "abstract": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second.", "authors": ["Y. LeCun", "Fu Jie Huang", "L. Bottou"], "related_topics": ["2776151529", "124504099", "12267149"], "citation_count": "1467", "reference_count": "28", "references": ["2164598857", "2310919327", "2217896605", "2124087378", "2124351082", "2123977795", "2155511848", "2160225842", "2295106276", "2141376824"], "date": "2004"}, {"id": "2104993419", "title": "Interactive analytical processing in big data systems: a cross-industry study of MapReduce workloads", "abstract": "Within the past few years, organizations in diverse industries have adopted MapReduce-based systems for large-scale data processing. Along with these new users, important new workloads have emerged which feature many small, short, and increasingly interactive jobs in addition to the large, long-running batch jobs for which MapReduce was originally designed. As interactive, large-scale query processing is a strength of the RDBMS community, it is important that lessons from that field be carried over and applied where possible in this new domain. However, these new workloads have not yet been described in the literature. We fill this gap with an empirical analysis of MapReduce traces from six separate business-critical deployments inside Facebook and at Cloudera customers in e-commerce, telecommunications, media, and retail. Our key contribution is a characterization of new MapReduce workloads which are driven in part by interactive analysis, and which make heavy use of query-like programming frameworks on top of MapReduce. These workloads display diverse behaviors which invalidate prior assumptions about MapReduce such as uniform data access, regular diurnal patterns, and prevalence of large jobs. A secondary contribution is a first step towards creating a TPC-like data processing benchmark for MapReduce.", "authors": ["Yanpei Chen", "Sara Alspaugh", "Randy Katz"], "related_topics": ["75684735", "47487241", "180198813"], "citation_count": "642", "reference_count": "44", "references": ["2173213060", "1995945562", "2130531694", "2055176966", "2114303224", "2164740236", "2105818147", "2163961697", "2110086534", "2112053513"], "date": "2012"}, {"id": "2117084652", "title": "Fast Approximate Search in Large Dictionaries", "abstract": "The need to correct garbled strings arises in many areas of natural language processing. If a dictionary is available that covers all possible input tokens, a natural set of candidates for correcting an erroneous input P is the set of all words in the dictionary for which the Levenshtein distance to P does not exceed a given (small) bound k. In this article we describe methods for efficiently selecting such candidate sets. After introducing as a starting point a basic correction method based on the concept of a \"universal Levenshtein automaton,\" we show how two filtering methods known from the field of approximate text search can be used to improve the basic procedure in a significant way. The first method, which uses standard dictionaries plus dictionaries with reversed words, leads to very short correction times for most classes of input strings. Our evaluation results demonstrate that correction times for fixed-distance bounds depend on the expected number of correction candidates, which decreases for longer input words. Similarly the choice of an optimal filtering method depends on the length of the input words.", "authors": ["Stoyan Mihov", "Klaus U. Schulz"], "related_topics": ["82508861", "2777515626", "20228898"], "citation_count": "108", "reference_count": "46", "references": ["2001496424", "2002089154", "2045821558", "2010595692", "1515839227", "1970026646", "1563342424", "2043481183", "1487429615", "2154478838"], "date": "2004"}, {"id": "2106285343", "title": "Approximating the permanent", "abstract": "A randomised approximation scheme for the permanent of a 0\u20131s presented. The task of estimating a permanent is reduced to that of almost uniformly generating perfect matchings in a graph; the latter is accomplished by simulating a Markov chain whose states are the matchings in the graph. For a wide class of 0\u20131 matrices the approximation scheme is fully-polynomial, i.e., runs in time polynomial in the size of the matrix and a parameter that controls the accuracy of the output. This class includes all dense matrices (those that contain sufficiently many 1\u2019s) and almost all sparse matrices in some reasonable probabilistic model for 0\u20131 matrices of given density.For the approach sketched above to be computationally efficient, the Markov chain must be rapidly mixing: informally, it must converge in a short time to its stationary distribution. A major portion of the paper is devoted to demonstrating that the matchings chain is rapidly mixing, apparently the first such result for a Markov chain with genuinely c...", "authors": ["M. Jerrum", "Alistair Sinclair"], "related_topics": ["97074811", "98763669", "2780878606"], "citation_count": "1069", "reference_count": "17", "references": ["2905110430", "2005228957", "2072211488", "2047422346", "2157211828", "1552744309", "2113750873", "2074599161", "2046097442", "2058699951"], "date": "1989"}, {"id": "2127785456", "title": "Short and tweet: experiments on recommending content from information streams", "abstract": "More and more web users keep up with newest information through information streams such as the popular micro-blogging website Twitter. In this paper we studied content recommendation on Twitter to better direct user attention. In a modular approach, we explored three separate dimensions in designing such a recommender: content sources, topic interest models for users, and social voting. We implemented 12 recommendation engines in the design space we formulated, and deployed them to a recommender service on the web to gather feedback from real Twitter users. The best performing algorithm improved the percentage of interesting content to 72% from a baseline of 33%. We conclude this work by discussing the implications of our recommender design and how our design can generalize to other information streams.", "authors": ["Jilin Chen", "Rowan Nairn", "Les Nelson", "Michael Bernstein", "Ed Chi"], "related_topics": ["557471498", "171686336", "136764020"], "citation_count": "557", "reference_count": "20", "references": ["2046804949", "1999047234", "2043403353", "1978394996", "2123427850", "2158515176", "2161443453", "1602359996", "2127480961", "2049670925"], "date": "2010"}, {"id": "1639032689", "title": "Genetic algorithms in search, optimization, and machine learning", "abstract": "From the Publisher: This book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. Major concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required.", "authors": ["David E. Goldberg"], "related_topics": ["6135463", "110332635", "94176051"], "citation_count": "106990", "reference_count": "0", "references": ["1992419399", "2165299997", "2097571405", "2106334424", "2168081761", "2017337590", "1999284878", "2167101736", "2165171393", "1501500081"], "date": "1988"}, {"id": "2164252468", "title": "Methods and apparatuses for operating a portable device based on an accelerometer", "abstract": "Methods and apparatuses for operating a portable device based on an accelerometer are described. According to one embodiment of the invention, an accelerometer attached to a portable device detects a movement of the portable device. In response, a machine executable code is executed within the portable device to perform one or more predetermined user configurable operations. Other methods and apparatuses are also described.", "authors": ["Paul J. Wehrenberg", "Aaron Leiba", "Richard C. Williams", "David R. Falkenburg", "Louis G. Gerbarg", "Ray L. Chang"], "related_topics": ["105671743", "160145156", "89805583"], "citation_count": "1348", "reference_count": "120", "references": ["2914950297", "2108025625", "2816441015", "1870503919", "1927836086", "2170781632", "1851518015", "2735289931", "3148502694", "2122532234"], "date": "2010"}, {"id": "2077658674", "title": "Practical Methods of Optimization", "abstract": "Preface Table of Notation Part 1: Unconstrained Optimization Introduction Structure of Methods Newton-like Methods Conjugate Direction Methods Restricted Step Methods Sums of Squares and Nonlinear Equations Part 2: Constrained Optimization Introduction Linear Programming The Theory of Constrained Optimization Quadratic Programming General Linearly Constrained Optimization Nonlinear Programming Other Optimization Problems Non-Smooth Optimization References Subject Index.", "authors": ["Roger Fletcher"], "related_topics": ["92995354", "29282572", "81845259"], "citation_count": "14091", "reference_count": "0", "references": ["2139212933", "2120145199", "1964357740", "2123871098", "1596717185", "2614081736", "2030723843", "1804110266", "1993170675", "2186428165"], "date": "1988"}, {"id": "2121947440", "title": "Normalized cuts and image segmentation", "abstract": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging.", "authors": ["Jianbo Shi", "J. Malik"], "related_topics": ["124504099", "105611402", "42314347"], "citation_count": "19516", "reference_count": "25", "references": ["2121947440", "2798909945", "1578099820", "1997063559", "1971784203", "2114487471", "2913192828", "2114030927", "2132603077", "100944330"], "date": "2000"}, {"id": "1864566053", "title": "A Bayesian approach to learning Bayesian networks with local structure", "abstract": "Recently several researchers have investigated techniques for using data to learn Bayesian networks containing compact representations for the conditional probability distributions (CPDs) stored at each node. The majority of this work has concentrated on using decision-tree representations for the CPDs. In addition, researchers typically apply non-Bayesian (or asymptotically Bayesian) scoring functions such as MDL to evaluate the goodness-of-fit of networks to the data. In this paper we investigate a Bayesian approach to learning Bayesian networks that contain the more general decision-graph representations of the CPDs. First, we describe how to evaluate the posterior probability-- that is, the Bayesian score--of such a network, given a database of observed cases. Second, we describe various search spaces that can be used, in conjunction with a scoring function and a search procedure, to identify one or more high-scoring networks. Finally, we present an experimentd evaluation of the search spaces, using a greedy algorithm and a Bayesian scoring function.", "authors": ["David Maxwell Chickering", "David Heckerman", "Christopher Meek"], "related_topics": ["101112237", "71983512", "33724603"], "citation_count": "520", "reference_count": "11", "references": ["1594031697", "2170112109", "2008906462", "1840338487", "2069469807", "1530964327", "1544444076", "1698663318", "1547246444", "1505477995"], "date": "1997"}, {"id": "2143503258", "title": "Learning state space trajectories in recurrent neural networks", "abstract": "Many neural network learning procedures compute gradients of the errors on the output layer of units after they have settled to their final values. We describe a procedure for finding E/wij, where E is an error functional of the temporal trajectory of the states of a continuous recurrent network and wij are the weights of that network. Computing these quantities allows one to perform gradient descent in the weights to minimize E. Simulations in which networks are taught to move through limit cycles are shown. This type of recurrent network seems particularly suited for temporally continuous domains, such as signal processing, control, and speech.", "authors": ["Barak A. Pearlmutter"], "related_topics": ["172025690", "147168706", "175202392"], "citation_count": "997", "reference_count": "14", "references": ["2581275558", "2154642048", "1597286183", "2173629880", "2016589492", "1507849272", "2007431958", "1971129545", "1959983357", "3121926921"], "date": "1989"}, {"id": "2074350771", "title": "Vocabulary in Language Teaching", "abstract": "Internationally recognised as one of the leading texts in its field, this volume offers a comprehensive introduction to vocabulary for language teachers who would like to know more about the way vocabulary works. Two leading specialists make research and theory accessible, providing the background knowledge necessary for practitioners to make informed choices about vocabulary teaching and testing. This second edition retains the popular format of the first edition, and has been rewritten to take account of the many developments in the past 20 years. There is a greater focus on the vocabulary learning process, with new chapters on incidental learning, and intentional learning, and a new wide-ranging discussion of formulaic language. The book now also includes extensive treatment of word lists and vocabulary tests, with explanations of their various strengths and limitations. Updated further reading sections, and new Exercises for Expansion make this volume more invaluable than ever.", "authors": ["Norbert Schmitt"], "related_topics": ["2777601683", "2910970233", "123960582"], "citation_count": "4164", "reference_count": "129", "references": ["2145713659", "1975978582", "2008457707", "2105933041", "1990451873", "2023928173", "2013596317", "773929776", "2063765880", "2001528051"], "date": "1999"}, {"id": "2053186076", "title": "Nonlinear dimensionality reduction by locally linear embedding.", "abstract": "Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.", "authors": ["Sam T. Roweis", "Lawrence K. Saul"], "related_topics": ["55128770", "70518039", "2778344778"], "citation_count": "16334", "reference_count": "12", "references": ["1902027874", "2610857016", "1991848143", "2107636931", "2121122425", "2122538988", "2047870719", "2070320140", "1513400187", "2019020850"], "date": "2000"}, {"id": "1982944197", "title": "Stochastic lexicalized tree-adjoining grammars", "abstract": "The notion of stochastic lexicalized tree-adjoining grammar (SLTAG) is formally defined. The parameters of a SLTAG correspond to the probability of combining two structures each one associated with a word. The characteristics of SLTAG are unique and novel since it is lexieally sensitive (as N-gram models or Hidden Markov Models) and yet hierarchical (as stochastic context-free grammars).Then, two basic algorithms for SLTAG arc introduced: an algorithm for computing the probability of a sentence generated by a SLTAG and an inside-outside-like iterative algorithm for estimating the parameters of a SLTAG given a training corpus.Finally, we should how SLTAG enables to define a lexicalized version of stochastic context-free grammars and we report preliminary experiments showing some of the advantages of SLTAG over stochastic context-free grammars.", "authors": ["Yves Schabes"], "related_topics": ["199624470", "134083981", "67621940"], "citation_count": "202", "reference_count": "16", "references": ["2439178139", "1995875735", "2077302143", "1978470410", "1541301615", "2131986285", "2047706513", "2153198088", "1526927911", "1504046386"], "date": "1992"}, {"id": "2010392031", "title": "Approximate String Matching", "abstract": "Approximate matching of strings is reviewed with the aim of surveying techniques suitable for finding an item in a database when there may be a spelling mistake or other error in the keyword. The methods found are classified as either equivalence or similarity problems. Equivalence problems are seen to be readily solved using canonical forms. For sinuiarity problems difference measures are surveyed, with a full description of the wellestablmhed dynamic programming method relating this to the approach using probabilities and likelihoods. Searches for approximate matches in large sets using a difference function are seen to be an open problem still, though several promising ideas have been suggested. Approximate matching (error correction) during parsing is briefly reviewed.", "authors": ["Patrick A. V. Hall", "Geoff R. Dowling"], "related_topics": ["32610155", "72545166", "22820288"], "citation_count": "855", "reference_count": "66", "references": ["1985108724", "2099964107", "1970026646", "2051768896", "2161694911", "2134826720", "1600795850", "1817451992", "1647671624", "1986022261"], "date": "1980"}, {"id": "2156909104", "title": "The Nature of Statistical Learning Theory", "abstract": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?.", "authors": ["Vladimir N. Vapnik"], "related_topics": ["32254414", "2779915298", "50292564"], "citation_count": "67802", "reference_count": "0", "references": ["2140190241", "2148603752", "2164278908", "2310919327", "2076063813", "2129812935", "1746819321", "1570448133", "2072128103", "2139212933"], "date": "1994"}, {"id": "1815076433", "title": "On the difficulty of training recurrent neural networks", "abstract": "There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.", "authors": ["Razvan Pascanu", "Tomas Mikolov", "Yoshua Bengio"], "related_topics": ["147168706", "79379906", "154945302"], "citation_count": "4011", "reference_count": "23", "references": ["2146502635", "2064675550", "1498436455", "1606347560", "196214544", "2110485445", "2171865010", "2122585011", "2118706537", "2107878631"], "date": "2013"}, {"id": "2078204800", "title": "Atomic Decomposition by Basis Pursuit", "abstract": "The time-frequency and time-scale communities have recently developed a large number of overcomplete waveform dictionaries---stationary wavelets, wavelet packets, cosine packets, chirplets, and warplets, to name a few. Decomposition into overcomplete systems is not unique, and several methods for decomposition have been proposed, including the method of frames (MOF), matching pursuit (MP), and, for special dictionaries, the best orthogonal basis (BOB). Basis pursuit (BP) is a principle for decomposing a signal into an \"optimal\"' superposition of dictionary elements, where optimal means having the smallest l1 norm of coefficients among all such decompositions. We give examples exhibiting several advantages over MOF, MP, and BOB, including better sparsity and superresolution. BP has interesting relations to ideas in areas as diverse as ill-posed problems, abstract harmonic analysis, total variation denoising, and multiscale edge denoising. BP in highly overcomplete dictionaries leads to large-scale optimization problems. With signals of length 8192 and a wavelet packet dictionary, one gets an equivalent linear program of size 8192 by 212,992. Such problems can be attacked successfully only because of recent advances in linear and quadratic programming by interior-point methods. We obtain reasonable success with a primal-dual logarithmic barrier method and conjugate-gradient solver.", "authors": ["Scott Shaobing Chen", "David L. Donoho", "Michael A. Saunders"], "related_topics": ["99217422", "649245", "155777637"], "citation_count": "24846", "reference_count": "43", "references": ["2062024414", "2798909945", "2146842127", "2099641086", "2151693816", "2103559027", "2152328854", "2156447271", "2611147814", "2128659236"], "date": "2000"}, {"id": "2116064496", "title": "Training products of experts by minimizing contrastive divergence", "abstract": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual \"expert\" models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called \"contrastive divergence\" whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.", "authors": ["Geoffrey E. Hinton"], "related_topics": ["123757993", "97385483", "79772020"], "citation_count": "5201", "reference_count": "23", "references": ["1652505363", "1997063559", "2096175520", "1746680969", "1993845689", "2165225968", "2083380015", "2114153178", "1547224907", "2101706260"], "date": "2002"}, {"id": "2123427850", "title": "Google news personalization: scalable online collaborative filtering", "abstract": "Several approaches to collaborative filtering have been studied but seldom have studies been reported for large (several millionusers and items) and dynamic (the underlying item set is continually changing) settings. In this paper we describe our approach to collaborative filtering for generating personalized recommendations for users of Google News. We generate recommendations using three approaches: collaborative filtering using MinHash clustering, Probabilistic Latent Semantic Indexing (PLSI), and covisitation counts. We combine recommendations from different algorithms using a linear model. Our approach is content agnostic and consequently domain independent, making it easily adaptable for other applications and languages with minimal effort. This paper will describe our algorithms and system setup in detail, and report results of running the recommendations engine on Google News.", "authors": ["Abhinandan S. Das", "Mayur Datar", "Ashutosh Garg", "Shyam Rajaram"], "related_topics": ["21569690", "183003079", "112933361"], "citation_count": "1969", "reference_count": "23", "references": ["2173213060", "1880262756", "2171960770", "1981420413", "1563088657", "2042281163", "2110325612", "3121531027", "2147717514", "2295428206"], "date": "2007"}, {"id": "2048330959", "title": "Cooperative computation of stereo disparity", "abstract": "Perhaps one of the most striking differences between a brain and today\u2019s computers is the amount of \u201cwiring.\u201d In a digital computer the ratio of connections to components is about 3, whereas for the mammalian cortex it lies between 10 and 10,000 (1).", "authors": ["D. Marr", "T. Poggio"], "related_topics": ["45374587", "87868495", "2777348757"], "citation_count": "2307", "reference_count": "13", "references": ["2170716495", "1997494543", "2052810501", "2087895317", "2089840306", "1975068880", "1992476998", "1981520343", "2001963156", "1989544735"], "date": "1987"}, {"id": "3132971798", "title": "Ondelettes et Operateurs", "abstract": "", "authors": ["Y. Meyer"], "related_topics": ["33923547"], "citation_count": "3058", "reference_count": "0", "references": ["2158940042", "2151693816", "2004217976", "3005363104", "2040135606", "2066462711", "2096613063", "2041752335", "2168141504", "2004421506"], "date": "1989"}, {"id": "1904365287", "title": "Improving neural networks by preventing co-adaptation of feature detectors", "abstract": "When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.", "authors": ["Geoffrey E. Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R. Salakhutdinov"], "related_topics": ["2776145597", "7374053", "22019652"], "citation_count": "8061", "reference_count": "18", "references": ["2108598243", "2911964244", "3118608800", "2310919327", "2100495367", "2116064496", "2912934387", "2147768505", "1993882792", "4919037"], "date": "2012"}, {"id": "2056857971", "title": "Least squares formulation of robust non-negative factor analysis", "abstract": "Abstract Positive matrix factorization (PMF) is a recently published factor analytic technique where the left and right factor matrices (corresponding to scores and loadings) are constrained to non-negative values. The PMF model is a weighted least squares fit, weights based on the known standard deviations of the elements of the data matrix. The following aspects of PMF are discussed in this work: (1) Robust factorization (based on the Huber influence function) is achieved by iterative reweighting of individual data values. This appears especially useful if individual data values may be in error. (2) Desired rotations may be obtained automatically with the help of suitably chosen regularization terms. (3) The algorithms for PMF are discussed. A synthetic spectroscopic example is shown, demonstrating both the robust processing and the automatic rotations.", "authors": ["Pentti Paatero"], "related_topics": ["176012381", "139018669", "187834632"], "citation_count": "2101", "reference_count": "10", "references": ["2059745395", "2012470056", "2163382882", "2033693394", "2022851313", "1579320743", "2031983382", "1511627810", "1582906485", "2006869732"], "date": "1997"}, {"id": "2151561903", "title": "Subject access in online catalogs: A design model", "abstract": "A model based on strikingly different philosophical as. sumptions from those currently popular is proposed for the design of online subject catalog access. Three design principles are presented and discussed: uncertainty (subject indexing is indeterminate and probabilistic beyond a certain point), variety (by Ashby\u2019s law of requisite variety, variety of searcher query must equal variety of document indexing), and complexity (the search process, particularly during the entry and orientation phases, is subtler and more complex, on several grounds, than current models assume). Design features presented are an access phase, including entry and orientation, a hunting phase, and a selection phase. An end-user thesaurus and a front-end system mind are presented as examples of online catalog system components to improve searcher success during entry and orientation. The proposed model is \u201cwrapped around\u201d existing Library of Congress subject-heading indexing in such a way as to enhance access greatly without requiring reindexing. It is argued that both for cost reasons and in principle this is a superior approach to other design philosophies.", "authors": ["Marcia J. Bates"], "related_topics": ["2778756484", "2778448390", "75165309"], "citation_count": "569", "reference_count": "56", "references": ["1969340322", "1530533107", "2993383518", "2111030512", "1964653871", "1521517187", "2315179971", "2011386395", "2006423836", "2110416104"], "date": "1986"}, {"id": "1549285799", "title": "Statistical Language Modeling using the CMU-Cambridge Toolkit", "abstract": "", "authors": ["Philip Clarkson", "Ronald Rosenfeld"], "related_topics": ["179603123", "137293760", "41008148"], "citation_count": "971", "reference_count": "0", "references": ["2153653739", "1631260214", "1916559533", "2143017621", "2142069714", "2158195707", "2134800885", "2159981908", "2116316001", "2016243284"], "date": "1996"}, {"id": "3119786062\n", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "abstract": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.", "authors": ["Alexey Dosovitskiy", "Lucas Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "Mostafa Dehghani", "Matthias Minderer", "Georg Heigold", "Sylvain Gelly", "Jakob Uszkoreit", "Neil Houlsby"], "related_topics": ["3117203110", "75294576", "31972630"], "citation_count": "315", "reference_count": "49", "references": ["2194775991", "2618530766", "2964121744", "2963341956", "2963403868", "1836465849", "2108598243", "3118608800", "2963091558", "3034978746"], "date": "2021"}, {"id": "2293807537", "title": "Optimal Filtering", "abstract": "", "authors": ["Brian D. O. Anderson", "John B. Moore", "Mansour Eslami"], "related_topics": ["41614226", "206833254", "157286648"], "citation_count": "8844", "reference_count": "0", "references": ["2137813581", "2126736494", "2161406034", "2137585588", "2110575115", "1578352865", "2166313543", "1883186006", "2119539043", "2012587148"], "date": "1982"}, {"id": "1994197834", "title": "An empirical evaluation of deep architectures on problems with many factors of variation", "abstract": "Recently, several learning algorithms relying on models with deep architectures have been proposed. Though they have demonstrated impressive performance, to date, they have only been evaluated on relatively simple problems such as digit recognition in a controlled environment, for which many machine learning algorithms already report reasonable results. Here, we present a series of experiments which indicate that these models show promise in solving harder learning problems that exhibit many factors of variation. These models are compared with well-established algorithms such as Support Vector Machines and single hidden-layer feed-forward neural networks.", "authors": ["Hugo Larochelle", "Dumitru Erhan", "Aaron Courville", "James Bergstra", "Yoshua Bengio"], "related_topics": ["115903097", "24138899", "50292564"], "citation_count": "1061", "reference_count": "13", "references": ["2153635508", "2136922672", "2100495367", "2116064496", "2110798204", "2134557905", "2147800946", "2613634265", "2159737176", "2124914669"], "date": "2007"}, {"id": "2142416747", "title": "Application of Hidden Markov Models in Speech Recognition", "abstract": "Hidden Markov Models (HMMs) provide a simple and effective framework for modelling time-varying spectral vector sequences. As a consequence, almost all present day large vocabulary continuous speech recognition (LVCSR) systems are based on HMMs. Whereas the basic principles underlying HMM-based LVCSR are rather straightforward, the approximations and simplifying assumptions involved in a direct implementation of these principles would result in a system which has poor accuracy and unacceptable sensitivity to changes in operating environment. Thus, the practical application of HMMs in modern systems involves considerable sophistication. The aim of this review is first to present the core architecture of a HMM-based LVCSR system and then describe the various refinements which are needed to achieve state-of-the-art performance. These refinements include feature projection, improved covariance modelling, discriminative parameter estimation, adaptation and normalisation, noise compensation and multi-pass system combination. The review concludes with a case study of LVCSR for Broadcast News and Conversation transcription in order to illustrate the techniques described.", "authors": ["Mark Gales", "Steve Young"], "related_topics": ["23224414", "204201278", "40608802"], "citation_count": "748", "reference_count": "186", "references": ["3124955340", "2125838338", "2112076978", "2049633694", "1770825568", "2121227244", "2146871184", "2100969003", "2002342963", "2046932483"], "date": "2008"}, {"id": "2115838129", "title": "Linear transform for simultaneous diagonalization of covariance and perceptual metric matrix in image coding", "abstract": "Two types ofredundancies are contained in images: statistical redundancy and psychovisual redundancy. Image representation techniques for image coding should remove both redundancies in order to obtain good results. In order to establish an appropriate representation, the standard approach to transform coding only considers the statistical redundancy, whereas the psychovisual factors are introduced after the selection ofthe representation as a simple scalar weighting in the transform domain. In this work, we take into account the psychovisual factors in the de8nition of the representation together with the statistical factors, by means of the perceptual metric and the covariance matrix, respectively. In general the ellipsoids described by these matrices are not aligned. Therefore, the optimal basis for image representation should simultaneously diagonalize both matrices. This approach to the basis selection problem has several advantages in the particular application ofimage coding. As the transform domain is Euclidean (by de8nition), the quantizer design is highly simpli8ed and at the same time, the use ofscalar quantizers is truly justi8ed. The proposed representation is compared to covariance-based representations such as the DCT and the KLT or PCA using standard JPEG-like and Max-Lloyd quantizers. ? 2003 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.", "authors": ["Irene Epifanio", "Jaime Gutierrez", "Jesus Malo"], "related_topics": ["169805256", "185142706", "178650346"], "citation_count": "28", "reference_count": "31", "references": ["1548802052", "2798909945", "2140196014", "1634005169", "2145889472", "3017143921", "2137234026", "2134383396", "98769269", "1500256440"], "date": "2003"}, {"id": "2002306339", "title": "Improving the effectiveness of information retrieval with local context analysis", "abstract": "Techniques for automatic query expansion have been extensively studied in information research as a means of addressing the word mismatch between queries and documents. These techniques can be categorized as either global or local. While global techniques rely on analysis of a whole collection to discover word relationships, local techniques emphasize analysis of the top-ranked documents retrieved for a query. While local techniques have shown to be more effective that global techniques in general, existing local techniques are not robust and can seriously hurt retrieved when few of the retrieval documents are relevant. We propose a new technique, called local context analysis, which selects expansion terms based on cooccurrence with the query terms within the top-ranked documents. Experiments on a number of collections, both English and non-English, show that local context analysis offers more effective and consistent retrieval results.", "authors": ["Jinxi Xu", "W. Bruce Croft"], "related_topics": ["99016210", "189430467", "52085439"], "citation_count": "788", "reference_count": "43", "references": ["2147152072", "2093390569", "1833785989", "1593045043", "2000672666", "1979459060", "2074449313", "2000569744", "2100873065", "1984565341"], "date": "1999"}, {"id": "2981264952", "title": "Numerical recipes in Pascal : the art of scientific computing", "abstract": "", "authors": ["William Henry Press", "Brian P Flannery", "Saul Arno Teukolsky"], "related_topics": ["94176051", "41008148", "199360897"], "citation_count": "12440", "reference_count": "0", "references": ["2139212933", "2217896605", "2000042664", "2132103241", "2123487311", "2596156494", "2112036188", "2034432063", "2020934227", "1510052597"], "date": "1988"}, {"id": "2342091124", "title": "Usability Engineering", "abstract": "From the Publisher: Written by the author of the best-selling HyperText & HyperMedia, this book provides an excellent guide to the methods of usability engineering. Special features: emphasizes cost-effective methods that will help developers improve their user interfaces immediately, shows you how to avoid the four most frequently listed reasons for delay in software projects, provides step-by-step information about which methods to use at various stages during the development life cycle, and offers information on the unique issues relating to informational usability. You do not need to have previous knowledge of usability to implement the methods provided, yet all of the latest research is covered.", "authors": ["Jakob Nielsen"], "related_topics": ["100302975", "23456302", "62993174"], "citation_count": "23306", "reference_count": "390", "references": ["2147152072", "2094204865", "2152309982", "2118243939", "2175951718", "2018415007", "1979349344", "2011317649", "2013073142", "2127841983"], "date": "1992"}, {"id": "1969572066", "title": "Context-sensitive learning methods for text categorization", "abstract": "Two recently implemented machine-learning algorithms, RIPPERand sleeping-experts for phrases, are evaluated on a number of large text categorization problems. These algorithms both construct classifiers that allow the \u201ccontext\u201d of a word w to affect how (or even whether) the presence or absence of w will contribute to a classification. However, RIPPER and sleeping-experts differ radically in many other respects: differences include different notions as to what constitutes a context, different ways of combining contexts to construct a classifier, different methods to search for a combination of contexts, and different criteria as to what contexts should be included in such a combination. In spite of these differences, both RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods. We view this result as a confirmation of the usefulness of classifiers that represent contextual information.", "authors": ["William W. Cohen", "Yoram Singer"], "related_topics": ["94124525", "2780049985", "95623464"], "citation_count": "1363", "reference_count": "41", "references": ["3124955340", "1670263352", "1619226191", "3124873412", "2085989833", "1999138184", "2060216474", "2129113961", "40914139", "2094934653"], "date": "1999"}, {"id": "2154642048", "title": "Learning internal representations by error propagation", "abstract": "This chapter contains sections titled: The Problem, The Generalized Delta Rule, Simulation Results, Some Further Generalizations, Conclusion", "authors": ["D. E. Rumelhart", "G. E. Hinton", "R. J. Williams"], "related_topics": ["75904356", "58973888", "155032097"], "citation_count": "31447", "reference_count": "23", "references": ["2154642048", "1652505363", "1535810436", "1507849272", "2101926813", "2073257493", "2021878536", "1490454746", "2115647291", "1505136099"], "date": "1987"}, {"id": "2161406034", "title": "C ONDENSATION \u2014Conditional Density Propagation forVisual Tracking", "abstract": "The problem of tracking curves in dense visual clutter is challenging. Kalman filtering is inadequate because it is based on Gaussian densities which, being unimo dal, cannot represent simultaneous alternative hypotheses. The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set. Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time. The result is highly robust tracking of agile motion. Notwithstanding the use of stochastic methods, the algorithm runs in near real-time.", "authors": ["Michael Isard", "Andrew Blake"], "related_topics": ["2777210071", "43555835", "149441793"], "citation_count": "8650", "reference_count": "50", "references": ["2170120409", "2104095591", "1560013842", "1997063559", "2098613108", "2085261163", "2571050459", "2077611006", "1481420047", "1569320505"], "date": "1998"}, {"id": "2162630772", "title": "Adaptive segmentation of MRI data", "abstract": "Intensity-based classification of MR images has proven problematic, even when advanced techniques are used. Intrascan and interscan intensity inhomogeneities are a common source of difficulty. While reported methods have had some success in correcting intrascan inhomogeneities, such methods require supervision for the individual scan. This paper describes a new method called adaptive segmentation that uses knowledge of tissue intensity properties and intensity inhomogeneities to correct and segment MR images. Use of the expectation-maximization (EM) algorithm leads to a method that allows for more accurate segmentation of tissue types as well as better visualization of magnetic resonance imaging (MRI) data, that has proven to be effective in a study that includes more than 1000 brain scans. Implementation and results are described for segmenting the brain in the following types of images: axial (dual-echo spin-echo), coronal [three dimensional Fourier transform (3-DFT) gradient-echo T1-weighted] all using a conventional head coil, and a sagittal section acquired using a surface coil. The accuracy of adaptive segmentation was found to be comparable with manual segmentation, and closer to manual segmentation than supervised multivariant classification while segmenting gray and white matter.", "authors": ["W.M. Wells", "W.E.L. Grimson", "R. Kikinis", "F.A. Jolesz"], "related_topics": ["65885262", "124504099", "89600930"], "citation_count": "1715", "reference_count": "29", "references": ["2049633694", "3017143921", "1627054999", "3129711340", "2015513598", "1995605620", "2137676365", "1606131697", "2115772934", "2063125200"], "date": "1995"}, {"id": "1883186006", "title": "Inference in Hidden Markov Models", "abstract": "This book is a comprehensive treatment of inference for hidden Markov models, including both algorithms and statistical theory. Topics range from filtering and smoothing of the hidden Markov chain to parameter estimation, Bayesian methods and estimation of the number of states. In a unified way the book covers both models with finite state spaces and models with continuous state spaces (also called state-space models) requiring approximate simulation-based algorithms that are also described in detail. Many examples illustrate the algorithms and theory. This book builds on recent developments to present a self-contained view.", "authors": ["Olivier Capp", "Eric Moulines", "Tobias Ryden"], "related_topics": ["64939953", "71983512", "54907487"], "citation_count": "2389", "reference_count": "98", "references": ["2099111195", "2125838338", "1483307070", "2610857016", "2981264952", "2049633694", "2126736494", "1513008779", "1985093013", "2098613108"], "date": "2008"}, {"id": "2128420091", "title": "Simplifying decision trees", "abstract": "Many systems have been developed for constructing decision trees from collections of examples. Although the decision trees generated by these methods are accurate and efficient, they often suffer the disadvantage of excessive complexity and are therefore incomprehensible to experts. It is questionable whether opaque structures of this kind can be described as knowledge, no matter how well they function. This paper discusses techniques for simplifying decision trees while retaining their accuracy. Four methods are described, illustrated, and compared on a test-bed of decision trees from a variety of domains.", "authors": ["J. R. Quinlan"], "related_topics": ["94131742", "120136583", "5481197"], "citation_count": "2955", "reference_count": "11", "references": ["1594031697", "2149706766", "3147316366", "1567276288", "3021257214", "2894813436", "3022593335", "98436501", "2063990820", "2914711136"], "date": "1987"}, {"id": "2000569744", "title": "Pivoted document length normalization", "abstract": "Automatic information retrieval systems have to deal with documents of varying lengths in a text collection. Document length normalization is used to fairly retrieve documents of all lengths. In this study, we ohserve that a normalization scheme that retrieves documents of all lengths with similar chances as their likelihood of relevance will outperform another scheme which retrieves documents with chances very different from their likelihood of relevance. We show that the retrievaf probabilities for a particular normalization method deviate systematically from the relevance probabilities across different collections. We present pivoted normalization, a technique that can be used to modify any normalization function thereby reducing the gap between the relevance and the retrieval probabilities. Training pivoted normalization on one collection, we can successfully use it on other (new) text collections, yielding a robust, collectzorz independent normalization technique. We use the idea of pivoting with the well known cosine normalization function. We point out some shortcomings of the cosine function andpresent two new normalization functions--pivoted unique normalization and piuotert byte size normalization.", "authors": ["Amit Singhal", "Chris Buckley", "Manclar Mitra"], "related_topics": ["123832482", "178980831", "124101348"], "citation_count": "1363", "reference_count": "13", "references": ["1956559956", "1978394996", "1833785989", "1482214997", "2014415866", "2165612380", "2887107689", "1525341925", "2019976352", "3151387521"], "date": "1996"}, {"id": "2130891992", "title": "On clusterings-good, bad and spectral", "abstract": "We propose a new measure for assessing the quality of a clustering. A simple heuristic is shown to give worst-case guarantees under the new measure. Then we present two results regarding the quality of the clustering found by a popular spectral algorithm. One proffers worst case guarantees whilst the other shows that if there exists a \"good\" clustering then the spectral algorithm will find one close to it.", "authors": ["R. Kannan", "S. Vempala", "A. Veta"], "related_topics": ["94641424", "33704608", "27964816"], "citation_count": "485", "reference_count": "23", "references": ["2121947440", "2011039300", "2002252750", "2133576408", "2160167256", "2063392856", "2067976091", "2085751730", "2139841919", "2021680564"], "date": "2000"}, {"id": "2122585011", "title": "A Novel Connectionist System for Unconstrained Handwriting Recognition", "abstract": "Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters, combined with the need to exploit surrounding context, has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed, most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition, despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network, specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large unconstrained handwriting databases, our approach achieves word recognition accuracies of 79.7 percent on online data and 74.1 percent on offline data, significantly outperforming a state-of-the-art HMM-based system. In addition, we demonstrate the network's robustness to lexicon size, measure the individual influence of its hidden layers, and analyze its use of context. Last, we provide an in-depth discussion of the differences between the network and HMMs, suggesting reasons for the network's superior performance.", "authors": ["A. Graves", "M. Liwicki", "S. Fernandez", "R. Bertolami", "H. Bunke", "J. Schmidhuber"], "related_topics": ["44868376", "112640561", "137293760"], "citation_count": "1884", "reference_count": "54", "references": ["2064675550", "2125838338", "2127141656", "3023071679", "2107878631", "2142069714", "2131774270", "2079735306", "1578856370", "2147568880"], "date": "2009"}, {"id": "1510073064", "title": "Kernel Methods for Pattern Analysis", "abstract": "Kernel methods provide a powerful and unified framework for pattern discovery, motivating algorithms that can act on general types of data (e.g. strings, vectors or text) and look for general types of relations (e.g. rankings, classifications, regressions, clusters). The application areas range from neural networks and pattern recognition to machine learning and data mining. This book, developed from lectures and tutorials, fulfils two major roles: firstly it provides practitioners with a large toolkit of algorithms, kernels and solutions ready to use for standard pattern discovery problems in fields such as bioinformatics, text analysis, image analysis. Secondly it provides an easy introduction for students and researchers to the growing field of kernel-based pattern analysis, demonstrating with examples how to handcraft an algorithm or a kernel for a new specific application, and covering all the necessary conceptual and mathematical tools to do so.", "authors": ["John Shawe-Taylor", "Nello Cristianini"], "related_topics": ["55851704", "2776879701", "140417398"], "citation_count": "8383", "reference_count": "25", "references": ["2148603752", "3124955340", "1601740268", "1975846642", "1542886316", "2579923771", "2139338362", "2099579348", "2106491486", "1520252399"], "date": "2003"}, {"id": "2136922672", "title": "A fast learning algorithm for deep belief nets", "abstract": "We show how to use \"complementary priors\" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.", "authors": ["Geoffrey E. Hinton", "Simon Osindero", "Yee-Whye Teh"], "related_topics": ["97385483", "2777579346", "167966045"], "citation_count": "15773", "reference_count": "30", "references": ["2310919327", "2116064496", "2057175746", "2159080219", "2156163116", "2131686571", "2158778629", "2567948266", "2159737176", "2124914669"], "date": "2006"}, {"id": "2072128103", "title": "Learning Deep Architectures for AI", "abstract": "Can machine learning deliver AI? Theoretical results, inspiration from the brain and cognition, as well as machine learning experiments suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one would need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers, graphical models with many levels of latent variables, or in complicated propositional formulae re-using many sub-formulae. Each level of the architecture represents features at a different level of abstraction, defined as a composition of lower-level features. Searching the parameter space of deep architectures is a difficult task, but new algorithms have been discovered and a new sub-area has emerged in the machine learning community since 2006, following these discoveries. Learning algorithms such as those for Deep Belief Networks and other related unsupervised learning algorithms have recently been proposed to train deep architectures, yielding exciting results and beating the state-of-the-art in certain areas. Learning Deep Architectures for AI discusses the motivations for and principles of learning algorithms for deep architectures. By analyzing and comparing recent results with different learning algorithms for deep architectures, explanations for their success are proposed and discussed, highlighting challenges and suggesting avenues for future explorations in this area.", "authors": ["Yoshua Bengio"], "related_topics": ["97385483", "8038995", "24138899"], "citation_count": "9739", "reference_count": "227", "references": ["2156909104", "2911964244", "2136922672", "2296616510", "2310919327", "2100495367", "2187089797", "2129131372", "2119821739", "2053186076"], "date": "2008"}, {"id": "1566135517", "title": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope", "abstract": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category.", "authors": ["Aude Oliva", "Antonio Torralba"], "related_topics": ["197654239", "2776277257", "146903032"], "citation_count": "7535", "reference_count": "45", "references": ["2117812871", "2128716185", "2012352340", "2130259898", "2156406284", "1524408959", "2180838288", "2142796031", "2104825706", "2167034998"], "date": "2001"}, {"id": "2057826272", "title": "A System to Filter Unwanted Messages from OSN User Walls", "abstract": "One fundamental issue in today's Online Social Networks (OSNs) is to give users the ability to control the messages posted on their own private space to avoid that unwanted content is displayed. Up to now, OSNs provide little support to this requirement. To fill the gap, in this paper, we propose a system allowing OSN users to have a direct control on the messages posted on their walls. This is achieved through a flexible rule-based system, that allows users to customize the filtering criteria to be applied to their walls, and a Machine Learning-based soft classifier automatically labeling messages in support of content-based filtering.", "authors": ["Marco Vanetti", "E. Binaghi", "E. Ferrari", "B. Carminati", "M. Carullo"], "related_topics": ["527821871", "37789001", "31258907"], "citation_count": "110", "reference_count": "47", "references": ["2171960770", "2118020653", "2149684865", "2132549764", "2150102617", "2164777277", "2482402870", "2053463056", "1978394996", "2170654002"], "date": "2013"}, {"id": "2053691921", "title": "Embedded image coding using zerotrees of wavelet coefficients", "abstract": "The embedded zerotree wavelet algorithm (EZW) is a simple, yet remarkably effective, image compression algorithm, having the property that the bits in the bit stream are generated in order of importance, yielding a fully embedded code. The embedded code represents a sequence of binary decisions that distinguish an image from the \"null\" image. Using an embedded coding algorithm, an encoder can terminate the encoding at any point thereby allowing a target rate or target distortion metric to be met exactly. Also, given a bit stream, the decoder can cease decoding at any point in the bit stream and still produce exactly the same image that would have been encoded at the bit rate corresponding to the truncated bit stream. In addition to producing a fully embedded bit stream, the EZW consistently produces compression results that are competitive with virtually all known compression algorithms on standard test images. Yet this performance is achieved with a technique that requires absolutely no training, no pre-stored tables or codebooks, and requires no prior knowledge of the image source. The EZW algorithm is based on four key concepts: (1) a discrete wavelet transform or hierarchical subband decomposition, (2) prediction of the absence of significant information across scales by exploiting the self-similarity inherent in images, (3) entropy-coded successive-approximation quantization, and (4) universal lossless data compression which is achieved via adaptive arithmetic coding. >", "authors": ["J.M. Shapiro"], "related_topics": ["78548338", "136968285", "81081738"], "citation_count": "8503", "reference_count": "33", "references": ["2132984323", "2098914003", "2140196014", "1996021349", "2156447271", "1970352604", "2103504761", "2129652681", "2166982406", "2186435531"], "date": "1993"}, {"id": "2007541434", "title": "Growing network with local rules: preferential attachment, clustering hierarchy, and degree correlations.", "abstract": "The linear preferential attachment hypothesis has been shown to be quite successful in explaining the existence of networks with power-law degree distributions. It is then quite important to determine if this mechanism is the consequence of a general principle based on local rules. In this work it is claimed that an effective linear preferential attachment is the natural outcome of growing network models based on local rules. It is also shown that the local models offer an explanation for other properties like the clustering hierarchy and degree correlations recently observed in complex networks. These conclusions are based on both analytical and numerical results for different local rules, including some models already proposed in the literature.", "authors": ["Alexei V\u00e1zquez"], "related_topics": ["2780600066", "34947359", "141002048"], "citation_count": "769", "reference_count": "79", "references": ["2112090702", "2008620264", "2124637492", "3013264884", "1976969221", "2769133055", "2038195874", "2144885342", "2136931666", "2065304353"], "date": "2003"}, {"id": "2030723843", "title": "The interior-point revolution in optimization: History, recent developments, and lasting consequences", "abstract": "Interior methods are a pervasive feature of the optimization landscape today, but it was not always so. Although interior-point techniques, primarily in the form of barrier methods, were widely used during the 1960s for problems with nonlinear constraints, their use for the fundamental problem of linear programming was unthinkable because of the total dominance of the simplex method. During the 1970s, barrier methods were superseded, nearly to the point of oblivion, by newly emerging and seemingly more efficient alternatives such as augmented Lagrangian and sequential quadratic programming methods. By the early 1980s, barrier methods were almost universally regarded as a closed chapter in the history of optimization. This picture changed dramatically in 1984, when Narendra Karmarkar announced a fast polynomial-time interior method for linear programming; in 1985, a formal connection was established between his method and classical barrier methods. Since then, interior methods have continued to transform both the theory and practice of constrained optimization. We present a condensed, unavoidably incomplete look at classical material and recent research about interior methods.", "authors": ["Margaret H. Wright"], "related_topics": ["155253501", "111397411", "41045048"], "citation_count": "336", "reference_count": "49", "references": ["2798766386", "2077658674", "2099839128", "2912522929", "2611147814", "1985123706", "1963547452", "2954064014", "2041684917", "1632601927"], "date": "2004"}, {"id": "2914746235", "title": "Multitask learning", "abstract": "Multitask Learning is an approach to inductive transfer that improves learning for one task by using the information contained in the training signals of other related tasks. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. In this thesis we demonstrate multitask learning for a dozen problems. We explain how multitask learning works and show that there are many opportunities for multitask learning in real domains. We show that in some cases features that would normally be used as inputs work better if used as multitask outputs instead. We present suggestions for how to get the most out of multitask learning in artificial neural nets, present an algorithm for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Multitask learning improves generalization performance, can be applied in many different kinds of domains, and can be used with different learning algorithms. We conjecture there will be many opportunities for its use on real-world problems.", "authors": ["Rich Caruana"], "related_topics": ["28006648", "77075516", "50644808"], "citation_count": "8169", "reference_count": "0", "references": ["1536680647", "2076063813", "2165698076", "2117130368", "2098411764", "2184188583", "2150341604", "2114315281", "1512387364", "2550821151"], "date": "1998"}, {"id": "2107745473", "title": "A universal algorithm for sequential data compression", "abstract": "A universal algorithm for sequential data compression is presented. Its performance is investigated with respect to a nonprobabilistic model of constrained sources. The compression ratio achieved by the proposed universal code uniformly approaches the lower bounds on the compression ratios attainable by block-to-variable codes and variable-to-block codes designed to match a completely specified source.", "authors": ["J. Ziv", "A. Lempel"], "related_topics": ["94835093", "81081738", "78548338"], "citation_count": "8276", "reference_count": "10", "references": ["2142901448", "2077770566", "2131024393", "1992371956", "2109227390", "2094396702", "2141463438", "1995000717", "2159253410", "2126590220"], "date": "1977"}, {"id": "2164558494", "title": "Telling more than we can know: Verbal reports on mental processes.", "abstract": "Evidence is reviewed which suggests that there may be little or no direct introspective access to higher order cognitive processes. Subjects are sometimes (a) unaware of the existence of a stimulus that importantly influenced a response, (b) unaware of the existence of the response, and (c) unaware that the stimulus has affected the response. It is proposed that when people attempt to report on their cognitive processes, that is, on the processes mediating the effects of a stimulus on a response, they do not do so on the basis of any true introspection. Instead, their reports are based on a priori, implicit causal theories, or judgments about the extent to which a particular stimulus is a plausible cause of a given response. This suggests that though people may not be able to observe directly their cognitive processes, they will sometimes be able to report accurately about them. Accurate reports will occur when influential stimuli are salient and are plausible causes of the responses they produce, and will not occur when stimuli are not salient or are not plausible causes.", "authors": ["Richard E. Nisbett", "Timothy DeCamp Wilson"], "related_topics": ["169900460", "147004232", "48329741"], "citation_count": "15779", "reference_count": "67", "references": ["158727920", "2035782089", "1980054641", "2089016366", "1748197048", "1555806226", "2079199322", "2963241992", "1719717336", "2096648510"], "date": "1977"}, {"id": "2963341956", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina N. Toutanova"], "related_topics": ["44291984", "137293760", "2779439875"], "citation_count": "22961", "reference_count": "52", "references": ["2963403868", "2153579005", "2250539671", "2108598243", "2962739339", "2131744502", "2251939518", "2963748441", "2117130368", "2025768430"], "date": "2018"}, {"id": "2165225968", "title": "Unsupervised learning of distributions on binary vectors using two layer networks", "abstract": "We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model can be represented by a particular type of Boltzmann machine with a bipartite graph structure that we call the combination machine. This machine is closely related to the Harmonium model defined by Smolensky. In the first part of the paper we analyze properties of this distribution representation scheme. We show that arbitrary distributions of binary vectors can be approximated by the combination model. We show how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits, and how the combination machine can be used as a mechanism for detecting these patterns. We compare the combination model with the mixture model and with principle component analysis. In the second part of the paper we present two algorithms for learning the combination model from examples. The first learning algorithm is the standard gradient ascent heuristic for computing maximum likelihood estimates for the parameters of the model. Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine. The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of projection pursuit density estimation. In the third part of the paper we give experimental results for these learning methods on synthetic data and on natural data of handwritten digit images.", "authors": ["Yoav Freund", "David Haussler"], "related_topics": ["17061570", "59404180", "112972136"], "citation_count": "401", "reference_count": "11", "references": ["2159080219", "1652505363", "1997063559", "2049633694", "2293063825", "1507849272", "1964724001", "2121407732", "2725061391", "2315016682"], "date": "1991"}, {"id": "2139823104", "title": "Semi-supervised learning using Gaussian fields and harmonic functions", "abstract": "An approach to semi-supervised learning is proposed that is based on a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The learning problem is then formulated in terms of a Gaussian random field on this graph, where the mean of the field is characterized in terms of harmonic functions, and is efficiently obtained using matrix methods or belief propagation. The resulting learning algorithms have intimate connections with random walks, electric networks, and spectral graph theory. We discuss methods to incorporate class priors and the predictions of classifiers obtained by supervised learning. We also propose a method of parameter learning by entropy minimization, and show the algorithm's ability to perform feature selection. Promising experimental results are presented for synthetic data, digit classification, and text classification tasks.", "authors": ["Xiaojin Zhu", "Zoubin Ghahramani", "John Lafferty"], "related_topics": ["58973888", "8038995", "107321475"], "citation_count": "4318", "reference_count": "21", "references": ["2121947440", "2143516773", "2165874743", "2154579312", "2122837498", "1511160855", "1585385982", "1979711143", "2113592823", "200434350"], "date": "2003"}, {"id": "2101706260", "title": "Recognizing handwritten digits using hierarchical products of experts", "abstract": "The product of experts learning procedure can discover a set of stochastic binary features that constitute a nonlinear generative model of handwritten images of digits. The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. To improve discriminative performance, a hierarchy of separate models can be learned, for each digit class. Each model in the hierarchy learns a layer of binary feature detectors that model the probability distribution of vectors of activity of feature detectors in the layer below. The models in the hierarchy are trained sequentially and each model uses a layer of binary feature detectors to learn a generative model of the patterns of feature activities in the preceding layer. After training, each layer of feature detectors produces a separate, unnormalized log probability score. With three layers of feature detectors for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data.", "authors": ["G. Mayraz", "G.E. Hinton"], "related_topics": ["167966045", "7374053", "97931131"], "citation_count": "83", "reference_count": "15", "references": ["2116064496", "2912934387", "2159080219", "2150884987", "28412257", "1547224907", "2104867159", "1667072054", "1813659000", "2100559472"], "date": "2002"}, {"id": "2100559472", "title": "A Gradient-Based Boosting Algorithm for Regression Problems", "abstract": "In adaptive boosting, several weak learners trained sequentially are combined to boost the overall algorithm performance. Recently adaptive boosting methods for classification problems have been derived as gradient descent algorithms. This formulation justifies key elements and parameters in the methods, all chosen to optimize a single common objective function. We propose an analogous formulation for adaptive boosting of regression problems, utilizing a novel objective function that leads to a simple boosting algorithm. We prove that this method reduces training error, and compare its performance to other regression methods.", "authors": ["Richard S. Zemel", "Toniann Pitassi"], "related_topics": ["70153297", "31912584", "46686674"], "citation_count": "115", "reference_count": "16", "references": ["3124955340", "2116064496", "1678356000", "2024046085", "2797583072", "2032210760", "2150884987", "2076118331", "2093717447", "2767905780"], "date": "1999"}, {"id": "2151103935", "title": "Distinctive Image Features from Scale-Invariant Keypoints", "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.", "authors": ["David G. Lowe"], "related_topics": ["14551309", "123134398", "7374053"], "citation_count": "63557", "reference_count": "42", "references": ["2033819227", "2124386111", "2154422044", "2012778485", "2124404372", "1676552347", "2124087378", "2111308925", "2165497495", "1949116567"], "date": "2004"}, {"id": "2136944077", "title": "Scale Structure, Degree Modification, and the Semantics of Gradable Predicates", "abstract": "In this article we develop a semantic typology of gradable predicates, with special emphasis/non deverbal adjectives. We argue for the linguistic relevance of this typology by demonstrating/nthat the distribution and interpretation of degree modifiers is sensitive to its two major classificatory/nparameters: (1) whether a gradable predicate is associated with what we call an open or closed/nscale,and (2) whether the standard of comparison for the applicability of the predicate is absolute/nor relative to a context. We further show that the classification of an important subclass of/nadjectives with in the typology is largely predictable.Specifically, the scale structure of adeverbal/ngradable adjective correlates either with the algebraic part structure of the event denoted by its/nsource verbor with the part structureof the entitiesto which the adjective applies.These correla-/ntions underscore the fact that gradability is characteristic not only of adjectives but also of verbs/nand nouns, and that scalar properties are shared by categorially distinct but derivationally related/nexpressions.", "authors": ["Christopher Kennedy", "Louise McNally"], "related_topics": ["2777683214", "40738166", "121934690"], "citation_count": "1624", "reference_count": "53", "references": ["1572948005", "1711163617", "1687416839", "2067551521", "1503836197", "2026725080", "2120857440", "1570679045", "1514506388", "1965909177"], "date": "2004"}, {"id": "1484413656", "title": "Fast algorithms for mining association rules", "abstract": "We consider the problem of discovering association rules between items in a large database of sales transactions. We present two new algorithms for solving thii problem that are fundamentally different from the known algorithms. Empirical evaluation shows that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. We also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called AprioriHybrid. Scale-up experiments show that AprioriHybrid scales linearly with the number of transactions. AprioriHybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database.", "authors": ["Rakesh Agrawal", "Ramakrishnan Srikant"], "related_topics": ["87146676", "197717643", "193524817"], "citation_count": "27617", "reference_count": "24", "references": ["2166559705", "2125055259", "1506285740", "2159080219", "1594031697", "1504694836", "2100406636", "2008906462", "1499049447", "1556507321"], "date": "1998"}, {"id": "1628850721", "title": "Experiments with the Tangora 20,000 word speech recognizer", "abstract": "The Speech Recognition Group at IBM Research in Yorktown Heights has developed a real-time, isolated-utterance speech recognizer for natural language based on the IBM Personal Computer AT and IBM Signal Processors. The system has recently been enhanced by expanding the vocabulary from 5,000 words to 20,000 words and by the addition of a speech workstation to support usability studies on document creation by voice. The system supports spelling and interactive personalization to augment the vocabularies. This paper describes the implementation, user interface, and comparative performance of the recognizer.", "authors": ["A. Averbuch", "L. Bahl", "R. Bakis", "P. Brown", "G. Daggett", "S. Das", "K. Davies", "S. De Gennaro", "P. de Souza", "E. Epstein", "D. Fraleigh", "F. Jelinek", "B. Lewis", "R. Mercer", "J. Moorhead", "A. Nadas", "D. Nahamoo", "M. Picheny", "G. Shichman", "P. Spinelli", "D. Van Compernolle", "H. Wilkens"], "related_topics": ["14999030", "61328038", "91863865"], "citation_count": "148", "reference_count": "10", "references": ["1966812932", "2134237567", "1990005915", "1521239006", "1507770639", "2134587001", "2170967986", "2056809970", "1901281023", "2089661020"], "date": "1986"}, {"id": "2137234026", "title": "The \"independent components\" of natural scenes are edge filters.", "abstract": "It has previously been suggested that neurons with line and edge selectivities found in primary visual cortex of cats and monkeys form a sparse, distributed representation of natural scenes, and it has been reasoned that such responses should emerge from an unsupervised learning algorithm that attempts to find a factorial code of independent visual features. We show here that a new unsupervised learning algorithm based on information maximization, a nonlinear \u201cinfomax\u201d network, when applied to an ensemble of natural scenes produces sets of visual filters that are localized and oriented. Some of these filters are Gabor-like and resemble those produced by the sparseness-maximization network. In addition, the outputs of these filters are as independent as possible, since this infomax network performs Independent Components Analysis or ICA, for sparse (super-gaussian) component distributions. We compare the resulting ICA filters and their associated basis functions, with other decorrelating filters produced by Principal Components Analysis (PCA) and zero-phase whitening filters (ZCA). The ICA filters have more sparsely distributed (kurtotic) outputs on natural scenes. They also resemble the receptive fields of simple cells in visual cortex, which suggests that these neurons form a natural, information-theoretic coordinate system for natural images.", "authors": ["Anthony J. Bell", "Terrence J. Sejnowski"], "related_topics": ["51432778", "153402090", "133219170"], "citation_count": "2771", "reference_count": "48", "references": ["2099111195", "2099741732", "2108384452", "1996355918", "2133069808", "2003370853", "1977067929", "2180838288", "2006500012", "2167034998"], "date": "1997"}, {"id": "2520931985", "title": "When is nearest neighbor meaningful", "abstract": "We explore the effect of dimensionality on the nearest neighbor problem. We show that under a broad set of conditions (much broader than independent and identically distributed dimensions), as dimensionality increases, the distance to the nearest data point approaches the distance to the farthest data point. To provide a practical perspective, we present empirical results on both real and synthetic data sets that demonstrate that this effect can occur for as few as 10-15 dimensions. These results should not be interpreted to mean that high-dimensional indexing is never meaningful; we illustrate this point by identifying some high-dimensional workloads for which this effect does not occur. However, our results do emphasize that the methodology used almost universally in the database literature to evaluate high-dimensional indexing techniques is flawed, and should be modified. In particular, most such techniques proposed in the literature are not evaluated versus simple linear scan, and are evaluated over workloads for which nearest neighbor is not meaningful. Often, even the reported experiments, when analyzed carefully, show that linear scan would outperform the techniques being proposed on the workloads studied in high (10-15) dimensionality!.", "authors": ["K. Beyer", "J. Goldstein", "R. Ramakrishnan", "U. Shaft"], "related_topics": ["111030470", "113238511", "141513077"], "citation_count": "3258", "reference_count": "0", "references": ["2107427524", "2794866576", "2031043614", "1859467588", "2802112837", "2792900401", "2977015089", "24166384", "1770242755", "3118324790"], "date": "1998"}, {"id": "2986444355", "title": "An Algorithm for Least-Squares Estimation of Nonlinear Parameters", "abstract": "", "authors": ["D. Marquardt"], "related_topics": ["11413529", "41008148", "2983372226"], "citation_count": "33281", "reference_count": "0", "references": ["2151165908", "1994349244", "2097599414", "2102653059", "2295959395", "2005348293", "3122443248", "2168844688", "2466913836", "1536075283"], "date": "1962"}, {"id": "2170102584", "title": "RADAR: an in-building RF-based user location and tracking system", "abstract": "The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.", "authors": ["P. Bahl", "V.N. Padmanabhan"], "related_topics": ["84236424", "161475128", "134406370"], "citation_count": "12139", "reference_count": "23", "references": ["2752885492", "1490482062", "2094204865", "2134342348", "2102449144", "2118269922", "2006725758", "2238624099", "1496940124", "2613359208"], "date": "2000"}, {"id": "2159080219", "title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "abstract": "From the Publisher: Probabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. Probabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability.", "authors": ["Judea Pearl"], "related_topics": ["89288958", "56397880", "18998212"], "citation_count": "24370", "reference_count": "235", "references": ["2581275558", "1997063559", "1593793857", "2797148637", "2155322595", "158727920", "2138162238", "2108309071", "1986808060", "2142901448"], "date": "1987"}, {"id": "2145607950", "title": "80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition", "abstract": "With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of non-parametric methods, we explore this world with the aid of a large dataset of 79,302,017 images collected from the Internet. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the dataset are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database gives a comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with nearest-neighbor methods to perform object classification over a range of semantic levels minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the dataset, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors.", "authors": ["A. Torralba", "R. Fergus", "W.T. Freeman"], "related_topics": ["157659113", "2776151529", "9417928"], "citation_count": "1899", "reference_count": "54", "references": ["2164598857", "2162915993", "2124386111", "2038721957", "2128017662", "2110764733", "1576445103", "2107034620", "1566135517", "2111993661"], "date": "2008"}, {"id": "2081612620", "title": "A high-performance, portable implementation of the MPI message passing interface standard", "abstract": "MPI (Message Passing Interface) is a specification for a standard library for message passing that was defined by the MPI Forum, a broadly based group of parallel computer vendors, library writers, and applications specialists. Multiple implementations of MPI have been developed. In this paper, we describe MPICH, unique among existing implementations in its design goal of combining portability with high performance. We document its portability and performance and describe the architecture by which these features are simultaneously achieved. We also discuss the set of tools that accompany the free distribution of MPICH, which constitute the beginnings of a portable parallel programming environment. A project of this scope inevitably imparts lessons about parallel computing, the specification being followed, the current hardware and software environment for parallel computing, and project management; we describe those we have learned. Finally, we discuss future developments for MPICH, including those necessary to accommodate extensions to the MPI Standard now being contemplated by the MPI Forum.", "authors": ["William Gropp", "Ewing Lusk", "Nathan Doss", "Anthony Skjellum"], "related_topics": ["2779035128", "2776893622", "166782233"], "citation_count": "3262", "reference_count": "28", "references": ["1575350781", "1510543252", "1589918049", "2752853835", "1570906644", "2114728910", "2415611842", "2171453084", "1964564149", "2010269868"], "date": "1996"}, {"id": "2067551521", "title": "Thematic proto-roles and argument selection", "abstract": "As a novel attack on the perennially vexing questions of the theoretical status of thematic roles and the inventory of possible roles, this paper defends a strategy of basing accounts of roles on more unified domains of linguistic data than have been used in the past to motivate roles, addressing in particular the problem of ARGUMENT SELECTION (principles determining which roles are associated with which grammatical relations). It is concluded that the best theory for describing this domain is not a traditional system of discrete roles (Agent, Patient, Source, etc.) but a theory in which the only roles are two cluster-concepts called PROTO-AGENT and PROTO-PATIENT, each characterized by a set of verbal entailments: an argument of a verb may bear either of the two proto-roles (or both) to varying degrees, according to the number of entailments of each kind the verb gives it. Both fine-grained and coarse-grained classes of verbal arguments (corresponding to traditional thematic roles and other classes as well) follow automatically, as do desired 'role hierarchies'. By examining occurrences of the 'same' verb with different argument configurations\u2014e.g. two forms of psych predicates and object-oblique alternations as in the familiar spray/load class\u2014it can also be argued that proto-roles act as defaults in the learning of lexical meanings. Are proto-role categories manifested elsewhere in language or as cognitive categories? If so, they might be a means of making grammar acquisition easier for the child, they might explain certain other typological and acquisitional observations, and they may lead to an account of contrasts between unaccusative and unergative intransitive verbs that does not rely on deriving unaccusatives from underlying direct objects.", "authors": ["David Dowty"], "related_topics": ["2779185107", "2781128744", "2776397901"], "citation_count": "3404", "reference_count": "82", "references": ["1586060904", "2097028840", "1972573551", "1563307389", "2123987305", "2170716495", "2094249282", "2032527312", "1601637950", "2143745167"], "date": "1991"}, {"id": "2058929792", "title": "n-Gram Statistics for Natural Language Understanding and Text Processing", "abstract": "n-gram (n = 1 to 5) statistics and other properties of the English language were derived for applications in natural language understanding and text processing. They were computed from a well-known corpus composed of 1 million word samples. Similar properties were also derived from the most frequent 1000 words of three other corpuses. The positional distributions of n-grams obtained in the present study are discussed. Statistical studies on word length and trends of n-gram frequencies versus vocabulary are presented. In addition to a survey of n-gram statistics found in the literature, a collection of n-gram statistics obtained by other researchers is reviewed and compared.", "authors": ["Ching Y. Suen"], "related_topics": ["117884012", "2777601683", "2779500292"], "citation_count": "263", "reference_count": "74", "references": ["2142384583", "1970026646", "1647671624", "2008819433", "2157477135", "2066792529", "2042008249", "2071663716", "2079145130", "2027085566"], "date": "1979"}, {"id": "2098947662", "title": "View-based and modular eigenspaces for face recognition", "abstract": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated. >", "authors": ["Pentland", "Moghaddam", "Starner"], "related_topics": ["88799230", "14551309", "40608802"], "citation_count": "2984", "reference_count": "13", "references": ["2138451337", "2113341759", "2135463994", "2138313032", "2130506643", "2157418942", "1993867646", "2112684592", "2121863133", "2030234875"], "date": "1994"}, {"id": "2055712799", "title": "Smart sensing within a pyramid vision machine", "abstract": "A machine is designed, based on a pyramid architecture, that supports smart sensing and related highly efficient processing. Key elements of the design are (a) hierarchical data structures for image representation, (b) fine-to-coarse algorithms for the fast generation of image measures, (c) coarse-to-fine search strategies that rapidly locate objects or events within a scene, and (d) high-level control mechanisms that guide data gathering even as visual information is being interpreted. This system, known as the Pyramid Vision Machine, achieves high performance at modest cost. Design considerations and several applications are described. >", "authors": ["P.J. Burt"], "related_topics": ["79284318", "98025372", "162319229"], "citation_count": "432", "reference_count": "18", "references": ["2103504761", "2003370853", "2978983090", "2153709524", "2067398582", "2074163268", "2033266778", "1964415410", "1834283795", "2075554361"], "date": "1988"}, {"id": "2912934387", "title": "Bagging predictors", "abstract": "", "authors": ["Leo Breiman"], "related_topics": ["41008148", "162040801", "2983237105"], "citation_count": "27552", "reference_count": "0", "references": ["2911964244", "2140190241", "2076063813", "1904365287", "1570448133", "2117812871", "2063978378", "2294059674", "1983364832", "2112076978"], "date": "1996"}, {"id": "2124386111", "title": "Object recognition from local scale-invariant features", "abstract": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.", "authors": ["D.G. Lowe"], "related_topics": ["14551309", "123134398", "99102927"], "citation_count": "21546", "reference_count": "23", "references": ["2914885528", "2124087378", "2123977795", "2011891945", "22745672", "2096077837", "2096600681", "2131806657", "2042243448", "1553558465"], "date": "1999"}, {"id": "2153579005", "title": "Distributed Representations of Words and Phrases and their Compositionality", "abstract": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.", "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "related_topics": ["2776461190", "2777462759", "70777604"], "citation_count": "25996", "reference_count": "19", "references": ["1614298861", "2117130368", "2141599568", "2132339004", "2158139315", "1423339008", "1498436455", "1662133657", "1889268436", "2131462252"], "date": "2013"}, {"id": "1574877594", "title": "Learning with Labeled and Unlabeled Data", "abstract": "In this paper, on the one hand, we aim to give a review on literature dealing with the problem of supervised learning aided by additional unlabeled data. On the other hand, being a part of the author's first year PhD report, the paper serves as a frame to bundle related work by the author as well as numerous suggestions for potential future work. Therefore, this work contains more speculative and partly subjective material than the reader might expect from a literature review. We give a rigorous definition of the problem and relate it to supervised and unsupervised learning. The crucial role of prior knowledge is put forward, and we discuss the important notion of input-dependent regularization. We postulate a number of baseline methods, being algorithms or algorithmic schemes which can more or less straightforwardly be applied to the problem, without the need for genuinely new concepts. However, some of them might serve as basis for a genuine method. In the literature review, we try to cover the wide variety of (recent) work and to classify this work into meaningful categories. We also mention work done on related problems and suggest some ideas towards synthesis. Finally, we discuss some caveats and tradeoffs of central importance to the problem.", "authors": ["Matthias Seeger"], "related_topics": ["58973888", "8038995", "136389625"], "citation_count": "730", "reference_count": "89", "references": ["2156909104", "2148603752", "2099111195", "1554663460", "2139212933", "2581275558", "2112076978", "1576520375", "2049633694", "1528905581"], "date": "1999"}, {"id": "2111192396", "title": "Computer programs for detecting and correcting spelling errors", "abstract": "With the increase in word and text processing computer systems, programs which check and correct spelling will become more and more common. Peterson investigates the basic structure of several such existing programs and their approaches to solving the problems which arise when this type of program is created. The basic framework and background necessary to write a spelling checker or corrector are provided.", "authors": ["James L. Peterson"], "related_topics": ["2777801307", "2779500292", "61249035"], "citation_count": "538", "reference_count": "44", "references": ["2326587081", "1970026646", "2007780422", "2008819433", "2039262760", "2066792529", "2054882906", "2071663716", "2027085566", "2032579751"], "date": "1980"}, {"id": "1629473008", "title": "Clustering Methods for Collaborative Filtering", "abstract": "Grouping people into clusters based on the items they have purchased allows accurate recommendations of new items for purchase: if you and I have liked many of the same movies, then I will probably enjoy other movies that you like. Recommending items based on similarity of interest (a.k.a. collaborative filtering) is attractive for many domains: books, CDs, movies, etc., but does not always work well. Because data are always sparse - any given person has seen only a small fraction of all movies - much more accurate predictions can be made by grouping people into clusters with similar movies and grouping movies into clusters which tend to be liked by the same people. Finding optimal clusters is tricky because the movie groups should be used to help determine the people groups and visa versa. We present a formal statistical model of collaborative filtering, and compare different algorithms for estimating the model parameters including variations of K-means clustering and Gibbs Sampling. This formal model is easily extended to handle clustering of objects with multiple attributes.", "authors": ["Lyle H. Ungar", "Dean P. Foster"], "related_topics": ["21569690", "73555534", "17212007"], "citation_count": "1078", "reference_count": "10", "references": ["2049633694", "2124591829", "1966553486", "2117853077", "1999047234", "2567948266", "2163738067", "2137719099", "2798543290", "1501730368"], "date": "1997"}, {"id": "2159782014", "title": "Estimation of probabilities in the language model of the IBM speech recognition system", "abstract": "The language model probabilities are estimated by an empirical Bayes approach in which a prior distribution for the unknown probabilities is itself estimated through a novel choice of data. The predictive power of the model thus fitted is compared by means of its experimental perplexity [1] to the model as fitted by the Jelinek-Mercer deleted estimator and as fitted by the Turing-Good formulas for probabilities of unseen or rarely seen events.", "authors": ["A. Nadas"], "related_topics": ["39608478", "177769412", "100279451"], "citation_count": "128", "reference_count": "10", "references": ["1966812932", "2795495912", "1975953721", "2082092506", "2079145130", "1972612985", "2079819958", "1590636096", "1997361079", "2904521336"], "date": "1984"}, {"id": "2121927366", "title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics", "abstract": "This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties.", "authors": ["D. Martin", "C. Fowlkes", "D. Tal", "J. Malik"], "related_topics": ["124504099", "89600930", "146849305"], "citation_count": "6606", "reference_count": "15", "references": ["2121947440", "2126326837", "2124731682", "1524408959", "2101933716", "2120838001", "2150117517", "2139643804", "2124592837", "1537519384"], "date": "2001"}, {"id": "2129766733", "title": "Diversity and multiplexing: a fundamental tradeoff in multiple-antenna channels", "abstract": "Multiple antennas can be used for increasing the amount of diversity or the number of degrees of freedom in wireless communication systems. We propose the point of view that both types of gains can be simultaneously obtained for a given multiple-antenna channel, but there is a fundamental tradeoff between how much of each any coding scheme can get. For the richly scattered Rayleigh-fading channel, we give a simple characterization of the optimal tradeoff curve and use it to evaluate the performance of existing multiple antenna schemes.", "authors": ["Lizhong Zheng", "D.N.C. Tse"], "related_topics": ["60069766", "207987634", "19275194"], "citation_count": "5283", "reference_count": "19", "references": ["2107080958", "2130509920", "2118040894", "2110659753", "2798333393", "2133475491", "2106929598", "2117359246", "2168571551", "2096765600"], "date": "2003"}, {"id": "1708874574", "title": "The Architecture of Cognition", "abstract": "Now available in paper, The Architecture of Cognition is a classic work that remains relevant to theory and research in cognitive science. The new version of Anderson's theory of cognitive architecture -- Adaptive Control of Thought (ACT*) -- is a theory of the basic principles of operation built into the cognitive system and is the main focus of the book. (http://books.google.fr/books?id=Uip3_g7zlAUC&printsec=frontcover&hl=fr#v=onepage&q&f=false)", "authors": ["John R. Anderson"], "related_topics": ["20854674", "2780583044", "169900460"], "citation_count": "17190", "reference_count": "0", "references": ["2132454116", "2154455818", "2151137320", "2126385963", "2266639535", "2136518234", "2166667242", "2149355902", "2130142026", "2125655203"], "date": "1994"}, {"id": "1570679045", "title": "The Origins of Telicity", "abstract": "The distinction between telic and atelic predicates has been described in terms of the algebraic properties of their meaning since the early days of model-theoretic semantics. This perspective was inspired by Aristotle\u2019s discussion of types of actions that do or do not take time to be completed which was taken up and turned into a linguistic discussion of action-denoting predicates by Vendler (1957). The algebraic notion that seemed to be most conducive to express the Aristotelian distinction appeared to be the mereological notion of a part, applied to the time at which these predicates hold: atelic predicates, like push a cart, have the subinterval property, that is, whenever they are true at a time interval, then they are true at any part of that interval; this does not hold for telic predicates, like eat an apple, cf. Bennett & Partee (1972), Taylor (1977), and Dowty (1979)2. Bach (1986) integrated these insights into a semantics based on events.", "authors": ["Manfred Krifka"], "related_topics": ["2781128744", "112700740", "189950617"], "citation_count": "1397", "reference_count": "45", "references": ["1687416839", "2080293785", "2523440281", "1989485152", "1658909445", "2070939632", "2025589690", "2079093047", "1522746076", "2152578812"], "date": "1997"}, {"id": "2156515921", "title": "Shallow parsing with conditional random fields", "abstract": "Conditional random fields for sequence labeling offer advantages over both generative models like HMMs and classifiers applied at each sequence position. Among sequence labeling tasks in language processing, shallow parsing has received much attention, with the development of standard evaluation datasets and extensive comparison among methods. We show here how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model. Improved training methods based on modern optimization algorithms were critical in achieving these results. We present extensive comparisons between models and training methods that confirm and strengthen previous results on shallow parsing and training methods for maximum-entropy models.", "authors": ["Fei Sha", "Fernando Pereira"], "related_topics": ["152565575", "2778120102", "35639132"], "citation_count": "1926", "reference_count": "33", "references": ["1995945562", "2147880316", "2008652694", "2096175520", "1934019294", "1773803948", "2160842254", "2962735828", "2117400858", "1520377376"], "date": "2003"}, {"id": "2110638361", "title": "Marketing in Hypermedia Computer-Mediated Environments: Conceptual Foundations", "abstract": "The authors address the role of marketing in hypermedia computer-mediated environments (CMEs). Their approach considers hypermedia CMEs to be large-scale (i.e., national or global) networked enviro...", "authors": ["Donna L. Hoffman", "Thomas P. Novak"], "related_topics": ["2780126544", "180198813", "545109879"], "citation_count": "9007", "reference_count": "152", "references": ["2099697766", "1562891728", "2140205964", "175500210", "3019273456", "2179683524", "1491644571", "2030144199", "1568713441", "1982210139"], "date": "1996"}, {"id": "2119821739", "title": "Support-Vector Networks", "abstract": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.", "authors": ["Corinna Cortes", "Vladimir Vapnik"], "related_topics": ["59404180", "77967617", "83665646"], "citation_count": "48716", "reference_count": "14", "references": ["2154642048", "1498436455", "2087347434", "2154579312", "1530699444", "2168228682", "2504871398", "1568787085", "5594912", "2322002063"], "date": "1995"}, {"id": "1979711143", "title": "Large margin classification using the perceptron algorithm", "abstract": "We introduce and analyze a new algorithm for linear classification which combines Rosenblatt\u2018s perceptron algorithm with Helmbold and Warmuth\u2018s leave-one-out method. Like Vapnik\u2018s maximal-margin classifier, our algorithm takes advantage of data that are linearly separable with large margins. Compared to Vapnik\u2018s algorithm, however, ours is much simpler to implement, and much more efficient in terms of computation time. We also show that our algorithm can be efficiently used in very high dimensional spaces using kernel functions. We performed some experiments using our algorithm, and some variants of it, for classifying images of handwritten digits. The performance of our algorithm is close to, but not as good as, the performance of maximal-margin classifiers on the same problem, while saving significantly on computation time and programming effort.", "authors": ["Yoav Freund", "Robert E. Schapire"], "related_topics": ["60908668", "139532973", "195358245"], "citation_count": "1612", "reference_count": "22", "references": ["2156909104", "2148603752", "2119821739", "2087347434", "1530699444", "2069317438", "1979675141", "1496612019", "1667072054", "2011395874"], "date": "1998"}, {"id": "2121601095", "title": "Detecting faces in images: a survey", "abstract": "Images containing faces are essential to intelligent vision-based human-computer interaction, and research efforts in face processing include face recognition, face tracking, pose estimation and expression recognition. However, many reported methods assume that the faces in an image or an image sequence have been identified and localized. To build fully automated systems that analyze the information contained in face images, robust and efficient face detection algorithms are required. Given a single image, the goal of face detection is to identify all image regions which contain a face, regardless of its 3D position, orientation and lighting conditions. Such a problem is challenging because faces are non-rigid and have a high degree of variability in size, shape, color and texture. Numerous techniques have been developed to detect faces in a single image, and the purpose of this paper is to categorize and evaluate these algorithms. We also discuss relevant issues such as data collection, evaluation metrics and benchmarking. After analyzing these algorithms and identifying their limitations, we conclude with several promising directions for future research.", "authors": ["Ming-Hsuan Yang", "D.J. Kriegman", "N. Ahuja"], "related_topics": ["4641261", "71681937", "88799230"], "citation_count": "5804", "reference_count": "174", "references": ["2099111195", "1554663460", "2138451337", "2217896605", "2121647436", "2145023731", "2104095591", "1594031697", "1560013842", "2033419168"], "date": "2001"}, {"id": "1901129140", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .", "authors": ["Olaf Ronneberger", "Philipp Fischer", "Thomas Brox"], "related_topics": ["2908962259", "108583219", "89600930"], "citation_count": "26984", "reference_count": "13", "references": ["2618530766", "2962835968", "1903029394", "2155893237", "1677182931", "1948751323", "2167510172", "1893585201", "2148349024", "2147800946"], "date": "2015"}, {"id": "1698663318", "title": "Learning Bayesian networks with local structure", "abstract": "In this paper we examine a novel addition to the known methods for learning Bayesian networks from data that improves the quality of the learned networks. Our approach explicitly represents and learns the local structure in the conditional probability tables (CPTs), that quantify these networks. This increases the space of possible models, enabling the representation of CPTs with a variable number of parameters that depends on the learned local structures. The resulting learning procedure is capable of inducing models that better emulate the real complexity of the interactions present in the data. We describe the theoretical foundations and practical aspects of learning local structures, as well as an empirical evaluation of the proposed method. This evaluation indicates that learning curves characterizing the procedure that exploits the local structure converge faster than these of the standard procedure. Our results also show that networks learned with local structure tend to be more complex (in terms of arcs), yet require less parameters.", "authors": ["Nir Friedman", "Moises Goldszmidt"], "related_topics": ["28006648", "58973888", "33724603"], "citation_count": "645", "reference_count": "25", "references": ["2099111195", "2125055259", "2159080219", "2168175751", "2170112109", "2008906462", "1533169541", "2083380015", "1983661866", "1530964327"], "date": "1996"}, {"id": "2169805405", "title": "Convolutional networks can learn to generate affinity graphs for image segmentation", "abstract": "Many image segmentation algorithms first generate an affinity graph and then partition it. We present a machine learning approach to computing an affinity graph using a convolutional network (CN) trained using ground truth provided by human experts. The CN affinity graph can be paired with any standard partitioning algorithm and improves segmentation accuracy significantly compared to standard hand-designed affinity functions. We apply our algorithm to the challenging 3D segmentation problem of reconstructing neuronal processes from volumetric electron microscopy (EM) and show that we are able to learn a good affinity graph directly from the raw EM images. Further, we show that our affinity graph improves the segmentation accuracy of both simple and sophisticated graph partitioning algorithms. In contrast to previous work, we do not rely on prior knowledge in the form of hand-designed image features or image preprocessing. Thus, we expect our algorithm to generalize effectively to arbitrary image types.", "authors": ["Srinivas C. Turaga", "Joseph F. Murray", "Viren Jain", "Fabian Roth", "Moritz Helmstaedter", "Kevin Briggman", "Winfried Denk", "H. Sebastian Seung"], "related_topics": ["124504099", "25694479", "65885262"], "citation_count": "387", "reference_count": "48", "references": ["3145128584", "2310919327", "2121947440", "2752885492", "1999478155", "2143516773", "1983364832", "2098979973", "2119823327", "2147800946"], "date": "2010"}, {"id": "2164976997", "title": "POSITIVE PSYCHOLOGICAL CAPITAL: MEASUREMENT AND RELATIONSHIP WITH PERFORMANCE AND SATISFACTION", "abstract": "Two studies were conducted to analyze how hope, resilience, optimism, and efficacy individually and as a composite higher-order factor predicted work performance and satisfaction. Results from Study 1 provided psychometric support for a new survey measure designed to assess each of these 4 facets, as well as a composite factor. Study 2 results indicated a significant positive relationship regarding the composite of these 4 facets with performance and satisfaction. Results from Study 2 also indicated that the composite factor may be a better predictor of performance and satisfaction than the 4 individual facets. Limitations and practical implications conclude the article.", "authors": ["Fred Luthans", "Bruce J. Avolio", "James B. Avey", "Steven M. Norman"], "related_topics": ["2718322", "2779077761", "2777991910"], "citation_count": "4663", "reference_count": "81", "references": ["2071666535", "1562208008", "2106096361", "1665332082", "2012186625", "2007445014", "2162090451", "1976439938", "2020137493", "1746951143"], "date": "2007"}, {"id": "2104095591", "title": "Snakes : Active Contour Models", "abstract": "A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching. We have used snakes successfully for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest.", "authors": ["Michael Kass", "Andrew P. Witkin", "Demetri Terzopoulos"], "related_topics": ["112353826", "129641003", "95020103"], "citation_count": "25285", "reference_count": "23", "references": ["2109863423", "2003370853", "1995756857", "1531060698", "2139762693", "2107198582", "2582614493", "2045798786", "1631253743", "1977699267"], "date": "1987"}, {"id": "2163059190", "title": "A scalable content-addressable network", "abstract": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.", "authors": ["Sylvia Ratnasamy", "Paul Francis", "Mark Handley", "Richard Karp", "Scott Shenker"], "related_topics": ["43995721", "99138194", "2780224649"], "citation_count": "10901", "reference_count": "21", "references": ["2158049821", "2101963262", "2174507869", "2104210894", "2164192722", "2000876023", "2145721479", "2115599946", "2155659292", "1989163006"], "date": "2001"}, {"id": "2020137493", "title": "Ordinary magic. Resilience processes in development.", "abstract": "The study of resilience in development has overturned many negative assumptions and deficit-focused models about children growing up under the threat of disadvantage and adversity. The most surprising conclusion emerging from studies of these children is the ordinariness of resilience. An examination of converging findings from variable-focused and person-focused investigations of these phenomena suggests that resilience is common and that it usually arises from the normative functions of human adaptational systems, with the greatest threats to human development being those that compromise these protective systems. The conclusion that resilience is made of ordinary rather than extraordinary processes offers a more positive outlook on human development and adaptation, as well as direction for policy and practice aimed at enhancing the development of children at risk for problems and psychopathology.", "authors": ["Ann S. Masten"], "related_topics": ["137176749", "109260823", "44725695"], "citation_count": "11046", "reference_count": "110", "references": ["2053133047", "2118919126", "2016679285", "2080756469", "1978743055", "1922192126", "1537259130", "1817265267", "2136424426", "2154559347"], "date": "2001"}, {"id": "2105464873", "title": "Sparse Coding with an Overcomplete Basis Set: A Strategy Employed by V1 ?", "abstract": "The spatial receptive fields of simple cells in mammalian striate cortex have been reasonably well described physiologically and can be characterized as being localized, oriented, and bandpass, comparable with the basis functions of wavelet transforms. Previously, we have shown that these receptive field properties may be accounted for in terms of a strategy for producing a sparse distribution of output activity in response to natural images. Here, in addition to describing this work in a more expansive fashion, we examine the neurobiological implications of sparse coding. Of particular interest is the case when the code is overcomplete--i.e., when the number of code elements is greater than the effective dimensionality of the input space. Because the basis functions are non-orthogonal and not linearly independent of each other, sparsifying the code will recruit only those basis functions necessary for representing a given input, and so the input-output function will deviate from being purely linear. These deviations from linearity provide a potential explanation for the weak forms of non-linearity observed in the response properties of cortical simple cells, and they further make predictions about the expected interactions among units in response to naturalistic stimuli.", "authors": ["Bruno A. Olshausen", "David J. Field"], "related_topics": ["5917680", "133219170", "77637269"], "citation_count": "4209", "reference_count": "38", "references": ["2132984323", "2099741732", "2108384452", "2145889472", "1536929369", "2133069808", "2107790757", "2167034998", "3022628558", "2145012779"], "date": "1997"}, {"id": "2155328222", "title": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews", "abstract": "This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs. A phrase has a positive semantic orientation when it has good associations (e.g., \"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g., \"very cavalier\"). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \"excellent\" minus the mutual information between the given phrase and the word \"poor\". A review is classified as recommended if the average semantic orientation of its phrases is positive. The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The accuracy ranges from 84% for automobile reviews to 66% for movie reviews.", "authors": ["Peter Turney"], "related_topics": ["130318100", "2776224158", "152139883"], "citation_count": "4350", "reference_count": "12", "references": ["1983578042", "2199803028", "1567365482", "1493790738", "1593045043", "1998442272", "1565863475", "3151392175", "2170381724", "1997855593"], "date": "2002"}, {"id": "2114030927", "title": "Partitioning sparse matrices with eigenvectors of graphs", "abstract": "The problem of computing a small vertex separator in a graph arises in the context of computing a good ordering for the parallel factorization of sparse, symmetric matrices. An algebraic approach for computing vertex separators is considered in this paper. It is, shown that lower bounds on separator sizes can be obtained in terms of the eigenvalues of the Laplacian matrix associated with a graph. The Laplacian eigenvectors of grid graphs can be computed from Kronecker products involving the eigenvectors of path graphs, and these eigenvectors can be used to compute good separators in grid graphs. A heuristic algorithm is designed to compute a vertex separator in a general graph by first computing an edge separator in the graph from an eigenvector of the Laplacian matrix, and then using a maximum matching in a subgraph to compute the vertex separator. Results on the quality of the separators computed by the spectral algorithm are presented, and these are compared with separators obtained from other algorith...", "authors": ["Alex Pothen", "Horst D. Simon", "Kan-Pu Liou"], "related_topics": ["80899671", "115178988", "164529433"], "citation_count": "2360", "reference_count": "45", "references": ["2798909945", "2059586807", "2151417892", "2095117703", "2983896310", "2161455936", "1981885118", "1515707356", "2147542748", "1989042829"], "date": "1990"}, {"id": "2169287257", "title": "Method and apparatus for use of rotational user inputs", "abstract": "Improved approaches for users of computing devices to interact with graphical user interfaces are described. According to one aspect, a rotational user action supplied by a user at a user input device is transformed into linear action with respect to a graphical user interface. According to another aspect, a portion of an extended list of items is displayed by a graphical user interface and, through rotational user actions at a user input device, the portion of the list being displayed can be varied with welcomed ease of use. Although the type of computing device can vary, the improved approaches are particularly well-suited for use with a portable media player.", "authors": ["Jeffrey L. Robbin", "Steve Jobs", "Philip W. Schiller"], "related_topics": ["197070257", "89505385", "149229913"], "citation_count": "999", "reference_count": "319", "references": ["2113918921", "2107118797", "2128423220", "1886112015", "1948825421", "2138051480", "1897547913", "2747151024", "2104761778", "2170249432"], "date": "2002"}, {"id": "2080563952", "title": "Signal representation using adaptive normalized Gaussian functions", "abstract": "Abstract In this paper, a new joint time-frequency signal representation, the adaptive Gaussian basis representation (AGR), is presented. Unlike the Gabor expansion and the wavelet decomposition, the bandwidth and time-frequency centers of the localized Gaussian elementary functions h p ( t ) used in the AGR can be adjusted to best match the analyzed signal. Each expansion coefficient B p is defined as the inner product s p ( t ) and h p ( t ), where s p ( t ) is the remainder of the orthogonal projection of s p \u22121 ( t ) onto h p \u22121 ( t ). Consequently, the AGR not only accurately captures signal local behavior, but also has a monotonically decreasing reconstruction error \u2016 s p ( t )\u2016 2 . By combining the AGR and the Wigner-Ville distribution, we further develop an adaptive spectrogram that is non-negative, cross-term free, and of high resolution. Finally, an efficient numerical algorithm to compute the optimal Gaussian elementary functions h p ( t ) is discussed.", "authors": ["Shie Qian", "Dapang Chen"], "related_topics": ["7218915", "163716315", "47432892"], "citation_count": "316", "reference_count": "11", "references": ["2581275558", "2151693816", "1996021349", "1989491465", "2003243598", "2033570251", "1968179574", "2021626442", "2154455356", "1984313570"], "date": "1994"}, {"id": "2124087378", "title": "Local grayvalue invariants for image retrieval", "abstract": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations.", "authors": ["C. Schmid", "R. Mohr"], "related_topics": ["189391414", "1667742", "75165309"], "citation_count": "2336", "reference_count": "36", "references": ["2914885528", "2111308925", "2098693229", "2123977795", "2095757522", "2011891945", "2109863423", "2112328181", "2022735534", "2160835070"], "date": "1997"}, {"id": "1631253743", "title": "Ill-Posed Problems and Regularization Analysis in Early Vision", "abstract": "While in classical optics the problem is to determine the images of physical objects, vision is confronted with the inverse problem of recovering three-dimensional shape from the light distribution in the image. Most processes of early vision such as stereomatching, computation of motion and all the ``structure from\" processes can be regarded as solutions to inverse problems. This common characteristic of early vision can be formalized---{\\it most early vision problems are ``ill-posed problems\" in the sense of Hadamard}. We will show that a mathematical theory developed for regularizing ill-posed problems leads in a natural way to the solution of early vision problems in terms of variational principles of a certain class. This is a new theoretical framework for some of the variational solutions already obtained in the analysis of early vision processes. It also shows how several other problems in early vision can be approached and solved.", "authors": ["Tomaso Poggio", "Vincent Torre"], "related_topics": ["12229352", "135252773", "106214006"], "citation_count": "190", "reference_count": "0", "references": ["2104095591", "2115689562", "1597286183", "2150535417", "2131910503", "2148107745", "2019635781", "3022071797", "2154841693", "2161958784"], "date": "1984"}, {"id": "2132267493", "title": "Tensor Rank and the Ill-Posedness of the Best Low-Rank Approximation Problem", "abstract": "There has been continued interest in seeking a theorem describing optimal low-rank approximations to tensors of order 3 or higher that parallels the Eckart-Young theorem for matrices. In this paper, we argue that the naive approach to this problem is doomed to failure because, unlike matrices, tensors of order 3 or higher can fail to have best rank-$r$ approximations. The phenomenon is much more widespread than one might suspect: examples of this failure can be constructed over a wide range of dimensions, orders, and ranks, regardless of the choice of norm (or even Bregman divergence). Moreover, we show that in many instances these counterexamples have positive volume: they cannot be regarded as isolated phenomena.  In one extreme case, we exhibit a tensor space in which no rank-3 tensor has an optimal rank-2 approximation. The notable exceptions to this misbehavior are rank-1 tensors and order-2 tensors (i.e., matrices). In a more positive spirit, we propose a natural way of overcoming the ill-posedness of the low-rank approximation problem, by using weak solutions when true solutions do not exist. For this to work, it is necessary to characterize the set of weak solutions, and we do this  in the case of rank 2, order 3 (in arbitrary dimensions). In our work we emphasize the importance of closely studying concrete low-dimensional examples as a first step toward more general results. To this end, we present a detailed analysis of equivalence classes of $2 \\times 2 \\times 2$ tensors, and we develop methods for extending results upward to higher orders and dimensions. Finally, we link our work to existing studies of tensors from an algebraic geometric point of view. The rank of a tensor can in theory be given a semialgebraic description; in other words, it can be determined by a system of polynomial inequalities. We study some of these polynomials in cases of interest to us; in particular, we make extensive use of the hyperdeterminant $\\Delta$ on $\\mathbb{R}^{2\\times 2 \\times 2}$.", "authors": ["Vin de Silva", "Lek-Heng Lim"], "related_topics": ["158158286", "107180903", "2779501479"], "citation_count": "892", "reference_count": "70", "references": ["1981745143", "2013912476", "2128978199", "2027559251", "1509568713", "2039748980", "1981663184", "2018282388", "1561337879", "290527292"], "date": "2008"}, {"id": "1825604117", "title": "Open-vocabulary Object Retrieval", "abstract": "", "authors": ["Sergio Guadarrama", "Erik Rodner", "Kate Saenko", "Ning Zhang", "Ryan Farrell", "Jeff Donahue", "Trevor Darrell"], "related_topics": ["189391414", "41008148", "204321447"], "citation_count": "81", "reference_count": "34", "references": ["2088049833", "2131846894", "2128017662", "2141362318", "2094728533", "1889268436", "1618905105", "21006490", "1897761818", "2066134726"], "date": "2014"}, {"id": "2056809970", "title": "Application of an adaptive auditory model to speech recognition", "abstract": "One approach to designing signal processors for speech recognition has been to model the mammalian auditory system. Most designs have not attempted to capture the time\u2010varying nature of the system, but have focused on the psychophysical aspects of critical bandwidth and loudness estimation. The IBM 5000\u2010word speech recognition system [Bahl et al., IEEE Trans. Pattern Anal. Machine Intell. PAMI\u20105, 179\u2013190 (1983)] uses an auditory model in which psychophysical critical\u2010band tuning and loudness estimation are combined with a firing\u2010rate model patterned after that of Schroeder and Hall [J. Acoust. Soc. Am. 55, 1055\u20131060 (1974)]. The signal processing system consists of a critical\u2010bandwidth filter bank, loudness estimation (intensity to the 1/3 power), and a reservoir\u2010type firing\u2010rate model with one internal state for each band. This model enhances transient events in the auditory signal, and causes rapid stimulus offsets to be marked by outputs smaller than the resting rate. The use of this auditory model in the IBM system produces a 4.4% error rate on a standard corpus of four speakers, while the previous filter\u2010bank signal processor produces 7.4% errors on the same data.", "authors": ["Jordan R. Cohen"], "related_topics": ["73208851", "79018884", "40969351"], "citation_count": "16", "reference_count": "0", "references": ["2080921589", "2003333103", "1628850721", "1507770639", "1611176049", "1560114291", "2128241392", "2401811773", "941483363", "2170429824"], "date": "1985"}, {"id": "2123716044", "title": "Neurocontrol of nonlinear dynamical systems with Kalman filter trained recurrent networks", "abstract": "Although the potential of the powerful mapping and representational capabilities of recurrent network architectures is generally recognized by the neural network research community, recurrent neural networks have not been widely used for the control of nonlinear dynamical systems, possibly due to the relative ineffectiveness of simple gradient descent training algorithms. Developments in the use of parameter-based extended Kalman filter algorithms for training recurrent networks may provide a mechanism by which these architectures will prove to be of practical value. This paper presents a decoupled extended Kalman filter (DEKF) algorithm for training of recurrent networks with special emphasis on application to control problems. We demonstrate in simulation the application of the DEKF algorithm to a series of example control problems ranging from the well-known cart-pole and bioreactor benchmark problems to an automotive subsystem, engine idle speed control. These simulations suggest that recurrent controller networks trained by Kalman filter methods can combine the traditional features of state-space controllers and observers in a homogeneous architecture for nonlinear dynamical systems, while simultaneously exhibiting less sensitivity than do purely feedforward controller networks to changes in plant parameters and measurement noise. >", "authors": ["G.V. Puskorius", "L.A. Feldkamp"], "related_topics": ["206833254", "147168706", "157286648"], "citation_count": "759", "reference_count": "27", "references": ["2138484437", "2016589492", "2150355110", "1583833196", "2143787696", "2057653135", "2132152975", "2112462566", "2090248140", "1529008516"], "date": "1994"}, {"id": "2154498027", "title": "Digital libraries and autonomous citation indexing", "abstract": "The revolution the Web has brought to information dissemination is not so much due to the availability of data-huge amounts of information has long been available in libraries-but rather the improved efficiency of accessing (improved accessibility to) that information. The Web promises to make more scientific articles more easily available. By making the context of citations easily and quickly browsable, autonomous citation indexing can help to evaluate the importance of individual contributions more accurately and quickly. Digital libraries incorporating ACI can help organize scientific literature and may significantly improve the efficiency of dissemination and feedback. ACI may also help speed the transition to scholarly electronic publishing.", "authors": ["S. Lawrence", "C. Lee Giles", "K. Bollacker"], "related_topics": ["18599908", "513874922", "105345328"], "citation_count": "1073", "reference_count": "11", "references": ["2147164982", "2168190036", "43327620", "2173701363", "2061312249", "2001450038", "2037055884", "2151395351", "2126263514", "2169882007"], "date": "1999"}, {"id": "2099968818", "title": "Boosting in the limit: maximizing the margin of learned ensembles", "abstract": "The \"minimum margin\" of an ensemble classifier on a given training set is, roughly speaking, the smallest vote it gives to any correct training label. Recent work has shown that the Adaboost algorithm is particularly effective at producing ensembles with large minimum margins, and theory suggests that this may account for its success at reducing generalization error. We note, however, that the problem of finding good margins is closely related to linear programming, and we use this connection to derive and test new \"LPboosting\" algorithms that achieve better minimum margins than Adaboost.However, these algorithms do not always yield better generalization performance. In fact, more often the opposite is true. We report on a series of controlled experiments which show that no simple version of the minimum-margin story can be complete. We conclude that the crucial question as to why boosting works so well in practice, and how to further improve upon it, remains mostly open.Some of our experiments are interesting for another reason: we show that Adaboost sometimes does overfit--eventually. This may take a very long time to occur, however, which is perhaps why this phenomenon has gone largely unnoticed.", "authors": ["Adam J. Grove", "Dale Schuurmans"], "related_topics": ["31912584", "148667399", "46686674"], "citation_count": "365", "reference_count": "17", "references": ["2119821739", "3124955340", "2125055259", "2112076978", "2152761983", "1504694836", "2982720039", "1966280301", "2266946488", "1553313034"], "date": "1998"}, {"id": "1990451873", "title": "Levels of processing: A framework for memory research", "abstract": "This paper briefly reviews the evidence for multistore theories of memory and points out some difficulties with the approach. An alternative framework for human memory research is then outlined in terms of depth or levels of processing. Some current data and arguments are reexamined in the light of this alternative framework and implications for further research considered.", "authors": ["Fergus I.M. Craik", "Robert S. Lockhart"], "related_topics": ["207317066", "49790547", "14482466"], "citation_count": "14777", "reference_count": "89", "references": ["2232925767", "1984314602", "1878893887", "631551527", "1773016195", "1980384741", "2049059074", "2073588290", "2240086165", "2043030203"], "date": "1972"}, {"id": "2089016366", "title": "Attribution: Perceiving the Causes of Behavior", "abstract": "", "authors": ["Edward Ellsworth Jones"], "related_topics": ["143299363", "81717268", "15744967"], "citation_count": "1642", "reference_count": "0", "references": ["2106096361", "2089457241", "2107223217", "1746951143", "2158810025", "2154380314", "2099141989", "1556726625", "2075585362", "2153134053"], "date": "1987"}, {"id": "2156598602", "title": "Photo tourism: exploring photo collections in 3D", "abstract": "We present a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface. Our system consists of an image-based modeling front end that automatically computes the viewpoint of each photograph as well as a sparse 3D model of the scene and image to model correspondences. Our photo explorer uses image-based rendering techniques to smoothly transition between photographs, while also enabling full 3D navigation and exploration of the set of images and world geometry, along with auxiliary information such as overhead maps. Our system also makes it easy to construct photo tours of scenic or historic locations, and to annotate image details, which are automatically transferred to other relevant images. We demonstrate our system on several large personal photo collections as well as images gathered from Internet photo sharing sites.", "authors": ["Noah Snavely", "Steven M. Seitz", "Richard Szeliski"], "related_topics": ["84396730", "205711294", "103230337"], "citation_count": "4029", "reference_count": "43", "references": ["2151103935", "3029645440", "2033819227", "2131846894", "2110764733", "1980911747", "2141282920", "2119781527", "2063366997", "2085261163"], "date": "2006"}, {"id": "585341442", "title": "The Economics of Reproducibility in Preclinical Research", "abstract": "Low reproducibility rates within life science research undermine cumulative knowledge production and contribute to both delays and costs of therapeutic drug development. An analysis of past studies indicates that the cumulative (total) prevalence of irreproducible preclinical research exceeds 50%, resulting in approximately US$28,000,000,000 (US$28B)/year spent on preclinical research that is not reproducible\u2014in the United States alone. We outline a framework for solutions and a plan for long-term improvements in reproducibility rates that will help to accelerate the discovery of life-saving therapies and cures.", "authors": ["Leonard P. Freedman", "Iain M. Cockburn", "Timothy S. Simcoe"], "related_topics": ["64903051", "177713679", "9893847"], "citation_count": "745", "reference_count": "33", "references": ["1987777080", "2175723801", "2048060485", "2067833766", "2137516955", "1975130349", "2066703498", "2166378641", "2069578934", "2114224807"], "date": "2015"}, {"id": "2031043614", "title": "On High Dimensional Indexing of Uncertain Data", "abstract": "In this paper, we will examine the problem of distance function computation and indexing uncertain data in high dimensionality for nearest neighbor and range queries. Because of the inherent noise in uncertain data, traditional distance function measures such as the Lq-metric and their probabilistic variants are not qualitatively effective. This problem is further magnified by the sparsity issue in high dimensionality. In this paper, we examine methods of computing distance functions for high dimensional data which are qualitatively effective and friendly to the use of indexes. In this paper, we show how to construct an effective index structure in order to handle uncertain similarity and range queries in high dimensionality. Typical range queries in high dimensional space use only a subset of the ranges in order to resolve the queries. Furthermore, it is often desirable to run similarity queries with only a subset of the large number of dimensions. Such queries are difficult to resolve with traditional index structures which use the entire set of dimensions. We propose query-processing techniques which use effective search methods on the index in order to compute the final results. We discuss the experimental results on a number of real and synthetic data sets in terms of effectiveness and efficiency. We show that the proposed distance measures are not only more effective than traditional Lq -norms, but can also be computed more efficiently over our proposed index structure.", "authors": ["C.C. Aggarwal", "P.S. Yu"], "related_topics": ["2778865114", "110432227", "2639959"], "citation_count": "26", "reference_count": "14", "references": ["2151135734", "2238624099", "2171776999", "1595303882", "2129035130", "2142909274", "1796251476", "1969642980", "2024400846", "2125791539"], "date": "2008"}, {"id": "2142909274", "title": "Efficient indexing methods for probabilistic threshold queries over uncertain data", "abstract": "It is infeasible for a sensor database to contain the exact value of each sensor at all points in time. This uncertainty is inherent in these systems due to measurement and sampling errors, and resource limitations. In order to avoid drawing erroneous conclusions based upon stale data, the use of uncertainty intervals that model each data item as a range and associated probability density function (pdf) rather than a single value has recently been proposed. Querying these uncertain data introduces imprecision into answers, in the form of probability values that specify the likeliness the answer satisfies the query. These queries are more expensive to evaluate than their traditional counterparts but are guaranteed to be correct and more informative due to the probabilities accompanying the answers. Although the answer probabilities are useful, for many applications, it is only necessary to know whether the probability exceeds a given threshold - we term these Probabilistic Threshold Queries (PTQ). In this paper we address the efficient computation of these types of queries. In particular, we develop two index structures and associated algorithms to efficiently answer PTQs. The first index scheme is based on the idea of augmenting uncertainty information to an R-tree. We establish the difficulty of this problem by mapping one-dimensional intervals to a two-dimensional space, and show that the problem of interval indexing with probabilities is significantly harder than interval indexing which is considered a well-studied problem. To overcome the limitations of this R-tree based structure, we apply a technique we call variance-based clustering, where data points with similar degrees of uncertainty are clustered together. Our extensive index structure can answer the queries for various kinds of uncertainty pdfs, in an almost optimal sense. We conduct experiments to validate the superior performance of both indexing schemes.", "authors": ["Reynold Cheng", "Yuni Xia", "Sunil Prabhakar", "Rahul Shah", "Jeffrey Scott Vitter"], "related_topics": ["2778865114", "49937458", "75165309"], "citation_count": "378", "reference_count": "23", "references": ["2126455177", "2097995023", "2101429492", "2171776999", "1599406659", "2119493805", "2043148321", "2067631433", "2096659092", "2797212254"], "date": "2004"}, {"id": "2100115174", "title": "Fundamentals of digital image processing", "abstract": "Introduction. 1. Two Dimensional Systems and Mathematical Preliminaries. 2. Image Perception. 3. Image Sampling and Quantization. 4. Image Transforms. 5. Image Representation by Stochastic Models. 6. Image Enhancement. 7. Image Filtering and Restoration. 8. Image Analysis and Computer Vision. 9. Image Reconstruction From Projections. 10. Image Data Compression.", "authors": ["Anil K. Jain"], "related_topics": ["106430172", "180462255", "9417928"], "citation_count": "17599", "reference_count": "0", "references": ["2122122381", "1976709621", "2145803225", "2015370045", "2122086266", "2115689562", "2172128189", "2110505738", "2163398148", "2130258210"], "date": "1988"}, {"id": "2093191240", "title": "QBIC project: querying images by content, using color, texture, and shape", "abstract": "In the query by image content (QBIC) project we are studying methods to query large on-line image databases using the images' content as the basis of the queries. Examples of the content we use include color, texture, and shape of image objects and regions. Potential applications include medical (`Give me other images that contain a tumor with a texture like this one'), photo-journalism (`Give me images that have blue at the top and red at the bottom'), and many others in art, fashion, cataloging, retailing, and industry. Key issues include derivation and computation of attributes of images and objects that provide useful query functionality, retrieval methods based on similarity as opposed to exact match, query by image example or user drawn image, the user interfaces, query refinement and navigation, high dimensional database indexing, and automatic and semi-automatic database population. We currently have a prototype system written in X/Motif and C running on an RS/6000 that allows a variety of queries, and a test database of over 1000 images and 1000 objects populated from commercially available photo clip art images. In this paper we present the main algorithms for color texture, shape and sketch query that we use, show example query results, and discuss future directions.\u00a9 (1993) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.", "authors": ["Carlton Wayne Niblack", "Ron Barber", "Will Equitz", "Myron D. Flickner", "Eduardo H. Glasman", "Dragutin Petkovic", "Peter Yanker", "Christos Faloutsos", "Gabriel Taubin"], "related_topics": ["157692150", "194222762", "99016210"], "citation_count": "3024", "reference_count": "14", "references": ["3017143921", "2151135734", "2118269922", "2074429597", "2149173084", "1576247523", "2147956424", "2061749544", "2094078373", "2110499305"], "date": "1993"}, {"id": "2147880316", "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data", "abstract": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data.", "authors": ["John D. Lafferty", "Andrew McCallum", "Fernando C. N. Pereira"], "related_topics": ["54907487", "196956702", "155846161"], "citation_count": "15804", "reference_count": "24", "references": ["2310919327", "3124955340", "1574901103", "2009570821", "2096175520", "1934019294", "1773803948", "2160842254", "3021452258", "2117400858"], "date": "2001"}, {"id": "2132332894", "title": "Matching images with different resolutions", "abstract": "In this paper we address the problem of matching two images with two different resolutions: a high-resolution image and a low-resolution one. On the premise that changes in resolution act as a smoothing equivalent to changes in scale, a scale-space representation of the high-resolution image is produced. Hence the one-to-one classical image matching paradigm becomes one-to-many because the low-resolution image is compared with all the scale-space representations of the high-resolution one. Key to the success of such a process is the proper representation of the features to be matched in scale-space. We show how to extract interest points at variable scales and we devise a method allowing the comparison of two images at two different resolutions. The method comprises the use of photometric- and rotation-invariant descriptors, a geometric model mapping the high-resolution image onto a low-resolution image region, and an image matching strategy based on the robust estimation of this geometric model. Extensive experiments show that our matching method can be used for scale changes up to a factor 6.", "authors": ["Y. Dufournaud", "C. Schmid", "R. Horaud"], "related_topics": ["158096908", "9417928", "205372480"], "citation_count": "283", "reference_count": "19", "references": ["2124386111", "2124087378", "2109200236", "2111308925", "2085261163", "2112328181", "2022735534", "2143753158", "1984757472", "1773272891"], "date": "2000"}, {"id": "2088032561", "title": "Input space versus feature space in kernel-based methods", "abstract": "This paper collects some ideas targeted at advancing our understanding of the feature spaces associated with support vector (SV) kernel functions. We first discuss the geometry of feature space. In particular, we review what is known about the shape of the image of input space under the feature space map, and how this influences the capacity of SV methods. Following this, we describe how the metric governing the intrinsic geometry of the mapped surface can be computed in terms of the kernel, using the example of the class of inhomogeneous polynomial kernels, which are often used in SV pattern recognition. We then discuss the connection between feature space and input space by dealing with the question of how one can, given some vector in feature space, find a preimage (exact or approximate) in input space. We describe algorithms to tackle this issue, and show their utility in two applications of kernel methods. First, we use it to reduce the computational complexity of SV decision functions; second, we combine it with the kernel PCA algorithm, thereby constructing a nonlinear statistical denoising technique which is shown to perform well on real-world data.", "authors": ["B. Scholkopf", "S. Mika", "C.J.C. Burges", "P. Knirsch", "K.-R. Muller", "G. Ratsch", "A.J. Smola"], "related_topics": ["122280245", "134517425", "160446489"], "citation_count": "1612", "reference_count": "29", "references": ["2156909104", "2139212933", "2140095548", "2151693816", "2087347434", "2797583072", "2147800946", "2146766088", "26816478", "854322902"], "date": "1999"}, {"id": "2068730032", "title": "Scalable Object Detection Using Deep Neural Networks", "abstract": "Deep convolutional neural networks have recently achieved state-of-the-art performance on a number of image recognition benchmarks, including the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC-2012). The winning model on the localization sub-task was a network that predicts a single bounding box and a confidence score for each object category in the image. Such a model captures the whole-image context around the objects but cannot handle multiple instances of the same object in the image without naively replicating the number of outputs for each instance. In this work, we propose a saliency-inspired neural network model for detection, which predicts a set of class-agnostic bounding boxes along with a single score for each box, corresponding to its likelihood of containing any object of interest. The model naturally handles a variable number of instances for each class and allows for cross-class generalization at the highest levels of the network. We are able to obtain competitive recognition performance on VOC2007 and ILSVRC2012, while using only the top few predicted locations in each image and a small number of neural network evaluations.", "authors": ["Dumitru Erhan", "Christian Szegedy", "Alexander Toshev", "Dragomir Anguelov"], "related_topics": ["175202392", "2776151529", "147037132"], "citation_count": "1074", "reference_count": "16", "references": ["2618530766", "2102605133", "2168356304", "2031489346", "2088049833", "2130306094", "2129305389", "2017691720", "2128715914", "2122146326"], "date": "2014"}, {"id": "2166051523", "title": "Green Optical Communications\u2014Part II: Energy Limitations in Networks", "abstract": "This is Part II of a two-part paper that explores the fundamental limitations on energy consumption in optical communications. Part I covers energy consumption in optical transport. Part II explores the lower bound on energy consumption in optical switches and networks, analyzes the energy performance of a range of switching devices, and presents quantitative models of the lower bounds on energy consumption in these devices. These models are incorporated into a simple model of a global switched network and the lower bound on total network energy consumption is estimated. We compare the results of this bottom-up calculation of the lower bound on network energy with a previous top-down analysis of overall network energy consumption based on real-world data for state-of-the art equipment and \u201cbusiness-as-usual\u201d forward projections. The present analysis confirms a previous finding in that in a global scale network, the energy consumption of the switching infrastructure is larger than the energy consumption of the transport infrastructure. We find that the theoretical lower bounds on transport energy identified in Part I and the switching energy in this paper are more than three orders of magnitude lower than predicted by a \u201cbusiness-as-usual\u201d analysis. In this paper, we explore how the gap between the theoretical lower bounds on energy consumption and current trends in network energy efficiency can be closed. We argue that future research needs to focus on improving the energy efficiency of switching and on devising methods to reduce the quantity of switching infrastructure in the network. Further key strategies for reducing network energy consumption include developing of low-energy transport technologies, reducing the energy overheads associated with peripheral functions that are not central to the transport and switching of data, and reducing the energy consumption of the access network.", "authors": ["R S Tucker"], "related_topics": ["2780165032", "132853815", "2742236"], "citation_count": "292", "reference_count": "29", "references": ["2065088268", "2149641812", "2270461788", "2152241065", "2154267461", "2087924620", "2097247107", "2065055728", "1989857681", "2060292259"], "date": "2011"}, {"id": "2020246210", "title": "Learning in Artificial Neural Networks: A Statistical Perspective", "abstract": "The premise of this article is that learning procedures used to train artificial neural networks are inherently statistical techniques. It follows that statistical theory can provide considerable insight into the properties, advantages, and disadvantages of different network learning methods. We review concepts and analytical results from the literatures of mathematical statistics, econometrics, systems identification, and optimization theory relevant to the analysis of learning in artificial neural networks. Because of the considerable variety of available learning procedures and necessary limitations of space, we cannot provide a comprehensive treatment. Our focus is primarily on learning procedures for feedforward networks. However, many of the concepts and issues arising in this framework are also quite broadly relevant to other network learning paradigms. In addition to providing useful insights, the material reviewed here suggests some potentially useful new training methods for artificial neural ne...", "authors": ["Halbert White"], "related_topics": ["32254414", "50644808", "50292564"], "citation_count": "1220", "reference_count": "71", "references": ["1639032689", "1497256448", "2581275558", "2154642048", "2137983211", "2103496339", "3146803896", "1971735090", "2165758113", "2056099894"], "date": "1989"}, {"id": "2010315761", "title": "Cognitron: A self-organizing multilayered neural network", "abstract": "A new hypothesis for the organization of synapses between neurons is proposed: \"The synapse from neuron x to neuron y is reinforced when x fires provided that no neuron in the vicinity of y is firing stronger than y\". By introducing this hypothesis, a new algorithm with which a multilayered neural network is effectively organized can be deduced. A self-organizing multilayered neural network, which is named \"cognitron\", is constructed following this algorithm, and is simulated on a digital computer. Unlike the organization of a usual brain models such as a three-layered perceptron, the self-organization of a cognitron progresses favorably without having a \"teacher\" which instructs in all particulars how the individual cells respond. After repetitive presentations of several stimulus patterns, the cognitron is self-organized in such a way that the receptive fields of the cells become relatively larger in a deeper layer. Each cell in the final layer integrates the information from whole parts of the first layer and selectively responds to a specific stimulus pattern or a feature.", "authors": ["Kunihiko Fukushima"], "related_topics": ["19071747", "60908668", "50644808"], "citation_count": "569", "reference_count": "12", "references": ["2887242076", "2116360511", "2322002063", "2155051950", "1594551768", "2103212315", "2008625057", "2048205984", "2091546412", "2058568633"], "date": "1975"}, {"id": "1490482062", "title": "Computer Graphics: Principles and Practice", "abstract": "1. Introduction. Image Processing as Picture Analysis. The Advantages of Interactive Graphics. Representative Uses of Computer Graphics. Classification of Applications. Development of Hardware and Software for Computer Graphics. Conceptual Framework for Interactive Graphics. 2. Programming in the Simple Raster Graphics Package (SRGP)/. Drawing with SRGP/. Basic Interaction Handling/. Raster Graphics Features/. Limitations of SRGP/. 3. Basic Raster Graphics Algorithms for Drawing 2d Primitives. Overview. Scan Converting Lines. Scan Converting Circles. Scan Convertiing Ellipses. Filling Rectangles. Fillign Polygons. Filling Ellipse Arcs. Pattern Filling. Thick Primiives. Line Style and Pen Style. Clipping in a Raster World. Clipping Lines. Clipping Circles and Ellipses. Clipping Polygons. Generating Characters. SRGP_copyPixel. Antialiasing. 4. Graphics Hardware. Hardcopy Technologies. Display Technologies. Raster-Scan Display Systems. The Video Controller. Random-Scan Display Processor. Input Devices for Operator Interaction. Image Scanners. 5. Geometrical Transformations. 2D Transformations. Homogeneous Coordinates and Matrix Representation of 2D Transformations. Composition of 2D Transformations. The Window-to-Viewport Transformation. Efficiency. Matrix Representation of 3D Transformations. Composition of 3D Transformations. Transformations as a Change in Coordinate System. 6. Viewing in 3D. Projections. Specifying an Arbitrary 3D View. Examples of 3D Viewing. The Mathematics of Planar Geometric Projections. Implementing Planar Geometric Projections. Coordinate Systems. 7. Object Hierarchy and Simple PHIGS (SPHIGS). Geometric Modeling. Characteristics of Retained-Mode Graphics Packages. Defining and Displaying Structures. Modeling Transformations. Hierarchical Structure Networks. Matrix Composition in Display Traversal. Appearance-Attribute Handling in Hierarchy. Screen Updating and Rendering Modes. Structure Network Editing for Dynamic Effects. Interaction. Additional Output Features. Implementation Issues. Optimizing Display of Hierarchical Models. Limitations of Hierarchical Modeling in PHIGS. Alternative Forms of Hierarchical Modeling. 8. Input Devices, Interaction Techniques, and Interaction Tasks. Interaction Hardware. Basic Interaction Tasks. Composite Interaction Tasks. 9. Dialogue Design. The Form and Content of User-Computer Dialogues. User-Interfaces Styles. Important Design Considerations. Modes and Syntax. Visual Design. The Design Methodology. 10. User Interface Software. Basic Interaction-Handling Models. Windows-Management Systems. Output Handling in Window Systems. Input Handling in Window Systems. Interaction-Technique Toolkits. User-Interface Management Systems. 11. Representing Curves and Surfaces. Polygon Meshes. Parametric Cubic Curves. Parametric Bicubic Surfaces. Quadric Surfaces. 12. Solid Modeling. Representing Solids. Regularized Boolean Set Operations. Primitive Instancing. Sweep Representations. Boundary Representations. Spatial-Partitioning Representations. Constructive Solid Geometry. Comparison of Representations. User Interfaces for Solid Modeling. 13. Achromatic and Colored Light. Achromatic Light. Chromatic Color. Color Models for Raster Graphics. Reproducing Color. Using Color in Computer Graphics. 14. The Quest for Visual Realism. Why Realism? Fundamental Difficulties. Rendering Techniques for Line Drawings. Rendering Techniques for Shaded Images. Improved Object Models. Dynamics. Stereopsis. Improved Displays. Interacting with Our Other Senses. Aliasing and Antialiasing. 15. Visible-Surface Determination. Functions of Two Variables. Techniques for Efficient Visible-Surface Determination. Algorithms for Visible-Line Determination. The z-Buffer Algorithm. List-Priority Algorithms. Scan-Line Algorithms. Area-Subdivision Algorithms. Algorithms for Octrees. Algorithms for Curved Surfaces. Visible-Surface Ray Tracing. 16. Illumination And Shading. Illumination Modeling. Shading Models for Polygons. Surface Detail. Shadows. Transparency. Interobject Reflections. Physically Based Illumination Models. Extended Light Sources. Spectral Sampling. Improving the Camera Model. Global Illumination Algorithms. Recursive Ray Tracing. Radiosity Methods. The Rendering Pipeline. 17. Image Manipulation and Storage. What Is an Image? Filtering. Image Processing. Geometric Transformations of Images. Multipass Transformations. Image Compositing. Mechanisms for Image Storage. Special Effects with Images. Summary. 18. Advanced Raster Graphic Architecture. Simple Raster-Display System. Display-Processor Systems. Standard Graphics Pipeline. Introduction to Multiprocessing. Pipeline Front-End Architecture. Parallel Front-End Architectures. Multiprocessor Rasterization Architectures. Image-Parallel Rasterization. Object-Parallel Rasterization. Hybrid-Parallel Rasterization. Enhanced Display Capabilities. 19. Advanced Geometric and Raster Algorithms. Clipping. Scan-Converting Primitives. Antialiasing. The Special Problems of Text. Filling Algorithms. Making copyPixel Fast. The Shape Data Structure and Shape Algebra. Managing Windows with bitBlt. Page Description Languages. 20. Advanced Modeling Techniques. Extensions of Previous Techniques. Procedural Models. Fractal Models. Grammar-Based Models. Particle Systems. Volume Rendering. Physically Based Modeling. Special Models for Natural and Synthetic Objects. Automating Object Placement. 21. Animation. Conventional and Computer-Assisted Animation. Animation Languages. Methods of Controlling Animation. Basic Rules of Animation. Problems Peculiar to Animation. Appendix: Mathematics for Computer Graphics. Vector Spaces and Affine Spaces. Some Standard Constructions in Vector Spaces. Dot Products and Distances. Matrices. Linear and Affine Transformations. Eigenvalues and Eigenvectors. Newton-Raphson Iteration for Root Finding. Bibliography. Index. 0201848406T04062001", "authors": ["James D. Foley"], "related_topics": ["59662460", "75453227", "181844469"], "citation_count": "11505", "reference_count": "0", "references": ["2170102584", "2122122381", "3124420883", "2080528351", "2160126058", "2002195659", "2161304134", "2169150396", "1513768190", "1502024436"], "date": "1994"}, {"id": "1678356000", "title": "Greedy function approximation: A gradient boosting machine.", "abstract": "Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent \u201cboosting\u201d paradigm is developed for additive expansions based on any fitting criterion.Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such \u201cTreeBoost\u201d models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.", "authors": ["Jerome H. Friedman"], "related_topics": ["70153297", "31912584", "61070697"], "citation_count": "13655", "reference_count": "20", "references": ["2156909104", "2117812871", "2112076978", "1594031697", "1498436455", "2151693816", "2024046085", "740415", "2797583072", "2102201073"], "date": "2001"}, {"id": "2122146326", "title": "Fast, Accurate Detection of 100,000 Object Classes on a Single Machine", "abstract": "Many object detection systems are constrained by the time required to convolve a target image with a bank of filters that code for different aspects of an object's appearance, such as the presence of component parts. We exploit locality-sensitive hashing to replace the dot-product kernel operator in the convolution with a fixed number of hash-table probes that effectively sample all of the filter responses in time independent of the size of the filter bank. To show the effectiveness of the technique, we apply it to evaluate 100,000 deformable-part models requiring over a million (part) filters on multiple scales of a target image in less than 20 seconds using a single multi-core processor with 20GB of RAM. This represents a speed-up of approximately 20,000 times - four orders of magnitude - when compared with performing the convolutions explicitly on the same hardware. While mean average precision over the full set of 100,000 object classes is around 0.16 due in large part to the challenges in gathering training data and collecting ground truth for so many classes, we achieve a mAP of at least 0.20 on a third of the classes and 0.30 or better on about 20% of the classes.", "authors": ["Thomas Dean", "Mark A. Ruzon", "Mark Segal", "Jonathon Shlens", "Sudheendra Vijayanarasimhan", "Jay Yagnik"], "related_topics": ["182521987", "2776151529", "71681937"], "citation_count": "395", "reference_count": "22", "references": ["2618530766", "2161969291", "2168356304", "3097096317", "2037227137", "2120419212", "2094728533", "2147717514", "1736726159", "2129305389"], "date": "2013"}, {"id": "2141376824", "title": "Contour and Texture Analysis for Image Segmentation", "abstract": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture. Natural images contain both textured and untextured regions, so the cues of contour and texture differences are exploited simultaneously. Contours are treated in the intervening contour framework, while texture is analyzed using textons. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on the texturedness of the neighborhood at a pixel. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown.", "authors": ["Jitendra Malik", "Serge Belongie", "Thomas Leung", "Jianbo Shi"], "related_topics": ["63099799", "144743038", "54243161"], "citation_count": "1600", "reference_count": "38", "references": ["2121947440", "2145023731", "1578099820", "1997063559", "2121927366", "1634005169", "3017143921", "2114487471", "2160167256", "1490632837"], "date": "2001"}, {"id": "1508977358", "title": "Generating Typed Dependency Parses from Phrase Structure Parses", "abstract": "This paper describes a system for extracting typed dependency parses of English sentences from phrase structure parses. In order to capture inherent relations occurring in corpus texts that can be critical in real-world applications, many NP relations are included in the set of grammatical relations used. We provide a comparison of our system with Minipar and the Link parser. The typed dependency extraction facility described here is integrated in the Stanford Parser, available for download.", "authors": ["Marie-Catherine de Marneffe", "Bill MacCartney", "Christopher D. Manning"], "related_topics": ["80877019", "186644900", "19768560"], "citation_count": "2906", "reference_count": "14", "references": ["2097606805", "1535015163", "2092654472", "73274768", "1586060904", "1722351164", "3089319657", "10376690", "2080278171", "13173216"], "date": "2006"}, {"id": "1555806226", "title": "The Intuitive Psychologist And His Shortcomings: Distortions in the Attribution Process1", "abstract": "Publisher Summary Attribution theory is concerned with the attempts of ordinary people to understand the causes and implications of the events they witness. It deals with the \u201cnaive psychology\u201d of the \u201cman in the street\u201d as he interprets his own behaviors and the actions of others. For man\u2014in the perspective of attribution theory\u2014is an intuitive psychologist who seeks to explain behavior and draw inferences about actors and their environments. To better understand the perceptions and actions of this intuitive scientist, his methods must be explored. The sources of oversight, error, or bias in his assumptions and procedures may have serious consequences, both for the lay psychologist himself and for the society that he builds and perpetuates. These shortcomings, explored from the vantage point of contemporary attribution theory, are the focus of the chapter. The logical or rational schemata employed by intuitive psychologists and the sources of bias in their attempts at understanding, predicting, and controlling the events that unfold around them are considered. Attributional biases in the psychology of prediction, perseverance of social inferences and social theories, and the intuitive psychologist's illusions and insights are described.", "authors": ["Lee Ross"], "related_topics": ["50094484", "638126", "143299363"], "citation_count": "7265", "reference_count": "101", "references": ["2017680376", "158727920", "2164558494", "2100826189", "1998193015", "2035782089", "1980054641", "2089016366", "1748197048", "2016377072"], "date": "1976"}, {"id": "2159981908", "title": "Rumor has it: Identifying Misinformation in Microblogs", "abstract": "A rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP). Finally, we believe that our dataset is the first large-scale dataset on rumor detection. It can open new dimensions in analyzing online misinformation and other aspects of microblog conversations.", "authors": ["Vahed Qazvinian", "Emily Rosengren", "Dragomir R. Radev", "Qiaozhu Mei"], "related_topics": ["2780469804", "2776552730", "2776990098"], "citation_count": "770", "reference_count": "26", "references": ["1532325895", "2097726431", "2166706824", "2114524997", "40549020", "2127492100", "2140173168", "1988520084", "2050619059", "3021916629"], "date": "2011"}, {"id": "2055176966", "title": "VL2: a scalable and flexible data center network", "abstract": "To be agile and cost effective, data centers must allow dynamic resource allocation across large server pools. In particular, the data center network should provide a simple flat abstraction: it should be able to take any set of servers anywhere in the data center and give them the illusion that they are plugged into a physically separate, noninterfering Ethernet switch with as many ports as the service needs. To meet this goal, we present VL2, a practical network architecture that scales to support huge data centers with uniform high capacity between servers, performance isolation between services, and Ethernet layer-2 semantics. VL2 uses (1) flat addressing to allow service instances to be placed anywhere in the network, (2) Valiant Load Balancing to spread traffic uniformly across network paths, and (3) end system--based address resolution to scale to large server pools without introducing complexity to the network control plane. VL2's design is driven by detailed measurements of traffic and fault data from a large operational cloud service provider. VL2's implementation leverages proven network technologies, already available at low cost in high-speed hardware implementations, to build a scalable and reliable network architecture. As a result, VL2 networks can be deployed today, and we have built a working prototype. We evaluate the merits of the VL2 design using measurement, analysis, and experiments. Our VL2 prototype shuffles 2.7 TB of data among 75 servers in 395 s---sustaining a rate that is 94% of the maximum possible.", "authors": ["Albert Greenberg", "James R. Hamilton", "Navendu Jain", "Srikanth Kandula", "Changhoon Kim", "Parantap Lahiri", "David A. Maltz", "Parveen Patel", "Sudipta Sengupta"], "related_topics": ["93996380", "193415008", "119404949"], "citation_count": "3432", "reference_count": "18", "references": ["2173213060", "2130531694", "2055176966", "1501077214", "2126210439", "1493893823", "2062832101", "3021428210", "2117235019", "2101768888"], "date": "2011"}, {"id": "2010595692", "title": "Techniques for automatically correcting words in text", "abstract": "Research aimed at correcting words in text has focused on three progressively more difficult problems:(1) nonword error detection; (2) isolated-word error correction; and (3) context-dependent work correction. In response to the first problem, efficient pattern-matching and n-gram analysis techniques have been developed for detecting strings that do not appear in a given word list. In response to the second problem, a variety of general and application-specific spelling correction techniques have been developed. Some of them were based on detailed studies of spelling error patterns. In response to the third problem, a few experiments using natural-language-processing tools or statistical-language models have been carried out. This article surveys documented findings on spelling error patterns, provides descriptions of various nonword detection and isolated-word error correction techniques, reviews the state of the art of context-dependent word correction techniques, and discusses research issues related to all three areas of automatic error correction in text.", "authors": ["Karen Kukich"], "related_topics": ["103088060", "2777801307", "61249035"], "citation_count": "1807", "reference_count": "139", "references": ["2154642048", "2147152072", "1833785989", "2121227244", "2099247782", "2097333193", "1966812932", "1501400124", "2142384583", "23758216"], "date": "1992"}, {"id": "2154952480", "title": "Learnability and the Vapnik-Chervonenkis dimension", "abstract": "Valiant's learnability model is extended to learning classes of concepts defined by regions in Euclidean space En. The methods in this paper lead to a unified treatment of some of Valiant's results, along with previous results on distribution-free convergence of certain pattern recognition algorithms. It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, the complexity and closure properties of learnable classes are analyzed, and the necessary and sufficient conditions are provided for feasible learnability.", "authors": ["Anselm Blumer", "A. Ehrenfeucht", "David Haussler", "Manfred K. Warmuth"], "related_topics": ["2777723229", "176248197", "119322782"], "citation_count": "2283", "reference_count": "64", "references": ["2011039300", "3017143921", "1655990431", "2752853835", "2611147814", "2165758113", "1530699444", "2019363670", "2117362057", "2129113961"], "date": "1989"}, {"id": "2125055259", "title": "C4.5: Programs for Machine Learning", "abstract": "From the Publisher: Classifier systems play a major role in machine learning and knowledge-based systems, and Ross Quinlan's work on ID3 and C4.5 is widely acknowledged to have made some of the most significant contributions to their development. This book is a complete guide to the C4.5 system as implemented in C for the UNIX environment. It contains a comprehensive guide to the system's use , the source code (about 8,800 lines), and implementation notes. The source code and sample datasets are also available on a 3.5-inch floppy diskette for a Sun workstation. C4.5 starts with large sets of cases belonging to known classes. The cases, described by any mixture of nominal and numeric properties, are scrutinized for patterns that allow the classes to be reliably discriminated. These patterns are then expressed as models, in the form of decision trees or sets of if-then rules, that can be used to classify new cases, with emphasis on making the models understandable as well as accurate. The system has been applied successfully to tasks involving tens of thousands of cases described by hundreds of properties. The book starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting. Advantages and disadvantages of the C4.5 approach are discussed and illustrated with several case studies. This book and software should be of interest to developers of classification-based intelligent systems and to students in machine learning and expert systems courses.", "authors": ["J. Ross Quinlan"], "related_topics": ["183931066", "56397880", "52003472"], "citation_count": "27075", "reference_count": "0", "references": ["1484413656", "2148143831", "2149684865", "2112076978", "3100785508", "607505555", "2132549764", "2142827986", "2153010521", "2017337590"], "date": "1992"}, {"id": "2107941094", "title": "Ant system: optimization by a colony of cooperating agents", "abstract": "An analogy with the way ant colonies function has suggested the definition of a new computational paradigm, which we call ant system (AS). We propose it as a viable new approach to stochastic combinatorial optimization. The main characteristics of this model are positive feedback, distributed computation, and the use of a constructive greedy heuristic. Positive feedback accounts for rapid discovery of good solutions, distributed computation avoids premature convergence, and the greedy heuristic helps find acceptable solutions in the early stages of the search process. We apply the proposed methodology to the classical traveling salesman problem (TSP), and report simulation results. We also discuss parameter selection and the early setups of the model, and compare it with tabu search and simulated annealing using TSP. To demonstrate the robustness of the approach, we show how the ant system (AS) can be applied to other optimization problems like the asymmetric traveling salesman, the quadratic assignment and the job-shop scheduling. Finally we discuss the salient characteristics-global data structure revision, distributed communication and probabilistic transitions of the AS.", "authors": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "related_topics": ["109718341", "40128228", "188919014"], "citation_count": "15973", "reference_count": "29", "references": ["1639032689", "1497256448", "2581275558", "1652505363", "2152150600", "2104670598", "2297395784", "1492640216", "3011460294", "2042986967"], "date": "1996"}, {"id": "2113112851", "title": "XSEarch: a semantic search engine for XML", "abstract": "XSEarch, a semantic search engine for XML, is presented. XSEarch has a simple query language, suitable for a naive user. It returns semantically related document fragments that satisfy the user's query. Query answers are ranked using extended information-retrieval techniques and are generated in an order similar to the ranking. Advanced indexing techniques were developed to facilitate efficient implementation of XSEarch. The performance of the different techniques as well as the recall and the precision were measured experimentally. These experiments indicate that XSEarch is efficient, scalable and ranks quality results highly.", "authors": ["Sara Cohen", "Jonathan Mamou", "Yaron Kanza", "Yehoshua Sagiv"], "related_topics": ["192028432", "166423231", "75165309"], "citation_count": "847", "reference_count": "14", "references": ["3013264884", "1660390307", "1973828215", "2084243240", "2074863013", "2108572131", "2124770891", "1562549404", "43380317", "2131747693"], "date": "2003"}, {"id": "2075665712", "title": "Solving Least Squares Problems", "abstract": "", "authors": ["Charles L. Lawson", "Richard J. Hanson"], "related_topics": ["126090379", "45923927", "169241690"], "citation_count": "8310", "reference_count": "0", "references": ["1570448133", "2135046866", "2024165284", "2063978378", "2047920195", "2752849906", "2172249709", "2110096996", "2017288758", "2079810998"], "date": "1974"}, {"id": "2171776999", "title": "Evaluating probabilistic queries over imprecise data", "abstract": "Many applications employ sensors for monitoring entities such as temperature and wind speed. A centralized database tracks these entities to enable query processing. Due to continuous changes in these values and limited resources (e.g., network bandwidth and battery power), it is often infeasible to store the exact values at all times. A similar situation exists for moving object environments that track the constantly changing locations of objects. In this environment, it is possible for database queries to produce incorrect or invalid results based upon old data. However, if the degree of error (or uncertainty) between the actual value and the database value is controlled, one can place more confidence in the answers to queries. More generally, query answers can be augmented with probabilistic estimates of the validity of the answers. In this paper we study probabilistic query evaluation based upon uncertain data. A classification of queries is made based upon the nature of the result set. For each class, we develop algorithms for computing probabilistic answers. We address the important issue of measuring the quality of the answers to these queries, and provide algorithms for efficiently pulling data from relevant sensors or moving objects in order to improve the quality of the executing queries. Extensive experiments are performed to examine the effectiveness of several data update policies.", "authors": ["Reynold Cheng", "Dmitri V. Kalashnikov", "Sunil Prabhakar"], "related_topics": ["172722865", "174539288", "24028149"], "citation_count": "813", "reference_count": "17", "references": ["1993482412", "1599406659", "2136793462", "2020584928", "2119493805", "2110849300", "1602423797", "2135252439", "2592414837", "1482356393"], "date": "2003"}, {"id": "2752853835", "title": "The Art of Computer Programming", "abstract": "", "authors": ["Donald Ervin Knuth"], "related_topics": ["113041634", "61714564", "33857546"], "citation_count": "27471", "reference_count": "0", "references": ["2024165284", "1992419399", "1506281249", "1736726159", "1996360405", "2156186849", "2540924152", "2137147061", "2095595785", "2156030242"], "date": "1967"}, {"id": "2171928131", "title": "Extensions of recurrent neural network language model", "abstract": "We present several modifications of the original recurrent neural network language model (RNN LM).While this model has been shown to significantly outperform many competitive language modeling techniques in terms of accuracy, the remaining problem is the computational complexity. In this work, we show approaches that lead to more than 15 times speedup for both training and testing phases. Next, we show importance of using a backpropagation through time algorithm. An empirical comparison with feedforward networks is also provided. In the end, we discuss possibilities how to reduce the amount of parameters in the model. The resulting RNN model can thus be smaller, faster both during training and testing, and more accurate than the basic one.", "authors": ["Tomas Mikolov", "Stefan Kombrink", "Lukas Burget", "Jan Cernocky", "Sanjeev Khudanpur"], "related_topics": ["2780005939", "147168706", "137293760"], "citation_count": "5360", "reference_count": "20", "references": ["179875071", "2132339004", "1498436455", "2110485445", "2107878631", "2613634265", "36903255", "2096072088", "2111305191", "2152808281"], "date": "2011"}, {"id": "1947481746", "title": "Indication of progress towards satisfaction of a user input condition", "abstract": "In some embodiments of the invention, a graphical user interface in an electronic device includes one or more user-interface objects associated with a second user-interface state. While the device is in a first user-interface state, the one or more objects transition in optical intensity to indicate progress towards satisfaction of a user input condition needed to transition to the second user-interface state.", "authors": ["Freddy Allen Anzures", "Bas Ording", "Imran Chaudhri", "Marcel van Os", "Stephen O. Lemay", "Greg Christie", "Scott Forstall"], "related_topics": ["37789001", "48103436", "107457646"], "citation_count": "507", "reference_count": "65", "references": ["1955828807", "2128637996", "2113918921", "1901544345", "2115218409", "1485033854", "1489671546", "1849545308", "1881530487", "2829102984"], "date": "2008"}, {"id": "1822002357", "title": "The Syntax-Morphology Interface: A Study of Syncretism", "abstract": "Preface List of abbreviations and symbols 1. Introduction 2. Characteristics of syncretism 3. Cross-linguistic typology of features 4. Formal representation 5. Formal framework and case studies 6. Conclusion References Indexes.", "authors": ["Matthew Baerman", "Dunstan Brown", "Greville G. Corbett"], "related_topics": ["2780158765", "166553842", "41895202"], "citation_count": "489", "reference_count": "209", "references": ["239563548", "1574095631", "1970481396", "1590441455", "1602192136", "602086463", "1585233683", "173533992", "2106136173", "435038712"], "date": "2009"}, {"id": "1886112015", "title": "Capacitive position sensor", "abstract": "A capacitive position sensor has a two-layer electrode structure. Drive electrodes extending in a first direction on a first plane on one side of a substrate. Sense electrodes extend in a second direction on a second plane on the other side of the substrate so that the sense electrodes cross the drive electrodes at a plurality of intersections which collectively form a position sensing array. The sense electrodes are provided with branches extending in the first direction part of the way towards each adjacent sense electrode so that end portions of the branches of adjacent sense electrodes co-extend with each other in the first direction separated by a distance sufficiently small that capacitive coupling to the drive electrode adjacent to the co-extending portion is reduced. Providing sense electrode branches allow a sensor to be made which has a greater extent in the first direction for a given number of sense channels, since the co-extending portions provide an interpolating effect. The number of sense electrode branches per drive electrode can be increased which allows a sensor to be made which has ever greater extent in the first direction without having to increase the number of sense channels.", "authors": ["Harald Philipp"], "related_topics": ["29258643", "206755178", "143141573"], "citation_count": "1227", "reference_count": "120", "references": ["1930456798", "2123650448", "2137305553", "1901544345", "2107118797", "2165432612", "2258130146", "2849334407", "2162399989", "1519940482"], "date": "2010"}, {"id": "1557757161", "title": "The SMART Retrieval System\u2014Experiments in Automatic Document Processing", "abstract": "", "authors": ["G. Salton"], "related_topics": ["177937566", "2278759", "161156560"], "citation_count": "2721", "reference_count": "0", "references": ["1662133657", "2150102617", "2097089247", "2053463056", "1978394996", "1550258693", "2075597533", "1924689489", "2138662031", "2171104838"], "date": "1970"}, {"id": "2094934653", "title": "Automated learning of decision rules for text categorization", "abstract": "We describe the results of extensive experiments using optimized rule-based induction methods on large document collections. The goal of these methods is to discover automatically classification patterns that can be used for general document categorization or personalized filtering of free text. Previous reports indicate that human-engineered rule-based systems, requiring many man-years of developmental efforts, have been successfully built to \u201cread\u201d documents and assign topics to them. We show that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation. In comparison with other machine-learning techniques, results on a key benchmark from the Reuters collection show a large gain in performance, from a previously reported 67% recall/precision breakeven point to 80.5%. In the context of a very high-dimensional feature space, several methodological alternatives are examined, including universal versus local dictionaries, and binary versus frequency-related features.", "authors": ["Chidanand Apt\u00e9", "Fred Damerau", "Sholom M. Weiss"], "related_topics": ["84839998", "94124525", "2780049985"], "citation_count": "1222", "reference_count": "20", "references": ["1593045043", "2136000097", "2128420091", "2137719099", "1527532036", "2042986967", "2126502509", "1570286060", "1993934121", "2043772506"], "date": "1994"}, {"id": "1667950888", "title": "On Limits of Wireless Communications in a Fading Environment when UsingMultiple Antennas", "abstract": "This paper is motivated by the need for fundamental understanding of ultimate limits of bandwidth efficient delivery of higher bit-rates in digital wireless communications and to also begin to look into how these limits might be approached. We examine exploitation of multi-element array (MEA) technology, that is processing the spatial dimension (not just the time dimension) to improve wireless capacities in certain applications. Specifically, we present some basic information theory results that promise great advantages of using MEAs in wireless LANs and building to building wireless communication links. We explore the important case when the channel characteristic is not available at the transmitter but the receiver knows (tracks) the characteristic which is subject to Rayleigh fading. Fixing the overall transmitted power, we express the capacity offered by MEA technology and we see how the capacity scales with increasing SNR for a large but practical number, n, of antenna elements at both transmitter and receiver. We investigate the case of independent Rayleigh faded paths between antenna elements and find that with high probability extraordinary capacity is available. Compared to the baseline n = 1 case, which by Shannon\u2018s classical formula scales as one more bit/cycle for every 3 dB of signal-to-noise ratio (SNR) increase, remarkably with MEAs, the scaling is almost like n more bits/cycle for each 3 dB increase in SNR. To illustrate how great this capacity is, even for small n, take the cases n = 2, 4 and 16 at an average received SNR of 21 dB. For over 99% of the channels the capacity is about 7, 19 and 88 bits/cycle respectively, while if n = 1 there is only about 1.2 bit/cycle at the 99% level. For say a symbol rate equal to the channel bandwith, since it is the bits/symbol/dimension that is relevant for signal constellations, these higher capacities are not unreasonable. The 19 bits/cycle for n = 4 amounts to 4.75 bits/symbol/dimension while 88 bits/cycle for n = 16 amounts to 5.5 bits/symbol/dimension. Standard approaches such as selection and optimum combining are seen to be deficient when compared to what will ultimately be possible. New codecs need to be invented to realize a hefty portion of the great capacity promised.", "authors": ["G. J. Foschini", "M. J. Gans"], "related_topics": ["74645175", "81978471", "156996364"], "citation_count": "14131", "reference_count": "40", "references": ["2121606987", "1549664537", "2128978199", "1596939795", "2021573106", "2165205968", "2139593345", "3152750074", "2142901448", "1974755392"], "date": "1998"}, {"id": "2148107745", "title": "Boundary finding with parametrically deformable models", "abstract": "Segmentation using boundary finding is enhanced both by considering the boundary as a whole and by using model-based global shape information. The authors apply flexible constraints, in the form of a probabilistic deformable model, to the problem of segmenting natural 2-D objects whose diversity and irregularity of shape make them poorly represented in terms of fixed features or form. The parametric model is based on the elliptic Fourier decomposition of the boundary. Probability distributions on the parameters of the representation bias the model to a particular overall shape while allowing for deformations. Boundary finding is formulated as an optimization problem using a maximum a posteriori objective function. Results of the method applied to real and synthetic images are presented, including an evaluation of the dependence of the method on prior information and image quality. >", "authors": ["L.H. Staib", "J.S. Duncan"], "related_topics": ["62354387", "24574437", "117251300"], "citation_count": "1177", "reference_count": "42", "references": ["2341283081", "2104095591", "2911709767", "2740373864", "22745672", "2125848778", "2131806657", "2007153649", "2095905764", "1574225613"], "date": "1992"}, {"id": "2581275558", "title": "Optimization by simulated annealing", "abstract": "There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.", "authors": ["S. Kirkpatrick", "C. D. Gelatt", "M. P. Vecchi"], "related_topics": ["137836250", "52692508", "126980161"], "citation_count": "52083", "reference_count": "14", "references": ["2042986967", "2022820481", "2114552889", "2022494241", "2143037347", "2056760934", "2148673189", "86906884", "2014952973", "2014068360"], "date": "1986"}, {"id": "1999138184", "title": "Learning Logical Definitions from Relations", "abstract": "This paper describes FOIL, a system that learns Horn clauses from data expressed as relations. FOIL is based on ideas that have proved effective in attribute-value learning systems, but extends them to a first-order formalism. This new system has been applied successfully to several tasks taken from the machine learning literature.", "authors": ["J. R. Quinlan"], "related_topics": ["32254414", "28006648", "24138899"], "citation_count": "2699", "reference_count": "32", "references": ["1594031697", "2149706766", "2136000097", "2128420091", "1983661866", "2180885055", "145476170", "2428981601", "2106596127", "2101602574"], "date": "1990"}, {"id": "2156218005", "title": "Value-based requirements engineering: exploring innovative e-commerce ideas", "abstract": "Innovative e-commerce ideas are characterised by commercial products yet unknown to the market, enabled by information technology such as the Internet and technologies on top of it. How to develop such products is hardly known. We propose an interdisciplinary approach, e3-value, to explore an innovative e-commerce idea with the aim of understanding such an idea thoroughly and evaluating it for potential profitability. Our methodology exploits a requirements engineering way of working, but employs concepts and terminology from business science, marketing and axiology. It shows how to model business requirements and improve business---IT alignment, in sophisticated multi-actor value constellations that are common in electronic commerce. In addition to the e3-value approach methodology, we also present the action research-based development of our methodology, by using one of the longitudinal projects we carried out in the field of online news article provisioning.", "authors": ["Jaap Gordijn", "J. M. Akkermans"], "related_topics": ["123247970", "6604083", "78597825"], "citation_count": "1237", "reference_count": "92", "references": ["1649645444", "1660562555", "23685451", "2174507869", "1562891728", "2133109597", "1998017916", "2295656366", "1603504818", "3149395617"], "date": "2003"}, {"id": "2151498684", "title": "A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input", "abstract": "We propose a method for automatically answering questions about images by bringing together recent advances from natural language processing and computer vision. We combine discrete reasoning with uncertain predictions by a multi-world approach that represents uncertainty about the perceived world in a bayesian framework. Our approach can handle human questions of high complexity about realistic scenes and replies with range of answer like counts, object classes, instances and lists of them. The system is directly trained from question-answer pairs. We establish a first benchmark for this task that can be seen as a modern attempt at a visual turing test.", "authors": ["Mateusz Malinowski", "Mario Fritz"], "related_topics": ["44291984", "577917", "64729616"], "citation_count": "488", "reference_count": "26", "references": ["2912565176", "1532325895", "125693051", "2081580037", "2067912884", "2161002933", "2319794630", "2236233024", "2136480620", "2142900973"], "date": "2014"}, {"id": "2303573281", "title": "Intelligent management for an electronic device", "abstract": "An electronic device is disclosed. The electronic device includes a first input device; a second input device capable of operating in a first operating mode; and a system management module in communication with the first input device and the second input device. The system management module is configured for switching the second input device to a second operating mode in response to detecting, by the first input device, a presence of a user without receiving any operation-specific input from the user.", "authors": ["Nima Parivar", "Kelsey Y. Ho"], "related_topics": ["47531307", "121449826", "48677424"], "citation_count": "55", "reference_count": "67", "references": ["1930456798", "1584397650", "2113918921", "2107118797", "2147555786", "2925818728", "2748207967", "2103081962", "2742592547", "1960928974"], "date": "2015"}, {"id": "1901544345", "title": "Proximity detector in handheld device", "abstract": "Proximity based systems and methods that are implemented on an electronic device are disclosed. The method includes sensing an object spaced away and in close proximity to the electronic device. The method also includes performing an action in the electronic device when an object is sensed.", "authors": ["Steve P. Hotelling", "Brian Q. Huppi", "Joshua A. Strickon", "Duncan Robert Kerr", "Bas Ording", "Imran Chaudhri", "Greg Christie", "Jonathan P. Ive", "Peter J. Kennedy", "Anthony M. Fadell", "Jeffrey L. Robbin"], "related_topics": ["64729616", "94915269", "186967261"], "citation_count": "2124", "reference_count": "500", "references": ["1930456798", "1584397650", "2914705496", "2113918921", "1893940590", "2121019134", "2126698653", "2005198142", "2930602263", "2107118797"], "date": "2005"}, {"id": "2125791539", "title": "The management of probabilistic data", "abstract": "It is often desirable to represent in a database, entities whose properties cannot be deterministically classified. The authors develop a data model that includes probabilities associated with the values of the attributes. The notion of missing probabilities is introduced for partially specified probability distributions. This model offers a richer descriptive language allowing the database to more accurately reflect the uncertain real world. Probabilistic analogs to the basic relational operators are defined and their correctness is studied. A set of operators that have no counterpart in conventional relational systems is presented. >", "authors": ["D. Barbara", "H. Garcia-Molina", "D. Porter"], "related_topics": ["174539288", "5655090", "148840519"], "citation_count": "644", "reference_count": "25", "references": ["2138709157", "2143075689", "1992810975", "2988119170", "1990391007", "2074622901", "2017978889", "2003017562", "2158655585", "1716383435"], "date": "1992"}, {"id": "2001496424", "title": "A guided tour to approximate string matching", "abstract": "We survey the current techniques to cope with the problem of string matching that allows errors. This is becoming a more and more relevant issue for many fast growing areas such as information retrieval and computational biology. We focus on online searching and mostly on edit distance, explaining the problem and its relevance, its statistical behavior, its history and current developments, and the central ideas of the algorithms and their complexities. We present a number of experiments to compare the performance of the different algorithms and show which are the best choices. We conclude with some directions for future work and open problems.", "authors": ["Gonzalo Navarro"], "related_topics": ["7757238", "22820288", "32610155"], "citation_count": "3227", "reference_count": "136", "references": ["2055043387", "1660390307", "2752885492", "2107252390", "1990061958", "1655990431", "2610179052", "2002089154", "938539187", "100509257"], "date": "2001"}, {"id": "2158365276", "title": "The Connection Machine", "abstract": "The Connection Machine describes a fundamentally different kind of computer. It offers a preview of a parallel processing computer that Daniel Hillis and others are now developing to perform tasks that no conventional, sequential machine can solve in a reasonable time.", "authors": ["W. Daniel Hillis"], "related_topics": ["2776867014", "48725833", "9390403"], "citation_count": "2834", "reference_count": "0", "references": ["2118051273", "1587263632", "1997841190", "1850405760", "1689445748", "2161061943", "2058972589", "2127331687", "2160610190", "2563587242"], "date": "1984"}, {"id": "1994373531", "title": "Net Gain: Expanding Markets through Virtual Communities", "abstract": "Abstract What are virtual communities? How do they operate? How can they help expand markets, increase visibility, and improve profitability? What effects have they had on business models and marketing strategies? John Hagel discussed these issues in his keynote speech at the Direct Marketing Association's 1998 net.marketing Conference held April 1998.", "authors": ["John Hagel", "Arthur G. Armstrong"], "related_topics": ["536005652", "4216890", "129361004"], "citation_count": "2595", "reference_count": "0", "references": ["2032285541", "1983895294", "2049318638", "2144336601", "2041563290", "1975694814", "2116578868", "1569292578", "2109091500", "1480415088"], "date": "1996"}, {"id": "255556494", "title": "Data Mining and Analysis: Fundamental Concepts and Algorithms", "abstract": "The fundamental algorithms in data mining and analysis form the basis for the emerging field of data science, which includes automated methods to analyze patterns and models for all kinds of data, with applications ranging from scientific discovery to business intelligence and analytics. This textbook for senior undergraduate and graduate data mining courses provides a broad yet in-depth overview of data mining, integrating related concepts from machine learning and statistics. The main parts of the book include exploratory data analysis, pattern mining, clustering, and classification. The book lays the basic foundations of these tasks, and also covers cutting-edge topics such as kernel methods, high-dimensional data analysis, and complex graphs and networks. With its comprehensive coverage, algorithmic perspective, and wealth of examples, this book offers solid guidance in data mining for students, researchers, and practitioners alike. Key features: Covers both core methods and cutting-edge research Algorithmic approach with open-source implementations Minimal prerequisites: all key mathematical concepts are presented, as is the intuition behind the formulas Short, self-contained chapters with class-tested examples and exercises allow for flexibility in designing a course and for easy reference Supplementary website with lecture slides, videos, project ideas, and more", "authors": ["Mohammed J. Zaki", "Wagner Meira"], "related_topics": ["176775163", "79158427", "2767350"], "citation_count": "1177", "reference_count": "136", "references": ["2911964244", "1663973292", "2140190241", "1995945562", "2112090702", "2008620264", "1570448133", "1565377632", "3013264884", "1480376833"], "date": "2014"}, {"id": "1679913846", "title": "Self-Organizing Maps", "abstract": "The Self-Organising Map (SOM) algorithm was introduced by the author in 1981. Its theory and many applications form one of the major approaches to the contemporary artificial neural networks field, and new technologies have already been based on it. The most important practical applications are in exploratory data analysis, pattern recognition, speech analysis, robotics, industrial and medical diagnostics, instrumentation, and control, and literally hundreds of other tasks. In this monograph the mathematical preliminaries, background, basic ideas, and implications are expounded in a manner which is accessible without prior expert knowledge.", "authors": ["Teuvo Kohonen"], "related_topics": ["90322556", "2778005913", "111168008"], "citation_count": "23381", "reference_count": "0", "references": ["2150926065", "2122646361", "2117812871", "2157795344", "2132549764", "2169064301", "2135187880", "2097645701", "1998025025", "1501500081"], "date": "1994"}, {"id": "2140427797", "title": "Streaming First Story Detection with application to Twitter", "abstract": "With the recent rise in popularity and size of social media, there is a growing need for systems that can extract useful information from this amount of data. We address the problem of detecting new events from a stream of Twitter posts. To make event detection feasible on web-scale corpora, we present an algorithm based on locality-sensitive hashing which is able overcome the limitations of traditional approaches, while maintaining competitive results. In particular, a comparison with a state-of-the-art system on the first story detection task shows that we achieve over an order of magnitude speedup in processing time, while retaining comparable performance. Event detection experiments on a collection of 160 million Twitter posts show that celebrity deaths are the fastest spreading news on Twitter.", "authors": ["Sa\u0161a Petrovi\u0107", "Miles Osborne", "Victor Lavrenko"], "related_topics": ["518677369", "5366617", "99138194"], "citation_count": "859", "reference_count": "18", "references": ["2046804949", "2147717514", "2162006472", "2000200507", "2012833704", "1965972569", "2148212498", "1982381099", "1594112393", "2150731624"], "date": "2010"}, {"id": "1997063559", "title": "Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images*", "abstract": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, non-linear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low-energy states (\u2018annealing\u2019), or what is the same thing, the most probable states under the Gib...", "authors": ["Stuart Geman", "Donald Geman"], "related_topics": ["158424031", "67926830", "193999330"], "citation_count": "26658", "reference_count": "48", "references": ["2581275558", "2150060382", "1622620102", "2154061444", "2114220616", "1979622972", "2065301447", "2107792892", "2056760934", "1567885833"], "date": "1992"}, {"id": "1587263632", "title": "The ant colony optimization meta-heuristic", "abstract": "This chapter contains sections titled: Combinatorial Optimization, The ACO Metaheuristic, How Do I Apply ACO?, Other Metaheuristics, Bibliographical Remarks, Things to Remember, Thought and Computer Exercises", "authors": ["Marco Dorigo", "Gianni Di Caro"], "related_topics": ["109718341", "40128228", "119487961"], "citation_count": "2171", "reference_count": "44", "references": ["2107941094", "2154929945", "2126554879", "2098432798", "2118051273", "2104670598", "1664011265", "2297395784", "2167920923", "1174849168"], "date": "1998"}, {"id": "2084544490", "title": "Decision theoretic generalizations of the PAC model for neural net and other learning applications", "abstract": "We describe a generalization of the PAC learning model that is based on statistical decision theory. In this model the learner receives randomly drawn examples, each example consisting of an instance x in X and an outcome y in Y , and tries to find a hypothesis h : X --< A , where h in H , that specifies the appropriate action a in A to take for each instance x , in order to minimize the expectation of a loss l(y,a). Here X, Y, and A are arbitrary sets, l is a real-valued function, and examples are generated according to an arbitrary joint distribution on X times Y . Special cases include the problem of learning a function from X into Y , the problem of learning the conditional probability distribution on Y given X (regression), and the problem of learning a distribution on X (density estimation). We give theorems on the uniform convergence of empirical loss estimates to true expected loss rates for certain hypothesis spaces H , and show how this implies learnability with bounded sample size, disregarding computational complexity. As an application, we give distribution-independent upper bounds on the sample size needed for learning with feedforward neural networks. Our theorems use a generalized notion of VC dimension that applies to classes of real-valued functions, adapted from Pollard''s work, and a notion of *capacity* and *metric dimension* for classes of functions that map into a bounded metric space. (Supersedes 89-30 and 90-52.) [Also in \"Information and Computation\", Vol. 100, No.1, September 1992]", "authors": ["David Haussler"], "related_topics": ["43555835", "18653775", "34388435"], "citation_count": "1230", "reference_count": "77", "references": ["1594031697", "1652505363", "1988520084", "3017143921", "2171277043", "2165758113", "1530699444", "2019363670", "2114766824", "2056099894"], "date": "1992"}, {"id": "2067885219", "title": "Arcing classifier (with discussion and a rejoinder by the author)", "abstract": "Recent work has shown that combining multiple versions of unstable classifiers such as trees or neural nets results in reduced test set error. One of the more effective is bagging. Here, modified training sets are formed by resampling from the original training set, classifiers constructed using these training sets and then combined by voting. Freund and Schapire propose an algorithm the basis of which is to adaptively resample and combine (hence the acronym \u201carcing\u201d) so that the weights in the resampling are increased for those cases most often misclassified and the combining is done by weighted voting. Arcing is more successful than bagging in test set error reduction. We explore two arcing algorithms, compare them to each other and to bagging, and try to understand how arcing works. We introduce the definitions of bias and variance for a classifier as components of the test set error. Unstable classifiers can have low bias on a large range of data sets. Their problem is high variance. Combining multiple versions either through bagging or arcing reduces variance significantly.", "authors": ["Leo Breiman"], "related_topics": ["169903167", "46686674", "132778050"], "citation_count": "1939", "reference_count": "0", "references": ["2911964244", "2053463056", "2032210760", "1966701961", "3104887532", "2075647286", "2167917621", "1540007258", "2155806188", "2168020168"], "date": "1998"}, {"id": "2294059674", "title": "Maxout Networks", "abstract": "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.", "authors": ["Ian Goodfellow", "David Warde-Farley", "Mehdi Mirza", "Aaron Courville", "Yoshua Bengio"], "related_topics": ["190502265", "153083717", "119857082"], "citation_count": "2224", "reference_count": "23", "references": ["2618530766", "3118608800", "2310919327", "1904365287", "2546302380", "2912934387", "2131241448", "2335728318", "2156387975", "189596042"], "date": "2013"}, {"id": "2089457241", "title": "Construal-Level Theory of Psychological Distance", "abstract": "People are capable of thinking about the future, the past, remote locations, another person\u2019s perspective, and counterfactual alternatives. Without denying the uniqueness of each process, it is proposed that they constitute different forms of traversing psychological distance. Psychological distance is egocentric: Its reference point is the self in the here and now, and the different ways in which an object might be removed from that point\u2014in time, in space, in social distance, and in hypotheticality\u2014constitute different distance dimensions. Transcending the self in the here and now entails mental construal, and the farther removed an object is from direct experience, the higher (more abstract) the level of construal of that object. Supporting this analysis, research shows (a) that the various distances are cognitively related to each other, (b) that they similarly influence and are influenced by level of mental construal, and (c) that they similarly affect prediction, preference, and action.", "authors": ["Yaacov Trope", "Nira Liberman"], "related_topics": ["26326936", "2780110242", "172656115"], "citation_count": "4884", "reference_count": "187", "references": ["2140534852", "2133469585", "2120357670", "1896027656", "2150375089", "2159035740", "2052610531", "2134170969", "1603542031", "1993325457"], "date": "2010"}, {"id": "2113592823", "title": "Cluster Kernels for Semi-Supervised Learning", "abstract": "We propose a framework to incorporate unlabeled data in kernel classifier, based on the idea that two points in the same cluster are more likely to have the same label. This is achieved by modifying the eigenspectrum of the kernel matrix. Experimental results assess the validity of this approach.", "authors": ["Olivier Chapelle", "Jason Weston", "Bernhard Sch\u00f6lkopf"], "related_topics": ["58973888", "99018454", "95623464"], "citation_count": "643", "reference_count": "13", "references": ["2165874743", "2140095548", "2048679005", "2158001550", "2107008379", "2160167256", "2166473218", "2122837498", "2139578439", "1574877594"], "date": "2001"}, {"id": "2138621811", "title": "Authoritative sources in a hyperlinked environment", "abstract": "The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of context on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of \u201cauthorative\u201d information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of \u201chub pages\u201d that join them together in the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristrics for link-based analysis.", "authors": ["Jon M. Kleinberg"], "related_topics": ["195409031", "105606406", "1173588"], "citation_count": "16207", "reference_count": "52", "references": ["3013264884", "2798909945", "2147152072", "1578099820", "2148694408", "2006119904", "2089192108", "1568713441", "2079672501", "1996764654"], "date": "1999"}, {"id": "2119352491", "title": "Fast quantizing and decoding and algorithms for lattice quantizers and codes", "abstract": "For each of the lattices A_{n}(n \\geq 1), D_{n}(n \\geq 2), E_{6}, E_{7}, E_{8} , and their duals a very fast algorithm is given for finding the closest lattice point to an arbitrary point. If these lattices are used for vector quantizing of uniformly distributed data, the algorithm finds the minimum distortion lattice point. If the lattices are used as codes for a Gaussian channel, the algorithm performs maximum likelihood decoding.", "authors": ["J. Conway", "N. Sloane"], "related_topics": ["191184047", "57273362", "134722173"], "citation_count": "542", "reference_count": "12", "references": ["2752853835", "2142228262", "2089419199", "2029495080", "1973387369", "2120788459", "2316593342", "1557027117", "2001114217", "2156310455"], "date": "1982"}, {"id": "2087924620", "title": "Optical Packet-Switched WDM Networks: a Cost and Energy Perspective", "abstract": "A collection of slides from the author's conference presentation on \"Optical packet-switched WDM networks: a cost and energy perspective\" is given.", "authors": ["Rodney S Tucker"], "related_topics": ["197417287", "101336846", "113508815"], "citation_count": "93", "reference_count": "0", "references": ["2168780914", "2152241065", "2166051523", "2144645861", "2065055728", "2145889720", "2107828244", "2163455434", "2140293583", "2049806335"], "date": "2008"}, {"id": "1565746575", "title": "Statistical Comparisons of Classifiers over Multiple Data Sets", "abstract": "While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.", "authors": ["Janez Dem\u0161ar"], "related_topics": ["2776888448", "26693636", "160710788"], "citation_count": "9938", "reference_count": "39", "references": ["2084812512", "2009543464", "2115012618", "1966280301", "2167277498", "2121044470", "1585743408", "2030360178", "2024081693", "1524761913"], "date": "2006"}, {"id": "1975978582", "title": "A FRAMEWORK FOR THE IMPLEMENTATION OF TASK-BASED INSTRUCTION", "abstract": "L'enseignement base sur des travaux est un domaine ayant pris de l'importance depuis les 10 dernieres annees. Dans cet article, l'A. examine les critiques concernant cette mode actuelle de l'enseignement de la langue en matiere de communication, et passe en revue les theories et les recherches qui decrivent ses limites et ses qualites. Il propose ensuite un cadre permettant d'habiliter les enseignants a appliquer ce type d'instruction et d'eviter ainsi certains dangers qu'il comprend", "authors": ["Peter Skehan"], "related_topics": ["15708023", "41895202", "15744967"], "citation_count": "2485", "reference_count": "19", "references": ["3023683204", "2004415003", "2021034890", "2075509776", "1570202701", "2035091448", "2130513922", "2136737367", "2158083885", "633815501"], "date": "1996"}, {"id": "2037227137", "title": "The Pascal Visual Object Classes Challenge: A Retrospective", "abstract": "The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008---2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community's progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.", "authors": ["Mark Everingham", "S. M. Eslami", "Luc Gool", "Christopher K. Williams", "John Winn", "Andrew Zisserman"], "related_topics": ["94176051", "95623464", "73555534"], "citation_count": "3738", "reference_count": "47", "references": ["2618530766", "2151103935", "2102605133", "2153635508", "2161969291", "2168356304", "1849277567", "2031489346", "2088049833", "2155541015"], "date": "2014"}, {"id": "2150884987", "title": "Adaptive mixtures of local experts", "abstract": "We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised network, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.", "authors": ["Robert A. Jacobs", "Michael I. Jordan", "Steven J. Nowlan", "Geoffrey E. Hinton"], "related_topics": ["58973888", "136389625", "120822770"], "citation_count": "4718", "reference_count": "13", "references": ["2171277043", "1992402718", "2056763477", "1505136099", "1979500821", "2097863906", "2092845679", "2060542468", "1498431753", "2137242837"], "date": "1991"}, {"id": "1594031697", "title": "Classification and regression trees", "abstract": "Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index.", "authors": ["Leo Breiman", "Jerome H Friedman", "Richard A Olshen", "Charles J Stone"], "related_topics": ["52670214", "62764039", "5481197"], "citation_count": "51813", "reference_count": "24", "references": ["2011039300", "3017143921", "2022554507", "2127218421", "2583466288", "2164240509", "2123838014", "1976123439", "2150418026", "1970074386"], "date": "1982"}, {"id": "2098979973", "title": "Medical image analysis: progress over two decades and the challenges ahead", "abstract": "The analysis of medical images has been woven into the fabric of the pattern analysis and machine intelligence (PAMI) community since the earliest days of these Transactions. Initially, the efforts in this area were seen as applying pattern analysis and computer vision techniques to another interesting dataset. However, over the last two to three decades, the unique nature of the problems presented within this area of study have led to the development of a new discipline in its own right. Examples of these include: the types of image information that are acquired, the fully three-dimensional image data, the nonrigid nature of object motion and deformation, and the statistical variation of both the underlying normal and abnormal ground truth. In this paper, we look at progress in the field over the last 20 years and suggest some of the challenges that remain for the years to come.", "authors": ["J.S. Duncan", "N. Ayache"], "related_topics": ["34127721", "124504099", "115925183"], "citation_count": "4117", "reference_count": "131", "references": ["2104095591", "2049981393", "2038952578", "2034432063", "1991113069", "2133584444", "2149184914", "2157848968", "2128409098", "2004537679"], "date": "1999"}, {"id": "2024476015", "title": "The EM Algorithm\u2014an Old Folk\u2010song Sung to a Fast New Tune", "abstract": "Celebrating the 20th anniversary of the presentation of the paper by Dempster, Laird and Rubin which popularized the EM algorithm, we investigate, after a brief historical account, strategies that aim to make the EM algorithm converge faster while maintaining its simplicity and stability (e.g. automatic monotone convergence in likelihood). First we introduce the idea of a \u2018working parameter\u2019 to facilitate the search for efficient data augmentation schemes and thus fast EM implementations. Second, summarizing various recent extensions of the EM algorithm, we formulate a general alternating expectation\u2013conditional maximization algorithm AECM that couples flexible data augmentation schemes with model reduction schemes to achieve efficient computations. We illustrate these methods using multivariate t-models with known or unknown degrees of freedom and Poisson models for image reconstruction. We show, through both empirical and theoretical evidence, the potential for a dramatic reduction in computational time with little increase in human effort. We also discuss the intrinsic connection between EM-type algorithms and the Gibbs sampler, and the possibility of using the techniques presented here to speed up the latter. The main conclusion of the paper is that, with the help of statistical considerations, it is possible to construct algorithms that are simple, stable and fast.", "authors": ["Xiao-Li Meng", "David Van Dyk"], "related_topics": ["112972136", "182081679", "158424031"], "citation_count": "905", "reference_count": "110", "references": ["2045656233", "2610857016", "2049633694", "2117853077", "2106706098", "2148534890", "2154744699", "2082246284", "2017899835", "2033482494"], "date": "1996"}, {"id": "2119823327", "title": "Learning to detect natural image boundaries using local brightness, color, and texture cues", "abstract": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images.", "authors": ["D.R. Martin", "C.C. Fowlkes", "J. Malik"], "related_topics": ["63099799", "193536780", "125245961"], "citation_count": "2776", "reference_count": "37", "references": ["2153635508", "2145023731", "2121927366", "2111308925", "2032210760", "2135705692", "2093191240", "2141376824", "2025653905", "1490632837"], "date": "2004"}, {"id": "2107223217", "title": "A Threat in the Air How Stereotypes Shape Intellectual Identity and Performance", "abstract": "A general theory of domain identification is used to describe achievement barriers still faced by women in advanced quantitative areas and by African Americans in school. The theory assumes that sustained school success requires identification with school and its subdomains; that societal pressures on these groups (e.g., economic disadvantage, gender roles) can frustrate this identification; and that in school domains where these groups are negatively stereotyped, those who have become domain identified face the further barrier of stereotype threat, the threat that others' judgments or their own actions will negatively stereotype them in the domain. Research shows that this threat dramatically depresses the standardized test performance of women and African Americans who are in the academic vanguard of their groups (offering a new interpretation of group differences in standardized test performance), that it causes disidentification with school, and that practices that reduce this threat can reduce these negative effects.", "authors": ["Claude M. Steele"], "related_topics": ["2776845425", "2777805627", "203151758"], "citation_count": "8091", "reference_count": "85", "references": ["2116199508", "2888190061", "2179683524", "2161923363", "1996652948", "2005906308", "3000074734", "2047982742", "1935421882", "2162397375"], "date": "1997"}, {"id": "2130660124", "title": "Content-based image retrieval at the end of the early years", "abstract": "Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps for image retrieval systems. Step one of the review is image processing for retrieval sorted by color, texture, and local geometry. Features for retrieval are discussed next, sorted by: accumulative and global features, salient points, object and shape features, signs, and structural combinations thereof. Similarity of pictures and objects in pictures is reviewed for each of the feature types, in close connection to the types and means of feedback the user of the systems is capable of giving by interaction. We briefly discuss aspects of system engineering: databases, system architecture, and evaluation. In the concluding section, we present our view on: the driving force of the field, the heritage from computer vision, the influence on computer vision, the role of similarity and of interaction, the need for databases, the problem of evaluation, and the role of the semantic gap.", "authors": ["A.W.M. Smeulders", "M. Worring", "S. Santini", "A. Gupta", "R. Jain"], "related_topics": ["2780052074", "189391414", "199579030"], "citation_count": "8514", "reference_count": "203", "references": ["2156909104", "2062024414", "2128272608", "2132549764", "2049633694", "2914885528", "2124087378", "2482402870", "2125148312", "2160066518"], "date": "2000"}, {"id": "2154455356", "title": "Theory of communication", "abstract": "", "authors": ["D. Gabor"], "related_topics": ["3716254", "76155785", "41008148"], "citation_count": "12730", "reference_count": "0", "references": ["2121609805", "3123786616", "2278339107", "2903237554", "2033670296", "2008130267", "2001331333", "2558099463", "2897430850", "3124698598"], "date": "1946"}, {"id": "1989314580", "title": "Statistical Principles in Experimental Design", "abstract": "CHAPTER 1: Introduction to Design CHAPTER 2: Principles of Estimation and Inference: Means and Variance CHAPTER 3: Design and Analysis of Single-Factor Experiments: Completely Randomized Design CHAPTER 4: Single-Factor Experiments Having Repeated Measures on the Same Element CHAPTER 5: Design and Analysis of Factorial Experiments: Completely-Randomized Design CHAPTER 6: Factorial Experiments: Computational Procedures and Numerical Example CHAPTER 7: Multifactor Experiments Having Repeated Measures on the Same Element CHAPTER 8: Factorial Experiments in which Some of the Interactions are Confounded CHAPTER 9: Latin Squares and Related Designs CHAPTER 10: Analysis of Covariance", "authors": ["B. J. Winer"], "related_topics": ["11923724", "169222746", "119340705"], "citation_count": "43044", "reference_count": "78", "references": ["2092713296", "2021142183", "2324309783", "2012757283", "2140101900", "2062526841", "2587072524", "2076731491", "2020737422", "2010878583"], "date": "1961"}, {"id": "2125655203", "title": "Where's the evidence that active learning works?", "abstract": "Calls for reforms in the ways we teach science at all levels, and in all disciplines, are wide spread. The effectiveness of the changes being called for, employment of student-centered, active learning pedagogy, is now well supported by evidence. The relevant data have come from a number of different disciplines that include the learning sciences, cognitive psychology, and educational psychology. There is a growing body of research within specific scientific teaching communities that supports and validates the new approaches to teaching that have been adopted. These data are reviewed, and their applicability to physiology education is discussed. Some of the inherent limitations of research about teaching and learning are also discussed.", "authors": ["Joel A. Michael"], "related_topics": ["96427005", "151416629", "26258499"], "citation_count": "1657", "reference_count": "105", "references": ["1761828760", "2134512579", "2008785686", "1708874574", "2158534319", "1985190484", "1985858077", "1594874760", "2526962366", "2769416443"], "date": "2006"}, {"id": "2047870719", "title": "Topology representing networks", "abstract": "Abstract A Hebbian adaptation rule with winner-take-all like competition is introduced. It is shown that this competitive Hebbian rule forms so-called Delaunay triangulations, which play an important role in computational geometry for efficiently solving proximity problems. Given a set of neural units i, i = 1,\u2026, N, the synaptic weights of which can be interpreted as pointers wi, i = 1,\u2026, N in RD, the competitive Hebbian rule leads to a connectivity structure between the units i that corresponds to the Delaunay triangulation of the set of pointers wi. Such competitive Hebbian rule develops connections (Cij > 0) between neural units i, j with neighboring receptive fields (Voronoi polygons) Vi, Vj, whereas between all other units i, j no connections evolve (Cij = 0). Combined with a procedure that distributes the pointers wi over a given feature manifold M, for example, a submanifold M \u2282 RD, the competitive Hebbian rule provides a novel approach to the problem of constructing topology preserving feature maps and representing intricately structured manifolds. The competitive Hebbian rule connects only neural units, the receptive fields (Voronoi polygons) Vi, Vj of which are adjacent on the given manifold M. This leads to a connectivity structure that defines a perfectly topology preserving map and forms a discrete, path preserving representation of M, also in cases where M has an intricate topology. This makes this novel approach particularly useful in all applications where neighborhood relations have to be exploited or the shape and topology of submanifolds have to be take into account.", "authors": ["Thomas Martinetz", "", "Klaus Schulten"], "related_topics": ["111437709", "68010082", "107073374"], "citation_count": "1138", "reference_count": "48", "references": ["2046079134", "1991848143", "3017143921", "65738273", "22297218", "2913399920", "2005314985", "2166322089", "2002182716", "2098929365"], "date": "1994"}, {"id": "26816478", "title": "Simplified support vector decision rules", "abstract": "A Support Vector Machine SVM is a uni versal learning machine whose decision sur face is parameterized by a set of support vec tors and by a set of corresponding weights An SVM is also characterized by a kernel function Choice of the kernel determines whether the resulting SVM is a polynomial classi er a two layer neural network a ra dial basis function machine or some other learning machine SVMs are currently considerably slower in test phase than other approaches with sim ilar generalization performance To address this we present a general method to signif icantly decrease the complexity of the deci sion rule obtained using an SVM The pro posed method computes an approximation to the decision rule in terms of a reduced set of vectors These reduced set vectors are not support vectors and can in some cases be computed analytically We give ex perimental results for three pattern recogni tion problems The results show that the method can decrease the computational com plexity of the decision rule by a factor of ten with no loss in generalization perfor mance making the SVM test speed com petitive with that of other methods Fur ther the method allows the generalization performance complexity trade o to be di rectly controlled The proposed method is not speci c to pattern recognition and can be applied to any problem where the Sup port Vector algorithm is used for example regression INTRODUCTION SUPPORT VECTOR MACHINES Consider a two class classi er for which the decision rule takes the form", "authors": ["Christopher J. C. Burges"], "related_topics": ["145828037", "125168437", "122280245"], "citation_count": "689", "reference_count": "0", "references": ["2139212933", "1964357740", "2140095548", "1648445109", "2124351082", "2108995755", "2143331230", "2149298154", "1608462934", "2125027820"], "date": "1996"}, {"id": "1719717336", "title": "Attribution theory in social psychology", "abstract": "", "authors": ["Harold H. Kelley"], "related_topics": ["638126", "43200436", "143299363"], "citation_count": "8781", "reference_count": "0", "references": ["1986721142", "2070203783", "2123376091", "1971931485", "2126311339", "1843246605", "2171975196", "2153134053", "2167366201", "2079667200"], "date": "1966"}, {"id": "2995035536", "title": "Hanging on the metaphone", "abstract": "", "authors": ["L. Philips"], "related_topics": ["2778586387", "2776782451", "41008148"], "citation_count": "354", "reference_count": "0", "references": ["2108991785", "2157765050", "2147018385", "2128219564", "2788640655", "2189217339", "2127610924", "2006642610", "2341328702", "2980946630"], "date": "1989"}, {"id": "2136424426", "title": "The life course as developmental theory.", "abstract": "The pioneering longitudinal studies of child development (all launched in the 1920s and 1930s) were extended well beyond childhood. Indeed, they eventually followed their young study members up to the middle years and later life. In doing so, they generated issues that could not be addressed satisfactorily by available theories. These include the recognition that individual lives are influenced by their ever-changing historical context, that the study of human lives calls for new ways of thinking about their pattern and dynamic, and that concepts of human development should apply to processes across the life span. Life course theory has evolved since the 1960s through programmatic efforts to address such issues.", "authors": ["Glen H. Elder"], "related_topics": ["1691868", "91996132", "117250062"], "citation_count": "3501", "reference_count": "69", "references": ["1562208008", "2004877893", "2109469951", "2332321565", "2904798609", "3000074734", "410291145", "1688594209", "18807917", "1838289455"], "date": "1998"}, {"id": "2074863013", "title": "Integrating keyword search into XML query processing", "abstract": "Abstract Due to the popularity of the XML data format, several query languages for XML have been proposed, specially devised to handle data of which the structure is unknown, loose, or absent. While these languages are rich enough to allow for querying the content and structure of an XML document, a varying or unknown structure can make formulating queries a very difficult task. We propose an extension to XML query languages that enables keyword search at the granularity of XML elements, that helps novice users formulate queries, and also yields new optimization opportunities for the query processor. We present an implementation of this extension on top of a commercial RDBMS; we then discuss implementation choices and performance results.", "authors": ["Daniela Florescu", "Donald Kossmann", "Ioana Manolescu"], "related_topics": ["44883583", "55348073", "11508877"], "citation_count": "392", "reference_count": "12", "references": ["2165286227", "1997841190", "2149532506", "1560626952", "2108014443", "1993819379", "2114627486", "2151763080", "2084761702", "1576757369"], "date": "2000"}, {"id": "2058568633", "title": "Visual Feature Extraction by a Multilayered Network of Analog Threshold Elements", "abstract": "A new type of visual feature extracting network has been synthesized, and the response of the network has been simulated on a digital computer. This research has been done as a first step towards the realization of a recognizer of handwritten characters. The design of the network was suggested by biological systems, especially, the visual systems of cat and monkey. The network is composed of analog threshold elements connected in layers. Each analog threshold element receives inputs from a large number of elements in the neighbouring layers and performs its own special functions. It takes care of one restricted part of the photoreceptor layer, on which an input pattem is presented, and it responds to one particular feature of the input pattem, such as brightness contrast, a dot in the pattern, a line segment of a particular orientation, or an end of the line. This means that the network performs parallel processing of the information. With the propagation of the information through the layered network, the input pattern is successively decomposed into dots, groups of line segments of the same orientation, and the ends of these line segments.", "authors": ["Kunihiko Fukushima"], "related_topics": ["182124507", "57620373", "52622490"], "citation_count": "63", "reference_count": "19", "references": ["1554576613", "2116360511", "1594551768", "2103212315", "1757333299", "2118017998", "2122741244", "1860887978", "2037529930", "1965673217"], "date": "1969"}, {"id": "1964357740", "title": "A tutorial on support vector regression", "abstract": "In this tutorial we give an overview of the basic ideas underlying Support Vector (SV) machines for function estimation. Furthermore, we include a summary of currently used algorithms for training SV machines, covering both the quadratic (or convex) programming part and advanced methods for dealing with large datasets. Finally, we mention some modifications and extensions that have been applied to the standard SV algorithm, and discuss the aspect of regularization from a SV perspective.", "authors": ["Alex J. Smola", "Bernhard Sch\u00f6lkopf"], "related_topics": ["145828037", "14948415", "125168437"], "citation_count": "11502", "reference_count": "155", "references": ["2153635508", "2156909104", "2148603752", "2124776405", "1995945562", "1554663460", "2119821739", "2139212933", "1563088657", "2078204800"], "date": "2004"}, {"id": "2006642610", "title": "Automated misspelling detection and correction in clinical free-text records", "abstract": "Display Omitted We develop a spelling correction system for medical text.Our dictionaries include both internal and external resources.We use a noisy channel model to select the most probable correction.We evaluate our system's performance on misspelling detection and correction.The system achieves good performance on a variety of clinical documents. Accurate electronic health records are important for clinical care and research as well as ensuring patient safety. It is crucial for misspelled words to be corrected in order to ensure that medical records are interpreted correctly. This paper describes the development of a spelling correction system for medical text. Our spell checker is based on Shannon's noisy channel model, and uses an extensive dictionary compiled from many sources. We also use named entity recognition, so that names are not wrongly corrected as misspellings. We apply our spell checker to three different types of free-text data: clinical notes, allergy entries, and medication orders; and evaluate its performance on both misspelling detection and correction. Our spell checker achieves detection performance of up to 94.4% and correction accuracy of up to 88.2%. We show that high-performance spelling correction is possible on a variety of clinical documents.", "authors": ["Kenneth H. Lai", "Maxim Topaz", "Foster R. Goss", "Li Zhou"], "related_topics": ["120400215", "2777801307", "2779135771"], "citation_count": "73", "reference_count": "25", "references": ["2096765155", "2121227244", "2010595692", "2114039834", "1995875735", "1520449809", "2128004504", "2144226312", "2132423390", "1972099155"], "date": "2015"}, {"id": "2110575115", "title": "Dynamic bayesian networks: representation, inference and learning", "abstract": "", "authors": ["Kevin Patrick Murphy", "Stuart Russell"], "related_topics": ["162376815", "101112237", "2776214188"], "citation_count": "3528", "reference_count": "383", "references": ["1554663460", "1480376833", "2147880316", "2160337655", "2122410182", "2125838338", "2581275558", "2137813581", "1483307070", "2159080219"], "date": "2001"}, {"id": "2020934227", "title": "New extension of the Kalman filter to nonlinear systems", "abstract": "The Kalman Filter (KF) is one of the most widely used methods for tracking and estimation due to its simplicity, optimality, tractability and robustness. However, the application of the KF to nonlinear systems can be difficult. The most common approach is to use the Extended Kalman Filter (EKF) which simply linearizes all nonlinear models so that the traditional linear Kalman filter can be applied. Although the EKF (in its many forms) is a widely used filtering strategy, over thirty years of experience with it has led to a general consensus within the tracking and control community that it is difficult to implement, difficult to tune, and only reliable for systems which are almost linear on the time scale of the update intervals. In this paper a new linear estimator is developed and demonstrated. Using the principle that a set of discretely sampled points can be used to parameterize mean and covariance, the estimator yields performance equivalent to the KF for linear systems yet generalizes elegantly to nonlinear systems without the linearization steps required by the EKF. We show analytically that the expected performance of the new approach is superior to that of the EKF and, in fact, is directly comparable to that of the second order Gauss filter. The method is not restricted to assuming that the distributions of noise sources are Gaussian. We argue that the ease of implementation and more accurate estimation features of the new filter recommend its use over the EKF in virtually all applications.", "authors": ["Simon J. Julier", "Jeffrey K. Uhlmann"], "related_topics": ["8639503", "206833254", "139399703"], "citation_count": "6669", "reference_count": "20", "references": ["2981264952", "2098613108", "1559536185", "2137043637", "2113908741", "2122512809", "2059665194", "2145118576", "1600022730", "3156050587"], "date": "1997"}, {"id": "2040300040", "title": "Learnability and cognition: The acquisition of argument structure.", "abstract": "Part 1 A learnability paradox: argument structure and the lexicon the logical problem of language acquisition Baker's paradox attempted solutions to Baker's paradox. Part 2 Constraints on lexical rules: morphological and phonological constraints semantic constraints how semantic and morphological constraints might resolve Baker's paradox evidence for criteria-governed productivity problems for the criteria-governed productivity theory. Part 3 Constraints and the nature of argument structure: overview - why lexical rules carry semantic constraints constraints of lexical rules as manifestations of more general phenomena a theory of argument structure on universality. Part 4 Possible and actual forms: the problem of negative exceptions transitive action verbs as evidence for narrow subclasses the nature of narrow conflation classes defining and motivating subclasses of verbs licensing the four alterations the relation between narrow-range and broad-range rules. Part 5 Representation: the need for a theory of lexicosemantic representation is a theory of lexical semantics feasible? evidence for a semantic subsystem underlying verb meanings a cross-linguistic inventory of components of verb meaning a theory of the representation of grammatically relevant semantic structures explicit representations of lexical rules an lexicosemantic structures summary. Part 6 Learning: linking rules lexical semantic structures broad conflation classes (thematic cores) and broad range lexical rules summary of learning mechanisms. Part 7 Development: developmental sequence for argument structure alterations the unlearning problem children's argument structure changing rules are always semantically conditioned do children's errors have the same cause as adults? acquisition of verb meaning and errors in argument structure some predictions about the acquisition of narrow-range rules summary of development. Part 8 Conclusions: a brief summary of the resolution of the paradox argument structure as a pointer between syntactic structure and propositions the autonomy of semantic representation implications for the semantic bootstrapping hyposthesis conservatism, listedness and the lexicon spatial schemas and abstract thought.", "authors": ["Steven Pinker"], "related_topics": ["98954769", "2779930064", "2778121359"], "citation_count": "2158", "reference_count": "0", "references": ["2102381086", "2159398820", "2005181355", "2167366201", "2128092632", "2002103405", "2143801939", "2016429292", "2124819629", "2117909082"], "date": "1992"}, {"id": "2158164339", "title": "Modeling Human Motion Using Binary Latent Variables", "abstract": "We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \"visible\" variables that represent joint angles. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. Such an architecture makes on-line inference efficient and allows us to use a simple approximate learning procedure. After training, the model finds a single set of parameters that simultaneously capture several different kinds of motion. We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line filling in of data lost during motion capture.", "authors": ["Graham W. Taylor", "Geoffrey E. Hinton", "Sam T. Roweis"], "related_topics": ["112933361", "51167844", "70727504"], "citation_count": "887", "reference_count": "14", "references": ["2136922672", "2310919327", "2116064496", "2124914669", "2293741035", "2114153178", "2147010501", "2248685949", "1991942383", "2123236823"], "date": "2006"}, {"id": "2024165284", "title": "Tensor Decompositions and Applications", "abstract": "This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A tensor is a multidimensional or $N$-way array. Decompositions of higher-order tensors (i.e., $N$-way arrays with $N \\geq 3$) have applications in psycho-metrics, chemometrics, signal processing, numerical linear algebra, computer vision, numerical analysis, data mining, neuroscience, graph analysis, and elsewhere. Two particular tensor decompositions can be considered to be higher-order extensions of the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes a tensor as a sum of rank-one tensors, and the Tucker decomposition is a higher-order form of principal component analysis. There are many other tensor decompositions, including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, and PARATUCK2 as well as nonnegative variants of all of the above. The N-way Toolbox, Tensor Toolbox, and Multilinear Engine are examples of software packages for working with tensors.", "authors": ["Tamara G. Kolda", "Brett W. Bader"], "related_topics": ["124007464", "64835786", "20178491"], "citation_count": "7947", "reference_count": "223", "references": ["1902027874", "2798909945", "2099741732", "2147152072", "2013912476", "2090208105", "2752853835", "2072773380", "2113722075", "2132267493"], "date": "2009"}, {"id": "2107034620", "title": "A Bayesian hierarchical model for learning natural scene categories", "abstract": "We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a \"theme\". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes.", "authors": ["L. Fei-Fei", "P. Perona"], "related_topics": ["8038995", "94124525", "167611913"], "citation_count": "4729", "reference_count": "19", "references": ["1880262756", "2124386111", "2045656233", "1566135517", "1484228140", "2127006916", "2171188998", "1699734612", "2104924585", "2094414211"], "date": "2005"}, {"id": "1997841190", "title": "Information Retrieval: Data Structures and Algorithms", "abstract": "An edited volume containing data structures and algorithms for information retrieved including a disk with examples written in C. For programmers and students interested in parsing text, automated indexing, its the first collection in book form of the basic data structures and algorithms that are critical to the storage and retrieval of documents.", "authors": ["William B. Frakes", "Ricardo Baeza-Yates"], "related_topics": ["90288658", "189391414", "116425068"], "citation_count": "3652", "reference_count": "223", "references": ["2098162425", "1956559956", "1491178396", "2987803397", "1655990431", "2752853835", "2002089154", "2000672666", "2029195137", "2158365276"], "date": "1992"}, {"id": "1553004968", "title": "Connectionist Speech Recognition: A Hybrid Approach", "abstract": "From the Publisher: Connectionist Speech Recognition: A Hybrid Approach describes the theory and implementation of a method to incorporate neural network approaches into state-of-the-art continuous speech recognition systems based on Hidden Markov Models (HMMs) to improve their performance. In this framework, neural networks (and in particular, multilayer perceptrons or MLPs) have been restricted to well-defined subtasks of the whole system, i.e., HMM emission probability estimation and feature extraction. The book describes a successful five year international collaboration between the authors. The lessons learned form a case study that demonstrates how hybrid systems can be developed to combine neural networks with more traditional statistical approaches. The book illustrates both the advantages and limitations of neural networks in the framework of a statistical system. Using standard databases and comparing with some conventional approaches, it is shown that MLP probability estimation can improve recognition performance. Other approaches are discussed, though there is no such unequivocal experimental result for these methods. Connectionist Speech Recognition: A Hybrid Approach is of use to anyone intending to use neural networks for speech recognition or within the framework provided by an existing successful statistical approach. This includes research and development groups working in the field of speech recognition, both with standard and neural network approaches, as well as other pattern recognition and/or neural network researchers. This book is also suitable as a text for advanced courses on neural networks or speech processing.", "authors": ["Herve A. Bourlard", "Nelson Morgan"], "related_topics": ["175202392", "61328038", "40608802"], "citation_count": "1650", "reference_count": "201", "references": ["2125838338", "2798909945", "2154642048", "1555915743", "2042264548", "2049633694", "2103496339", "2110485445", "2147800946", "1991848143"], "date": "1993"}, {"id": "34972688", "title": "Computer programs for spelling correction", "abstract": "", "authors": ["James Lyle Peterson"], "related_topics": ["2777801307", "41008148", "28490314"], "citation_count": "65", "reference_count": "0", "references": ["2031338704", "2088955004", "2039307316", "2031469331", "2098258619", "2109469864", "2130032538", "2140177165", "2051200211", "2093760433"], "date": "1979"}, {"id": "2576297379", "title": "Computer-Mediated Communication Impersonal, Interpersonal, and Hyperpersonal Interaction", "abstract": "While computer-mediated communication use and research are proliferating rapidly, findings offer contrasting images regarding the interpersonal character of this technology. Research trends over the history of these media are reviewed with observations across trends suggested so as to provide integrative principles with which to apply media to different circumstances. First, the notion that the media reduce personal influences\u2014their impersonal effects\u2014is reviewed. Newer theories and research are noted explaining normative \u201cinterpersonal\u201d uses of the media. From this vantage point, recognizing that impersonal communication is sometimes advantageous, strategies for the intentional depersonalization of media use are inferred, with implications for Group Decision Support Systems effects. Additionally, recognizing that media sometimes facilitate communication that surpasses normal interpersonal levels, a new perspective on \u201chyperpersonal\u201d communication is introduced. Subprocesses are discussed pertaining to re...", "authors": ["Joseph B. Walther"], "related_topics": ["77826724", "164850336", "40986600"], "citation_count": "6285", "reference_count": "132", "references": ["2116339812", "2340966270", "2108752510", "2024372407", "2098572648", "2038281539", "1524086313", "1573558308", "1595891490", "2042846381"], "date": "1996"}, {"id": "2039748980", "title": "Symmetric Tensors and Symmetric Tensor Rank", "abstract": "A symmetric tensor is a higher order generalization of a symmetric matrix. In this paper, we study various properties of symmetric tensors in relation to a decomposition into a symmetric sum of outer product of vectors. A rank-1 order-$k$ tensor is the outer product of $k$ nonzero vectors. Any symmetric tensor can be decomposed into a linear combination of rank-1 tensors, each of which is symmetric or not. The rank of a symmetric tensor is the minimal number of rank-1 tensors that is necessary to reconstruct it. The symmetric rank is obtained when the constituting rank-1 tensors are imposed to be themselves symmetric. It is shown that rank and symmetric rank are equal in a number of cases and that they always exist in an algebraically closed field. We will discuss the notion of the generic symmetric rank, which, due to the work of Alexander and Hirschowitz [J. Algebraic Geom., 4 (1995), pp. 201-222], is now known for any values of dimension and order. We will also show that the set of symmetric tensors of symmetric rank at most $r$ is not closed unless $r=1$.", "authors": ["Pierre Comon", "Gene Golub", "Lek-Heng Lim", "Bernard Mourrain"], "related_topics": ["20178491", "64338288", "156903151"], "citation_count": "493", "reference_count": "57", "references": ["2013912476", "2090208105", "1483218536", "2132267493", "2264065105", "2098301339", "601143573", "1561337879", "2101641981", "2024166170"], "date": "2008"}, {"id": "1976969221", "title": "On power-law relationships of the Internet topology", "abstract": "Despite the apparent randomness of the Internet, we discover some surprisingly simple power-laws of the Internet topology. These power-laws hold for three snapshots of the Internet, between November 1997 and December 1998, despite a 45% growth of its size during that period. We show that our power-laws fit the real data very well resulting in correlation coefficients of 96% or higher.Our observations provide a novel perspective of the structure of the Internet. The power-laws describe concisely skewed distributions of graph properties such as the node outdegree. In addition, these power-laws can be used to estimate important parameters such as the average neighborhood size, and facilitate the design and the performance analysis of protocols. Furthermore, we can use them to generate and select realistic topologies for simulation purposes.", "authors": ["Michalis Faloutsos", "Petros Faloutsos", "Christos Faloutsos"], "related_topics": ["99237066", "110875604", "181822070"], "citation_count": "7446", "reference_count": "30", "references": ["2170120409", "2078206416", "2105818147", "2148275477", "2408227189", "2138543759", "2145721479", "2171873915", "2175892715", "2128796442"], "date": "1999"}, {"id": "1966264494", "title": "Linear prediction: A tutorial review", "abstract": "This paper gives an exposition of linear prediction in the analysis of discrete signals. The signal is modeled as a linear combination of its past values and present and past values of a hypothetical input to a system whose output is the given signal. In the frequency domain, this is equivalent to modeling the signal spectrum by a pole-zero spectrum. The major part of the paper is devoted to all-pole models. The model parameters are obtained by a least squares analysis in the time domain. Two methods result, depending on whether the signal is assumed to be stationary or nonstationary. The same results are then derived in the frequency domain. The resulting spectral matching formulation allows for the modeling of selected portions of a spectrum, for arbitrary spectral shaping in the frequency domain, and for the modeling of continuous as well as discrete spectra. This also leads to a discussion of the advantages and disadvantages of the least squares error criterion. A spectral interpretation is given to the normalized minimum prediction error. Applications of the normalized error are given, including the determination of an \"optimal\" number of poles. The use of linear prediction in data compression is reviewed. For purposes of transmission, particular attention is given to the quantization and encoding of the reflection (or partial correlation) coefficients. Finally, a brief introduction to pole-zero modeling is given.", "authors": ["J. Makhoul"], "related_topics": ["19118579", "103824480", "131109320"], "citation_count": "5401", "reference_count": "67", "references": ["2142635246", "2058815839", "2105934661", "2158208985", "2031887434", "2031530284", "2078841894", "2097645910", "2061317273", "2106445473"], "date": "1975"}, {"id": "2080756469", "title": "The development of competence in favorable and unfavorable environments. Lessons from research on successful children", "abstract": "The development of competence holds great interest for parents and society alike. This article considers implications from research on competence and resilience in children and adolescents for policy and interventions designed to foster better outcomes among children at risk. Foundations of competence in early development are discussed, focusing on the role of attachment relationships and self-regulation. Results from studies of competence in the domains of peer relations, conduct, school, work, and activities are highlighted. Lessons are drawn from studies of naturally occurring resilience among children at risk because of disadvantage or trauma and also from efforts to deliberately alter the course of competence through early childhood education and preventive interventions. Converging evidence suggests that the same powerful adaptive systems protect development in both favorable and unfavorable environments.", "authors": ["Ann S. Masten", "J. Douglas Coatsworth"], "related_topics": ["25148115", "100521375", "178229462"], "citation_count": "5834", "reference_count": "189", "references": ["2085491458", "1542722502", "2135943618", "2106131177", "1978743055", "2408871023", "2057563009", "1817265267", "1977587923", "1583364134"], "date": "1997"}, {"id": "1975846642", "title": "Boosting the margin: a new explanation for the effectiveness of voting methods", "abstract": "One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label. We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those based on the bias-variance decomposition.", "authors": ["Robert E. Schapire", "Yoav Freund", "Peter Bartlett", "Wee Sun Lee"], "related_topics": ["173102733", "31912584", "148667399"], "citation_count": "3542", "reference_count": "36", "references": ["2156909104", "2119821739", "3124955340", "2912934387", "2112076978", "1594031697", "2087347434", "1605688901", "2032210760", "2982720039"], "date": "1998"}, {"id": "1567276288", "title": "Inductive knowledge acquisition: a case study", "abstract": "", "authors": ["J. R. Quinlan", "P. J. Compton", "K. A. Horn", "L. Lazarus"], "related_topics": ["2777220311", "41008148", "56739046"], "citation_count": "306", "reference_count": "0", "references": ["1966280301", "2147169507", "2136000097", "2132166479", "2128420091", "2083780116", "2135190479", "2042385018", "2134696506", "1927345150"], "date": "1987"}, {"id": "740415", "title": "The Nature of Statistical Learning", "abstract": "", "authors": ["V. N. Vapnik"], "related_topics": ["41008148", "145420912", "2982736386"], "citation_count": "3683", "reference_count": "0", "references": ["2139212933", "1678356000", "1964357740", "2150769028", "2149684865", "607505555", "2170654002", "2150165932", "2168020168", "2093229042"], "date": "1994"}, {"id": "2074622901", "title": "Generalizing database relational algebra for the treatment of incomplete or uncertain information and vague queries", "abstract": "Abstract This paper deals with relational databases which are extended in the sense that fuzzily known values are allowed for attributes. Precise as well as partial (imprecise, uncertain) knowledge concerning the value of the attributes are represented by means of [0,1]-valued possibility distributions in Zadeh's sense. Thus, we have to manipulate ordinary relations on Cartesian products of sets of fuzzy subsets rather than fuzzy relations. Besides, vague queries whose contents are also represented by possibility distributions can be taken into account. The basic operations of relational algebra, union, intersection, Cartesian product, projection, and selection are extended in order to deal with partial information and vague queries. Approximate equalities and inequalities modeled by fuzzy relations can also be taken into account in the selection operation. Then, the main features of a query language based on the extended relational algebra are presented. An illustrative example is provided. This approach, which enables a very general treatment of relational databases with fuzzy attribute values, makes an extensive use of dual possibility and necessity measures.", "authors": ["Henri Prade", "Claudette Testemale"], "related_topics": ["95916125", "99436015", "65647387"], "citation_count": "699", "reference_count": "18", "references": ["2330022088", "2019950953", "2157041604", "2598771954", "2122789628", "2078538587", "2002418751", "2072960837", "2092013679", "2022912352"], "date": "1984"}, {"id": "2151369449", "title": "Stance, Alignment, and Affiliation During Storytelling: When Nodding Is a Token of Affiliation", "abstract": "Through stories, tellers communicate their stance toward what they are reporting. Story recipients rely on different interactional resources to display alignment with the telling activity and affiliation with the teller's stance. In this article, I examine the communication resources participants to tellings rely on to manage displays of alignment and affiliation during the telling. The primary finding is that whereas vocal continuers simply align with the activity in progress, nods also claim access to the teller's stance toward the events (whether directly or indirectly). In mid-telling, when a recipient nods, she or he claims to have access to the teller's stance toward the event being reported, which in turn conveys preliminary affiliation with the teller's position and that the story is on track toward preferred uptake at story completion. Thus, the concepts of structural alignment and social affiliation are separate interactional issues and are managed by different response tokens in the mid-telling...", "authors": ["Tanya Stivers"], "related_topics": ["2778346408", "2776538412", "77805123"], "citation_count": "1060", "reference_count": "43", "references": ["2013833248", "1498883201", "1513874694", "1980298376", "2162840157", "103927176", "2060865824", "2030695833", "1484421455", "2063915530"], "date": "2008"}, {"id": "1967810725", "title": "Data parallel algorithms", "abstract": "Parallel computers with tens of thousands of processors are typically programmed in a data parallel style, as opposed to the control parallel style used in multiprocessing. The success of data parallel algorithms\u2014even on problems that at first glance seem inherently serial\u2014suggests that this style of programming has much wider applicability than was previously thought.", "authors": ["W. Daniel Hillis", "Guy L. Steele"], "related_topics": ["126909462", "538114610", "2776867014"], "citation_count": "1394", "reference_count": "12", "references": ["2752853835", "2172307690", "2119241866", "2141389982", "2063068243", "1979036815", "1999736981", "2149644771", "2097561580", "2294936504"], "date": "1986"}, {"id": "3023786531", "title": "Learning with kernels", "abstract": "", "authors": ["Bernhard Sch\u00f6lkopf"], "related_topics": ["41008148"], "citation_count": "9233", "reference_count": "0", "references": ["1746819321", "1964357740", "2142827986", "2035720976", "1570963478", "2108995755", "2145295623", "2117154949", "2124101779", "2538008885"], "date": "2001"}, {"id": "2899609382", "title": "Formal representation of ambulatory assessment protocols in HTML5 for human readability and computer execution.", "abstract": "Ambulatory assessment (AA) is a research method that aims to collect longitudinal biopsychosocial data in groups of individuals. AA studies are commonly conducted via mobile devices such as smartphones. Researchers tend to communicate their AA protocols to the community in natural language by describing step-by-step procedures operating on a set of materials. However, natural language requires effort to transcribe onto and from the software systems used for data collection, and may be ambiguous, thereby making it harder to reproduce a study. Though AA protocols may also be written as code in a programming language, most programming languages are not easily read by most researchers. Thus, the quality of scientific discourse on AA stands to gain from protocol descriptions that are easy to read, yet remain formal and readily executable by computers. This paper makes the case for using the HyperText Markup Language (HTML) to achieve this. While HTML can suitably describe AA materials, it cannot describe AA procedures. To resolve this, and taking away lessons from previous efforts with protocol implementations in a system called TEMPEST, we offer a set of custom HTML5 elements that help treat HTML documents as executable programs that can both render AA materials, and effect AA procedures on computational platforms.", "authors": ["Nikolaos Batalas", "Vassilis Javed Khan", "Minita Franzen", "Panos Markopoulos", "Marije aan het Rot"], "related_topics": ["138708601", "160145156", "195324797"], "citation_count": "2", "reference_count": "51", "references": ["1965014786", "1996109622", "1767470961", "1568713441", "1995054497", "1511496623", "2078074240", "2056499831", "2776017876", "2124931356"], "date": "2019"}, {"id": "2130032538", "title": "A Graph Approach to Spelling Correction in Domain-Centric Search", "abstract": "Spelling correction for keyword-search queries is challenging in restricted domains such as personal email (or desktop) search, due to the scarcity of query logs, and due to the specialized nature of the domain. For that task, this paper presents an algorithm that is based on statistics from the corpus data (rather than the query log). This algorithm, which employs a simple graph-based approach, can incorporate different types of data sources with different levels of reliability (e.g., email subject vs. email body), and can handle complex spelling errors like splitting and merging of words. An experimental study shows the superiority of the algorithm over existing alternatives in the email domain.", "authors": ["Zhuowei Bao", "Benny Kimelfeld", "Yunyao Li"], "related_topics": ["136134403", "2777801307", "204321447"], "citation_count": "17", "reference_count": "21", "references": ["2119821739", "1579838312", "2131058166", "155995321", "2010595692", "2098720114", "66690650", "1544537492", "2129271949", "20984399"], "date": "2011"}, {"id": "2122683098", "title": "Convolutional Codes and Their Performance in Communication Systems", "abstract": "This tutorial paper begins with an elementary presentation of the fundamental properties and structure of convolutional codes and proceeds with the development of the maximum likelihood decoder. The powerful tool of generating function analysis is demonstrated to yield for arbitrary codes both the distance properties and upper bounds on the bit error probability for communication over any memoryless channel. Previous results on code ensemble average error probabilities are also derived and extended by these techniques. Finally, practical considerations concerning finite decoding memory, metric representation, and synchronization are discussed.", "authors": ["A. Viterbi"], "related_topics": ["157899210", "33529081", "2400350"], "citation_count": "1522", "reference_count": "15", "references": ["1991133427", "2153810958", "2035227369", "1515682093", "1993944611", "2151814693", "2087362480", "2005530146", "2079363366", "2148981728"], "date": "1971"}, {"id": "2024400846", "title": "ProbView: a flexible probabilistic database system", "abstract": "Probability theory is mathematically the best understood paradigm for modeling and manipulating uncertain information. Probabilities of complex events can be computed from those of basic events on which they depend, using any of a number of strategies. Which strategy is appropriate depends very much on the known interdependencies among the events involved. Previous work on probabilistic databases has assumed a fixed and restrictivecombination strategy (e.g., assuming all events are pairwise independent). In this article, we characterize, using postulates, whole classes of strategies for conjunction, disjunction, and negation, meaningful from the viewpoint of probability theory. (1) We propose a probabilistic relational data model and a genericprobabilistic relational algebra that neatly captures various strategiessatisfying the postulates, within a single unified framework. (2) We show that as long as the chosen strategies can be computed in polynomial time, queries in the positive fragment of the probabilistic relational algebra have essentially the same data complexity as classical relational algebra. (3) We establish various containments and equivalences between algebraic expressions, similar in spirit to those in classical algebra. (4) We develop algorithms for maintaining materialized probabilistic views. (5) Based on these ideas, we have developed a prototype probabilistic database system called ProbView on top of Dbase V.0. We validate our complexity results with experiments and show that rewriting certain types of queries to other equivalent forms often yields substantial savings.", "authors": ["Laks V. S. Lakshmanan", "Nicola Leone", "Robert Ross", "V. S. Subrahmanian"], "related_topics": ["174539288", "65647387", "99436015"], "citation_count": "461", "reference_count": "33", "references": ["2011039300", "1787564306", "2012670464", "2034956514", "2125791539", "1990391007", "1487522439", "2005649826", "2414883570", "2017978889"], "date": "1997"}, {"id": "1893940590", "title": "Mode-based graphical user interfaces for touch sensitive input devices", "abstract": "A user interface method is disclosed. The method includes detecting a touch and then determining a user interface mode when a touch is detected. The method further includes activating one or more GUI elements based on the user interface mode and in response to the detected touch.", "authors": ["Steve Peter Hotelling", "Joshua Strickon", "Brian Q. Huppi", "Duncan Robert Kerr", "Imran Chaudhri", "Greg Christie", "Jonathan P. Ive", "Bas Ording"], "related_topics": ["197070257", "187482481", "89505385"], "citation_count": "2223", "reference_count": "500", "references": ["1930456798", "1584397650", "2914705496", "2113918921", "1901544345", "2121019134", "2126698653", "2005198142", "2930602263", "2107118797"], "date": "2005"}, {"id": "2911489562", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining.", "abstract": "Motivation Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. Results We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts. Availability and implementation We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.", "authors": ["Jinhyuk Lee", "Wonjin Yoon", "Sungdong Kim", "Donghyeon Kim", "Sunkyu Kim", "Chan Ho So", "Jaewoo Kang"], "related_topics": ["165141518", "2779135771", "137293760"], "citation_count": "1040", "reference_count": "43", "references": ["2963341956", "2963403868", "2919115771", "2153579005", "2250539671", "2962739339", "2963748441", "2132339004", "2525778437", "2963756346"], "date": "2019"}, {"id": "1556726625", "title": "The grammar of society: the nature and dynamics of social norms", "abstract": "In The Grammar of Society, first published in 2006, Cristina Bicchieri examines social norms, such as fairness, cooperation, and reciprocity, in an effort to understand their nature and dynamics, the expectations that they generate, and how they evolve and change. Drawing on several intellectual traditions and methods, including those of social psychology, experimental economics and evolutionary game theory, Bicchieri provides an integrated account of how social norms emerge, why and when we follow them, and the situations where we are most likely to focus on relevant norms. Examining the existence and survival of inefficient norms, she demonstrates how norms evolve in ways that depend upon the psychological dispositions of the individual and how such dispositions may impair social efficiency. By contrast, she also shows how certain psychological propensities may naturally lead individuals to evolve fairness norms that closely resemble those we follow in most modern societies.", "authors": ["Cristina Bicchieri"], "related_topics": ["199452025", "144468488", "206836424"], "citation_count": "3150", "reference_count": "162", "references": ["3022808291", "2135410596", "2140950724", "3122867100", "3122042041", "2139774323", "3123711457", "2096452841", "158727920", "1965514675"], "date": "2005"}, {"id": "2100873065", "title": "MULTI-PARAGRAPH SEGMENTATION EXPOSITORY TEXT", "abstract": "This paper describes TextTiling, an algorithm for partitioning expository texts into coherent multi-paragraph discourse units which reflect the subtopic structure of the texts. The algorithm uses domain-independent lexical frequency and distribution information to recognize the interactions of multiple simultaneous themes. Two fully-implemented versions of the algorithm are described and shown to produce segmentation that corresponds well to human judgments of the major subtopic boundaries of thirteen lengthy texts.", "authors": ["Marti A. Hearst"], "related_topics": ["2777206241", "89600930", "204321447"], "citation_count": "889", "reference_count": "27", "references": ["2102381086", "1833785989", "1570542661", "2167702024", "1710422233", "2040004971", "2015933299", "1977182536", "1516391399", "2071188151"], "date": "1994"}, {"id": "1527532036", "title": "Computer systems that learn", "abstract": "", "authors": ["Sholom M. Weiss"], "related_topics": ["113041634", "41008148", "199360897"], "citation_count": "1521", "reference_count": "0", "references": ["2132549764", "2147194983", "1997362234", "2125965138", "2133218851", "1560688497", "2158143121", "608314793", "2115358726", "2094934653"], "date": "1990"}, {"id": "2315179971", "title": "The Dancing Wu Li Masters: An Overview of the New Physics", "abstract": "", "authors": ["Robert Draper", "Gary Zukav"], "related_topics": ["52119013", "142362112", "554144382"], "citation_count": "262", "reference_count": "0", "references": ["2007179372", "1575714269", "2151561903", "2006320147", "2047425471", "2327943158", "1564858658", "2063575816", "1657358085", "2065684202"], "date": "1981"}, {"id": "1983661866", "title": "Inferring decision trees using the minimum description length principle", "abstract": "Abstract We explore the use of Rissanen's minimum description length principle for the construction of decision trees. Empirical results comparing this approach to other methods are given.", "authors": ["J. R. Quinlan", "R. L. Rivest"], "related_topics": ["87465248", "84525736", "180198813"], "citation_count": "1025", "reference_count": "15", "references": ["1594031697", "2149706766", "1993449345", "2128420091", "2054658115", "2106596127", "1968908999", "2119047110", "3121299688", "1970074386"], "date": "1989"}, {"id": "2169150396", "title": "Larrabee: a many-core x86 architecture for visual computing", "abstract": "This paper presents a many-core visual computing architecture code named Larrabee, a new software rendering pipeline, a manycore programming model, and performance analysis for several applications. Larrabee uses multiple in-order x86 CPU cores that are augmented by a wide vector processor unit, as well as some fixed function logic blocks. This provides dramatically higher performance per watt and per unit of area than out-of-order CPUs on highly parallel workloads. It also greatly increases the flexibility and programmability of the architecture as compared to standard GPUs. A coherent on-die 2nd level cache allows efficient inter-processor communication and high-bandwidth local data access by CPU cores. Task scheduling is performed entirely with software in Larrabee, rather than in fixed function logic. The customizable software graphics rendering pipeline for this architecture uses binning in order to reduce required memory bandwidth, minimize lock contention, and increase opportunities for parallelism relative to standard GPUs. The Larrabee native programming model supports a variety of highly parallel applications that use irregular data structures. Performance analysis on those applications demonstrates Larrabee's potential for a broad range of parallel computation.", "authors": ["Larry Seiler", "Doug Carmean", "Eric Sprangle", "Tom Forsyth", "Michael Abrash", "Pradeep Dubey", "Stephen Junkins", "Adam Lake", "Jeremy Sugerman", "Robert Cavin", "Roger Espasa", "Ed Grochowski", "Toni Juan", "Pat Hanrahan"], "related_topics": ["109772839", "78766204", "150552126"], "citation_count": "1155", "reference_count": "50", "references": ["1490482062", "2028499920", "2108157916", "2032309817", "3138798301", "1575732703", "2022740893", "2169706611", "1536852470", "1965387308"], "date": "2008"}, {"id": "2032309817", "title": "Brook for GPUs: stream computing on graphics hardware", "abstract": "In this paper, we present Brook for GPUs, a system for general-purpose computation on programmable graphics hardware. Brook extends C to include simple data-parallel constructs, enabling the use of the GPU as a streaming co-processor. We present a compiler and runtime system that abstracts and virtualizes many aspects of graphics hardware. In addition, we present an analysis of the effectiveness of the GPU as a compute engine compared to the CPU, to determine when the GPU can outperform the CPU for a particular algorithm. We evaluate our system with five applications, the SAXPY and SGEMV BLAS operators, image segmentation, FFT, and ray tracing. For these applications, we demonstrate that our Brook implementations perform comparably to hand-written GPU code and up to seven times faster than their CPU counterparts.", "authors": ["Ian Buck", "Tim Foley", "Daniel Horn", "Jeremy Sugerman", "Kayvon Fatahalian", "Mike Houston", "Pat Hanrahan"], "related_topics": ["18945957", "169590947", "49154492"], "citation_count": "1836", "reference_count": "38", "references": ["2150134853", "2154118576", "2172212694", "2096070062", "2169706611", "2132540527", "1964031104", "2118688057", "2117236520", "2997945685"], "date": "2004"}, {"id": "2109863423", "title": "Scale-space filtering", "abstract": "The extrema in a signal and its first few derivatives provide a useful general-purpose qualitative description for many kinds of signals. A fundamental problem in computing such descriptions is scale: a derivative must be taken over some neighborhood, but there is seldom a principled basis for choosing its size. Scale-space filtering is a method that describes signals qualitatively, managing the ambiguity of scale in an organized and natural way. The signal is first expanded by convolution with gaussian masks over a continuum of sizes. This \"scale-space\" image is then collapsed, using its qualitative structure, into a tree providing a concise but complete qualitative description covering all scales of observation. The description is further refined by applying a stability criterion, to identify events that persist of large changes in scale.", "authors": ["Andrew P. Witkin"], "related_topics": ["27434737", "99102927", "2778755073"], "citation_count": "4020", "reference_count": "16", "references": ["1995756857", "1968245656", "1530383550", "2824445807", "2117900366", "1870339432", "2059376358", "2524793274", "1965555058", "2044972977"], "date": "1986"}, {"id": "1796251476", "title": "Capturing the Uncertainty of Moving-Object Representations", "abstract": "Spatiotemporal applications, such as fleet management and air traffic control, involving continuously moving objects are increasingly at the focus of research efforts. The representation of the continuously changing positions of the objects is fundamentally important in these applications. This paper reports on on-going research in the representation of the positions of moving-point objects. More specifically, object positions are sampled using the Global Positioning System, and interpolation is applied to determine positions in-between the samples. Special attention is given in the representation to the quantification of the position uncertainty introduced by the sampling technique and the interpolation. In addition, the paper considers the use for query processing of the proposed representation in conjunction with indexing. It is demonstrated how queries involving uncertainty may be answered using the standard filter-and-refine approach known from spatial query processing.", "authors": ["Dieter Pfoser", "Christian S. Jensen"], "related_topics": ["172722865", "50341643", "203689450"], "citation_count": "664", "reference_count": "11", "references": ["1512470852", "2032521898", "1545923740", "2124199440", "2000366549", "2058903936", "2100315210", "1938177792", "2026136061", "1983255417"], "date": "1999"}, {"id": "3138367763", "title": "C-store: a column-oriented DBMS", "abstract": "This paper presents the design of a read-optimized relational DBMS that contrasts sharply with most current systems, which are write-optimized. Among the many differences in its design are: storage of data by column rather than by row, careful coding and packing of objects into storage including main memory during query processing, storing an overlapping collection of column-oriented projections, rather than the current fare of tables and indexes, a non-traditional implementation of transactions which includes high availability and snapshot isolation for read-only transactions, and the extensive use of bitmap indexes to complement B-tree structures.We present preliminary performance data on a subset of TPC-H and show that the system we are building, C-Store, is substantially faster than popular commercial products. Hence, the architecture looks very encouraging.", "authors": ["Mike Stonebraker", "Daniel J. Abadi", "Adam Batkin", "Xuedong Chen", "Mitch Cherniack", "Miguel Ferreira", "Edmond Lau", "Amerson Lin", "Sam Madden", "Elizabeth O'Neil", "Pat O'Neil", "Alex Rasin", "Nga Tran", "Stan Zdonik"], "related_topics": ["135689500", "24394798", "92111932"], "citation_count": "2991", "reference_count": "24", "references": ["2103201239", "1515932031", "2129652681", "2124851765", "2158237121", "1997020216", "2117917070", "2111967617", "2068739275", "2104954161"], "date": "2005"}, {"id": "2143331230", "title": "Learning to rank using gradient descent", "abstract": "We investigate using gradient descent methods for learning ranking functions; we propose a simple probabilistic cost function, and we introduce RankNet, an implementation of these ideas using a neural network to model the underlying ranking function. We present test results on toy data and on data from a commercial internet search engine.", "authors": ["Chris Burges", "Tal Shaked", "Erin Renshaw", "Ari Lazier", "Matt Deeds", "Nicole Hamilton", "Greg Hullender"], "related_topics": ["206688291", "124975894", "153258448"], "citation_count": "2684", "reference_count": "17", "references": ["3023786531", "2107890099", "26816478", "1985554184", "2988119488", "2019575783", "2171541062", "2108263314", "2171590421", "2127589108"], "date": "2005"}, {"id": "2109065830", "title": "X10: an object-oriented approach to non-uniform cluster computing", "abstract": "It is now well established that the device scaling predicted by Moore's Law is no longer a viable option for increasing the clock frequency of future uniprocessor systems at the rate that had been sustained during the last two decades. As a result, future systems are rapidly moving from uniprocessor to multiprocessor configurations, so as to use parallelism instead of frequency scaling as the foundation for increased compute capacity. The dominant emerging multiprocessor structure for the future is a Non-Uniform Cluster Computing (NUCC) system with nodes that are built out of multi-core SMP chips with non-uniform memory hierarchies, and interconnected in horizontally scalable cluster configurations such as blade servers. Unlike previous generations of hardware evolution, this shift will have a major impact on existing software. Current OO language facilities for concurrent and distributed programming are inadequate for addressing the needs of NUCC systems because they do not support the notions of non-uniform data access within a node, or of tight coupling of distributed nodes.We have designed a modern object-oriented programming language, X10, for high performance, high productivity programming of NUCC systems. A member of the partitioned global address space family of languages, X10 highlights the explicit reification of locality in the form of places}; lightweight activities embodied in async, future, foreach, and ateach constructs; a construct for termination detection (finish); the use of lock-free synchronization (atomic blocks); and the manipulation of cluster-wide global data structures. We present an overview of the X10 programming model and language, experience with our reference implementation, and results from some initial productivity comparisons between the X10 and Java\u2122 languages.", "authors": ["Philippe Charles", "Christian Grothoff", "Vijay Saraswat", "Christopher Donawa", "Allan Kielstra", "Kemal Ebcioglu", "Christoph von Praun", "Vivek Sarkar"], "related_topics": ["34165917", "79189994", "60832428"], "citation_count": "1959", "reference_count": "36", "references": ["1644882639", "1510543252", "1570906644", "2155066383", "2108204150", "2085407655", "2140300123", "1981393723", "168248273", "1812582761"], "date": "2005"}, {"id": "2065684202", "title": "The normative origins of positive theories: Ideology and accounting thought", "abstract": "Abstract \u201cPositive\u201d, \u201cdescriptive\u201d and \u201cempirical\u201d theories are frequently promoted as being more realistic, factual and relevant than normative approaches. This paper argues that \u201cpositive\u201d or \u201cempirical\u201d theories are also normative and value-laden in that they usually mask a conservative ideological bias in their accounting policy implications. We argue that labels such as \u201cpositive\u201d and \u201cempirical\u201d emanate from a Realist theory of knowledge; a wholly inadequate epistemological basis for a social science. We use an alternative philosophical position (of Historical Materialism) together with a historical review of the concept of value to illustrate first, the partisan role played by theories and theoreticians in questions concerning social control, social conflict and social order; second, the ideologically conservative underpinnings of positive accounting theories; and last, some indications of alternative (radical) approaches to accounting policy.", "authors": ["Anthony M. Tinker", "Barbara D. Merino", "Marilyn Dale Neimark"], "related_topics": ["126415523", "44725695", "19891933"], "citation_count": "875", "reference_count": "143", "references": ["2753533763", "2332433940", "1563052884", "2057931959", "2966017312", "1559924327", "2079374669", "2061276533", "2007870489", "1547848350"], "date": "1981"}, {"id": "1507699566", "title": "Practical Face Recognition and Verification with Wisard", "abstract": "WISARD (Wilkie, Aleksander, and Stonham\u2019s Recognition Device) is a general purpose pattern recognition machine with a special semi-parallel structure unlike that of conventional single instruction single data computers. The machine is self-adapting. It does not require programming where an explict set of rules, defining the operations to be performed on the data, have to be supplied. The behaviour of the system is established by a learning process whereby a representative set of patterns from the class of data to be recognised, is input to the machine. A wide range of pattern recognition problems can be solved with this approach, they include industrial inspection, speech recognition, medical pattern recognition and artificial vision.", "authors": ["T. J. Stonham"], "related_topics": ["88799230", "153180895", "191070858"], "citation_count": "122", "reference_count": "0", "references": ["2138451337", "2098693229", "2135463994", "2168239064", "2078118580", "2095999100", "2282794079", "2025588980", "1983240749", "2154164341"], "date": "1985"}, {"id": "2053463056", "title": "BoosTexter: A Boosting-based Systemfor Text Categorization", "abstract": "This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks. Our approach is based on a new and improved family of boosting algorithms. We describe in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks. We present results comparing the performance of BoosTexter and a number of other text-categorization algorithms on a variety of tasks. We conclude by describing the application of our system to automatic call-type identification from unconstrained spoken customer responses.", "authors": ["Robert E. Schapire", "Yoram Singer"], "related_topics": ["46686674", "94124525", "123860398"], "citation_count": "2960", "reference_count": "37", "references": ["3124955340", "2112076978", "1975846642", "1956559956", "2114535528", "2032210760", "1670263352", "2096152098", "1966280301", "2067885219"], "date": "2000"}, {"id": "2063904635", "title": "Empirical study of topic modeling in Twitter", "abstract": "Social networks such as Facebook, LinkedIn, and Twitter have been a crucial source of information for a wide spectrum of users. In Twitter, popular information that is deemed important by the community propagates through the network. Studying the characteristics of content in the messages becomes important for a number of tasks, such as breaking news detection, personalized message recommendation, friends recommendation, sentiment analysis and others. While many researchers wish to use standard text mining tools to understand messages on Twitter, the restricted length of those messages prevents them from being employed to their full potential.We address the problem of using standard topic models in micro-blogging environments by studying how the models can be trained on the dataset. We propose several schemes to train a standard topic model and compare their quality and effectiveness through a set of carefully designed experiments from both qualitative and quantitative perspectives. We show that by training a topic model on aggregated messages we can obtain a higher quality of learned model which results in significantly better performance in two real-world classification problems. We also discuss how the state-of-the-art Author-Topic model fails to model hierarchical relationships between entities in Social Media.", "authors": ["Liangjie Hong", "Brian D. Davison"], "related_topics": ["518677369", "66402592", "171686336"], "citation_count": "1238", "reference_count": "21", "references": ["1880262756", "1532325895", "2046804949", "2001082470", "2076219102", "2000200507", "2098062695", "1969486090", "2140124448", "2137958601"], "date": "2010"}, {"id": "2127492100", "title": "Meme-tracking and the dynamics of the news cycle", "abstract": "Tracking new topics, ideas, and \"memes\" across the Web has been an issue of considerable interest. Recent work has developed methods for tracking topic shifts over long time scales, as well as abrupt spikes in the appearance of particular named entities. However, these approaches are less well suited to the identification of content that spreads widely and then fades over time scales on the order of days - the time scale at which we perceive news and events.We develop a framework for tracking short, distinctive phrases that travel relatively intact through on-line text; developing scalable algorithms for clustering textual variants of such phrases, we identify a broad class of memes that exhibit wide spread and rich variation on a daily basis. As our principal domain of study, we show how such a meme-tracking approach can provide a coherent representation of the news cycle - the daily rhythms in the news media that have long been the subject of qualitative interpretation but have never been captured accurately enough to permit actual quantitative analysis. We tracked 1.6 million mainstream media sites and blogs over a period of three months with the total of 90 million articles and we find a set of novel and persistent temporal patterns in the news cycle. In particular, we observe a typical lag of 2.5 hours between the peaks of attention to a phrase in the news media and in blogs respectively, with divergent behavior around the overall peak and a \"heartbeat\"-like pattern in the handoff between news and blogs. We also develop and analyze a mathematical model for the kinds of temporal variation that the system exhibits.", "authors": ["Jure Leskovec", "Lars Backstrom", "Jon Kleinberg"], "related_topics": ["529147693", "165120375", "2776224158"], "citation_count": "1850", "reference_count": "29", "references": ["1880262756", "2124637492", "2072644219", "1521478692", "2152284345", "2021314079", "2058465497", "2171343266", "2113889316", "2073689275"], "date": "2009"}, {"id": "2128637996", "title": "Unlocking a device by performing gestures on an unlock image", "abstract": "A device with a touch-sensitive display may be unlocked via gestures performed on the touch-sensitive display. The device is unlocked if contact with the display corresponds to a predefined gesture for unlocking the device. The device displays one or more unlock images with respect to which the predefined gesture is to be performed in order to unlock the device. The performance of the predefined gesture with respect to the unlock image may include moving the unlock image to a predefined location and/or moving the unlock image along a predefined path. The device may also display visual cues of the predefined gesture on the touch screen to remind a user of the gesture.", "authors": ["Imran Chaudhri", "Bas Ording", "Freddy Allen Anzures", "Marcel van Os", "Scott Forstall", "Greg Christie"], "related_topics": ["207347870", "31972630", "111370547"], "citation_count": "2295", "reference_count": "186", "references": ["1955828807", "2113918921", "1915041554", "1901544345", "3142638428", "2115218409", "1485033854", "1626123658", "2816155880", "2099988124"], "date": "2013"}, {"id": "2150117517", "title": "Fundamental bounds on edge detection: an information theoretic evaluation of different edge cues", "abstract": "We treat the problem of edge detection as one of statistical inference. Local edge cues, implemented by filters, provide information about the likely positions of edges which can be used as input to higher-level models. Different edge cues can be evaluated by the statistical effectiveness of their corresponding filters evaluated on a dataset of 100 presegmented images. We use information theoretic measures to determine the effectiveness of a variety of different edge detectors working at multiple scales on black and white and color images. Our results give quantitative measures for the advantages of multi-level processing, for the use of chromaticity in addition to greyscale, and for the relative effectiveness of different detectors.", "authors": ["S. Konishi", "A.L. Yuille", "J. Coughlan", "Song Chun Zhu"], "related_topics": ["193536780", "2776151529", "78201319"], "citation_count": "128", "reference_count": "10", "references": ["2099111195", "2117812871", "2145023731", "2126174118", "2128439793", "1562206072", "2149396346", "1569587969", "2164814911", "2156741519"], "date": "1999"}, {"id": "2168844688", "title": "The B\u2010matrix must be rotated when correcting for subject motion in DTI data", "abstract": "To estimate diffusion tensor MRI (DTI) measures, such as fractional anisotropy and fiber orientation, reliably, a large number of diffusion-encoded images is needed, preferably cardiac gated to reduce pulsation artifacts. However, the concomitant longer acquisition times increase the chances of subject motion adversely affecting the estimation of these measures. While correcting for motion artifacts improves the accuracy of DTI, an often overlooked step in realigning the images is to reorient the B-matrix so that orientational information is correctly preserved. To the best of our knowledge, most research groups and software packages currently omit this reorientation step. Given the recent explosion of DTI applications including, for example, neurosurgical planning (in which errors can have drastic consequences), it is important to investigate the impact of neglecting to perform the B-matrix reorientation. In this work, a systematic study to investigate the effect of neglecting to reorient the B-matrix on DTI data during motion correction is presented. The consequences for diffusion fiber tractography are also discussed. Magn Reson Med 61:1336\u20131349, 2009.", "authors": ["Alexander Leemans", "Derek K. Jones"], "related_topics": ["149550507", "89916169", "18762648"], "citation_count": "1163", "reference_count": "40", "references": ["2034432063", "2142900310", "2147133578", "2986444355", "2124525546", "2138764991", "2149337534", "2066931954", "2051781844", "1992107615"], "date": "2009"}, {"id": "2046804949", "title": "Why we twitter: understanding microblogging usage and communities", "abstract": "Microblogging is a new form of communication in which users can describe their current status in short posts distributed by instant messages, mobile phones, email or the Web. Twitter, a popular microblogging tool has seen a lot of growth since it launched in October, 2006. In this paper, we present our observations of the microblogging phenomena by studying the topological and geographical properties of Twitter's social network. We find that people use microblogging to talk about their daily activities and to seek or share information. Finally, we analyze the user intentions associated at a community level and show how users with similar intentions connect with each other.", "authors": ["Akshay Java", "Xiaodan Song", "Tim Finin", "Belle Tseng"], "related_topics": ["143275388", "518677369", "114713312"], "citation_count": "4805", "reference_count": "28", "references": ["2112090702", "2008620264", "2138621811", "1971421925", "2000042664", "2047940964", "2164928285", "2950627632", "2175110005", "2156037541"], "date": "2007"}, {"id": "2128978199", "title": "The Theory of Matrices", "abstract": "Volume 2: XI. Complex symmetric, skew-symmetric, and orthogonal matrices: 1. Some formulas for complex orthogonal and unitary matrices 2. Polar decomposition of a complex matrix 3. The normal form of a complex symmetric matrix 4. The normal form of a complex skew-symmetric matrix 5. The normal form of a complex orthogonal matrix XII. Singular pencils of matrices: 1. Introduction 2. Regular pencils of matrices 3. Singular pencils. The reduction theorem 4. The canonical form of a singular pencil of matrices 5. The minimal indices of a pencil. Criterion for strong equivalence of pencils 6. Singular pencils of quadratic forms 7. Application to differential equations XIII. Matrices with non-negative elements: 1. General properties 2. Spectral properties of irreducible non-negative matrices 3. Reducible matrices 4. The normal form of a reducible matrix 5. Primitive and imprimitive matrices 6. Stochastic matrices 7. Limiting probabilities for a homogeneous Markov chain with a finite number of states 8. Totally non-negative matrices 9. Oscillatory matrices XIV. Applications of the theory of matrices to the investigation of systems of linear differential equations: 1. Systems of linear differential equations with variable coefficients. General concepts 2. Lyapunov transformations 3. Reducible systems 4. The canonical form of a reducible system. Erugin's theorem 5. The matricant 6. The multiplicative integral. The infinitesimal calculus of Volterra 7. Differential systems in a complex domain. General properties 8. The multiplicative integral in a complex domain 9. Isolated singular points 10. Regular singularities 11. Reducible analytic systems 12. Analytic functions of several matrices and their application to the investigation of differential systems. The papers of Lappo-Danilevskii XV. The problem of Routh-Hurwitz and related questions: 1. Introduction 2. Cauchy indices 3. Routh's algorithm 4. The singular case. Examples 5. Lyapunov's theorem 6. The theorem of Routh-Hurwitz 7. Orlando's formula 8. Singular cases in the Routh-Hurwitz theorem 9. The method of quadratic forms. Determination of the number of distinct real roots of a polynomial 10. Infinite Hankel matrices of finite rank 11. Determination of the index of an arbitrary rational fraction by the coefficients of numerator and denominator 12. Another proof of the Routh-Hurwitz theorem 13. Some supplements to the Routh-Hurwitz theorem. Stability criterion of Lienard and Chipart 14. Some properties of Hurwitz polynomials. Stieltjes' theorem. Representation of Hurwitz polynomials by continued fractions 15. Domain of stability. Markov parameters 16. Connection with the problem of moments 17. Theorems of Markov and Chebyshev 18. The generalized Routh-Hurwitz problem Bibliography Index.", "authors": ["F. R. Gantmakher"], "related_topics": ["137127113", "20836784", "62555958"], "citation_count": "13075", "reference_count": "0", "references": ["1667950888", "1506342804", "1878853999", "1991252559", "616418331", "2145364632", "1985123706", "1698699930", "2012445782", "659300758"], "date": "1984"}, {"id": "2093717447", "title": "The Strength of Weak Learnability", "abstract": "This paper addresses the problem of improving the accuracy of an hypothesis output by a learning algorithm in the distribution-free (PAC) learning model. A concept class is learnable (or strongly learnable) if, given access to a source of examples of the unknown concept, the learner with high probability is able to output an hypothesis that is correct on all but an arbitrarily small fraction of the instances. The concept class is weakly learnable if the learner can produce an hypothesis that performs only slightly better than random guessing. In this paper, it is shown that these two notions of learnability are equivalent. A method is described for converting a weak learning algorithm into one that achieves arbitrarily high accuracy. This construction may have practical applications as a tool for efficiently converting a mediocre learning algorithm into one that performs extremely well. In addition, the construction has some interesting theoretical consequences, including a set of general upper bounds on the complexity of any strong learning algorithm as a function of the allowed error e.", "authors": ["Robert E. Schapire"], "related_topics": ["184414520", "203313322", "112972136"], "citation_count": "5987", "reference_count": "23", "references": ["2019363670", "2154952480", "2139709458", "2428981601", "2070902649", "2117049614", "2091401625", "2066688546", "1965415591", "2157526632"], "date": "1990"}, {"id": "1584397650", "title": "Multi-functional hand-held device", "abstract": "Disclosed herein is a multi-functional hand-held device capable of configuring user inputs based on how the device is to be used. Preferably, the multifunctional hand-held device has at most only a few physical buttons, keys, or switches so that its display size can be substantially increased. The multifunctional hand-held device also incorporates a variety of input mechanisms, including touch sensitive screens, touch sensitive housings, display actuators, audio input, etc. The device also incorporates a user-configurable GUI for each of the multiple functions of the devices.", "authors": ["Steven Porter Hotelling"], "related_topics": ["164597639", "170003942", "9390403"], "citation_count": "2939", "reference_count": "181", "references": ["1930456798", "2113918921", "1893940590", "2107118797", "1886112015", "2925818728", "1928196547", "2103081962", "1489671546", "2760775914"], "date": "2006"}, {"id": "2160598920", "title": "Intrusion detection using an ensemble of intelligent paradigms", "abstract": "Soft computing techniques are increasingly being used for problem solving. This paper addresses using an ensemble approach of different soft computing and hard computing techniques for intrusion detection. Due to increasing incidents of cyber attacks, building effective intrusion detection systems are essential for protecting information systems security, and yet it remains an elusive goal and a great challenge. We studied the performance of Artificial Neural Networks (ANNs), Support Vector Machines (SVMs) and Multivariate Adaptive Regression Splines (MARS). We show that an ensemble of ANNs, SVMs and MARS is superior to individual approaches for intrusion detection in terms of classification accuracy.", "authors": ["Srinivas Mukkamala", "Andrew H. Sung", "Ajith Abraham"], "related_topics": ["35525427", "140073362", "182590292"], "citation_count": "481", "reference_count": "36", "references": ["2156909104", "1554663460", "1576520375", "2133671888", "2102201073", "2148138104", "3161062409", "2150847526", "2051812123", "2085305295"], "date": "2005"}, {"id": "1895577753", "title": "Show and tell: A neural image caption generator", "abstract": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.", "authors": ["Oriol Vinyals", "Alexander Toshev", "Samy Bengio", "Dumitru Erhan"], "related_topics": ["167966045", "203005215", "94176051"], "citation_count": "4638", "reference_count": "36", "references": ["2097117768", "1836465849", "2117539524", "2964308564", "1614298861", "2130942839", "2157331557", "2963542991", "2064675550", "2155541015"], "date": "2015"}, {"id": "1557657228", "title": "Experiences with GroupLens: marking usenet useful again", "abstract": "Collaborative filetering attempts to alleviate information overload by offering recommendations on whether information is valuable based on the opinions of those who have already evaluated it. Usenet news is an information source whose value is being severely diminished by the volume of low-quality and uninteresting information posted in its newsgroups. The GroupLens system applies collaborative filtering to Usenet news to demonstrate how we can restore the value of Usenet news by sharing our judgements of articles, with our identities protected by pseudonyms. This paper extends the original GroupLens work by reporting on a significantly enhanced system and the results of a seven week trial with 250 users and over 20,000 news articles. GroupLens has an open and flexible architecture that allows easy integration of new newsreader clients and ratings bureaus. We show ratings and prediction profiles for three news-groups, and assess the accuracy of the predictions.", "authors": ["Bradley N. Miller", "John T. Riedl", "Joseph A. Konstan"], "related_topics": ["21569690", "186625053", "2777474334"], "citation_count": "125", "reference_count": "11", "references": ["3121531027", "2124591829", "1966553486", "1956559956", "175500210", "2030144199", "2137719099", "2037717074", "1579638493", "2173548719"], "date": "1997"}, {"id": "2002938383", "title": "Spelling checkers,spelling correctors and the misspellings of poor spellers", "abstract": "A large corpus of spelling errors taken from free writing is analyzed to assess how great a challenge such errors present for automatic checking and correction. The analysis reveals a high proportion of errors that match dictionary words; these would necessitate the use of context in error detection. Some of these errors are caused by incorrect word-division, a type of error difficult to spot since it calls into question the placing of word boundaries. Misspellings tend to differ from the correct words more than mistypings do. Some knowledge of pronunciation would help in correcting many of the errors, but misspellings do not always reflect pronunciation in a simple way.", "authors": ["Roger Mitton"], "related_topics": ["2777801307", "2780844864", "2780049985"], "citation_count": "157", "reference_count": "14", "references": ["2111192396", "2046980440", "2143635578", "2034163998", "2109469864", "2066792529", "1517504840", "2088534712", "115535506", "1995407914"], "date": "1987"}, {"id": "2112053513", "title": "Web caching and Zipf-like distributions: evidence and implications", "abstract": "This paper addresses two unresolved issues about Web caching. The first issue is whether Web requests from a fixed user community are distributed according to Zipf's (1929) law. The second issue relates to a number of studies on the characteristics of Web proxy traces, which have shown that the hit-ratios and temporal locality of the traces exhibit certain asymptotic properties that are uniform across the different sets of the traces. In particular, the question is whether these properties are inherent to Web accesses or whether they are simply an artifact of the traces. An answer to these unresolved issues will facilitate both Web cache resource planning and cache hierarchy design. We show that the answers to the two questions are related. We first investigate the page request distribution seen by Web proxy caches using traces from a variety of sources. We find that the distribution does not follow Zipf's law precisely, but instead follows a Zipf-like distribution with the exponent varying from trace to trace. Furthermore, we find that there is only (i) a weak correlation between the access frequency of a Web page and its size and (ii) a weak correlation between access frequency and its rate of change. We then consider a simple model where the Web accesses are independent and the reference probability of the documents follows a Zipf-like distribution. We find that the model yields asymptotic behaviour that are consistent with the experimental observations, suggesting that the various observed properties of hit-ratios and temporal locality are indeed inherent to Web accesses observed by proxies. Finally, we revisit Web cache replacement algorithms and show that the algorithm that is suggested by this simple model performs best on real trace data. The results indicate that while page requests do indeed reveal short-term correlations and other structures, a simple model for an independent request stream following a Zipf-like distribution is sufficient to capture certain asymptotic properties observed at Web proxies.", "authors": ["L. Breslau", "Pei Cao", "Li Fan", "G. Phillips", "S. Shenker"], "related_topics": ["21959979", "2775834730", "115537543"], "citation_count": "4339", "reference_count": "14", "references": ["1918432491", "1543886729", "2144684817", "2048392910", "2155979007", "1521825954", "1772464603", "1533813939", "2115103717", "3013106704"], "date": "1999"}, {"id": "2120788459", "title": "Tables of sphere packings and spherical codes", "abstract": "The theta function of a sphere packing gives the number of centers at each distance from the origin. The theta functions of a number of important packings ( A_{n},D_{n},E_{n} , the Leech lattice, and others) and tables of the first fifty or so of their coefficients are given in this paper.", "authors": ["N. Sloane"], "related_topics": ["118636789", "183893376", "105546189"], "citation_count": "194", "reference_count": "43", "references": ["2142228262", "2584020404", "2060968961", "201252986", "1969165241", "1999547040", "2316593342", "2013083117", "2031398796", "2144552676"], "date": "1981"}, {"id": "1545923740", "title": "GPS satellite surveying", "abstract": "Elements of Satellite Surveying The Global Positioning System Adjustment Computations Least-Squares Adjustment Examples Links to Physical Observations The Three-Dimensional Geodetic Model GPS Observables Propagation Media, Multipath, and Phase Center Processing GPS Carrier Phases Network Adjustments Ellipsoidal and Conformal Mapping Models Useful Transformations Datums, Standards, and Specifications Appendices References Abbreviations for Frequently Used References Indexes.", "authors": ["Alfred Leick"], "related_topics": ["60229501", "58754882", "36301306"], "citation_count": "3889", "reference_count": "0", "references": ["1544411027", "2112306707", "2745396148", "2791124749", "1939330307", "1796251476", "2174616381", "2138442469", "2124160566", "2087718299"], "date": "1989"}, {"id": "3138640687", "title": "Optimized Online Lecture for Narrow-Bandwidth Network", "abstract": "Education plays an important role in a country\u2019s development, and remote education, where barriers of distance can be overcome by information technology and more education resources are thus made available, can be used to improve education accessibility in low-income countries. However, one of the key problems of current distance education approaches, such as Massive Open Online Courses (MOOCs), is the high requirement of bandwidth which is not necessarily available. In this paper, we propose a method of carrying out online lectures in an optimized form where the influence of the low bandwidth on the quality of the lecture is minimized. The proposed method only involves transmission of audio, courseware as static files, and actions encoded as textual data. With replicated state machine theory, the synchronization between all clients is guaranteed. This allows us to achieve lecture delivery with good quality under low-bandwidth network conditions. A prototypical platform for the delivery of such optimized lectures is designed, implemented using Golang and JavaScript, and evaluated.", "authors": ["Tingyu Chen", "Anandha Gopalan"], "related_topics": ["2776257435", "503872463", "10784920"], "citation_count": "0", "reference_count": "11", "references": ["2156580773", "3021428210", "2152465173", "87727730", "2579551568", "1866530474", "2120783929", "2514655373", "1485692346", "2484276928"], "date": "2021"}, {"id": "1993882792", "title": "Acoustic Modeling Using Deep Belief Networks", "abstract": "Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models.", "authors": ["A. Mohamed", "G. E. Dahl", "G. Hinton"], "related_topics": ["167966045", "23224414", "97385483"], "citation_count": "1900", "reference_count": "41", "references": ["2136922672", "3118608800", "2100495367", "2116064496", "2147768505", "2159080219", "44815768", "1994197834", "2913932916", "2103359087"], "date": "2011"}, {"id": "1802356529", "title": "Energy-based models for sparse overcomplete representations", "abstract": "We present a new way of extending independent components analysis (ICA) to overcomplete representations. In contrast to the causal generative extensions of ICA which maintain marginal independence of sources, we define features as deterministic (linear) functions of the inputs. This assumption results in marginal dependencies among the features, but conditional independence of the features given the inputs. By assigning energies to the features a probability distribution over the input states is defined through the Boltzmann distribution. Free parameters of this model are trained using the contrastive divergence objective (Hinton, 2002). When the number of features is equal to the number of input dimensions this energy-based model reduces to noiseless ICA and we show experimentally that the proposed learning algorithm is able to perform blind source separation on speech data. In additional experiments we train overcomplete energy-based models to extract features from various standard data-sets containing speech, natural images, hand-written digits and faces.", "authors": ["Yee Whye Teh", "Max Welling", "Simon Osindero", "Geoffrey E. Hinton"], "related_topics": ["51432778", "35651441", "79772020"], "citation_count": "206", "reference_count": "31", "references": ["2116064496", "2078204800", "2154642048", "1652505363", "2099741732", "2108384452", "2151693816", "2145889472", "2146474141", "2105464873"], "date": "2003"}, {"id": "1748197048", "title": "SELF-PERCEPTION THEORY", "abstract": "Publisher Summary Individuals come to \u201cknow\u201d their own attitudes, emotions, and other internal states partially by inferring them from observations of their own overt behavior and/ or the circumstances in which this behavior occurs. Thus, to the extent that internal cues are weak, ambiguous, or uninterpretable, the individual is functionally in the same position as an outside observer, an observer who must necessarily rely upon those same external cues to infer the individual's inner states. This chapter traces the conceptual antecedents and empirical consequences of these propositions, attempts to place the theory in a slightly enlarged frame of reference, and clarifies just what phenomena the theory can and cannot account for in the rapidly growing experimental literature of self-attribution phenomena. Several experiments and paradigms from the cognitive dissonance literature are amenable to self-perception interpretations. But precisely because such experiments are subject to alternative interpretations, they cannot be used as unequivocal evidence for self-perception theory. The reinterpretation of cognitive dissonance phenomena and other self-perception phenomena have been discussed. The chapter highlights some differences between self-perception and interpersonal perception and shift of paradigm in social psychology. It discusses some unsolved problems, such as the conceptual status of noncognitive response classes and the strategy of functional analysis.", "authors": ["Daryl J. Bem"], "related_topics": ["113445564", "77513098", "2778968331"], "citation_count": "6766", "reference_count": "67", "references": ["2017680376", "2071464654", "2963241992", "1719717336", "2156616450", "2061131717", "2138612226", "2157300266", "1995724078", "2161264813"], "date": "1971"}, {"id": "2131910503", "title": "Using dynamic programming for solving variational problems in vision", "abstract": "Dynamic programming is discussed as an approach to solving variational problems in vision. Dynamic programming ensures global optimality of the solution, is numerically stable, and allows for hard constraints to be enforced on the behavior of the solution within a natural and straightforward structure. As a specific example of the approach's efficacy, applying dynamic programming to the energy-minimizing active contours is described. The optimization problem is set up as a discrete multistage decision process and is solved by a time-delayed discrete dynamic programming algorithm. A parallel procedure for decreasing computational costs is discussed. >", "authors": ["A.A. Amini", "T.E. Weymouth", "R.C. Jain"], "related_topics": ["173404611", "150762246", "137631369"], "citation_count": "1667", "reference_count": "35", "references": ["2145023731", "2104095591", "1997063559", "2911709767", "2620619910", "2796837256", "2913192828", "2139762693", "1977948323", "2019635781"], "date": "1990"}, {"id": "2063575816", "title": "Is the Moon There When Nobody Looks? Reality and the Quantum Theory", "abstract": "In May 1935, Albert Einstein, Boris Podolsky and Nathan Rosen published an argument that quantum mechanics fails to provide a complete description of physical reality. Today, 50 years later, the EPR paper and the theoretical and experimental work it inspired remain remarkable for the vivid illustration they provide of one of the most bizarre aspects of the world revealed to us by the quantum theory.", "authors": ["N. David Mermin"], "related_topics": ["171811987", "18399536", "137002209"], "citation_count": "668", "reference_count": "15", "references": ["2179731956", "2014306526", "2039004790", "2052140519", "2135830616", "3003547482", "2099911643", "3000632564", "2315179971", "2149499942"], "date": "1985"}, {"id": "1592847719", "title": "Recent Advances in Hierarchical Reinforcement Learning", "abstract": "Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of semi-Markov decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting.", "authors": ["Andrew G. Barto", "Sridhar Mahadevan"], "related_topics": ["97541855", "2780217385", "106189395"], "citation_count": "1302", "reference_count": "88", "references": ["2121863487", "1515851193", "2107726111", "1576452626", "2099529102", "1564534945", "2168359464", "2109910161", "3011120880", "32403112"], "date": "2002"}, {"id": "2104671481", "title": "Pedestrian detection using wavelet templates", "abstract": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes. This problem poses several challenges. People are highly non-rigid objects with a high degree of variability in size, shape, color, and texture. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or on motion. The detection technique is based on the novel idea of the wavelet template that defines the shape of an object in terms of a subset of the wavelet coefficients of the image. It is invariant to changes in color and texture and can be used to robustly define a rich and complex class of objects such as people. We show how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection.", "authors": ["M. Oren", "C. Papageorgiou", "P. Sinha", "E. Osuna", "T. Poggio"], "related_topics": ["2776151529", "196216189", "47432892"], "citation_count": "1109", "reference_count": "14", "references": ["2156909104", "2132984323", "2087347434", "2159686933", "2159173611", "2056695679", "2125713050", "2145910025", "1676612073", "2164475575"], "date": "1997"}, {"id": "2147800946", "title": "Backpropagation applied to handwritten zip code recognition", "abstract": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.", "authors": ["Y. LeCun", "B. Boser", "J. S. Denker", "D. Henderson", "R. E. Howard", "W. Hubbard", "L. D. Jackel"], "related_topics": ["155032097", "136738937", "178980831"], "citation_count": "8794", "reference_count": "14", "references": ["2154642048", "2165758113", "169539560", "19621276", "2101926813", "56903235", "2157475639", "2606594511", "1965770722", "2116360511"], "date": "1989"}, {"id": "2504871398", "title": "Learning representations by back-propagation errors, nature", "abstract": "", "authors": ["DE Rumelhart", "GE Hinton", "RJ William"], "related_topics": ["188147891", "155032097", "15744967"], "citation_count": "1461", "reference_count": "0", "references": ["2119821739", "1787224781", "2109722477", "2914746235", "2160958420", "2218318129", "2105728138", "1613249581", "2124537004", "2803163155"], "date": "1985"}, {"id": "1522746076", "title": "Toward the Logic of Tense and Aspect in English", "abstract": "", "authors": ["Michael Bennett", "Barbara Hall Partee"], "related_topics": ["206977991", "187714233", "140205497"], "citation_count": "798", "reference_count": "0", "references": ["2067551521", "1570679045", "2070939632", "1499647402", "2022429923", "3032342983", "2152578812", "2506173291", "1582394651", "2098116521"], "date": "2008"}, {"id": "2139762693", "title": "Regularization of Inverse Visual Problems Involving Discontinuities", "abstract": "Inverse problems, such as the reconstruction problems that arise in early vision, tend to be mathematically ill-posed. Through regularization, they may be reformulated as well-posed variational principles whose solutions are computable. Standard regularization theory employs quadratic stabilizing functionals that impose global smoothness constraints on possible solutions. Discontinuities present serious difficulties to standard regularization, however, since their reconstruction requires a precise spatial control over the smoothing properties of stabilizers. This paper proposes a general class of controlled-continuity stabilizers which provide the necessary control over smoothness. These nonquadratic stabilizing functionals comprise multiple generalized spline kernels combined with (noncontinuous) continuity control functions. In the context of computational vision, they may be thought of as controlled-continuity constraints. These generic constraints are applicable to visual reconstruction problems that involve both continuous regions and discontinuities, for which global smoothness constraints fail.", "authors": ["Demetri Terzopoulos"], "related_topics": ["27872270", "8398441", "135252773"], "citation_count": "1258", "reference_count": "34", "references": ["2581275558", "1997063559", "2177721432", "2109863423", "2133155955", "2074797641", "3141390961", "2022140147", "2003945700", "3021591933"], "date": "1986"}, {"id": "2159230047", "title": "Arbitrariness, Iconicity, and Systematicity in Language", "abstract": "The notion that the form of a word bears an arbitrary relation to its meaning accounts only partly for the attested relations between form and meaning in the languages of the world. Recent research suggests a more textured view of vocabulary structure, in which arbitrariness is complemented by iconicity (aspects of form resemble aspects of meaning) and systematicity (statistical regularities in forms predict function). Experimental evidence suggests these form-to-meaning correspondences serve different functions in language processing, development, and communication: systematicity facilitates category learning by means of phonological cues, iconicity facilitates word learning and communication by means of perceptuomotor analogies, and arbitrariness facilitates meaning individuation through distinctive forms. Processes of cultural evolution help to explain how these competing motivations shape vocabulary structure.", "authors": ["Mark Dingemanse", "Dami\u00e1n E. Blasi", "Gary Lupyan", "Morten H. Christiansen", "", "Padraic Monaghan"], "related_topics": ["175475021", "2777451423", "2777601683"], "citation_count": "379", "reference_count": "131", "references": ["2085876742", "809551758", "1996672843", "2232925767", "2000196122", "2010927954", "239563548", "4941964", "2104563567", "2087360383"], "date": "2015"}, {"id": "2057503509", "title": "Three-way arrays: rank and uniqueness of trilinear decompositions, with application to arithmetic complexity and statistics", "abstract": "Abstract A three-way array X (or three-dimensional matrix) is an array of numbers xijk subscripted by three indices. A triad is a multiplicative array, xijk = aibjck. Analogous to the rank and the row rank of a matrix, we define rank (X) to be the minimum number of triads whose sum is X, and dim1(X) to be the dimensionality of the space of matrices generated by the 1-slabs of X. (Rank and dim1 may not be equal.) We prove several lower bounds on rank. For example, a special case of Theorem 1 is that rank(X)\u2a7edim 1 (UX) + rank(XW) \u2212 dim 1 (UXW) , where U and W are matrices; this generalizes a matrix theorem of Frobenius. We define the triple product [A, B, C] of three matrices to be the three-way array whose (i, j, k) element is given by \u2a5erairbjrckr; in other words, the triple product is the sum of triads formed from the columns of A, B, and C. We prove several sufficient conditions for the factors of a triple product to be essentially unique. For example (see Theorem 4a), suppose [A, B, C] = [ A , B , C ] , and each of the matrices has R columns. Suppose every set of rank (A) columns of A are independent, and similar conditions hold for B and C. Suppose rank (A) + rank (B) + rank (C) \u2a7e 2R + 2. Then there exist diagonal matrices \u039b, M, N and a permutation matrix P such that A = AP\u039b, B = BP M , C = CP N . Our results have applications to arithmetic complexity theory and to statistical models used in three-way multidimensional scaling.", "authors": ["Joseph B. Kruskal"], "related_topics": ["1026927", "200681373", "137127113"], "citation_count": "2004", "reference_count": "16", "references": ["1655990431", "2000215628", "2035476608", "1538550540", "201320490", "2032765816", "2010537260", "2010811692", "2088676085", "2079231426"], "date": "1976"}, {"id": "3032342983", "title": "Measure of change: The adjectival core of degree achievements.", "abstract": "", "authors": ["Christopher Kennedy", "Beth Levin"], "related_topics": ["2164484", "2776013501", "9035317"], "citation_count": "453", "reference_count": "44", "references": ["2067551521", "2026725080", "2120857440", "1965909177", "2025589690", "2108770909", "1481656063", "2079093047", "1522746076", "189529527"], "date": "2007"}, {"id": "83940682", "title": "Symbols among the neurons: details of a connectionist inference architecture", "abstract": "Pattern matching and variable binding are easily implemented in conventional computer architectures, but not necessarily in all architectures. In a distributed neural network architecture each symbol is represented by activity in many units and each unit contributes to the representation of many symbols. Manipulating symbols using this type of distributed representation is not as easy as with a local representation whore each unit denotes one symbol, but there is evidence that the distributed approach is the one chosen by nature. We describe a working implementation of a production system interpreter in a neural network using distributed representations for both symbols and rules. The research provides a detailed account of two important symbolic reasoning operations, pattern matching and variable binding, as emergent properties of collections of neuron-like elements. The success of our production system implementation goes some way towards answering a common criticism of connectionist theories: that they aren't powerful enough to do symbolic reasoning.", "authors": ["David S. Touretzky", "Geoffrey E. Minton"], "related_topics": ["24929129", "8521452", "68859911"], "citation_count": "274", "reference_count": "15", "references": ["2581275558", "1652505363", "2293063825", "1507849272", "2073257493", "2112325651", "2912225506", "1533832053", "39428922", "1981025738"], "date": "1985"}, {"id": "2153635508", "title": "LIBSVM: A library for support vector machines", "abstract": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.", "authors": ["Chih-Chung Chang", "Chih-Jen Lin"], "related_topics": ["10719679", "125168437", "12267149"], "citation_count": "43942", "reference_count": "52", "references": ["2148603752", "2119821739", "2109943925", "2172000360", "1512098439", "2104978738", "1576520375", "2087347434", "2132870739", "2124351082"], "date": "2011"}, {"id": "2168081761", "title": "Biogeography-Based Optimization", "abstract": "Biogeography is the study of the geographical distribution of biological organisms. Mathematical equations that govern the distribution of organisms were first discovered and developed during the 1960s. The mindset of the engineer is that we can learn from nature. This motivates the application of biogeography to optimization problems. Just as the mathematics of biological genetics inspired the development of genetic algorithms (GAs), and the mathematics of biological neurons inspired the development of artificial neural networks, this paper considers the mathematics of biogeography as the basis for the development of a new field: biogeography-based optimization (BBO). We discuss natural biogeography and its mathematics, and then discuss how it can be used to solve optimization problems. We see that BBO has features in common with other biology-based optimization methods, such as GAs and particle swarm optimization (PSO). This makes BBO applicable to many of the same types of problems that GAs and PSO are used for, namely, high-dimension problems with multiple local optima. However, BBO also has some features that are unique among biology-based optimization methods. We demonstrate the performance of BBO on a set of 14 standard benchmarks and compare it with seven other biology-based optimization algorithms. We also demonstrate BBO on a real-world sensor selection problem for aircraft engine health estimation.", "authors": ["D. Simon"], "related_topics": ["122357587", "137836250", "159149176"], "citation_count": "3203", "reference_count": "33", "references": ["1639032689", "2142183404", "1997600725", "2102248717", "2790374560", "315572163", "2013205100", "1498178627", "2027945080", "2117640392"], "date": "2008"}, {"id": "1970381522", "title": "Cheap and Fast -- But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks", "abstract": "Human linguistic annotation is crucial for many natural language processing tasks but can be expensive and time-consuming. We explore the use of Amazon's Mechanical Turk system, a significantly cheaper and faster method for collecting annotations from a broad base of paid non-expert contributors over the Web. We investigate five tasks: affect recognition, word similarity, recognizing textual entailment, event temporal ordering, and word sense disambiguation. For all five, we show high agreement between Mechanical Turk non-expert annotations and existing gold standard labels provided by expert labelers. For the task of affect recognition, we also show that using non-expert labels for training machine learning algorithms can be as effective as using gold standard annotations from experts. We propose a technique for bias correction that significantly improves annotation quality on two tasks. We conclude that many large labeling tasks can be effectively designed and carried out in this method at a fraction of the usual expense.", "authors": ["Rion Snow", "Brendan O'Connor", "Daniel Jurafsky", "Andrew Ng"], "related_topics": ["95318506", "195324797", "2777884278"], "citation_count": "2306", "reference_count": "31", "references": ["2141282920", "1632114991", "2151401338", "2158847908", "2525127255", "2125943921", "2149489787", "2115792525", "1659833910", "2130158090"], "date": "2008"}, {"id": "2150847526", "title": "An Intrusion-Detection Model", "abstract": "A model of a real-time intrusion-detection expert system capable of detecting break-ins, penetrations, and other forms of computer abuse is described. The model is based on the hypothesis that security violations can be detected by monitoring a system's audit records for abnormal patterns of system usage. The model includes profiles for representing the behavior of subjects with respect to objects in terms of metrics and statistical models, and rules for acquiring knowledge about this behavior from audit records and for detecting anomalous behavior. The model is independent of any particular system, application environment, system vulnerability, or type of intrusion, thereby providing a framework for a general-purpose intrusion-detection expert system.", "authors": ["D.E. Denning"], "related_topics": ["137524506", "90936777", "35525427"], "citation_count": "5896", "reference_count": "0", "references": ["2122646361", "2097356832", "2142889610", "3136767761", "2164210932", "1985987493", "1970867218", "2007087405", "1941427975", "2056451850"], "date": "1987"}, {"id": "2102248717", "title": "Evolutionary algorithms in theory and practice", "abstract": "", "authors": ["Thomas Back"], "related_topics": ["157741563", "121835503", "105902424"], "citation_count": "4166", "reference_count": "0", "references": ["2168081761", "2125899728", "1999284878", "1560921017", "1504943474", "2001979953", "2004617458", "2049176600", "2118840131", "2053900989"], "date": "1995"}, {"id": "2119714163", "title": "Interpreting the data: Parallel analysis with Sawzall", "abstract": "Very large data sets often have a flat but regular structure and span multiple disks and machines. Examples include telephone call records, network logs, and web document repositories. These large data sets are not amenable to study using traditional database techniques, if only because they can be too large to fit in a single relational database. On the other hand, many of the analyses done on them can be expressed using simple, easily distributed computations: filtering, aggregation, extraction of statistics, and so on. We present a system for automating such analyses. A filtering phase, in which a query is expressed using a new procedural programming language, emits data to an aggregation phase. Both phases are distributed over hundreds or even thousands of computers. The results are then collated and saved to a file. The design -- including the separation into two phases, the form of the programming language, and the properties of the aggregators -- exploits the parallelism inherent in having data and computation distributed across many machines.", "authors": ["Rob Pike", "Sean Dorward", "Robert Griesemer", "Sean Quinlan"], "related_topics": ["56288433", "148840519", "5655090"], "citation_count": "980", "reference_count": "15", "references": ["2173213060", "2119565742", "2148317584", "2032309817", "2118828104", "1493892051", "2112452856", "1586338668", "1991962718", "1525451871"], "date": "2005"}, {"id": "2145803225", "title": "Snakes, shapes, and gradient vector flow", "abstract": "Snakes, or active contours, are used extensively in computer vision and image processing applications, particularly to locate object boundaries. Problems associated with initialization and poor convergence to boundary concavities, however, have limited their utility. This paper presents a new external force for active contours, largely solving both problems. This external force, which we call gradient vector flow (GVF), is computed as a diffusion of the gradient vectors of a gray-level or binary edge map derived from the image. It differs fundamentally from traditional snake external forces in that it cannot be written as the negative gradient of a potential function, and the corresponding snake is formulated directly from a force balance condition rather than a variational formulation. Using several two-dimensional (2-D) examples and one three-dimensional (3-D) example, we show that GVF has a large capture range and is able to move snakes into boundary concavities.", "authors": ["Chenyang Xu", "J.L. Prince"], "related_topics": ["112353826", "115680565", "20749125"], "citation_count": "6004", "reference_count": "24", "references": ["2104095591", "2100115174", "2134820502", "2620619910", "2149184914", "2086921140", "2144133758", "2162837059", "2106160885", "2132663727"], "date": "1998"}, {"id": "2962793481", "title": "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks", "abstract": "Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X \u2192 Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y \u2192 X and introduce a cycle consistency loss to push F(G(X)) \u2248 X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.", "authors": ["Jun-Yan Zhu", "Taesung Park", "Phillip Isola", "Alexei A. Efros"], "related_topics": ["2779757391", "2780528193", "159363923"], "citation_count": "8408", "reference_count": "54", "references": ["2194775991", "2962835968", "2117539524", "1903029394", "2099471712", "1959608418", "2963684088", "2100495367", "2340897893", "2963373786"], "date": "2017"}, {"id": "2022554507", "title": "Linear Prediction of Speech", "abstract": "1. Introduction.- 1.1 Basic Physical Principles.- 1.2 Acoustical Waveform Examples.- 1.3 Speech Analysis and Synthesis Models.- 1.4 The Linear Prediction Model.- 1.5 Organization of Book.- 2. Formulations.- 2.1 Historical Perspective.- 2.2 Maximum Likelihood.- 2.3 Minimum Variance.- 2.4 Prony's Method.- 2.5 Correlation Matching.- 2.6 PARCOR (Partial Correlation).- 2.6.1 Inner Products and an Orthogonality Principle.- 2.6.2 The PARCOR Lattice Structure.- 3. Solutions and Properties.- 3.1 Introduction.- 3.2 Vector Spaces and Inner Products.- 3.2.1 Filter or Polynomial Norms.- 3.2.2 Properties of Inner Products.- 3.2.3 Orthogonality Relations.- 3.3 Solution Algorithms.- 3.3.1 Correlation Matrix.- 3.3.2 Initialization.- 3.3.3 Gram-Schmidt Orthogonalization.- 3.3.4 Levinson Recursion.- 3.3.5 Updating Am(z).- 3.3.6 A Test Example.- 3.4 Matrix Forms.- 4. Acoustic Tube Modeling.- 4.1 Introduction.- 4.2 Acoustic Tube Derivation.- 4.2.1 Single Section Derivation.- 4.2.2 Continuity Conditions.- 4.2.3 Boundary Conditions.- 4.3 Relationship between Acoustic Tube and Linear Prediction.- 4.4 An Algorithm, Examples, and Evaluation.- 4.4.1 An Algorithm.- 4.4.2 Examples.- 4.4.3 Evaluation of the Procedure.- 4.5 Estimation of Lip Impedance.- 4.5.1 Lip Impedance Derivation.- 4.6 Further Topics.- 4.6.1 Losses in the Acoustic Tube Model.- 4.6.2 Acoustic Tube Stability.- 5. Speech Synthesis Structures.- 5.1 Introduction.- 5.2 Stability.- 5.2.1 Step-up Procedure.- 5.2.2 Step-down Procedure.- 5.2.3 Polynomial Properties.- 5.2.4 A Bound on |Fm(z)|.- 5.2.5 Necessary and Sufficient Stability Conditions.- 5.2.6 Application of Results.- 5.3 Recursive Parameter Evaluation.- 5.3.1 Inner Product Properties.- 5.3.2 Equation Summary with Program.- 5.4 A General Synthesis Structure.- 5.5 Specific Speech Synthesis Structures.- 5.5.1 The Direct Form.- 5.5.2 Two-Multiplier Lattice Model.- 5.5.3 Kelly-Lochbaum Model.- 5.5.4 One-Multiplier Models.- 5.5.5 Normalized Filter Model.- 5.5.6 A Test Example.- 6. Spectral Analysis.- 6.1 Introduction.- 6.2 Spectral Properties.- 6.2.1 Zero Mean All-Pole Model.- 6.2.2 Gain Factor for Spectral Matching.- 6.2.3 Limiting Spectral Match.- 6.2.4 Non-uniform Spectral Weighting.- 6.2.5 Minimax Spectral Matching.- 6.3 A Spectral Flatness Model.- 6.3.1 A Spectral Flatness Measure.- 6.3.2 Spectral Flatness Transformations.- 6.3.3 Numerical Evaluation.- 6.3.4 Experimental Results.- 6.3.5 Driving Function Models.- 6.4 Selective Linear Prediction.- 6.4.1 Selective Linear Prediction (SLP) Algorithm.- 6.4.2 A Selective Linear Prediction Program.- 6.4.3 Computational Considerations.- 6.5 Considerations in Choice of Analysis Conditions.- 6.5.1 Choice of Method.- 6.5.2 Sampling Rates.- 6.5.3 Order of Filter.- 6.5.4 Choice of Analysis Interval.- 6.5.5 Windowing.- 6.5.6 Pre-emphasis.- 6.6 Spectral Evaluation Techniques.- 6.7 Pole Enhancement.- 7. Automatic Formant Trajectory Estimation.- 7.1 Introduction.- 7.2 Formant Trajectory Estimation Procedure.- 7.2.1 Introduction.- 7.2.2 Raw Data from A(z).- 7.2.3 Examples of Raw Data.- 7.3 Comparison of Raw Data from Linear Prediction and Cepstral Smoothing.- 7.4 Algorithm 1.- 7.5 Algorithm 2.- 7.5.1 Definition of Anchor Points.- 7.5.2 Processing of Each Voiced Segment.- 7.5.3 Final Smoothing.- 7.5.4 Results and Discussion.- 7.6 Formant Estimation Accuracy.- 7.6.1 An Example of Synthetic Speech Analysis.- 7.6.2 An Example of Real Speech Analysis.- 7.6.3 Influence of Voice Periodicity.- 8. Fundamental Frequency Estimation.- 8.1 Introduction.- 8.2 Preprocessing by Spectral Flattening.- 8.2.1 Analysis of Voiced Speech with Spectral Regularity.- 8.2.2 Analysis of Voiced Speech with Spectral Irregularities.- 8.2.3 The STREAK Algorithm.- 8.3 Correlation Techniques.- 8.3.1 Autocorrelation Analysis.- 8.3.2 Modified Autocorrelation Analysis.- 8.3.3 Filtered Error Signal Autocorrelation Analysis.- 8.3.4 Practical Considerations.- 8.3.5 The SIFT Algorithm.- 9. Computational Considerations in Analysis.- 9.1 Introduction.- 9.2 Ill-Conditioning.- 9.2.1 A Measure of Ill-Conditioning.- 9.2.2 Pre-emphasis of Speech Data.- 9.2.3 Prefiltering before Sampling.- 9.3 Implementing Linear Prediction Analysis.- 9.3.1 Autocorrelation Method.- 9.3.2 Covariance Method.- 9.3.3 Computational Comparison.- 9.4 Finite Word Length Considerations.- 9.4.1 Finite Word Length Coefficient Computation.- 9.4.2 Finite Word Length Solution of Equations.- 9.4.3 Overall Finite Word Length Implementation.- 10. Vocoders.- 10.1 Introduction.- 10.2 Techniques.- 10.2.1 Coefficient Transformations.- 10.2.2 Encoding and Decoding.- 10.2.3 Variable Frame Rate Transmission.- 10.2.4 Excitation and Synthesis Gain Matching.- 10.2.5 A Linear Prediction Synthesizer Program.- 10.3 Low Bit Rate Pitch Excited Vocoders.- 10.3.1 Maximum Likelihood and PARCOR Vocoders.- 10.3.2 Autocorrelation Method Vocoders.- 10.3.3 Covariance Method Vocoders.- 10.4 Base-Band Excited Vocoders.- 11. Further Topics.- 11.1 Speaker Identification and Verification.- 11.2 Isolated Word Recognition.- 11.3 Acoustical Detection of Laryngeal Pathology.- 11.4 Pole-Zero Estimation.- 11.5 Summary and Future Directions.- References.", "authors": ["John E. Markel", "A. H. Gray"], "related_topics": ["131109320", "82412256", "122212055"], "citation_count": "2870", "reference_count": "0", "references": ["2125838338", "1594031697", "2074788634", "2044535354", "2112844139", "2130640900", "2748207967", "1508471544", "2137639365", "2301027021"], "date": "2011"}, {"id": "2094249282", "title": "Language learnability and language development", "abstract": "Language learnability and language devlopment revisited the acquisition theory - assumptions and postulates phrase structure rules phrase stucture rules - developmental considerations inflection complementation and control auxiliaries lexical entries and lexical rules.", "authors": ["Steven Pinker"], "related_topics": ["2777723229", "80877019", "185954173"], "citation_count": "2926", "reference_count": "0", "references": ["2110485445", "1562911371", "1498878034", "1928882148", "1732736211", "2161070585", "2002103405", "2067551521", "2152824855", "2016429292"], "date": "1983"}, {"id": "1978743055", "title": "Psychosocial resilience and protective mechanisms.", "abstract": "The concept of mechanisms that protect people against the psychological risks associated with adversity is discussed in relation to four main processes: 1) reduction of risk impact, 2) reduction of negative chain reactions, 3) establishment and maintenance of self-esteem and self-efficacy, and 4) opening up of opportunities. The mechanisms operating at key turning points in people's lives must be given special attention.", "authors": ["Michael Rutter"], "related_topics": ["2776519147", "150966472", "73282008"], "citation_count": "11770", "reference_count": "56", "references": ["1550621568", "2076192758", "2098952248", "562595160", "2122898463", "1966135462", "3009553456", "2056763236", "2037302276", "2135496634"], "date": "1987"}, {"id": "1493893823", "title": "DryadLINQ: a system for general-purpose distributed data-parallel computing using a high-level language", "abstract": "DryadLINQ is a system and a set of language extensions that enable a new programming model for large scale distributed computing. It generalizes previous execution environments such as SQL, MapReduce, and Dryad in two ways: by adopting an expressive data model of strongly typed .NET objects; and by supporting general-purpose imperative and declarative operations on datasets within a traditional high-level programming language.A DryadLINQ program is a sequential program composed of LINQ expressions performing arbitrary side-effect-free transformations on datasets, and can be written and debugged using standard .NET development tools. The DryadLINQ system automatically and transparently translates the data-parallel portions of the program into a distributed execution plan which is passed to the Dryad execution platform. Dryad, which has been in continuous operation for several years on production clusters made up of thousands of computers, ensures efficient, reliable execution of this plan.We describe the implementation of the DryadLINQ compiler and runtime. We evaluate DryadLINQ on a varied set of programs drawn from domains such as web-graph analysis, large-scale log mining, and machine learning. We show that excellent absolute performance can be attained--a general-purpose sort of 1012 Bytes of data executes in 319 seconds on a 240-computer, 960- disk cluster--as well as demonstrating near-linear scaling of execution time on representative applications as we vary the number of computers used for a job.", "authors": ["Yuan Yu", "Michael Isard", "Dennis Fetterly", "Mihai Budiu", "\u00dalfar Erlingsson", "Pradeep Kumar Gunda", "Jon Currey"], "related_topics": ["90392147", "34165917", "510870499"], "citation_count": "1049", "reference_count": "35", "references": ["2173213060", "1981420413", "2100830825", "2098935637", "2119400430", "2154894831", "2119714163", "3138135046", "2172143128", "2032401773"], "date": "2008"}, {"id": "2002089154", "title": "Introduction to Automata Theory, Languages, and Computation", "abstract": "This book is a rigorous exposition of formal languages and models of computation, with an introduction to computational complexity. The authors present the theory in a concise and straightforward manner, with an eye out for the practical applications. Exercises at the end of each chapter, including some that have been solved, help readers confirm and enhance their understanding of the material. This book is appropriate for upper-level computer science undergraduates who are comfortable with mathematical arguments.", "authors": ["John E. Hopcroft", "Rajeev Motwani", "Rotwani", "Jeffrey D. Ullman"], "related_topics": ["24858836", "146072743", "184596265"], "citation_count": "21162", "reference_count": "0", "references": ["2101508170", "2340735175", "1527197079", "1556566737", "2099529102", "2092654472", "2001496424", "1984052055", "1845137714", "1944672"], "date": "1978"}, {"id": "2134031652", "title": "Automating Knowledge Acquisition for Machine Translation", "abstract": "Machine translation of human languages (for example, Japanese, English, Spanish) was one of the earliest goals of computer science research, and it remains an elusive one. Like many AI tasks, trans-lation requires an immense amount of knowledge about language and the world. Recent approaches to machine translation frequently make use of text-based learning algorithms to fully or partially automate the acquisition of knowledge. This article illustrates these approaches.", "authors": ["Kevin Knight"], "related_topics": ["24687705", "110046852", "148526163"], "citation_count": "129", "reference_count": "40", "references": ["2006969979", "2158195707", "2097333193", "1489181569", "2913739034", "2153439141", "2117652747", "2161204834", "1480519300", "2138437366"], "date": "1997"}, {"id": "1995724078", "title": "INTRINSIC MOTIVATION, EXTRINSIC REINFORCEMENT, AND INEQUITY", "abstract": "If a person who is intrinsically motivated to perform an activity begins to receive external reinforcement for the activity, what will happen to his intrinsic motivation? Previous studies and the present study indicate that money decreases intrinsic motivation, while verbal reinforcements tend to enhance intrinsic motivation. The beginning of a cognitive evaluation theory is discussed, and an apparently discrepant prediction between this theory and inequity theory is pointed out. It is argued, however, that the theories are not conceptually discrepant, and the present study gives support for this argument. It is possible to distinguish between two broad classes of motivation to perform an activity: intrinsic motivation and extrinsic motivation. A person is intrinsically motivated if he performs an activity for no apparent reward except the activity itself (cf. Berlyne, 1966; Hunt, 1965; White, 1959). Extrinsic motivation, on the other hand, refers to the performance of an activity because it leads to external rewards (e.g., status, approval, or passing grades). The question of interest in this study is whether there will be changes in a person's intrinsic motivation for an activity when he receives external rewards for performing that activity. Deci (1971) reported that external reinforcements do affect intrinsic motivation, and he suggested the initial elements of a cognitive evaluation theory to account for the changes in intrinsic motivation following an experience with extrinsic rewards. The theory focuses on a person's cognitive evaluation of an activity and the reasons for his engaging in the activity. It suggests that distinctions should be made among different kinds of external rewards, since a person's evaluation of different rewards may be different. In turn, this would 1 The author would like to thank Wayne Cascio for serving as the first experimenter and for helping with the data analysis; Victor Vroom for making helpful comments on an earlier draft of the manuscript; and Larry Coff for being the second experimenter.", "authors": ["Edward L. Deci"], "related_topics": ["76217610", "146854351", "167327282"], "citation_count": "1563", "reference_count": "15", "references": ["2145520874", "1986936900", "2071464654", "1585013689", "2163741736", "1564868126", "1989616852", "2089928324", "2111846090", "3041304715"], "date": "1971"}, {"id": "2954064014", "title": "Practical Optimization", "abstract": "", "authors": ["Philip E. Gill"], "related_topics": ["41008148"], "citation_count": "12723", "reference_count": "0", "references": ["2135046866", "2030723843", "2035379092", "1970101292", "1521785144", "2110575115", "2124313187", "2090267299", "1755563775", "2141870784"], "date": "1981"}, {"id": "2110636172", "title": "Information Overload and the Message Dynamics of Online Interaction Spaces: A Theoretical Model and Empirical Exploration", "abstract": "Online spaces that enable shared public interpersonal communications are of significant social, organizational, and economic importance. In this paper, a theoretical model and associated unobtrusive method are proposed for researching the relationship between online spaces and the behavior they host. The model focuses on the collective impact that individual information-overload coping strategies have on the dynamics of open, interactive public online group discourse. Empirical research was undertaken to assess the validity of both the method and the model, based on the analysis of over 2.65 million postings to 600 Usenet newsgroups over a 6-month period. Our findings support the assertion that individual strategies for coping with \"information overload\" have an observable impact on large-scale online group discourse. Evidence was found for the hypotheses that: (1) users are more likely to respond to simpler messages in overloaded mass interaction; (2) users are more likely to end active participation as the overloading of mass interaction increases; and (3) users are more likely to generate simpler responses as the overloading of mass interaction grows.The theoretical model outlined offers insight into aspects of computer-mediated communication tool usability, technology design, and provides a road map for future empirical research.", "authors": ["Quentin Jones", "Gilad Ravid", "Sheizaf Rafaeli"], "related_topics": ["120936955", "2777756574", "186625053"], "citation_count": "840", "reference_count": "46", "references": ["2079041580", "2116339812", "1994373531", "2133345793", "1583729138", "2098874414", "1595891490", "2049802678", "2164802537", "2156130609"], "date": "2004"}, {"id": "2099866409", "title": "Restricted Boltzmann machines for collaborative filtering", "abstract": "Most of the existing approaches to collaborative filtering cannot handle very large data sets. In this paper we show how a class of two-layer undirected graphical models, called Restricted Boltzmann Machines (RBM's), can be used to model tabular data, such as user's ratings of movies. We present efficient learning and inference procedures for this class of models and demonstrate that RBM's can be successfully applied to the Netflix data set, containing over 100 million user/movie ratings. We also show that RBM's slightly outperform carefully-tuned SVD models. When the predictions of multiple RBM models and multiple SVD models are linearly combined, we achieve an error rate that is well over 6% better than the score of Netflix's own system.", "authors": ["Ruslan Salakhutdinov", "Andriy Mnih", "Geoffrey Hinton"], "related_topics": ["199354608", "192576344", "21569690"], "citation_count": "2078", "reference_count": "15", "references": ["2136922672", "2100495367", "2116064496", "2147152072", "1612003148", "2122090912", "2158164339", "2124914669", "205159212", "2165395308"], "date": "2007"}, {"id": "1982210139", "title": "Self-efficacy mechanism in human agency.", "abstract": "This article addresses the centrality of the self-efficacy mechanism in human agency. Self-per- cepts of efficacy influence thought patterns, actions, and emotional arousal. In causal tests the higher the level of induced self-efficacy, the higher the perfor- mance accomplishments and the lower the emotional arousal. Different lines of research are reviewed, show- ing that the self-efficacy mechanism may have wide explanatory power. Perceived self-efficacy helps to ac- count for such diverse phenomena as changes in coping behavior produced by different modes of influence, level of physiological stress reactions, self-regulation of refractory behavior, resignation and despondency to failure experiences, self-debilitating effects of proxy control and illusory inefficaciousness, achievement strivings, growth of intrinsic interest, and career pur- suits. The influential role of perceived collective effi- cacy in social change is analyzed, as are the social con- ditions conducive to development of collective inefficacy. Psychological theorizing and research tend to cen- ter on issues concerning either acquisition of knowledge or execution of response patterns. As a result the processes governing the interrelation- ship between knowledge and action have been largely neglected (Newell, 1978). Some of the re- cent efforts to bridge this gap have been directed at the biomechanics problem\u2014how efferent com- mands of action plans guide the production of ap- propriate response patterns (Stelmach, 1976,1978). Others have approached the matter in terms of algorithmic knowledge, which furnishes guides for executing action sequences (Greeno, 1973; Newell, 1973). ,", "authors": ["Albert Bandura"], "related_topics": ["2778032263", "53811970", "89611455"], "citation_count": "28352", "reference_count": "90", "references": ["2179683524", "1550621568", "2029487046", "1532394360", "1561644443", "2144190976", "1748197048", "119946076", "2098688395", "1973272516"], "date": "1981"}, {"id": "2118079529", "title": "Collaborative Filtering: A Machine Learning Perspective", "abstract": "", "authors": ["Benjamin Marlin"], "related_topics": ["188888258", "77967617", "28006648"], "citation_count": "255", "reference_count": "41", "references": ["1880262756", "2119479037", "2125055259", "2798909945", "2110325612", "2159080219", "3121531027", "3143596294", "2049633694", "2073965851"], "date": "2003"}, {"id": "2110659753", "title": "Space-time block codes from orthogonal designs", "abstract": "We introduce space-time block coding, a new paradigm for communication over Rayleigh fading channels using multiple transmit antennas. Data is encoded using a space-time block code and the encoded data is split into n streams which are simultaneously transmitted using n transmit antennas. The received signal at each receive antenna is a linear superposition of the n transmitted signals perturbed by noise. Maximum-likelihood decoding is achieved in a simple way through decoupling of the signals transmitted from different antennas rather than joint detection. This uses the orthogonal structure of the space-time block code and gives a maximum-likelihood decoding algorithm which is based only on linear processing at the receiver. Space-time block codes are designed to achieve the maximum diversity order for a given number of transmit and receive antennas subject to the constraint of having a simple decoding algorithm. The classical mathematical framework of orthogonal designs is applied to construct space-time block codes. It is shown that space-time block codes constructed in this way only exist for few sporadic values of n. Subsequently, a generalization of orthogonal designs is shown to provide space-time block codes for both real and complex constellations for any number of transmit antennas. These codes achieve the maximum possible transmission rate for any number of transmit antennas using any arbitrary real constellation such as PAM. For an arbitrary complex constellation such as PSK and QAM, space-time block codes are designed that achieve 1/2 of the maximum possible transmission rate for any number of transmit antennas. For the specific cases of two, three, and four transmit antennas, space-time block codes are designed that achieve, respectively, all, 3/4, and 3/4 of maximum possible transmission rate using arbitrary complex constellations. The best tradeoff between the decoding delay and the number of transmit antennas is also computed and it is shown that many of the codes presented here are optimal in this sense as well.", "authors": ["V. Tarokh", "H. Jafarkhani", "A.R. Calderbank"], "related_topics": ["157125643", "83487572", "5546382"], "citation_count": "9566", "reference_count": "16", "references": ["2107080958", "2130509920", "1667950888", "2118040894", "2133475491", "2330078975", "2085099144", "2021573106", "2117507580", "2149632009"], "date": "1999"}, {"id": "2316593342", "title": "SPHERE PACKINGS AND ERROR-CORRECTING CODES", "abstract": "Error-correcting codes are used in several constructions for packings of equal spheres in ^-dimensional Euclidean spaces En. These include a systematic derivation of many of the best sphere packings known, and construction of new packings in dimensions 9-15, 36, 40, 48, 60, and 2m for m g 6. Most of the new packings are nonlattice packings. These new packings increase the previously greatest known numbers of spheres which one sphere may touch, and, except in dimensions 9, 12, 14, 15, they include denser packings than any previously known. The density A of the packings in En for n = 2m satisfies log A ~ \u2014 \\n log log n as n \u2014* oo. 1.1. Introduction. In this paper we make systematic use of error-correct ing codes to obtain sphere packings in En, including several of the densest packings known and several new packings. By use of cross-section s we then obtain packings in spaces of lower dimension, and by building up packings by layers we obtain packings in spaces of higher dimension. Collectively, these include all of the densest packings known, and further new packings are also con\u00ad structed. Part 1 of the paper is devoted to groundwork for the constructions. \u00a7 1.2 introduces sphere packings, and \u00a7\u00a7 1.3-1.8 survey the error-correcting code theory used in the later Parts. Part 2 describes and exploits Construction A, which is of main value in up to 15 dimensions. Part 3 describes Construction B% of main value in 16-24 dimensions. Part 4 digresses to deal with packings built up from layers, while Part 5 gives some special constructions for dimen\u00ad sions 36, 40, 48 and 60. Part 6 deals with Construction C, applicable to dimensions n = 2m and giving new denser packings for m ^ 6. We conclude with tables summarizing the results. Table I, for all n S 24, supersedes the tables of [18; 19], and Table II gives results for selected n > 24. The tables may be used as an index giving references to the sections of the paper in which the packings are discussed. Partial summaries of this work have appeared in [22; 23]. General references for sphere packing are [18; 19; 31] and for coding theory [4; 25].", "authors": ["John Leech", "N. J. A. Sloane"], "related_topics": ["183893376", "33676613", "129782007"], "citation_count": "244", "reference_count": "19", "references": ["1969165241", "2015337464", "2124166355", "2100838727", "2318203863", "2153848652", "3119473442", "2081780875", "1969700067", "1970966506"], "date": "1970"}, {"id": "2113918921", "title": "Method and apparatus for integrating manual input", "abstract": "Apparatus and methods are disclosed for simultaneously tracking multiple finger (202-204) and palm (206, 207) contacts as hands approach, touch, and slide across a proximity-sensing, compliant, and flexible multi-touch surface (2). The surface consists of compressible cushion (32), dielectric electrode (33), and circuitry layers. A simple proximity transduction circuit is placed under each electrode to maximize the signal-to-noise ratio and to reduce wiring complexity. Scanning and signal offset removal on electrode array produces low-noise proximity images. Segmentation processing of each proximity image constructs a group of electrodes corresponding to each distinguishable contacts and extracts shape, position and surface proximity features for each group. Groups in successive images which correspond to the same hand contact are linked by a persistent path tracker (245) which also detects individual contact touchdown and liftoff. Classification of intuitive hand configurations and motions enables unprecedented integration of typing, resting, pointing, scrolling, 3D manipulation, and handwriting into a versatile, ergonomic computer input device.", "authors": ["Wayne Carl Westerman", "John Greer Elias"], "related_topics": ["97562148", "121449826", "59046462"], "citation_count": "4352", "reference_count": "179", "references": ["2126698653", "2107118797", "1886112015", "2150874632", "2103081962", "1897547913", "2757200643", "1948150043", "1841110673", "95858216"], "date": "1999"}, {"id": "2123871098", "title": "On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming", "abstract": "We present a primal-dual interior-point algorithm with a filter line-search method for nonlinear programming. Local and global convergence properties of this method were analyzed in previous work. Here we provide a comprehensive description of the algorithm, including the feasibility restoration phase for the filter method, second-order corrections, and inertia correction of the KKT matrix. Heuristics are also considered that allow faster performance. This method has been implemented in the IPOPT code, which we demonstrate in a detailed numerical study based on 954 problems from the CUTEr test set. An evaluation is made of several line-search options, and a comparison is provided with two state-of-the-art interior-point codes for nonlinear programming.", "authors": ["Andreas W\u00e4chter", "Lorenz T. Biegler"], "related_topics": ["155253501", "115527620", "2776141612"], "citation_count": "6950", "reference_count": "28", "references": ["3029645440", "2077658674", "2149454052", "2035072927", "2048799772", "2041684917", "1971536112", "1508335918", "2085137170", "1976385924"], "date": "2006"}, {"id": "1605688901", "title": "An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization", "abstract": "Bagging and boosting are methods that generate a diverse ensemble of classifiers by manipulating the training data given to a \u201cbase\u201d learning algorithm. Breiman has pointed out that they rely for their effectiveness on the instability of the base learning algorithm. An alternative approach to generating an ensemble is to randomize the internal decisions made by the base algorithm. This general approach has been studied previously by Ali and Pazzani and by Dietterich and Kong. This paper compares the effectiveness of randomization, bagging, and boosting for improving the performance of the decision-tree algorithm C4.5. The experiments show that in situations with little or no classification noise, randomization is competitive with (and perhaps slightly superior to) bagging but not as accurate as boosting. In situations with substantial classification noise, bagging is much better than boosting, and sometimes better than randomization.", "authors": ["Thomas G. Dietterich"], "related_topics": ["70153297", "31912584", "2776888448"], "citation_count": "3140", "reference_count": "14", "references": ["2912934387", "2112076978", "2152761983", "2982720039", "1966280301", "2167277498", "2073738917", "2976840617", "1562197959", "1850527962"], "date": "2000"}, {"id": "1974755392", "title": "Eigenvalues and condition numbers of random matrices", "abstract": "Given a random matrix, what condition number should be expected? This paper presents a proof that for real or complex $n \\times n$ matrices with elements from a standard normal distribution, the ex...", "authors": ["Alan Edelman"], "related_topics": ["149488123", "64812099", "33962027"], "citation_count": "1499", "reference_count": "12", "references": ["2056099894", "2052645364", "2089028133", "2084661953", "2016885814", "2005522417", "2060581589", "2082763473", "2162322294", "2008462192"], "date": "1988"}, {"id": "2045798786", "title": "The Representation and Matching of Pictorial Structures", "abstract": "The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection.", "authors": ["M.A. Fischler", "R.A. Elschlager"], "related_topics": ["165064840", "64729616", "2776277257"], "citation_count": "1828", "reference_count": "11", "references": ["2133246412", "2062533874", "2133138342", "2129733001", "1999927042", "2127787769", "2166627017", "197595011", "2072632478", "29412004"], "date": "1972"}, {"id": "2282794079", "title": "Face Recognition: A Literature Review", "abstract": "", "authors": ["A. S. Tolba", "A.H. El-Baz", "A.A. El-Harby"], "related_topics": ["31510193", "50644808", "154945302"], "citation_count": "457", "reference_count": "78", "references": ["2156909104", "1782590233", "2138451337", "1989702938", "2121647436", "2123921160", "2098693229", "2115689562", "2160126058", "1578352865"], "date": "2008"}, {"id": "2056099894", "title": "Probability and Measure", "abstract": "Probability. Measure. Integration. Random Variables and Expected Values. Convergence of Distributions. Derivatives and Conditional Probability. Stochastic Processes. Appendix. Notes on the Problems. Bibliography. List of Symbols. Index.", "authors": ["Patrick Billingsley"], "related_topics": ["21031990", "103982235", "43555835"], "citation_count": "11776", "reference_count": "0", "references": ["2124758339", "2137983211", "2108207895", "1999814123", "3122732203", "1541527977", "2963423916", "2137344397", "2160837607", "1974708997"], "date": "1978"}, {"id": "2401811773", "title": "Issues and Limitations of HMM in Speech Processing: A Survey", "abstract": "is the most natural way of communication among humans. This mode of communication is constituted of two parts, namely sound and sense. The intelligent production and synthesis of speech has intrigued man himself for long and efforts at automated speech recognition, has gone through various phases. Hidden Markov Models (HMMs) provide a simple and effective framework for modeling time-varying spectral vector sequences. Application of HMMs to speech recognition has seen considerable success and gained much popularity. As a consequence, almost all present day speech recognition systems are based on HMMs.", "authors": ["Chandralika Chakraborty", "P.H. Talukdar"], "related_topics": ["61328038", "23224414", "28490314"], "citation_count": "6", "reference_count": "15", "references": ["2125838338", "2105594594", "2112529238", "2003333103", "2012705052", "2042494711", "2042732685", "2063125572", "2147229751", "2056809970"], "date": "2016"}, {"id": "2147568880", "title": "Learning precise timing with lstm recurrent networks", "abstract": "The temporal distance between events conveys information essential for numerous sequential tasks such as motor control and rhythm detection. While Hidden Markov Models tend to ignore this information, recurrent neural networks (RNNs) can in principle learn to make use of it. We focus on Long Short-Term Memory (LSTM) because it has been shown to outperform other RNNs on tasks involving long time lags. We find that LSTM augmented by \"peephole connections\" from its internal cells to its multiplicative gates can learn the fine distinction between sequences of spikes spaced either 50 or 49 time steps apart without the help of any short training exemplars. Without external resets or teacher forcing, our LSTM variant also learns to generate stable streams of precisely timed spikes and other highly nonlinear periodic patterns. This makes LSTM a promising approach for tasks that require the accurate measurement or generation of time intervals.", "authors": ["Felix A. Gers", "Nicol N. Schraudolph", "J\u00fcrgen Schmidhuber"], "related_topics": ["147168706", "23224414", "119857082"], "citation_count": "1395", "reference_count": "23", "references": ["2064675550", "2107878631", "2136848157", "2914484425", "2016589492", "1525783482", "194249466", "2154890045", "1674799117", "2121029939"], "date": "2003"}, {"id": "1597286183", "title": "Neural computation of decisions in optimization problems", "abstract": "Highly-interconnected networks of nonlinear analog neurons are shown to be extremely effective in computing. The networks can rapidly provide a collectively-computed solution (a digital output) to a problem on the basis of analog input information. The problems to be solved must be formulated in terms of desired optima, often subject to constraints. The general principles involved in constructing networks to solve specific problems are discussed. Results of computer simulations of a network designed to solve a difficult but well-defined optimization problem-the Traveling-Salesman Problem-are presented and used to illustrate the computational power of the networks. Good solutions to this problem are collectively computed within an elapsed time of only a few neural time constants. The effectiveness of the computation involves both the nonlinear analog response of the neurons and the large connectivity among them. Dedicated networks of biological or microelectronic neurons could provide the computational capabilities described for a wide class of problems having combinatorial complexity. The power and speed naturally displayed by such collective networks may contribute to the effectiveness of biological information processing.", "authors": ["J. J. Hopfield", "D. W. Tank"], "related_topics": ["137836250", "3832189", "46421273"], "citation_count": "8064", "reference_count": "28", "references": ["2581275558", "2011039300", "2293063825", "2177721432", "1666015432", "307896644", "2042986967", "2112325651", "2032533296", "1543738661"], "date": "1985"}, {"id": "2156273867", "title": "Bayesian inference in statistical analysis", "abstract": "Nature of Bayesian Inference Standard Normal Theory Inference Problems Bayesian Assessment of Assumptions: Effect of Non-Normality on Inferences About a Population Mean with Generalizations Bayesian Assessment of Assumptions: Comparison of Variances Random Effect Models Analysis of Cross Classification Designs Inference About Means with Information from More than One Source: One-Way Classification and Block Designs Some Aspects of Multivariate Analysis Estimation of Common Regression Coefficients Transformation of Data Tables References Indexes.", "authors": ["George E. P. Box", "George C. Tiao"], "related_topics": ["162376815", "2778963538", "101112237"], "citation_count": "8088", "reference_count": "0", "references": ["2045656233", "3145506661", "2038840577", "2125001590", "2113945798", "1582484699", "2083875149", "1982652137", "1999814123", "195465510"], "date": "1973"}, {"id": "3021923959", "title": "Changes in contact patterns shape the dynamics of the COVID-19 outbreak in China.", "abstract": "Intense nonpharmaceutical interventions were put in place in China to stop transmission of the novel coronavirus disease 2019 (COVID-19). As transmission intensifies in other countries, the interplay between age, contact patterns, social distancing, susceptibility to infection, and COVID-19 dynamics remains unclear. To answer these questions, we analyze contact survey data for Wuhan and Shanghai before and during the outbreak and contact-tracing information from Hunan province. Daily contacts were reduced seven- to eightfold during the COVID-19 social distancing period, with most interactions restricted to the household. We find that children 0 to 14 years of age are less susceptible to severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection than adults 15 to 64 years of age (odds ratio 0.34, 95% confidence interval 0.24 to 0.49), whereas individuals more than 65 years of age are more susceptible to infection (odds ratio 1.47, 95% confidence interval 1.12 to 1.92). Based on these data, we built a transmission model to study the impact of social distancing and school closure on transmission. We find that social distancing alone, as implemented in China during the outbreak, is sufficient to control COVID-19. Although proactive school closures cannot interrupt transmission on their own, they can reduce peak incidence by 40 to 60% and delay the epidemic.", "authors": ["Juanjuan Zhang", "Maria Litvinova", "Yuxia Liang", "Yan Wang", "Wei Wang", "Shanlu Zhao", "Qianhui Wu", "Stefano Merler", "C\u00e9cile Viboud", "Alessandro Vespignani", "", "Marco Ajelli", "Hongjie Yu"], "related_topics": ["116675565", "113162765", "40827391"], "citation_count": "623", "reference_count": "36", "references": ["3003668884", "3003573988", "3010781325", "3010131837", "3035011439", "3002764620", "3020184843", "3012789146", "3045614912", "3005995896"], "date": "2020"}, {"id": "2101522199", "title": "Joint induction of shape features and tree classifiers", "abstract": "We introduce a very large family of binary features for two-dimensional shapes. The salient ones for separating particular shapes are determined by inductive learning during the construction of classification trees. There is a feature for every possible geometric arrangement of local topographic codes. The arrangements express coarse constraints on relative angles and distances among the code locations and are nearly invariant to substantial affine and nonlinear deformations. They are also partially ordered, which makes it possible to narrow the search for informative ones at each node of the tree. Different trees correspond to different aspects of shape. They are statistically and weakly dependent due to randomization and are aggregated in a simple way. Adapting the algorithm to a shape family is then fully automatic once training samples are provided. As an illustration, we classified handwritten digits from the NIST database; the error rate was 0.7 percent.", "authors": ["Y. Amit", "D. Geman", "K. Wilder"], "related_topics": ["92757383", "52622490", "49209780"], "citation_count": "267", "reference_count": "26", "references": ["2912934387", "1594031697", "2087347434", "2120240539", "1676820704", "2154579312", "2102734279", "2168228682", "2100659887", "1530454533"], "date": "1997"}, {"id": "2092713296", "title": "MULTIPLE RANGE AND MULTIPLE F TESTS", "abstract": "", "authors": ["David B. Duncan"], "related_topics": ["20589650", "33923547", "30475298"], "citation_count": "29666", "reference_count": "14", "references": ["1998495461", "3101280595", "2318802957", "1515242458", "2025918513", "2046586101", "2053219361", "2037892350", "1977959532", "2056353558"], "date": "1955"}, {"id": "2170120409", "title": "Numerical recipes in C", "abstract": "Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08", "authors": ["William H. Press", "Saul A. Teukolsky", "William T. Vetterling", "Brian P. Flannery"], "related_topics": ["77741850", "121684516", "41008148"], "citation_count": "16021", "reference_count": "0", "references": ["1746819321", "1595159159", "2103546861", "2132103241", "2183707334", "1976969221", "2047205370", "2171268876", "2121016876", "2161406034"], "date": "1993"}, {"id": "2128017662", "title": "Scalable Recognition with a Vocabulary Tree", "abstract": "A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD\u0092s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.", "authors": ["D. Nister", "H. Stewenius"], "related_topics": ["2777601683", "167611913", "75165309"], "citation_count": "4716", "reference_count": "19", "references": ["2151103935", "2177274842", "2131846894", "1980911747", "2104978738", "2172188317", "2124404372", "2147717514", "2162006472", "2165497495"], "date": "2006"}, {"id": "2107743791", "title": "Probabilistic latent semantic indexing", "abstract": "Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data. Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain{specific synonymy as well as with polysemous words. In contrast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and defines a proper generative data model. Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methods as well as over LSI. In particular, the combination of models with different dimensionalities has proven to be advantageous.", "authors": ["Thomas Hofmann"], "related_topics": ["112933361", "500882744", "68841619"], "citation_count": "6791", "reference_count": "15", "references": ["2147152072", "2049633694", "1956559956", "1612003148", "2567948266", "2127314673", "1718512272", "2143144851", "2140842551", "2063089147"], "date": "1999"}, {"id": "1971735090", "title": "On the approximate realization of continuous mappings by neural networks", "abstract": "Abstract In this paper, we prove that any continuous mapping can be approximately realized by Rumelhart-Hinton-Williams' multilayer neural networks with at least one hidden layer whose output functions are sigmoid functions. The starting point of the proof for the one hidden layer case is an integral formula recently proposed by Irie-Miyake and from this, the general case (for any number of hidden layers) can be proved by induction. The two hidden layers case is proved also by using the Kolmogorov-Arnold-Sprecher theorem and this proof also gives non-trivial realizations.", "authors": ["K. Funahashi"], "related_topics": ["120264874", "81388566", "50644808"], "citation_count": "6046", "reference_count": "15", "references": ["2154642048", "2042264548", "1554576613", "3036751298", "1613359937", "3108739439", "2152088994", "3040500874", "2105393299", "2189011649"], "date": "1989"}, {"id": "2169793348", "title": "Using ambient light sensor to augment proximity sensor output", "abstract": "Apparatuses and methods to sense proximity of an object and operate a proximity sensor of a portable device. In some embodiments, a method includes receiving an ambient light sensor (ALS) output, and altering, based on the ALS output, an effect of a proximity sensor output on control of a proximity determination. The ALS sensor and the proximity sensor may be located adjacent to an earpiece of a portable device. In some cases, the proximity determination may be a proximity of an object to the proximity sensor, and altering the effect may include changing the proximity of the object from a proximity greater than a first threshold to a proximity less than the first threshold. Other apparatuses and methods and data processing systems and machine readable media are also described.", "authors": ["Scott M. Herz", "Roberto G. Yepez", "Wayne C. Westerman", "Stephen P. Hotelling"], "related_topics": ["135403697", "108572070", "23125352"], "citation_count": "583", "reference_count": "127", "references": ["1930456798", "1584397650", "1893940590", "1901544345", "2164252468", "2147555786", "2748207967", "1948825421", "1893741530", "1849545308"], "date": "2007"}, {"id": "2147717514", "title": "Approximate nearest neighbors: towards removing the curse of dimensionality", "abstract": "We present two algorithms for the approximate nearest neighbor problem in high-dimensional spaces. For data sets of size n living in R d , the algorithms require space that is only polynomial in n and d, while achieving query times that are sub-linear in n and polynomial in d. We also show applications to other high-dimensional geometric problems, such as the approximate minimum spanning tree. The article is based on the material from the authors' STOC'98 and FOCS'01 papers. It unifies, generalizes and simplifies the results from those papers.", "authors": ["Piotr Indyk", "Rajeev Motwani"], "related_topics": ["116738811", "161986146", "98501338"], "citation_count": "5030", "reference_count": "66", "references": ["2752885492", "2147152072", "1634005169", "2295428206", "1956559956", "2160066518", "1502916507", "3017143921", "2427881153", "2152565070"], "date": "1998"}, {"id": "2100960835", "title": "Fairness through awareness", "abstract": "We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of \"fair affirmative action,\" which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.", "authors": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard Zemel"], "related_topics": ["2908647359", "23130292", "2777732099"], "citation_count": "1465", "reference_count": "16", "references": ["2517104773", "2911978475", "1993116423", "1966340639", "1599656298", "2141902405", "2061130579", "1978593916", "2085427378", "1992678640"], "date": "2012"}, {"id": "2004421506", "title": "Nonuniform Sampling and Reconstruction in Shift-Invariant Spaces", "abstract": "This article discusses modern techniques for nonuniform sampling and reconstruction of functions in shift-invariant spaces. It is a survey as well as a research paper and provides a unified framework for uniform and nonuniform sampling and reconstruction in shift-invariant subspaces by bringing together wavelet theory, frame theory, reproducing kernel Hilbert spaces, approximation theory, amalgam spaces, and sampling. Inspired by applications taken from communication, astronomy, and medicine, the following aspects will be emphasized: (a) The sampling problem is well defined within the setting of shift-invariant spaces. (b) The general theory works in arbitrary dimension and for a broad class of generators. (c) The reconstruction of a function from any sufficiently dense nonuniform sampling set is obtained by efficient iterative algorithms. These algorithms converge geometrically and are robust in the presence of noise. (d) To model the natural decay conditions of real signals and images, the sampling theory is developed in weighted L p-spaces.", "authors": ["Akram Aldroubi", "Karlheinz Gr\u00f6chenig"], "related_topics": ["20326153", "90842384", "80884492"], "citation_count": "827", "reference_count": "91", "references": ["2062024414", "2132984323", "1658679052", "1980149518", "2166087152", "3132971798", "2041752335", "1606846851", "2126777570", "1552869711"], "date": "2001"}, {"id": "2143753158", "title": "Wide baseline stereo matching", "abstract": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically. This facilitates matching between quite disparate views-wide baseline stereo. Two extensions are made to the current small baseline algorithms: first, and most importantly, a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhoods over image pairs; second, algorithms are given for generating putative corner matches between image pairs using local homographies. Two novel infrastructure developments are also described: the automatic generation of local homographies, and the combination of possibly conflicting sets of matches prior to RANSAC estimation. The wide baseline matching algorithm is demonstrated on a number of image pairs with varying relative motion, and for different scene types. All processing is automatic.", "authors": ["P. Pritchett", "A. Zisserman"], "related_topics": ["23379248", "147946207", "185078393"], "citation_count": "438", "reference_count": "18", "references": ["2111308925", "2085261163", "2011891945", "2978983090", "1549739843", "1528423721", "2170026011", "2200154090", "2074163268", "1848858524"], "date": "1998"}, {"id": "2124351082", "title": "Training support vector machines: an application to face detection", "abstract": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points.", "authors": ["E. Osuna", "R. Freund", "F. Girosit"], "related_topics": ["10719679", "145828037", "12267149"], "citation_count": "3894", "reference_count": "13", "references": ["2156909104", "2119821739", "2087347434", "2159686933", "26816478", "2159173611", "2137346077", "2084844503", "2056695679", "2125713050"], "date": "1997"}, {"id": "2963516811", "title": "Training Region-Based Object Detectors with Online Hard Example Mining", "abstract": "The field of object detection has made significant advances riding on the wave of region-based ConvNets, but their training procedure still includes many heuristics and hyperparameters that are costly to tune. We present a simple yet surprisingly effective online hard example mining (OHEM) algorithm for training region-based ConvNet detectors. Our motivation is the same as it has always been \u2013 detection datasets contain an overwhelming number of easy examples and a small number of hard examples. Automatic selection of these hard examples can make training more effective and efficient. OHEM is a simple and intuitive algorithm that eliminates several heuristics and hyperparameters in common use. But more importantly, it yields consistent and significant boosts in detection performance on benchmarks like PASCAL VOC 2007 and 2012. Its effectiveness increases as datasets become larger and more difficult, as demonstrated by the results on the MS COCO dataset. Moreover, combined with complementary advances in the field, OHEM leads to state-of-the-art results of 78.9% and 76.3% mAP on PASCAL VOC 2007 and 2012 respectively.", "authors": ["Abhinav Shrivastava", "Abhinav Gupta", "Ross Girshick"], "related_topics": ["127705205", "2776151529", "94176051"], "citation_count": "1362", "reference_count": "34", "references": ["2618530766", "2962835968", "639708223", "2102605133", "2108598243", "2161969291", "2155893237", "1536680647", "2168356304", "2963542991"], "date": "2016"}, {"id": "1512387364", "title": "Toward an architecture for never-ending language learning", "abstract": "We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.", "authors": ["Andrew Carlson", "Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R. Hruschka", "Tom M. Mitchell"], "related_topics": ["4554734", "5894958", "195807954"], "citation_count": "1965", "reference_count": "27", "references": ["2903158431", "2048679005", "2136518234", "2914746235", "2101210369", "2068737686", "2785349534", "2132655161", "197270748", "2140243223"], "date": "2010"}, {"id": "2047425471", "title": "Ethics and accountability: from the for-itself to the for-the-other", "abstract": "Abstract Expanding global markets have resulted in renewed concern with accountability by transnational corporations and other economic agents. Reflections on economic accountability, however, often inadequately theorize necessary ethical presuppositions regarding the moral status of economic collectivities, including the scope of the moral community and the good that this community seeks. This essay addresses these ethical considerations. Taking as my starting point Schweiker's [Schweiker, W. (1993). Accounting for ourselves: accounting practice and the disclosure of ethics. Accounting Organizations and Society, 18(2/3), 231\u2013252] claim that economic entities are properly accountable to a wider scope of good than their own by virtue of the accounts that accountants render of such entities, I argue that the discourse in terms of which the accounts are rendered serves to negate the very relation of obligation from which this accountability derives. Specifically, I argue that the discourse of neoclassical economics that informs accounting practice constructs the identity of the accountable entity such that it is obligated to pursue only its own good. Consequently, extant accounting practices are inadequate to meet the demands for accountability that are legitimately entailed by the act of rendering an account. I explore the implications of this conclusion for understanding economic accountability and related social accounting practices, and I propose the ethics of Emmanuel Levinas to establish a broader accountability on the part of economic entities.", "authors": ["Teri Shearer"], "related_topics": ["150577722", "126415523", "2776007630"], "citation_count": "492", "reference_count": "83", "references": ["2177756622", "2038600245", "2052417512", "2070415764", "1536292473", "2080132762", "1520386898", "1490952496", "1999696232", "1622336883"], "date": "2002"}, {"id": "1514711945", "title": "Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex", "abstract": "The development of stimulus selectivity in the primary sensory cortex of higher vertebrates is considered in a general mathematical framework. A synaptic evolution scheme of a new kind is proposed in which incoming patterns rather than converging afferents complete. The change in the efficacy of a given synapse depends not only on instantaneous pre- and postsynaptic activities but also on a slowly varying time-averaged value of the postsynaptic activity. Assuming an appropriate nonlinear form this dependence, development of selectivity is obtained under quite general conditions on the sensory environment. One does not require nonlinearity of the neuron's integrative power nor does one need to assume any particular form for intracortical circuitry. This is first illustrated in simple cases, e.g., when the environment consists of only two different stimuli presented alternately in a random manner. The following formal statement then holds: the state of the system converges with probability 1 to points of maximum selectivity in the state space. We next consider the problem of early development of orientation selectivity and binocular interaction in primary visual cortex. Giving the environment an appropriate form, we obtain orientation tuning curves and ocular dominance comparable to what is observed in normally reared adult cats or monkeys. Simulations with binocular input and various types of normal or altered environments show good agreement with the relevant experimental data. Experiments are suggested that could test our theory further.", "authors": ["Elie L. Bienenstock", "Leon N. Cooper", "Paul W. Munro"], "related_topics": ["2779345533", "94487597", "147004232"], "citation_count": "3233", "reference_count": "26", "references": ["2887242076", "2116360511", "1539686131", "2155051950", "2090736342", "1870538900", "2257028141", "2019203033", "2039030743", "1757333299"], "date": "1987"}, {"id": "1664011265", "title": "AntNet: distributed stigmergetic control for communications networks", "abstract": "This paper introduces AntNet, a novel approach to the adaptive learning of routing tables in communications networks. AntNet is a distributed, mobile agents based Monte Carlo system that was inspired by recent work on the ant colony metaphor for solving optimization problems. AntNet's agents concurrently explore the network and exchange collected information. The communication among the agents is indirect and asynchronous, mediated by the network itself. This form of communication is typical of social insects and is called stigmergy. We compare our algorithm with six state-of-the-art routing algorithms coming from the telecommunications and machine learning fields. The algorithms' performance is evaluated over a set of realistic testbeds. We run many experiments over real and artificial IP datagram networks with increasing number of nodes and under several paradigmatic spatial and temporal traffic distributions. Results are very encouraging. AntNet showed superior performance under all the experimental conditions with respect to its competitors. We analyze the main characteristics of the algorithm and try to explain the reasons for its superiority.", "authors": ["Gianni Di Caro", "Marco Dorigo"], "related_topics": ["2776319702", "184896649", "151319957"], "citation_count": "2276", "reference_count": "48", "references": ["2107941094", "2154929945", "2098432798", "2107726111", "1576452626", "2297395784", "2112495447", "1492640216", "2078500988", "1583833196"], "date": "1998"}, {"id": "2153663612", "title": "Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries", "abstract": "We address the image denoising problem, where zero-mean white and homogeneous Gaussian additive noise is to be removed from a given image. The approach taken is based on sparse and redundant representations over trained dictionaries. Using the K-SVD algorithm, we obtain a dictionary that describes the image content effectively. Two training options are considered: using the corrupted image itself, or training on a corpus of high-quality image database. Since the K-SVD is limited in handling small image patches, we extend its deployment to arbitrary image sizes by defining a global image prior that forces sparsity over patches in every location in the image. We show how such Bayesian treatment leads to a simple and effective denoising algorithm. This leads to a state-of-the-art denoising performance, equivalent and sometimes surpassing recently published leading alternative denoising methods", "authors": ["M. Elad", "M. Aharon"], "related_topics": ["101453961", "30814859", "126422989"], "citation_count": "5601", "reference_count": "41", "references": ["2160547390", "2078204800", "2146842127", "2158940042", "2151693816", "2097323375", "2113945798", "2132680427", "2079724595", "2131686571"], "date": "2006"}, {"id": "2752849906", "title": "Deep learning with coherent nanophotonic circuits", "abstract": "Artificial Neural Networks have dramatically improved performance for many machine learning tasks. We demonstrate a new architecture for a fully optical neural network that enables a computational speed enhancement of at least two orders of magnitude and three orders of magnitude in power efficiency over state-of-the-art electronics.", "authors": ["Yichen Shen", "Nicholas C. Harris", "Scott Skirlo", "Dirk Englund", "Marin Soljacic"], "related_topics": ["2780262575", "2780596773", "50644808"], "citation_count": "1145", "reference_count": "48", "references": ["2618530766", "2919115771", "2145339207", "2155893237", "2257979135", "2100495367", "2076063813", "2289252105", "2518281301", "1978426240"], "date": "2017"}, {"id": "2162630660", "title": "Automating the Construction of Internet Portals with Machine Learning", "abstract": "Domain-specific internet portals are growing in popularity because they gather content from the Web and organize it for easy access, retrieval and search. For example, www.campsearch.com allows complex queries by age, location, cost and specialty over summer camps. This functionality is not possible with general, Web-wide search engines. Unfortunately these portals are difficult and time-consuming to maintain. This paper advocates the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific Internet portals. We describe new research in reinforcement learning, information extraction and text classification that enables efficient spidering, the identification of informative text segments, and the population of topic hierarchies. Using these techniques, we have built a demonstration system: a portal for computer science research papers. It already contains over 50,000 papers and is publicly available at www.cora.justresearch.com. These techniques are widely applicable to portal creation in other domains.", "authors": ["Andrew Kachites McCallum", "Kamal Nigam", "Jason Rennie", "Kristie Seymore"], "related_topics": ["110875604", "13743948", "2908647359"], "citation_count": "879", "reference_count": "44", "references": ["2138621811", "2125838338", "2049633694", "2048679005", "2097089247", "2107726111", "1550206324", "1489992655", "2158195707", "2100677568"], "date": "2000"}, {"id": "1970481396", "title": "Person and Number in Pronouns: A Feature-Geometric Analysis", "abstract": "The set of person and number features necessary to characterize the pronominal paradigms of the world's languages is highly constrained, and their interaction is demonstrably systematic. We develop a geometric representation of morphosyntactic features which provides a principled explanation for the observed restrictions on these paradigms. The organization of this geometry represents the grammaticalization of fundamental cognitive categories, such as reference, plurality, and taxonomy. We motivate the geometry through the analysis of pronoun paradigms in a broad range of genetically distinct languages.", "authors": ["Heidi Harley", "Elizabeth Ritter"], "related_topics": ["2776036464", "2778551981", "135756266"], "citation_count": "1116", "reference_count": "65", "references": ["2159035740", "1488363850", "1543984587", "1972573551", "2056573988", "2086426947", "2062707514", "2152134037", "1994381201", "173533992"], "date": "2002"}, {"id": "166263196", "title": "Collection Selection via Lexicon Inspection", "abstract": "", "authors": ["Justin Zobel"], "related_topics": ["2778121359", "23123220", "41008148"], "citation_count": "24", "reference_count": "0", "references": ["1660390307", "1483313504", "2340309946", "255396808", "2038526807", "2020795663", "2132285835", "2023624732", "2104588805", "2154627749"], "date": "1996"}, {"id": "2061130579", "title": "Approximation algorithms for classification problems with pairwise relationships: metric labeling and Markov random fields", "abstract": "In a traditional classification problem, we wish to assign one of k labels (or classes) to each of n objects, in a way that is consistent with some observed data that we have about the problem. An active line of research in this area is concerned with classification when one has information about pairwise relationships among the objects to be classified; this issue is one of the principal motivations for the framework of Markov random fields, and it arises in areas such as image processing, biometry, and document analysis. In its most basic form, this style of analysis seeks to find a classification that optimizes a combinatorial function consisting of assignment costs---based on the individual choice of label we make for each object---and separation costs---based on the pair of choices we make for two \"related\" objects.We formulate a general classification problem of this type, the metric labeling problem; we show that it contains as special cases a number of standard classification frameworks, including several arising from the theory of Markov random fields. From the perspective of combinatorial optimization, our problem can be viewed as a substantial generalization of the multiway cut problem, and equivalent to a type of uncapacitated quadratic assignment problem.We provide the first nontrivial polynomial-time approximation algorithms for a general family of classification problems of this type. Our main result is an O(log k log log k)-approximation algorithm for the metric labeling problem, with respect to an arbitrary metric on a set of k labels, and an arbitrary weighted graph of relationships on a set of objects. For the special case in which the labels are endowed with the uniform metric---all distances are the same---our methods provide a 2-approximation algorithm.", "authors": ["Jon Kleinberg", "\u00c9va Tardos"], "related_topics": ["35639132", "194146004", "17387949"], "citation_count": "702", "reference_count": "29", "references": ["2143516773", "1594031697", "1997063559", "2076008912", "1554544485", "1649464328", "2096139825", "1507028917", "1496929357", "79315950"], "date": "2002"}, {"id": "2051200211", "title": "A compact static double-array keeping character codes", "abstract": "A trie represented by a double-array enables us to search a key fast with a small space. However, the double-array uses extra space to be updated dynamically. This paper presents a compact structure for a static double-array. The new structure keeps character codes instead of indices in order to compress elements of the double-array. In addition, the new structure unifies common suffixes and consists of less elements than the old structure. Experimental results for English keys show that the new structure reduces space usage of the double-array up to 40%.", "authors": ["Susumu Yata", "Masaki Oono", "Kazuhiro Morita", "Masao Fuketa", "Toru Sumitomo", "Jun-ichi Aoe"], "related_topics": ["190290938", "163797641", "32717103"], "citation_count": "21", "reference_count": "18", "references": ["1491178396", "2753176400", "2099964107", "2100648544", "2088955004", "2006174344", "2098258619", "2018341643", "2140177165", "2337480916"], "date": "2006"}, {"id": "1584739173", "title": "Random indexing of text samples for latent semantic analysis", "abstract": "Random Indexing of Text Samples for Latent Semantic Analysis Pentti Kanerva Jan Kristoferson Anders Holst kanerva@sics.se, janke@sics.se, aho@sics.se RWCP Theoretical Foundation SICS Laboratory Swedish Institute of Computer Science, Box 1263, SE-16429 Kista, Sweden Latent Semantic Analysis is a method of computing vectors|and it has several randomly placed ; 1s and high-dimensional semantic vectors, or context vectors, 1s, with the rest 0s (e.g., four each of ; 1 and 1, or for words from their co-occurrence statistics. An exper- eight non-0s in 1,800, instead of one non-0 in 30,000 iment by Landauer & Dumais (1997) covers a vocabu- as above). Thus, we would accumulate the same data lary of 60,000 words (unique letter strings delimited by into a 60,000 1,800 words-by-contexts matrix instead word-space characters) in 30,000 contexts (text samples of 60,000 30,000. or \\documents of about 150 words each). The data are Our method has been veried with dierent data, a rst collected into a 60,000 30,000 words-by-contexts ten-million-word \\TASA corpus consisting of a 79,000- co-occurrence matrix, with each row representing a word word vocabulary (when words are truncated after the 8th and each column representing a text sample so that each character) in 37,600 text samples. The data were accu- entry gives the frequency of a given word in a given mulated into a 79,000 1,800 words-by-contexts matrix, text sample. The frequencies are normalized, and the which was normalized by thresholding into a matrix of normalized matrix is transformed with Singular-Value ; 1s, 0s, and 1s. The unnormalized 1,800-dimensional Decomposition (SVD) reducing its original 30,000 doc- context vectors gave 35{44% correct in the TOEFL test ument dimensions into a much smaller number of latent and the normalized ones gave 48{51% correct, which cor- dimensions, 300 proving to be optimal. Thus words are respond to Landauer & Dumais' 36% for their normal- represented by 300-dimensional semantic vectors. ized 30,000-dimensional vectors before SVD, for a dier- The point in all of this is that the vectors capture ent corpus (see above). Our words-by-contexts matrix meaning. Landauer and Dumais demonstrate it with a can be transformed further, for example with SVD as in synonym test called TOEFL (for \\Test Of English as a LSA, except that the matrix is much smaller. Mathematically, the 30,000- or 37,600-dimensional in- Foreign Language ). For each test word, four alterna- dex vectors are orthogonal, whereas the 1,800-dimen- tives are given, and the \\contestant is asked to nd the one that's the most synonymous. Choosing at random sional ones are only nearly orthogonal. They seem to would yield 25% correct. However, when the seman- work just as well, in addition to which they are more tic vector for the test word is compared to the seman- \\brainlike and less aected by the number of text sam- tic vectors for the four alternatives, it correlates most ples (1,800-dimensional index vectors can cover a wide- highly with the correct alternative in 64% of the cases. ranging number of text samples). We have used such However, when the same test is based on the 30,000- vectors also to index words in narrow context windows, dimensional vectors before SVD, the result is not nearly getting 62{70% correct, and conclude that random in- as good: only 36% correct. The authors conclude that dexing deserves to be studied and understood more fully. Acknowledgments. This research is supported by the reorganization of information by SVD somehow cor- Japan's Ministry of International Trade and Industry responds to human psychology. under the Real World Computing Partnership We have studied high-dimensional random distributed (MITI) (RWCP) The TASA corpus and 80 TOEFL representations, as models of brainlike representation of test items program. were made available to us by courtesy of Pro- information (Kanerva, 1994; Kanerva & Sj\u007fodin, 1999). fessor Thomas Landauer, University of Colorado. In this poster we report on the use of such a repre- sentation to reduce the dimensionality of the original words-by-contexts matrix. The method can be explained Kanerva, P. (1994). References The Spatter Code for encoding by looking at the 60,000 30,000 matrix of frequencies concepts at many levels. In M. Marinaro and P. G. above. Assume that each text sample is represented by a Morasso (eds.), ICANN '94, Proc. Int'l Conference 30,000-bit vector with a single 1 marking the place of the on Articial Neural Networks (Sorrento, Italy), vol. 1, sample in a list of all samples, and call it the sample's pp. 226{229. London: Springer-Verlag. index vector (i.e., the n th bit of the index vector for the Kanerva, P., and Sj\u007fodin, G. (1999). Stochastic Pattern n th text sample is 1|the representation is unitary or lo- Computing. Proc. 2000 Real World Computing Sym- cal). Then the words-by-contexts matrix of frequencies bosium (Report TR-99-002, pp. 271{276). Tsukuba- can be gotten by the following procedure: every time city, Japan: Real World Computing Partnership. that the word w occurs in the n th text sample, the n th index vector is added to the row for the word w . Landauer, T. K., and Dumais, S. T. (1997). A solution We use the same procedure for accumulating a words- to Plato's problem: The Latent Semantic Analysis by-contexts matrix, except that the index vectors are theory of the acquisition, induction, and representa- not unitary. A text-sample's index vector is \\small tion of knowledge. Psychological Review 104 (2):211{ by comparison|we have used 1,800-dimensional index", "authors": ["Pentti Kanerva", "Jan Kristoferson", "Anders Holst"], "related_topics": ["170133592", "2780291827", "22789450"], "citation_count": "545", "reference_count": "0", "references": ["1984052055", "2137607259", "2070862086", "2527896214", "1836521361", "188912188", "2554538030", "2807650837", "2083680351", "2476008461"], "date": "1999"}, {"id": "2963756346", "title": "Learned in translation: contextualized word vectors", "abstract": "Computer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art.", "authors": ["Bryan McCann", "James Bradbury", "Caiming Xiong", "Richard Socher"], "related_topics": ["203005215", "66402592", "2780049985"], "citation_count": "655", "reference_count": "64", "references": ["2194775991", "2618530766", "2962835968", "1836465849", "2102605133", "2964308564", "1614298861", "2250539671", "2108598243", "2130942839"], "date": "2017"}, {"id": "1505477995", "title": "The ALARM Monitoring System: A Case Study with two Probabilistic Inference Techniques for Belief Networks", "abstract": "ALARM (A Logical Alarm Reduction Mechanism) is a diagnostic application used to explore probabilistic reasoning techniques in belief networks. ALARM implements an alarm message system for patient monitoring; it calculates probabilities for a differential diagnosis based on available evidence. The medical knowledge is encoded in a graphical structure connecting 8 diagnoses, 16 findings and 13 intermediate variables. Two algorithms were applied to this belief network: (1) a message-passing algorithm by Pearl for probability updating in multiply connected networks using the method of conditioning; and (2) the Lauritzen-Spiegelhalter algorithm for local probability computations on graphical structures. The characteristics of both algorithms are analyzed and their specific applications and time complexities are shown.", "authors": ["Ingo A. Beinlich", "Henri Jacques Suermondt", "R. Martin Chavez", "Gregory F. Cooper"], "related_topics": ["33724603", "49937458", "18998212"], "citation_count": "1063", "reference_count": "14", "references": ["1593793857", "2143075689", "2113677269", "1978304080", "1991477862", "1574396325", "1580038098", "181660137", "2087284486", "2070013518"], "date": "1988"}, {"id": "2116485279", "title": "Spectral efficiency in the wideband regime", "abstract": "The tradeoff of spectral efficiency (b/s/Hz) versus energy-per-information bit is the key measure of channel capacity in the wideband power-limited regime. This paper finds the fundamental bandwidth-power tradeoff of a general class of channels in the wideband regime characterized by low, but nonzero, spectral efficiency and energy per bit close to the minimum value required for reliable communication. A new criterion for optimality of signaling in the wideband regime is proposed, which, in contrast to the traditional criterion, is meaningful for finite-bandwidth communication.", "authors": ["S. Verdu"], "related_topics": ["2780202535", "137246740", "74211669"], "citation_count": "1386", "reference_count": "36", "references": ["2099111195", "2133475491", "2912369344", "2120302973", "2098257210", "598996319", "2133214726", "2115543075", "2136979582", "2169693117"], "date": "2002"}, {"id": "1984194948", "title": "Quantitative performance analysis of object detection algorithms on underwater video footage", "abstract": "Object detection in underwater unconstrained environments is useful in domains like marine biology and geology, where the scientists need to study fish populations, underwater geological events etc. However, in literature, very little can be found regarding fish detection in unconstrained underwater videos. Nevertheless, the unconstrained underwater video domain constitutes a perfect soil for bringing state-of-the-art object detection algorithms to their limits because of the nature of the scenes, which often present with a number of intrinsic difficulties (e.g. multi-modal backgrounds, complex textures and color patterns, ever-changing illumination etc..).In this paper, we evaluated the performance of six state-of-the-art object detection algorithms in the task of fish detection in unconstrained, underwater video footage, discussing the properties of each of them and giving a detailed report of the achieved performance.", "authors": ["Isaak Kavasidis", "Simone Palazzo"], "related_topics": ["2776151529", "71681937", "98083399"], "citation_count": "13", "reference_count": "15", "references": ["3124955340", "2102625004", "2127070222", "2008393432", "2003709967", "2097512404", "1990054309", "1536214225", "2135737723", "2101849132"], "date": "2012"}, {"id": "1560147776", "title": "Context-Aware Recommender Systems", "abstract": "Context-aware recommender systems (CARS) generate more relevant recommendations by adapting them to the specific contextual situation of the user. This article explores how contextual information can be used to create more intelligent and useful recommender systems. It provides an overview of the multifaceted notion of context, discusses several approaches for incorporating contextual information in recommendation process, and illustrates the usage of such approaches in several application areas where different types of contexts are exploited. The article concludes by discussing the challenges and future research directions for context-aware recommender systems.", "authors": ["Gediminas Adomavicius", "Bamshad Mobasher", "Francesco Ricci", "Alexander Tuzhilin"], "related_topics": ["557471498", "2780049985", "4279774"], "citation_count": "2631", "reference_count": "67", "references": ["2171960770", "2042281163", "1971040550", "2110325612", "1994389483", "2163419627", "281665770", "2017231306", "2072764742", "2112430581"], "date": "2011"}, {"id": "1993325457", "title": "The adaptive decision maker", "abstract": "Preface 1. Adaptive decision behaviour: an introduction 2. Contingencies in decision making 3. Deciding how to decide: an effort/accuracy framework 4. Studying contingent decisions: an integrated methodology 5. Constructive processes in decision making 6. Why may adaptivity fail? 7. Improving decisions and other practical matters 8. The adaptive decision maker: a look backward and a look forward Appendix Footnotes Bibliography.", "authors": ["John W. Payne", "James R. Bettman", "Eric J. Johnson"], "related_topics": ["186116695", "135115379", "97944126"], "citation_count": "6352", "reference_count": "0", "references": ["1501241011", "2110638361", "2089457241", "2099201756", "2166982098", "2096016260", "2070203783", "2115281393", "2105938655", "2126311339"], "date": "1992"}, {"id": "2088386938", "title": "Compressed full-text indexes", "abstract": "Full-text indexes provide fast substring search over large text collections. A serious problem of these indexes has traditionally been their space consumption. A recent trend is to develop indexes that exploit the compressibility of the text, so that their size is a function of the compressed text length. This concept has evolved into self-indexes, which in addition contain enough information to reproduce any text portion, so they replace the text. The exciting possibility of an index that takes space close to that of the compressed text, replaces it, and in addition provides fast search over it, has triggered a wealth of activity and produced surprising results in a very short time, which radically changed the status of this area in less than 5 years. The most successful indexes nowadays are able to obtain almost optimal space and search time simultaneously.In this article we present the main concepts underlying (compressed) self-indexes. We explain the relationship between text entropy and regularities that show up in index structures and permit compressing them. Then we cover the most relevant self-indexes, focusing on how they exploit text compressibility to achieve compact structures that can efficiently solve various search problems. Our aim is to give the background to understand and follow the developments in this area.", "authors": ["Gonzalo Navarro", "Veli M\u00e4kinen"], "related_topics": ["2778753280", "75165309", "46604812"], "citation_count": "819", "reference_count": "129", "references": ["2099111195", "1660390307", "1990061958", "2149906774", "2158322625", "1997841190", "2161488606", "3022618749", "938539187", "100509257"], "date": "2007"}, {"id": "2051812123", "title": "Original Contribution: A scaled conjugate gradient algorithm for fast supervised learning", "abstract": "A supervised learning algorithm (Scaled Conjugate Gradient, SCG) is introduced. The performance of SCG is benchmarked against that of the standard back propagation algorithm (BP) (Rumelhart, Hinton, & Williams, 1986), the conjugate gradient algorithm with line search (CGL) (Johansson, Dowla, & Goodman, 1990) and the one-step Broyden-Fletcher-Goldfarb-Shanno memoriless quasi-Newton algorithm (BFGS) (Battiti, 1990). SCG is fully-automated, includes no critical user-dependent parameters, and avoids a time consuming line search, which CGL and BFGS use in each iteration in order to determine an appropriate step size. Experiments show that SCG is considerably faster than BP, CGL, and BFGS.", "authors": ["Martin Fodslette M\u00f8ller"], "related_topics": ["81184566", "132721684", "85522705"], "citation_count": "5211", "reference_count": "19", "references": ["2154642048", "2077658674", "2266946488", "2954064014", "2176028050", "169539560", "2033245860", "2160699933", "2043382734", "155854392"], "date": "1993"}, {"id": "133977063", "title": "LINPACK Users' Guide", "abstract": "General matrices Band matrices Positive definite matrices Positive definite band matrices Symmetric Indefinite Matrices Triangular matrices Tridiagonal matrices The Cholesky decomposition The QR decomposition Updating QR and Cholesky decompositions The singular value decomposition References Basic linear algebra subprograms Timing data Program listings BLA Listings.", "authors": ["J. J. Dongarra", "C. B. Moler", "J. R. Bunch", "G. W. Stewart"], "related_topics": ["34727166", "22789450", "188060507"], "citation_count": "3476", "reference_count": "0", "references": ["1969761972", "2102201073", "1686420892", "3105558219", "2022916138", "2002257715", "2090351291", "1966285605", "2006523031", "2006544565"], "date": "1986"}, {"id": "2161304134", "title": "User-defined gestures for surface computing", "abstract": "Many surface computing prototypes have employed gestures created by system designers. Although such gestures are appropriate for early investigations, they are not necessarily reflective of user behavior. We present an approach to designing tabletop gestures that relies on eliciting gestures from non-technical users by first portraying the effect of a gesture, and then asking users to perform its cause. In all, 1080 gestures from 20 participants were logged, analyzed, and paired with think-aloud data for 27 commands performed with 1 and 2 hands. Our findings indicate that users rarely care about the number of fingers they employ, that one hand is preferred to two, that desktop idioms strongly influence users' mental models, and that some commands elicit little gestural agreement, suggesting the need for on-screen widgets. We also present a complete user-defined gesture set, quantitative agreement scores, implications for surface technology, and a taxonomy of surface gestures. Our results will help designers create better gesture sets informed by user behavior.", "authors": ["Jacob O. Wobbrock", "Meredith Ringel Morris", "Andrew D. Wilson"], "related_topics": ["159437735", "207347870", "206539335"], "citation_count": "1301", "reference_count": "35", "references": ["1490482062", "2158707444", "2005198142", "2118163921", "1968211101", "2148819007", "1965447681", "1491504725", "2140190783", "2150792958"], "date": "2009"}, {"id": "1893741530", "title": "Haptic interface for laptop computers and other portable devices", "abstract": "A haptic feedback touch control used to provide input to a computer. A touch input device includes a planar touch surface that provides position information to a computer based on a location of user contact. The computer can position a cursor in a displayed graphical environment based at least in part on the position information, or perform a different function. At least one actuator is also coupled to the touch input device and outputs a force to provide a haptic sensation to the user. The actuator can move the touchpad laterally, or a separate surface member can be actuated. A flat E-core actuator, piezoelectric actuator, or other types of actuators can be used to provide forces. The touch input device can include multiple different regions to control different computer functions.", "authors": ["Erik J. Shahoian", "Bruce M. Schena", "Louis B. Rosenberg"], "related_topics": ["152086174", "121449826", "43199551"], "citation_count": "690", "reference_count": "196", "references": ["2107118797", "2128423220", "1973922175", "2855313633", "3141452745", "2159277521", "2409956777", "2165394321", "1933398918", "2137661177"], "date": "2002"}, {"id": "2027808858", "title": "Asymptotic analysis of a random walk on a hypercube with many dimensions", "abstract": "In nearest neighbor random walk on an n-dimensional cube a particle moves to one of its nearest neighbors (or stays fixed) with equal probability. the particle starts at 0. How long does it take to reach its stationary distribution? in fact, this occurs surprisingly rapidly. Previous analysis has shown that the total variation distance to stationarity is large if the number of steps N is 1/4n log n. This paper derives an explicit expression for the variation distance as n \u2192 \u221e in the transition region N \u02dc 1/4n log n. This permits the first careful evaluation of a cutoff phenomenon observed in a wide variety of Markov chains. the argument involves Fourier analysis to express the probability as a contour integral and saddle point approximation. the asymptotic results are in good agreement with numerical results for n as small as 100.", "authors": ["Persi Diaconis", "Ronald L. Graham", "John A. Morrison"], "related_topics": ["121194460", "205147927", "98951983"], "citation_count": "215", "reference_count": "10", "references": ["2120062331", "2751862591", "1556192255", "2074599161", "2138412601", "2083120484", "2018344665", "1983403768", "2001759372", "2023642785"], "date": "1990"}, {"id": "2914705496", "title": "User interface", "abstract": "A user interface is that portion of an interactive computer system that communicates with the user. Design of the user interface includes any aspect of the system that is visible to the user. Once, all computer users were specialists in computing, and interfaces consisted of jumper wires in patch boards, punched cards (q.v.) prepared offline, and batch printouts. Today a wide range of nonspecialists use computers, and keyboards, mice, and graphical displays are the most common interface hardware. The user interface is becoming a larger and larger portion of the software in a computer system--and a more important portion, as broader groups of people use computers. As computers become more powerful, the critical bottleneck in applying computer-based systems to solve problems is more often in the user interface rather than in the computer hardware or software.", "authors": ["Robert J. K. Jacob"], "related_topics": ["89505385", "108265739", "2777904410"], "citation_count": "3859", "reference_count": "10", "references": ["2099305423", "93247917", "2115647291", "2143292990", "1966971297", "2045328215", "1693620685", "2046345502", "1567920151", "1486372599"], "date": "2001"}, {"id": "2008620264", "title": "Emergence of Scaling in Random Networks", "abstract": "Systems as diverse as genetic networks or the World Wide Web are best described as networks with complex topology. A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. This feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. A model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.", "authors": ["Albert L\u00e1szl\u00f3 Barab\u00e1si", "R\u00e9ka Albert"], "related_topics": ["36647736", "34947359", "60723933"], "citation_count": "40132", "reference_count": "16", "references": ["2112090702", "2769133055", "2905110430", "2107252390", "3125161049", "1971788485", "1643412971", "2121821841", "2062021443", "2147164982"], "date": "1999"}, {"id": "2123987305", "title": "Semantics And Cognition", "abstract": "This book emphasizes the role of semantics as a bridge between the theory of language and the theories of other cognitive capacities such as visual perception and motor control. It develops the position that the study of semantics of natural language is the study of the structure of thought, and that grammatical structure offers a much more important source of evidence for the theory of cognition than is often supposed by linguists, philosophers, psychologists, or computer scientists. Semantics and Cognition is included in the series, Current Studies in Linguistics.", "authors": ["Ray S. Jackendoff"], "related_topics": ["66332616", "146499914", "200065993"], "citation_count": "7553", "reference_count": "0", "references": ["1562911371", "2102381086", "1572948005", "1503247412", "2236233024", "1980510330", "2128092632", "2045929671", "2067551521", "2143801939"], "date": "1984"}, {"id": "2109826612", "title": "Class prediction for high-dimensional class-imbalanced data", "abstract": "The goal of class prediction studies is to develop rules to accurately predict the class membership of new samples. The rules are derived using the values of the variables available for each subject: the main characteristic of high-dimensional data is that the number of variables greatly exceeds the number of samples. Frequently the classifiers are developed using class-imbalanced data, i.e., data sets where the number of samples in each class is not equal. Standard classification methods used on class-imbalanced data often produce classifiers that do not accurately predict the minority class; the prediction is biased towards the majority class. In this paper we investigate if the high-dimensionality poses additional challenges when dealing with class-imbalanced prediction. We evaluate the performance of six types of classifiers on class-imbalanced data, using simulated data and a publicly available data set from a breast cancer gene-expression microarray study. We also investigate the effectiveness of some strategies that are available to overcome the effect of class imbalance. Our results show that the evaluated classifiers are highly sensitive to class imbalance and that variable selection introduces an additional bias towards classification into the majority class. Most new samples are assigned to the majority class from the training set, unless the difference between the classes is very large. As a consequence, the class-specific predictive accuracies differ considerably. When the class imbalance is not too severe, down-sizing and asymmetric bagging embedding variable selection work well, while over-sampling does not. Variable normalization can further worsen the performance of the classifiers. Our results show that matching the prevalence of the classes in training and test set does not guarantee good performance of classifiers and that the problems related to classification with class-imbalanced data are exacerbated when dealing with high-dimensional data. Researchers using class-imbalanced data should be careful in assessing the predictive accuracy of the classifiers and, unless the class imbalance is mild, they should always use an appropriate method for dealing with the class imbalance problem.", "authors": ["Rok Blagus", "Lara Lusa"], "related_topics": ["169903167", "148483581", "58489278"], "citation_count": "208", "reference_count": "45", "references": ["2911964244", "1554944419", "1480376833", "2119821739", "3124955340", "2130979840", "2148143831", "2118978333", "2112076978", "2115709314"], "date": "2010"}, {"id": "2124608575", "title": "Exact matrix completion via convex optimization", "abstract": "Suppose that one observes an incomplete subset of entries selected from a low-rank matrix. When is it possible to complete the matrix and recover the entries that have not been seen? We demonstrate that in very general settings, one can perfectly recover all of the missing entries from most sufficiently large subsets by solving a convex programming problem that finds the matrix with the minimum nuclear norm agreeing with the observed entries. The techniques used in this analysis draw upon parallels in the field of compressed sensing, demonstrating that objects other than signals and images can be perfectly reconstructed from very limited information.", "authors": ["Emmanuel Cand\u00e8s", "Benjamin Recht"], "related_topics": ["2778459887", "157972887", "201829737"], "citation_count": "5148", "reference_count": "54", "references": ["2296616510", "2145096794", "2129638195", "2129131372", "2054141820", "2145962650", "1488435683", "2103972604", "1967073510", "2905110430"], "date": "2012"}, {"id": "2090208105", "title": "Eigenvalues of a real supersymmetric tensor", "abstract": "In this paper, we define the symmetric hyperdeterminant, eigenvalues and E-eigenvalues of a real supersymmetric tensor. We show that eigenvalues are roots of a one-dimensional polynomial, and when the order of the tensor is even, E-eigenvalues are roots of another one-dimensional polynomial. These two one-dimensional polynomials are associated with the symmetric hyperdeterminant. We call them the characteristic polynomial and the E-characteristic polynomial of that supersymmetric tensor. Real eigenvalues (E-eigenvalues) with real eigenvectors (E-eigenvectors) are called H-eigenvalues (Z-eigenvalues). When the order of the supersymmetric tensor is even, H-eigenvalues (Z-eigenvalues) exist and the supersymmetric tensor is positive definite if and only if all of its H-eigenvalues (Z-eigenvalues) are positive. An mth-order n-dimensional supersymmetric tensor where m is even has exactly n(m-1)^n^-^1 eigenvalues, and the number of its E-eigenvalues is strictly less than n(m-1)^n^-^1 when m>=4. We show that the product of all the eigenvalues is equal to the value of the symmetric hyperdeterminant, while the sum of all the eigenvalues is equal to the sum of the diagonal elements of that supersymmetric tensor, multiplied by (m-1)^n^-^1. The n(m-1)^n^-^1 eigenvalues are distributed in n disks in C. The centers and radii of these n disks are the diagonal elements, and the sums of the absolute values of the corresponding off-diagonal elements, of that supersymmetric tensor. On the other hand, E-eigenvalues are invariant under orthogonal transformations.", "authors": ["Liqun Qi"], "related_topics": ["20178491", "148125525", "2779501479"], "citation_count": "1097", "reference_count": "17", "references": ["1977415556", "1483218536", "217710249", "1599833186", "2090799283", "1602307574", "2070769763", "2154335661", "2044269663", "2115955567"], "date": "2005"}, {"id": "1971440513", "title": "The moderator\u2013mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations.", "abstract": "In this article, we attempt to distinguish between the properties of moderator and mediator variables at a number of levels. First, we seek to make theorists and researchers aware of the importance of not using the terms moderator and mediator interchangeably by carefully elaborating, both conceptually and strategically, the many ways in which moderators and mediators differ. We then go beyond this largely pedagogical function and delineate the conceptual and strategic implications of making use of such distinctions with regard to a wide range of phenomena, including control and stress, attitudes, and personality traits. We also provide a specific compendium of analytic procedures appropriate for making the most effective use of the moderator and mediator distinction, both separately and in terms of a broader causal system that includes both moderators and mediators.", "authors": ["Reuben M. Baron", "David A. Kenny"], "related_topics": ["93225998", "124936454", "24614281"], "citation_count": "104977", "reference_count": "39", "references": ["1491644571", "2159401492", "1989314580", "1976876708", "2004168348", "2024509488", "2133177370", "2019758655", "2051882866", "2056877099"], "date": "1986"}, {"id": "598996319", "title": "Digital Communication over Fading Channels: A Unified Approach to Performance Analysis", "abstract": "FUNDAMENTALS. Fading Channel Characterization and Modeling. Types of Communication. MATHEMATICAL TOOLS. Alternative Representations of Classical Functions. Useful Expressions for Evaluating Average Error Probability Performance. New Representations of Some PDF's and CDF's for Correlative Fading Applications. OPTIMUM RECEPTION AND PERFORMANCE EVALUATION. Optimum Receivers for Fading Channels. Performance of Single Channel Receivers. Performance of Multichannel Receivers. APPLICATION IN PRACTICAL COMMUNICATION SYSTEMS. Optimum Combining: A Diversity Technique for Communication Over Fading Channels in the Presence of Interference. Direct--Sequence Code--Division Multiple Access. FURTHER EXTENSIONS. Coded Communication Over Fading Channels. INDEX.", "authors": ["Marvin Kenneth Simon", "Mohamed-Slim Alouini"], "related_topics": ["161126049", "81978471", "148063708"], "citation_count": "3310", "reference_count": "0", "references": ["2116485279", "2148158411", "2158714612", "2110505033", "2155782306", "2096352778", "2168034909", "1556551509", "1514652980", "2126235070"], "date": "2000"}, {"id": "2047982742", "title": "Social stigma and self-esteem: The self-protective properties of stigma.", "abstract": "Although several psychological theories predict that members of stigmatized groups should have low global self-esteem, empirical research typically does not support this prediction. It is proposed here that this discrepancy may be explained by considering the ways in which membership in a stigmatized group may protect the self-concept It is proposed that members of stigmatized groups may (a) attribute negative feedback to prejudice against their group, (b) compare their outcomes with those of the ingroup, rather than with the relatively advantaged outgroup, and (c) selectively devalue those dimensions on which their group fares poorly and value those dimensions on which their group excels. Evidence for each of these processes and their consequences for self-esteem and motivation is reviewed. Factors that moderate the use of these strategies and implications of this analysis for treatment of stigmas are also discussed. For more than three decades, social psychological research on prejudice, stereotyping, and discrimination has examined both the content of stereotypes about a variety of social groups", "authors": ["Jennifer Crocker", "Brenda Major"], "related_topics": ["2778917007", "107344746", "180872759"], "citation_count": "8288", "reference_count": "239", "references": ["1799750435", "3124068636", "2171975196", "2018255452", "2029487046", "2067589470", "2019591258", "1550280742", "2076192758", "1971749549"], "date": "1988"}, {"id": "1499049447", "title": "Efficient Similarity Search In Sequence Databases", "abstract": "We propose an indexing method for time sequences for processing similarity queries. We use the Discrete Fourier Transform (DFT) to map time sequences to the frequency domain, the crucial observation being that, for most sequences of practical interest, only the first few frequencies are strong. Another important observation is Parseval's theorem, which specifies that the Fourier transform preserves the Euclidean distance in the time or frequency domain. Having thus mapped sequences to a lower-dimensionality space by using only the first few Fourier coefficients, we use R * -trees to index the sequences and efficiently answer similarity queries. We provide experimental results which show that our method is superior to search based on sequential scanning. Our experiments show that a few coefficients (1\u20133) are adequate to provide good performance. The performance gain of our method increases with the number and length of sequences.", "authors": ["Rakesh Agrawal", "Christos Faloutsos", "Arun N. Swami"], "related_topics": ["89451469", "21809047", "76563020"], "citation_count": "3008", "reference_count": "29", "references": ["2055043387", "2166559705", "2078206416", "2140196014", "1956559956", "1963623641", "2151135734", "2100406636", "2126455177", "2118269922"], "date": "1993"}, {"id": "2008906462", "title": "A Bayesian Method for the Induction of Probabilistic Networks from Data", "abstract": "This paper presents a Bayesian method for constructing probabilistic networks from databases. In particular, we focus on constructing Bayesian belief networks. Potential applications include computer-assisted hypothesis testing, automated scientific discovery, and automated construction of probabilistic expert systems. We extend the basic method to handle missing data and hidden (latent) variables. We show how to perform probabilistic inference by averaging over the inferences of multiple belief networks. Results are presented of a preliminary evaluation of an algorithm for constructing a belief network from a database of cases. Finally, we relate the methods in this paper to previous work, and we discuss open problems.", "authors": ["Gregory F. Cooper", "Edward Herskovits"], "related_topics": ["33724603", "155846161", "174539288"], "citation_count": "5736", "reference_count": "62", "references": ["1594031697", "2149706766", "2112440119", "1593793857", "2176028050", "1596324102", "2143075689", "1978304080", "1568555062", "2006258746"], "date": "1992"}, {"id": "2110485445", "title": "Finding Structure in Time", "abstract": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.", "authors": ["Jeffrey L. Elman"], "related_topics": ["2780451532", "2780049985", "124246873"], "citation_count": "12895", "reference_count": "39", "references": ["2154642048", "1652505363", "2173629880", "2016589492", "3036751298", "2118373646", "2046432185", "2122988375", "2170716495", "2094249282"], "date": "1990"}, {"id": "1623072288", "title": "Text Chunking Using Transformation-Based Learning", "abstract": "Transformation-based learning, a technique introduced by Eric Brill (1993b), has been shown to do part-of-speech tagging with fairly high accuracy. This same method can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive \u201cbaseNP\u201d chunks. For this purpose, it is convenient to view chunking as a tagging problem by encoding the chunk structure in new tags attached to each word. In automatic tests using Treebank-derived data, this technique achieved recall and precision rates of roughly 93% for baseNP chunks (trained on 950K words) and 88% for somewhat more complex chunks that partition the sentence (trained on 200K words). Working in this new application and with larger template and training sets has also required some interesting adaptations to the transformation-based learning approach.", "authors": ["Lance A. Ramshaw", "Mitchell P. Marcus"], "related_topics": ["203357204", "195153089", "2778120102"], "citation_count": "1440", "reference_count": "12", "references": ["2099247782", "2170381724", "2097125878", "1554031433", "2102924265", "2076002267", "2116266212", "2123282296", "2055438451", "2134351768"], "date": "1998"}, {"id": "1492839618", "title": "Latex : A Document Preparation System", "abstract": "This user's guide and reference for the LaTeX computer typesetting system has been revised to document features available in release LaTeX2e.", "authors": ["Leslie Lamport"], "related_topics": ["136764020", "49774154", "41008148"], "citation_count": "1201", "reference_count": "0", "references": ["2076139517", "2060440626", "1602193077", "2148033465", "1494975459", "2972968168", "34018906", "2139143639", "2042767877", "1485665416"], "date": "1985"}, {"id": "1570963478", "title": "Prediction, learning, and games", "abstract": "This important text and reference for researchers and students in machine learning, game theory, statistics and information theory offers a comprehensive treatment of the problem of predicting individual sequences. Unlike standard statistical approaches to forecasting, prediction of individual sequences does not impose any probabilistic assumption on the data-generating mechanism. Yet, prediction algorithms can be constructed that work well for all possible sequences, in the sense that their performance is always nearly as good as the best forecasting strategy in a given reference class. The central theme is the model of prediction using expert advice, a general framework within which many related problems can be cast and discussed. Repeated game playing, adaptive data compression, sequential investment in the stock market, sequential pattern analysis, and several other problems are viewed as instances of the experts' framework and analyzed from a common nonstochastic standpoint that often reveals new and intriguing connections.", "authors": ["Nicolo Cesa-Bianchi", "Gabor Lugosi"], "related_topics": ["202556891", "177142836", "49937458"], "citation_count": "3645", "reference_count": "266", "references": ["2148603752", "2099111195", "2119821739", "3124955340", "3023786531", "2137813581", "1510073064", "2168405694", "1601740268", "2087347434"], "date": "2005"}, {"id": "3141452745", "title": "Touch panel input device", "abstract": "A piezoelectric substrate is fixed to the movable plate or the support substrate directly or through a drive electrode of the piezoelectric substrate. When a pressure on an input operation surface is detected, a drive voltage is impressed on the drive electrodes of the piezoelectric substrate. In response, the piezoelectric substrate vibrates the movable plate or the support substrate, thereby providing tactile feedback to an operator. Because the movable plate or the support substrate directly vibrates without an independent vibrating source, there is no energy loss or transmission delay caused by transmitting the vibration, and finely control of the contraction and expansion of the piezoelectric substrate allows fine control of the vibration. In one embodiment, the drive voltage is modulated with signals dependent on the location of the pressure. In another embodiment, the drive voltage is modulated with audio frequencies to create a speaker.", "authors": ["Osamu Yoshikawa", "Hirotoshi Ishibashi"], "related_topics": ["2780142051", "107958047", "165801399"], "citation_count": "322", "reference_count": "17", "references": ["2128423220", "1532338640", "2160576303", "2409956777", "1530111492", "3146437216", "2832063624", "2114998762", "2737129770", "3142955533"], "date": "2002"}, {"id": "2045271686", "title": "A bridging model for parallel computation", "abstract": "The success of the von Neumann model of sequential computation is attributable to the fact that it is an efficient bridge between software and hardware: high-level languages can be efficiently compiled on to this model; yet it can be effeciently implemented in hardware. The author argues that an analogous bridge between software and hardware in required for parallel computation if that is to become as widely used. This article introduces the bulk-synchronous parallel (BSP) model as a candidate for this role, and gives results quantifying its efficiency both in implementing high-level language features and algorithms, as well as in being implemented in hardware.", "authors": ["Leslie G. Valiant"], "related_topics": ["156891508", "2776881475", "2777925698"], "citation_count": "5035", "reference_count": "29", "references": ["2052207834", "2143462372", "1555673550", "1989582918", "1969008575", "2107997203", "2069489095", "2103012681", "2137239103", "1544480906"], "date": "1990"}, {"id": "2117049614", "title": "Computational limitations on learning from examples", "abstract": "The computational complexity of learning Boolean concepts from examples is investigated. It is shown for various classes of concept representations that these cannot be learned feasibly in a distribution-free sense unless R = NP. These classes include (a) disjunctions of two monomials, (b) Boolean threshold functions, and (c) Boolean formulas in which each variable occurs at most once. Relationships between learning of heuristics and finding approximate solutions to NP-hard optimization problems are given.", "authors": ["Leonard Pitt", "Leslie G. Valiant"], "related_topics": ["158465420", "203313322", "141796577"], "citation_count": "648", "reference_count": "27", "references": ["2011039300", "2002252750", "2019363670", "2117362057", "2070902649", "2066789935", "2061079066", "2157054705", "1965415591", "2017603160"], "date": "1988"}, {"id": "2143292990", "title": "User interface software tools", "abstract": "Almost as long as there have been user interfaces, there have been special software systems and tools to help design and implement the user interface software. Many of these tools have demonstrated significant productivity gains for programmers, and have become important commercial products. Others have proven less successful at supporting the kinds of user interfaces people want to build. This article discusses the different kinds of user interface software tools, and investigates why some approaches have worked and others have not. Many examples of commercial and research systems are included. Finally, current research directions and open issues in the field are discussed.", "authors": ["Brad A. Myers"], "related_topics": ["149229913", "89505385", "197070257"], "citation_count": "496", "reference_count": "98", "references": ["2764466240", "2171739182", "2033337919", "2023192402", "1983893897", "1521539325", "1989952968", "2096636257", "2094228499", "2143722357"], "date": "1995"}, {"id": "2075554361", "title": "Change Detection and Tracking Using Pyramid Transform Techniques", "abstract": "An automated, or \"smart\", surveillance system must be sensitive to small object motion wherever it may occur within a large field of view. The system must also be capable of distinguishing changes of interest from other image activity or noise. Yet the data processing capabilities of practical systems is often quite limited. To achieve these performance objectives at a low data rate, a pyramid based image preprocessor has been constructed that can compute frequency tuned \"change energy\" measures in real time. A microprocessor then examines a relatively small set of these measures and follows a foveal search strategy to isolate moving objects for tracking or for more detailed analysis.", "authors": ["C. H. Anderson", "P. J. Burt", "G. S. van der Wal"], "related_topics": ["79284318", "203595873", "138827492"], "citation_count": "361", "reference_count": "0", "references": ["2128716185", "2096343094", "1687797484", "2125162832", "2131842403", "2055712799", "2119189625", "2117687030", "2139593995", "2148942974"], "date": "1985"}, {"id": "1494632860", "title": "Spelling Correction for Search Engine Queries", "abstract": "Search engines have become the primary means of accessing information on the Web. However, recent studies show misspelled words are very common in queries to these systems. When users misspell query, the results are incorrect or provide inconclusive information. In this work, we discuss the integration of a spelling correction component into tumba!, our community Web search engine. We present an algorithm that attempts to select the best choice among all possible corrections for a misspelled term, and discuss its implementation based on a ternary search tree data structure.", "authors": ["Bruno Martins", "M\u00e1rio J. Silva"], "related_topics": ["521815418", "136519935", "44359876"], "citation_count": "70", "reference_count": "34", "references": ["3013264884", "1660390307", "2752853835", "3036751298", "2010595692", "2029500199", "2326587081", "2057900969", "1970026646", "2000484009"], "date": "2004"}, {"id": "2019580127", "title": "A rule-based message filtering system", "abstract": "Much computerized support for knowledge workers has consisted of tools to handle low-level functions such as distribution, storage, and retrieval of information. However, the higher level processes of making decisions and taking actions with respect to this information have not been supported to the same degree. This paper describes the ISCREEN prototype system for screening text messages. ISCREEN includes a high-level interface for users to define rules, a component that screens text messages, and a conflict detection component that examines rules for inconsistencies. An explanation component uses text generation to answer user queries about past or potential system actions based on Grice's conversational maxims.", "authors": ["Stephen Pollock"], "related_topics": ["49585438", "149271511", "25621077"], "citation_count": "242", "reference_count": "13", "references": ["2264742718", "2037717074", "1570031249", "2799225444", "2073439152", "2078105735", "2134349767", "1535442853", "2217643063", "1921385128"], "date": "1988"}, {"id": "2000868500", "title": "Factor Analysis in Chemistry", "abstract": "Preface. Preface to the Second Edition. Preface to the First Edition. Historical Perspective of the Author. Prologue. Introduction. Main Steps. Mathematical Formulation of Target Factor Analysis. Effects of Experimental Error on Target Factor Analysis. Numerical Examples of Target Factor Analysis. Evolutionary Methods. Multimode Factor Analysis. Partial Least-Squares Regression. Component Analysis. Nuclear Magnetic Resonance. Chromatography. Additional Applications. Appendix A: Pseudoinverse. Appendix B: Toolbox for Chemical Factor Analysis. Appendix C: MATLAB Programs. Bibliography. Author Index. Subject Index.", "authors": ["Edmund R. Malinowski"], "related_topics": ["21556879", "2780692498", "2780365114"], "citation_count": "3829", "reference_count": "0", "references": ["2128728535", "2089468765", "2163949090", "1996118086", "2138520198", "2021873216", "2003516238", "1993694278", "2056452769", "1495773224"], "date": "1980"}, {"id": "2096765155", "title": "Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling", "abstract": "Most current statistical natural language processing models use only local features so as to permit dynamic programming in inference, but this makes them unable to fully account for the long distance structure that is prevalent in language use. We show how to solve this dilemma with Gibbs sampling, a simple Monte Carlo method used to perform approximate inference in factored probabilistic models. By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference. We use this technique to augment an existing CRF-based information extraction system with long-distance dependency models, enforcing label consistency and extraction template consistency constraints. This technique results in an error reduction of up to 9% over state-of-the-art systems on two established information extraction tasks.", "authors": ["Jenny Rose Finkel", "Trond Grenager", "Christopher Manning"], "related_topics": ["2777472644", "195807954", "158424031"], "citation_count": "3704", "reference_count": "23", "references": ["2147880316", "2125838338", "2581275558", "1997063559", "2135194391", "2160842254", "2962735828", "1513861746", "2171776966", "2129712609"], "date": "2005"}, {"id": "2052610531", "title": "Meeting of minds: the medial frontal cortex and social cognition.", "abstract": "Social interaction is a cornerstone of human life, yet the neural mechanisms underlying social cognition are poorly understood. Recently, research that integrates approaches from neuroscience and social psychology has begun to shed light on these processes, and converging evidence from neuroimaging studies suggests a unique role for the medial frontal cortex. We review the emerging literature that relates social cognition to the medial frontal cortex and, on the basis of anatomical and functional characteristics of this brain region, propose a theoretical model of medial frontal cortical function relevant to different aspects of social cognitive processing.", "authors": ["David M. Amodio", "Chris D. Frith"], "related_topics": ["123950299", "86658582", "2776559556"], "citation_count": "4082", "reference_count": "130", "references": ["2125823313", "2116146623", "2071538827", "2142823391", "2102748276", "2129900561", "2056081184", "2135572147", "2110247921", "2026482820"], "date": "2006"}, {"id": "2076139517", "title": "Crystallographic publishing in the electronic age", "abstract": "The journals of the International Union of Crystallography have grown in size and number over the past 60\u2005years to match developments in scientific practice and technique. High quality of publication has always been at the forefront of editorial policy and ways in which this has been achieved are described. In particular, the development of standard exchange and archive formats for crystallographic data has allowed the editorial office to conduct automated analyses of structural data supporting articles submitted for publication and these analyses assist the scientific editors in careful and critical peer review. The new information technologies of the Internet age have allowed the IUCr journals to flourish and to provide a wide range of powerful services to authors, editors and readers alike. The integration of literature and supporting structural data is of particular importance. The new technologies have also brought fresh economic and cultural challenges, and offer completely new opportunities to disseminate the results of scientific research. The journals continue to respond to these challenges and take advantage of new opportunities in innovative ways.", "authors": ["P.R. Strickland", "B. McMahon"], "related_topics": ["207267971", "91093795", "121017731"], "citation_count": "4", "reference_count": "29", "references": ["3146248460", "2166689829", "2086945873", "1986191025", "2070942956", "2132717858", "1492839618", "1968331067", "2497563688", "1944213880"], "date": "2007"}, {"id": "2027982384", "title": "Proximal alternating linearized minimization for nonconvex and nonsmooth problems", "abstract": "We introduce a proximal alternating linearized minimization (PALM) algorithm for solving a broad class of nonconvex and nonsmooth minimization problems. Building on the powerful Kurdyka---?ojasiewicz property, we derive a self-contained convergence analysis framework and establish that each bounded sequence generated by PALM globally converges to a critical point. Our approach allows to analyze various classes of nonconvex-nonsmooth problems and related nonconvex proximal forward---backward algorithms with semi-algebraic problem's data, the later property being shared by many functions arising in a wide variety of fundamental applications. A by-product of our framework also shows that our results are new even in the convex setting. As an illustration of the results, we derive a new and simple globally convergent algorithm for solving the sparse nonnegative matrix factorization problem.", "authors": ["J\u00e9r\u00f4me Bolte", "Shoham Sabach", "Marc Teboulle"], "related_topics": ["34388435", "152671427", "3828260"], "citation_count": "1075", "reference_count": "39", "references": ["2100556411", "1902027874", "3141595720", "205960364", "2118718620", "1246381107", "2110096996", "2153562582", "2017288758", "1603765807"], "date": "2014"}, {"id": "2157462866", "title": "A reliable effective terascale linear learning system", "abstract": "We present a system and a set of techniques for learning linear predictors with convex losses on terascale data sets, with trillions of features, billions of training examples and millions of parameters in an hour using a cluster of 1000 machines. Individually none of the component techniques are new, but the careful synthesis required to obtain an efficient implementation is. The result is, up to our knowledge, the most scalable and efficient linear learning system reported in the literature. We describe and thoroughly evaluate the components of the system, showing the importance of the various design choices.", "authors": ["Alekh Agarwal", "Olivier Chapelle", "Miroslav Dud\u00edk", "John Langford"], "related_topics": ["115903097", "77967617", "24138899"], "citation_count": "376", "reference_count": "34", "references": ["2173213060", "2164278908", "2146502635", "2168231600", "2131975293", "2109722477", "2166706236", "1564947197", "2148087609", "1603765807"], "date": "2013"}, {"id": "2970785670", "title": "The Logic of Connective Action: Digital Media and the Personalization of Contentious Politics", "abstract": "From the Arab Spring and los indignados in Spain, to Occupy Wall Street (and beyond), large-scale, sustained protests are using digital media in ways that go beyond sending and receiving messages. ...", "authors": ["W. Lance Bennett", "Alexandra Segerberg"], "related_topics": ["17632256", "2778814104", "183003079"], "citation_count": "4399", "reference_count": "188", "references": ["2112090702", "2008620264", "2134172592", "2147264455", "2300567117", "1644932108", "2126554879", "2053120142", "142345412", "2138899136"], "date": "2013"}, {"id": "2140190241", "title": "Data Mining: Concepts and Techniques", "abstract": "The increasing volume of data in modern business and science calls for more complex and sophisticated tools. Although advances in data mining technology have made extensive data collection much easier, it's still always evolving and there is a constant need for new techniques and tools that can help us transform this data into useful information and knowledge. Since the previous edition's publication, great advances have been made in the field of data mining. Not only does the third of edition of Data Mining: Concepts and Techniques continue the tradition of equipping you with an understanding and application of the theory and practice of discovering patterns hidden in large data sets, it also focuses on new, important topics in the field: data warehouses and data cube technology, mining stream, mining social networks, and mining spatial, multimedia and other complex data. Each chapter is a stand-alone guide to a critical topic, presenting proven algorithms and sound implementations ready to be used directly or with strategic modification against live data. This is the resource you need if you want to apply today's most powerful data mining techniques to meet real business challenges. * Presents dozens of algorithms and implementation examples, all in pseudo-code and suitable for use in real-world, large-scale data mining projects. * Addresses advanced topics such as mining object-relational databases, spatial databases, multimedia databases, time-series databases, text databases, the World Wide Web, and applications in several fields. *Provides a comprehensive, practical look at the concepts and techniques you need to get the most out of real business data", "authors": ["Jiawei Han", "Micheline Kamber", "Jian Pei"], "related_topics": ["197046077", "89198739", "176775163"], "citation_count": "50570", "reference_count": "485", "references": ["2156909104", "2911964244", "2912565176", "2148603752", "1554944419", "1995945562", "2008620264", "1639032689", "1554663460", "1570448133"], "date": "2000"}, {"id": "2007445014", "title": "The role of positive emotions in positive psychology. The broaden-and-build theory of positive emotions.", "abstract": "In this article, the author describes a new theoretical perspective on positive emotions and situates this new perspective within the emerging field of positive psychology. The broaden-and-build theory posits that experiences of positive emotions broaden people's momentary thought-action repertoires, which in turn serves to build their enduring personal resources, ranging from physical and intellectual resources to social and psychological resources. Preliminary empirical evidence supporting the broaden-and-build theory is reviewed, and open empirical questions that remain to be tested are identified. The theory and findings suggest that the capacity to experience positive emotions may be a fundamental human strength central to the study of human flourishing.", "authors": ["Barbara L. Fredrickson"], "related_topics": ["2781017355", "2775896857", "90386246"], "citation_count": "16032", "reference_count": "90", "references": ["2141846678", "2053133047", "2140205964", "1746951143", "1984186949", "2088155659", "2134419850", "2045565604", "1659631989", "2157607046"], "date": "2001"}, {"id": "2124404372", "title": "Robust wide-baseline stereo from maximally stable extremal regions", "abstract": "Abstract The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions , is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5\u00d7), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.", "authors": ["Jiri Matas", "Ondrej Chum", "Martin Urban", "Tom\u00e1s Pajdla"], "related_topics": ["85440238", "23379248", "6408098"], "citation_count": "7055", "reference_count": "22", "references": ["2033819227", "2124386111", "1676552347", "2124087378", "2119747362", "2165497495", "2124260943", "1541642243", "2132332894", "2143753158"], "date": "2004"}, {"id": "2140101900", "title": "Advanced Statistical Methods In Biometric Research", "abstract": "", "authors": ["C. Radhakrishna Rao"], "related_topics": ["179583182", "38180746", "184297639"], "citation_count": "3282", "reference_count": "0", "references": ["1969230115", "1989314580", "2116051586", "3123825539", "2102666490", "615175138", "1526673237", "2130075028", "2008164950", "2549601578"], "date": "1951"}, {"id": "2103305545", "title": "Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection", "abstract": "Paraphrase detection is the task of examining two sentences and determining whether they have the same meaning. In order to obtain high accuracy on this task, thorough syntactic and semantic analysis of the two statements is needed. We introduce a method for paraphrase detection based on recursive autoencoders (RAE). Our unsupervised RAEs are based on a novel unfolding objective and learn feature vectors for phrases in syntactic trees. These features are used to measure the word- and phrase-wise similarity between two sentences. Since sentences may be of arbitrary length, the resulting matrix of similarity measures is of variable size. We introduce a novel dynamic pooling layer which computes a fixed-sized representation from the variable-sized matrices. The pooled representation is then used as input to a classifier. Our method outperforms other state-of-the-art approaches on the challenging MSRP paraphrase corpus.", "authors": ["Richard Socher", "Eric H. Huang", "Jeffrey Pennin", "Christopher D Manning", "Andrew Y. Ng"], "related_topics": ["2780922921", "83665646", "70437156"], "citation_count": "978", "reference_count": "26", "references": ["2117130368", "2132339004", "2158139315", "1423339008", "71795751", "2296073425", "2097606805", "2140833774", "1566018662", "2095739681"], "date": "2011"}, {"id": "1574095631", "title": "A Thematic Guide to Optimality Theory", "abstract": "Introduction: an overview of optimality theory Part I. Core: 1. Basic architecture 2. Constraint typology 3. Modes of interaction 4. Illustration Part II. Context: 5. Classic generative phonology 6. Conspiracies 7. Representations and constraints on representations 8. Other constraint theories (TCRS, DP, etc.) Part III. Results: 9. Endogenous constraints 10. Consequences of markedness/faithfulness interaction 11. Consequences of constraint violability 12. Consequences of parallelism Part IV. Connections: 13. Learnability and acquisition 14. Parsing Morphology and the lexicon 15. Syntax and semantics 16. Language variation and change Part V. Issues and prospects: 17. Functionalism 18. Opacity 19. Serial OT 20. Local conjunction 21. 'Overkill' 22. Other topics.", "authors": ["John J. McCarthy"], "related_topics": ["2781082764", "2777723229", "2776134746"], "citation_count": "1291", "reference_count": "0", "references": ["2000196122", "1546150263", "2120321299", "1493009933", "2111797102", "2104420809", "1572105959", "2059665001", "2134616885", "2131191080"], "date": "2001"}, {"id": "2078626246", "title": "Neural networks and principal component analysis: learning from examples without local minima", "abstract": "Abstract We consider the problem of learning from examples in layered linear feed-forward neural networks using optimization methods, such as back propagation, with respect to the usual quadratic error function E of the connection weights. Our main result is a complete description of the landscape attached to E in terms of principal component analysis. We show that E has a unique minimum corresponding to the projection onto the subspace generated by the first principal vectors of a covariance matrix associated with the training patterns. All the additional critical points of E are saddle points (corresponding to projections onto subspaces generated by higher order vectors). The auto-associative case is examined in detail. Extensions and implications for the learning algorithms are discussed.", "authors": ["P. Baldi", "K. Hornik"], "related_topics": ["27438332", "50644808", "170383328"], "citation_count": "1646", "reference_count": "14", "references": ["2154642048", "1652505363", "2042264548", "1507849272", "1996773027", "2046432185", "2432567885", "2010069926", "2017257315", "2165746994"], "date": "1988"}, {"id": "1604938182", "title": "Advances in kernel methods: support vector learning", "abstract": "Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al.", "authors": ["Bernhard Sch\u00f6lkopf", "Christopher J. C. Burges", "Alexander J. Smola"], "related_topics": ["10719679", "14948415", "145828037"], "citation_count": "5767", "reference_count": "0", "references": ["2076063813", "2072128103", "1964357740", "1648445109", "2132870739", "2108995755", "2165966284", "2147238549", "2149298154", "2161920802"], "date": "1999"}, {"id": "1908696901", "title": "Theory of Indexing", "abstract": "", "authors": ["Gerard Salton"], "related_topics": ["75165309", "23123220", "41008148"], "citation_count": "174", "reference_count": "0", "references": ["1978394996", "2153252192", "2165612380", "2043909051", "1547082571", "2068632118", "2000950075", "2105378642", "2066807331", "2120820103"], "date": "1975"}, {"id": "2084844503", "title": "Human face detection in a complex background", "abstract": "Abstract The human face is a complex pattern. Finding human faces automatically in a scene is a difficult yet significant problem. It is the first important step in a fully automatic human face recognition system. In this paper a new method to locate human faces in a complex background is proposed. This system utilizes a hierarchical knowledge-based method and consists of three levels. The higher two levels are based on mosaic images at different resolutions. In the lower level, an improved edge detection method is proposed. In this research the problem of scale is dealt with, so that the system can locate unknown human faces spanning a wide range of sizes in a complex black-and-white picture. Some experimental results are given.", "authors": ["Guangzheng Yang", "Thomas S Huang"], "related_topics": ["4641261", "193536780", "31510193"], "citation_count": "1329", "reference_count": "11", "references": ["2098693229", "2135463994", "2032361618", "2782830414", "2762182259", "2051366222", "2062354294", "2020839919", "28988785", "2023377171"], "date": "1993"}, {"id": "2173701363", "title": "Tragic loss or good riddance? The impending demise of traditional scholarly journals", "abstract": "Scholarly publishing is on the verge of a drastic change from print journals to electronic ones. Although this change has been predicted for a long time, trends in technology and growth in the literature are making this transition inevitable. It is likely to occur in a few years, and is likely to be sudden. This article surveys the pressures that are leading to the impending change, and makes predictions about the future of journals, publishers, and libraries. The new electronic publishing methods are likely to improve greatly scholarly communication, partially through more rapid publication, but also through wider dissemination and a variety of novel features that cannot be implemented with the present print system, such as references in a paper to later papers that cite it.", "authors": ["Andrew M. Odlyzko"], "related_topics": ["2777462167", "18599908", "2777720223"], "citation_count": "569", "reference_count": "0", "references": ["1519946736", "2063332351", "2077825289", "2113754175", "2152879487", "2075071323", "1734242342", "2009265329", "2028887050", "2068108674"], "date": "1996"}, {"id": "2132103241", "title": "Kernel-based object tracking", "abstract": "A new approach toward target representation and localization, the central component in visual tracking of nonrigid objects, is proposed. The feature histogram-based target representations are regularized by spatial masking with an isotropic kernel. The masking induces spatially-smooth similarity functions suitable for gradient-based optimization, hence, the target localization problem can be formulated using the basin of attraction of the local maxima. We employ a metric derived from the Bhattacharyya coefficient as similarity measure, and use the mean shift procedure to perform the optimization. In the presented tracking examples, the new method successfully coped with camera motion, partial occlusions, clutter, and target scale variations. Integration with motion filters and data association techniques is also discussed. We describe only a few of the potential applications: exploitation of background information, Kalman tracking using motion models, and face tracking.", "authors": ["D. Comaniciu", "V. Ramesh", "P. Meer"], "related_topics": ["202474056", "48548287", "2776517306"], "citation_count": "6939", "reference_count": "82", "references": ["2170120409", "2099111195", "2160337655", "2067191022", "2125838338", "2341283081", "2140235142", "2981264952", "2159128898", "2126736494"], "date": "2003"}, {"id": "175500210", "title": "Agents that reduce work and information overload", "abstract": "Publisher Summary Computers are becoming the vehicle for an increasing range of everyday activities. Acquisition of news and information, mail and even social interactions and entertainment have become more and more computer based. These technological developments are not in line with a change in the way people interact with computers. Techniques from the field of AI, in particular so-called autonomous agents, can be used to implement a complementary style of interaction, which has been referred to as indirect management. Agents assist users in a range of different ways. They hide the complexity of difficult tasks, they perform tasks on the user's behalf, they can train or teach the user, they help different users collaborate, and they monitor events and procedures. The chapter focuses on an approach to building interface agents. It presents results from several prototype agents that have been built using this approach, including agents that provide personalized assistance with meeting scheduling, email handling, electronic news filtering, and selection of entertainment.", "authors": ["Pattie Maes"], "related_topics": ["13687954", "186625053", "25621077"], "citation_count": "8330", "reference_count": "0", "references": ["1532852017", "2119769170", "3068766759", "2953795759", "2109199471", "2157973139", "1999580455", "2147283253", "2106131232", "1526505611"], "date": "1995"}, {"id": "1979662808", "title": "The Shi arrangement and the Ish arrangement", "abstract": "This paper is about two arrangements of hyperplanes. The first --- the Shi arrangement --- was introduced by Jian-Yi Shi to describe the Kazhdan-Lusztig cells in the affine Weyl group of type $A$. The second --- the Ish arrangement --- was recently defined by the first author who used the two arrangements together to give a new interpretation of the $q,t$-Catalan numbers of Garsia and Haiman. In the present paper we will define a mysterious \"combinatorial symmetry\" between the two arrangements and show that this symmetry preserves a great deal of information. For example, the Shi and Ish arrangements share the same characteristic polynomial, the same numbers of regions, bounded regions, dominant regions, regions with $c$ \"ceilings\" and $d$ \"degrees of freedom\", etc. Moreover, all of these results hold in the greater generality of \"deleted\" Shi and Ish arrangements corresponding to an arbitrary subgraph of the complete graph. Our proofs are based on nice combinatorial labelings of Shi and Ish regions and a new set partition-valued statistic on these regions.", "authors": ["Drew Armstrong", "Brendon Rhoades", ""], "related_topics": ["2779886137", "125080357", "34388435"], "citation_count": "31", "reference_count": "15", "references": ["377884864", "2101769805", "2138241477", "2595477438", "1963809736", "2039415399", "93565887", "1512323832", "1538550540", "2035614872"], "date": "2012"}, {"id": "2008130267", "title": "Distortion invariant object recognition by matching hierarchically labeled graphs", "abstract": "A graph-matching process of object recognition is proposed. It is applied to face recognition. Gray-level images are represented by a resolution hierarchy of local Gabor components, which are all scaled and rotated versions of each other. The components centered on one image point form a Gabor jet. A single jet provides a distortion-insensitive local representation of part of an image. Object recognition is achieved by matching image point jets to jets in stored prototype patterns. For a selected image jet the best matches are determined, under a constraint preserving spatial arrangement. The procedure amounts to labeled graph matching, with Gabor jets forming labels to nodes and topology determining links. A contrast-insensitive similarity measure provides for invariance with respect to lighting conditions. The authors have formulated the matching procedure as an optimization task solved by diffusion of match points. This diffusion is controlled by a potential determined by jet similarity and the topology-preserving constraint. The algorithm implements a neural network architecture. >", "authors": ["Buhmann", "Lange", "von der Malsburg"], "related_topics": ["14551309", "31510193", "19453392"], "citation_count": "172", "reference_count": "11", "references": ["2160078223", "1972536405", "1989028283", "2029136760", "1998024692", "2077516901", "2154455356", "2025830639", "1966986926", "2037474041"], "date": "1988"}, {"id": "1503247412", "title": "Metaphor: A Practical Introduction", "abstract": "1. What Is Metaphor? 2. Common Source and Target Domains 3. Kinds of Metaphor 4. Metaphor in Literature 5. Nonlinguistic Realizations of Conceptual Metaphors 6. The Basis of Metaphor 7. The Partial Nature of Metaphorical Mappings 8. Cognitive Models, Metaphors, and Embodiment 9. Metaphorical Entailments 10. The Scope of Metaphor 11. Metaphor Systems 12. Another Figure: Metonymy 13. The Universality of Conceptual Metaphors 14. Cultural Variation in Metaphor and Metonymy 15. Metaphor, Metonymy, and Idioms 16. Metaphor and Metonymy in the Study of Language 17. Metaphors and Blends 18. Metaphor in Discourse 19. How Does All This 20. Hang Together? GLOSSARY SOLUTIONS TO EXERCISES REFERENCES GENERAL INDEX METAPHOR AND METONYMY INDEX", "authors": ["Zolt\u00e1n K\u00f6vecses", "R\u00e9ka Benczes"], "related_topics": ["2781338808", "2778311575", "2776402256"], "citation_count": "7252", "reference_count": "100", "references": ["1558866924", "2118163921", "1976460644", "1973826788", "2043220715", "2026161499", "1583187655", "2092910762", "2123987305", "2086461330"], "date": "2001"}, {"id": "1501077214", "title": "Principles and Practices of Interconnection Networks", "abstract": "One of the greatest challenges faced by designers of digital systems is optimizing the communication and interconnection between system components. Interconnection networks offer an attractive and economical solution to this communication crisis and are fast becoming pervasive in digital systems. Current trends suggest that this communication bottleneck will be even more problematic when designing future generations of machines. Consequently, the anatomy of an interconnection network router and science of interconnection network design will only grow in importance in the coming years. This book offers a detailed and comprehensive presentation of the basic principles of interconnection network design, clearly illustrating them with numerous examples, chapter exercises, and case studies. It incorporates hardware-level descriptions of concepts, allowing a designer to see all the steps of the process from abstract design to concrete implementation. \u00b7Case studies throughout the book draw on extensive author experience in designing interconnection networks over a period of more than twenty years, providing real world examples of what works, and what doesn't. \u00b7Tightly couples concepts with implementation costs to facilitate a deeper understanding of the tradeoffs in the design of a practical network. \u00b7A set of examples and exercises in every chapter help the reader to fully understand all the implications of every design decision. Table of Contents Chapter 1 Introduction to Interconnection Networks 1.1 Three Questions About Interconnection Networks 1.2 Uses of Interconnection Networks 1.3 Network Basics 1.4 History 1.5 Organization of this Book Chapter 2 A Simple Interconnection Network 2.1 Network Specifications and Constraints 2.2 Topology 2.3 Routing 2.4 Flow Control 2.5 Router Design 2.6 Performance Analysis 2.7 Exercises Chapter 3 Topology Basics 3.1 Nomenclature 3.2 Traffic Patterns 3.3 Performance 3.4 Packaging Cost 3.5 Case Study: The SGI Origin 2000 3.6 Bibliographic Notes 3.7 Exercises Chapter 4 Butterfly Networks 4.1 The Structure of Butterfly Networks 4.2 Isomorphic Butterflies 4.3 Performance and Packaging Cost 4.4 Path Diversity and Extra Stages 4.5 Case Study: The BBN Butterfly 4.6 Bibliographic Notes 4.7 Exercises Chapter 5 Torus Networks 5.1 The Structure of Torus Networks 5.2 Performance 5.3 Building Mesh and Torus Networks 5.4 Express Cubes 5.5 Case Study: The MIT J-Machine 5.6 Bibliographic Notes 5.7 Exercises Chapter 6 Non-Blocking Networks 6.1 Non-Blocking vs. Non-Interfering Networks 6.2 Crossbar Networks 6.3 Clos Networks 6.4 Benes Networks 6.5 Sorting Networks 6.6 Case Study: The Velio VC2002 (Zeus) Grooming Switch 6.7 Bibliographic Notes 6.8 Exercises Chapter 7 Slicing and Dicing 7.1 Concentrators and Distributors 7.2 Slicing and Dicing 7.3 Slicing Multistage Networks 7.4 Case Study: Bit Slicing in the Tiny Tera 7.5 Bibliographic Notes 7.6 Exercises Chapter 8 Routing Basics 8.1 A Routing Example 8.2 Taxonomy of Routing Algorithms 8.3 The Routing Relation 8.4 Deterministic Routing 8.5 Case Study: Dimension-Order Routing in the Cray T3D 8.6 Bibliographic Notes 8.7 Exercises Chapter 9 Oblivious Routing 9.1 Valiant's Randomized Routing Algorithm 9.2 Minimal Oblivious Routing 9.3 Load-Balanced Oblivious Routing 9.4 Analysis of Oblivious Routing 9.5 Case Study: Oblivious Routing in the Avici Terabit Switch Router(TSR) 9.6 Bibliographic Notes 9.7 Exercises Chapter 10 Adaptive Routing 10.1 Adaptive Routing Basics 10.2 Minimal Adaptive Routing 10.3 Fully Adaptive Routing 10.4 Load-Balanced Adaptive Routing 10.5 Search-Based Routing 10.6 Case Study: Adaptive Routing in the Thinking Machines CM-5 10.7 Bibliographic Notes 10.8 Exercises Chapter 11 Routing Mechanics 11.1 Table-Based Routing 11.2 Algorithmic Routing 11.3 Case Study: Oblivious Source Routing in the IBM Vulcan Network 11.4 Bibliographic Notes 11.5 Exercises Chapter 12 Flow Control Basics 12.1 Resources and Allocation Units 12.2 Bufferless Flow Control 12.3 Circuit Switching 12.4 Bibliographic Notes 12.5 Exercises Chapter 13 Buffered Flow Control 13.1 Packet-Buffer Flow Control 13.2 Flit-Buffer Flow Control 13.3 Buffer Management and Backpressure 13.4 Flit-Reservation Flow Control 13.5 Bibliographic Notes 13.6 Exercises Chapter 14 Deadlock and Livelock 14.1 Deadlock 14.2 Deadlock Avoidance 14.3 Adaptive Routing 14.4 Deadlock Recovery 14.5 Livelock 14.6 Case Study: Deadlock Avoidance in the Cray T3E 14.7 Bibliographic Notes 14.8 Exercises Chapter 15 Quality of Service 15.1 Service Classes and Service Contracts 15.2 Burstiness and Network Delays 15.3 Implementation of Guaranteed Services 15.4 Implementation of Best-Effort Services 15.5 Separation of Resources 15.6 Case Study: ATM Service Classes 15.7 Case Study: Virtual Networks in the Avici TSR 15.8 Bibliographic Notes 15.9 Exercises Chapter 16 Router Architecture 16.1 Basic Router Architecture 16.2 Stalls 16.3 Closing the Loop with Credits 16.4 Reallocating a Channel 16.5 Speculation and Lookahead 16.6 Flit and Credit Encoding 16.7 Case Study: The Alpha 21364 Router 16.8 Bibliographic Notes 16.9 Exercises Chapter 17 Router Datapath Components 17.1 Input Buffer Organization 17.2 Switches 17.3 Output Organization 17.4 Case Study: The Datapath of the IBM Colony Router 17.5 Bibliographic Notes 17.6 Exercises Chapter 18 Arbitration 18.1 Arbitration Timing 18.2 Fairness 18.3 Fixed Priority Arbiter 18.4 Variable Priority Iterative Arbiters 18.5 Matrix Arbiter 18.6 Queuing Arbiter 18.7 Exercises Chapter 19 Allocation 19.1 Representations 19.2 Exact Algorithms 19.3 Separable Allocators 19.4 Wavefront Allocator 19.5 Incremental vs. Batch Allocation 19.6 Multistage Allocation 19.7 Performance of Allocators 19.8 Case Study: The Tiny Tera Allocator 19.9 Bibliographic Notes 19.10 Exercises Chapter 20 Network Interfaces 20.1 Processor-Network Interface 20.2 Shared-Memory Interface 20.3 Line-Fabric Interface 20.4 Case Study: The MIT M-Machine Network Interface 20.5 Bibliographic Notes 20.6 Exercises Chapter 21 Error Control 411 21.1 Know Thy Enemy: Failure Modes and Fault Models 21.2 The Error Control Process: Detection, Containment, and Recovery 21.3 Link Level Error Control 21.4 Router Error Control 21.5 Network-Level Error Control 21.6 End-to-end Error Control 21.7 Bibliographic Notes 21.8 Exercises Chapter 22 Buses 22.1 Bus Basics 22.2 Bus Arbitration 22.3 High Performance Bus Protocol 22.4 From Buses to Networks 22.5 Case Study: The PCI Bus 22.6 Bibliographic Notes 22.7 Exercises Chapter 23 Performance Analysis 23.1 Measures of Interconnection Network Performance 23.2 Analysis 23.3 Validation 23.4 Case Study: Efficiency and Loss in the BBN Monarch Network 23.5 Bibliographic Notes 23.6 Exercises Chapter 24 Simulation 24.1 Levels of Detail 24.2 Network Workloads 24.3 Simulation Measurements 24.4 Simulator Design 24.5 Bibliographic Notes 24.6 Exercises Chapter 25 Simulation Examples 495 25.1 Routing 25.2 Flow Control Performance 25.3 Fault Tolerance Appendix A Nomenclature Appendix B Glossary Appendix C Network Simulator", "authors": ["William James Dally", "Brian Patrick Towles"], "related_topics": ["204948658", "196423136", "89305328"], "citation_count": "4402", "reference_count": "161", "references": ["2112090702", "2105818147", "1977545325", "3163287424", "2145021036", "1544623790", "2114728910", "2155066383", "2111366547", "2097560795"], "date": "2003"}, {"id": "1648445109", "title": "Sparse bayesian learning and the relevance vector machine", "abstract": "This paper introduces a general Bayesian framework for obtaining sparse solutions to regression and classification tasks utilising models linear in the parameters. Although this framework is fully general, we illustrate our approach with a particular specialisation that we denote the 'relevance vector machine' (RVM), a model of identical functional form to the popular and state-of-the-art 'support vector machine' (SVM). We demonstrate that by exploiting a probabilistic Bayesian learning framework, we can derive accurate prediction models which typically utilise dramatically fewer basis functions than a comparable SVM while offering a number of additional advantages. These include the benefits of probabilistic predictions, automatic estimation of 'nuisance' parameters, and the facility to utilise arbitrary basis functions (e.g. non-'Mercer' kernels). We detail the Bayesian framework and associated learning algorithm for the RVM, and give some illustrative examples of its application along with some comparative benchmarks. We offer some explanation for the exceptional degree of sparsity obtained, and discuss and demonstrate some of the advantageous features, and potential extensions, of Bayesian relevance learning.", "authors": ["Michael E. Tipping"], "related_topics": ["14948415", "71983512", "17061570"], "citation_count": "6820", "reference_count": "38", "references": ["2156909104", "2148603752", "1554663460", "2117812871", "2078204800", "2087347434", "1604938182", "1618905105", "2102201073", "1988520084"], "date": "2001"}, {"id": "2032372805", "title": "MIMO Broadcasting for Simultaneous Wireless Information and Power Transfer", "abstract": "Wireless power transfer (WPT) is a promising new solution to provide convenient and perpetual energy supplies to wireless networks. In practice, WPT is implementable by various technologies such as inductive coupling, magnetic resonate coupling, and electromagnetic (EM) radiation, for short-/mid-/long-range applications, respectively. In this paper, we consider the EM or radio signal enabled WPT in particular. Since radio signals can carry energy as well as information at the same time, a unified study on simultaneous wireless information and power transfer (SWIPT) is pursued. Specifically, this paper studies a multiple-input multiple-output (MIMO) wireless broadcast system consisting of three nodes, where one receiver harvests energy and another receiver decodes information separately from the signals sent by a common transmitter, and all the transmitter and receivers may be equipped with multiple antennas. Two scenarios are examined, in which the information receiver and energy receiver are separated and see different MIMO channels from the transmitter, or co-located and see the identical MIMO channel from the transmitter. For the case of separated receivers, we derive the optimal transmission strategy to achieve different tradeoffs for maximal information rate versus energy transfer, which are characterized by the boundary of a so-called rate-energy (R-E) region. For the case of co-located receivers, we show an outer bound for the achievable R-E region due to the potential limitation that practical energy harvesting receivers are not yet able to decode information directly. Under this constraint, we investigate two practical designs for the co-located receiver case, namely time switching and power splitting, and characterize their achievable R-E regions in comparison to the outer bound.", "authors": ["Rui Zhang", "Chin Keong Ho"], "related_topics": ["91330434", "65422117", "47798520"], "citation_count": "2463", "reference_count": "22", "references": ["2296319761", "2130509920", "1979408141", "2798333393", "2151795416", "2147942702", "2161410889", "1981044874", "2103749601", "2170263567"], "date": "2013"}, {"id": "1995054497", "title": "The case for open computer programs", "abstract": "Scientific communication relies on evidence that cannot be entirely included in publications, but the rise of computational science has added a new layer of inaccessibility. Although it is now accepted that data should be made available on request, the current regulations regarding the availability of software are inconsistent. We argue that, with some exceptions, anything less than the release of source programs is intolerable for results that depend on computation. The vagaries of hardware, software and natural language will always ensure that exact reproducibility remains uncertain, but withholding code increases the chances that efforts to reproduce results will fail.", "authors": ["Darrel C. Ince", "Leslie Hatton", "John Graham-Cumming"], "related_topics": ["2777904410", "121017731", "2775989791"], "citation_count": "572", "reference_count": "38", "references": ["1548849615", "1979440117", "3022734214", "2041114254", "2096435507", "2072876893", "2030620341", "2143964357", "2142188478", "2083042078"], "date": "2012"}, {"id": "2145023731", "title": "A Computational Approach to Edge Detection", "abstract": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.", "authors": ["John Canny"], "related_topics": ["14705441", "193536780", "167074055"], "citation_count": "38241", "reference_count": "13", "references": ["2003370853", "1995756857", "1968245656", "2130355536", "2002882922", "2007057443", "1533832053", "1555351000", "128364430", "2016396776"], "date": "1986"}, {"id": "2074788634", "title": "Survey on speech emotion recognition: Features, classification schemes, and databases", "abstract": "Recently, increasing attention has been directed to the study of the emotional content of speech signals, and hence, many systems have been proposed to identify the emotional content of a spoken utterance. This paper is a survey of speech emotion classification addressing three important aspects of the design of a speech emotion recognition system. The first one is the choice of suitable features for speech representation. The second issue is the design of an appropriate classification scheme and the third issue is the proper preparation of an emotional speech database for evaluating system performance. Conclusions about the performance and limitations of current speech emotion recognition systems are discussed in the last section of this survey. This section also suggests possible ways of improving speech emotion recognition systems.", "authors": ["Moataz El Ayadi", "Mohamed S. Kamel", "Fakhri Karray"], "related_topics": ["54953205", "206310091", "2775852435"], "citation_count": "1673", "reference_count": "140", "references": ["2966207845", "1554663460", "2124386111", "2139212933", "3124955340", "2912934387", "1563088657", "3149745985", "1560013842", "2132549764"], "date": "2011"}, {"id": "2030144199", "title": "Recommending and evaluating choices in a virtual community of use", "abstract": "", "authors": ["Will Hill", "Larry Stead", "Mark Rosenstein", "George Furnas"], "related_topics": ["2777756574", "136764020", "49774154"], "citation_count": "1751", "reference_count": "10", "references": ["3121531027", "1966553486", "2116339812", "2006551346", "2037717074", "2142094977", "2165978089", "2042007108", "1986519353", "1604792668"], "date": "1995"}, {"id": "2123487311", "title": "Unscented filtering and nonlinear estimation", "abstract": "The extended Kalman filter (EKF) is probably the most widely used estimation algorithm for nonlinear systems. However, more than 35 years of experience in the estimation community has shown that is difficult to implement, difficult to tune, and only reliable for systems that are almost linear on the time scale of the updates. Many of these difficulties arise from its use of linearization. To overcome this limitation, the unscented transformation (UT) was developed as a method to propagate mean and covariance information through nonlinear transformations. It is more accurate, easier to implement, and uses the same order of calculations as linearization. This paper reviews the motivation, development, use, and implications of the UT.", "authors": ["S.J. Julier", "J.K. Uhlmann"], "related_topics": ["139399703", "206833254", "11210021"], "citation_count": "7440", "reference_count": "51", "references": ["2033819227", "3097169496", "2981264952", "2432517183", "2020934227", "2121990344", "1559536185", "2571050459", "2107802551", "2124497430"], "date": "2004"}, {"id": "2018415007", "title": "Protocol Analysis: Verbal Reports as Data", "abstract": "Since the publication of Ericsson and Simon's work in the early 1980s, verbal data has been used increasingly to study cognitive processes in many areas of psychology, and concurrent and retrospective verbal reports are now generally accepted as important sources of data on subjects' cognitive processes in specific tasks. In this revised edition of the book that put protocol analysis on firm theoretical ground, the authors review major advances in verbal reports over the past decade, including new evidence on how giving verbal reports affects subjects' cognitive processes, and on the validity and completeness of such reports. In a new preface Ericsson and Simon summarize the central issues covered in the book and provide an updated version of their information-processing model, which explains verbalization and verbal reports. They describe new studies on the effects of verbalization, interpreting the results of these studies and showing how their theory can be extended to account for them. Next, they address the issue of completeness of verbally reported information, reviewing the new evidence in three particularly active task domains. They conclude by citing recent contributions to the techniques for encoding protocols, raising general issues, and proposing directions for future research.", "authors": ["K. Anders Ericsson", "Herbert Alexander Simon"], "related_topics": ["133112747", "78821406", "204159532"], "citation_count": "15661", "reference_count": "0", "references": ["2342091124", "2137247190", "1498878034", "1970953601", "2048395990", "2136208491", "2096834156", "2116104206", "1967971235", "2158241055"], "date": "1984"}, {"id": "2152241065", "title": "Evolution of WDM Optical IP Networks: A Cost and Energy Perspective", "abstract": "We review technologies and architectures for WDM optical IP networks from the viewpoint of capital expenditure and network energy consumption. We show how requirements of low cost and low energy consumption can influence the choice of switching technologies as well as the overall network architecture.", "authors": ["R.S. Tucker", "R. Parthiban", "J. Baliga", "K. Hinton", "R.W.A. Ayre", "W.V. Sorin"], "related_topics": ["2780165032", "192126672", "193415008"], "citation_count": "295", "reference_count": "22", "references": ["1588462524", "2149641812", "2169741605", "2161111878", "2270461788", "2052742517", "1585038871", "2087924620", "2097247107", "2159445174"], "date": "2009"}, {"id": "2122005484", "title": "Piggyback CrowdSensing (PCS): energy efficient crowdsourcing of mobile sensor data by exploiting smartphone app opportunities", "abstract": "Fueled by the widespread adoption of sensor-enabled smartphones, mobile crowdsourcing is an area of rapid innovation. Many crowd-powered sensor systems are now part of our daily life -- for example, providing highway congestion information. However, participation in these systems can easily expose users to a significant drain on already limited mobile battery resources. For instance, the energy burden of sampling certain sensors (such as WiFi or GPS) can quickly accumulate to levels users are unwilling to bear. Crowd system designers must minimize the negative energy side-effects of participation if they are to acquire and maintain large-scale user populations.To address this challenge, we propose Piggyback CrowdSensing (PCS), a system for collecting mobile sensor data from smartphones that lowers the energy overhead of user participation. Our approach is to collect sensor data by exploiting Smartphone App Opportunities -- that is, those times when smartphone users place phone calls or use applications. In these situations, the energy needed to sense is lowered because the phone need no longer be woken from an idle sleep state just to collect data. Similar savings are also possible when the phone either performs local sensor computation or uploads the data to the cloud. To efficiently use these sporadic opportunities, PCS builds a lightweight, user-specific prediction model of smartphone app usage. PCS uses this model to drive a decision engine that lets the smartphone locally decide which app opportunities to exploit based on expected energy/quality trade-offs.We evaluate PCS by analyzing a large-scale dataset (containing 1,320 smartphone users) and building an end-to-end crowdsourcing application that constructs an indoor WiFi localization database. Our findings show that PCS can effectively collect large-scale mobile sensor datasets (e.g., accelerometer, GPS, audio, image) from users while using less energy (up to 90% depending on the scenario) compared to a representative collection of existing approaches.", "authors": ["Nicholas D. Lane", "Yohan Chon", "Lin Zhou", "Yongzhe Zhang", "Fan Li", "Dongwon Kim", "Guanzhong Ding", "Feng Zhao", "Hojung Cha"], "related_topics": ["62230096", "79974875", "2742236"], "citation_count": "197", "reference_count": "33", "references": ["2170102584", "3124955340", "1506806321", "2168463792", "2022710553", "1996573126", "2100045669", "2131147042", "2127347346", "2041454412"], "date": "2013"}, {"id": "2119479037", "title": "An introduction to variable and feature selection", "abstract": "Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.", "authors": ["Isabelle Guyon", "Andr\u00e9 Elisseeff"], "related_topics": ["148483581", "7374053", "16811321"], "citation_count": "17391", "reference_count": "47", "references": ["2148603752", "2109363337", "3023786531", "2157795344", "2143426320", "1594031697", "2087347434", "2017337590", "2103333826", "2167277498"], "date": "2003"}, {"id": "2131191080", "title": "OT constraints are categorical", "abstract": "In Optimality Theory, constraints come in two types, which are distinguished by their mode of evaluation. Categorical constraints are either satisfied or not ; a categorical constraint assigns no more than one violation-mark, unless there are several violating structures in the form under evaluation. Gradient constraints evaluate extent of deviation ; they can assign multiple marks even when there is just a single instance of the non-conforming structure. This article proposes a restrictive definition of what an OT constraint is, from which it follows that all constraints must be categorical. The various gradient constraints that have been proposed are examined, and it is argued that none is necessary and many have undesirable consequences.", "authors": ["John J. McCarthy"], "related_topics": ["178791929", "5274069", "2776426709"], "citation_count": "535", "reference_count": "133", "references": ["1562911371", "1575528222", "587963984", "1608707468", "1595210733", "2170716495", "1484198809", "1533473429", "1574095631", "1504955803"], "date": "2003"}, {"id": "2963241992", "title": "The actor and the observer : Divergent perceptions of the causes of behavior", "abstract": "", "authors": ["E. E. Jones"], "related_topics": ["2780704645", "81717268", "15744967"], "citation_count": "3545", "reference_count": "0", "references": ["2106096361", "2089457241", "2107223217", "1966371634", "2167884222", "2096578021", "2072035149", "2001512623", "2157542520", "2136240258"], "date": "1971"}, {"id": "1572105959", "title": "Phonetically Based Phonology", "abstract": "List of contributors List of abbreviations 1. Introduction: the phonetic bases of phonological Markedness Bruce Hayes and Donca Steriade 2. A review of perceptual cues and cue robustness Richard Wright 3. Place assimilation Jongho Jun 4. The typology of rounding harmony Abigail R. Kaun 5. The evolution of metathesis Juliette Blevins and Andrew Garrett 6. The role of contrast-specific and language-specific phonetics in contour tone distribution Jie Zhang 7. Vowel reduction Katherine M. Crosswhite 8. Contrast and perceptual distinctiveness Edward Flemming 9. Syllable weight Matthew Gordon 10. Consonant lenition Robert Kirchner 11. Language processing and segmental OCP effects Stefan A. Frisch Index.", "authors": ["Bruce Hayes", "Robert Martin Kirchner", "Donca Steriade"], "related_topics": ["131892022", "2778400535", "137584468"], "citation_count": "451", "reference_count": "39", "references": ["1562911371", "1493009933", "1574095631", "1801810991", "2065141786", "1598851216", "1531793446", "2991416376", "132265529", "2150169469"], "date": "2008"}, {"id": "1964443764", "title": "Mean shift analysis and applications", "abstract": "A nonparametric estimator of density gradient, the mean shift, is employed in the joint, spatial-range (value) domain of gray level and color images for discontinuity preserving filtering and image segmentation. Properties of the mean shift are reviewed and its convergence on lattices is proven. The proposed filtering method associates with each pixel in the image the closest local mode in the density distribution of the joint domain. Segmentation into a piecewise constant structure requires only one more step, fusion of the regions associated with nearby modes. The proposed technique has two parameters controlling the resolution in the spatial and range domains. Since convergence is guaranteed, the technique does not require the intervention of the user to stop the filtering at the desired image quality. Several examples, for gray and color images, show the versatility of the method and compare favorably with results described in the literature for the same images.", "authors": ["D. Comaniciu", "P. Meer"], "related_topics": ["124504099", "67561299", "48548287"], "citation_count": "1543", "reference_count": "16", "references": ["2099244020", "2150134853", "2129905273", "2022686119", "2098152234", "204885769", "2167077256", "2121836097", "2132126381", "2109562068"], "date": "1999"}, {"id": "1977182536", "title": "A method for disambiguating word senses in a large corpus", "abstract": "Word sense disambiguation has been recognized as a major problem in natural language processing research for over forty years. Both quantitive and qualitative methods have been tried, but much of this work has been stymied by difficulties in acquiring appropriate lexical resources. The availability of this testing and training material has enabled us to develop quantitative disambiguation methods that achieve 92% accuracy in discriminating between two very distinct senses of a noun. In the training phase, we collect a number of instances of each sense of the polysemous noun. Then in the testing phase, we are given a new instance of the noun, and are asked to assign the instance to one of the senses. We attempt to answer this question by comparing the context of the unknown instance with contexts of known instances using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval. The proposed method is probably most appropriate for those aspects of sense disambiguation that are closest to the information retrieval task. In particular, the proposed method was designed to disambiguate senses that are usually associated with different topics.", "authors": ["William A. Gale", "Kenneth Ward Church", "David Yarowsky"], "related_topics": ["121934690", "2780276568", "161156560"], "citation_count": "878", "reference_count": "30", "references": ["2099247782", "2117652747", "2129139611", "1548013757", "2110529160", "2007780422", "1550769831", "2137638032", "2019911971", "1980491396"], "date": "1992"}, {"id": "1601529450", "title": "Knowledge Discovery in Databases", "abstract": "From the Publisher: Knowledge Discovery in Databases brings together current research on the exciting problem of discovering useful and interesting knowledge in databases. It spans many different approaches to discovery, including inductive learning, bayesian statistics, semantic query optimization, knowledge acquisition for expert systems, information theory, and fuzzy 1 sets. The rapid growth in the number and size of databases creates a need for tools and techniques for intelligent data understanding. Relationships and patterns in data may enable a manufacturer to discover the cause of a persistent disk failure or the reason for consumer complaints. But today's databases hide their secrets beneath a cover of overwhelming detail. The task of uncovering these secrets is called \"discovery in databases.\" This loosely defined subfield of machine learning is concerned with discovery from large amounts of possible uncertain data. Its techniques range from statistics to the use of domain knowledge to control search. Following an overview of knowledge discovery in databases, thirty technical chapters are grouped in seven parts which cover discovery of quantitative laws, discovery of qualitative laws, using knowledge in discovery, data summarization, domain specific discovery methods, integrated and multi-paradigm systems, and methodology and application issues. An important thread running through the collection is reliance on domain knowledge, starting with general methods and progressing to specialized methods where domain knowledge is built in. Gregory Piatetski-Shapiro is Senior Member of Technical Staff and Principal Investigator of the Knowledge Discovery Project at GTELaboratories. William Frawley is Principal Member of Technical Staff at GTE and Principal Investigator of the Learning in Expert Domains Project.", "authors": ["Gregory Piateski", "William Frawley"], "related_topics": ["120567893", "207685749", "103520596"], "citation_count": "2628", "reference_count": "0", "references": ["2140190241", "2076063813", "1570448133", "2166559705", "1506285740", "2017337590", "2186428165", "2138745909", "2100406636", "1575476631"], "date": "1991"}, {"id": "1966280301", "title": "Bagging, boosting, and C4.S", "abstract": "Breiman's bagging and Freund and Schapire's boosting are recent methods for improving the predictive power of classifier learning systems. Both form a set of classifiers that are combined by voting, bagging by generating replicated bootstrap samples of the data, and boosting by adjusting the weights of training instances. This paper reports results of applying both techniques to a system that learns decision trees and testing on a representative collection of datasets. While both approaches substantially improve predictive accuracy, boosting shows the greater benefit. On the other hand, boosting also produces severe degradation on some datasets. A small change to the way that boosting combines the votes of learned classifiers reduces this downside and also leads to slightly better results on most of the datasets considered.", "authors": ["J. R. Quinlan"], "related_topics": ["31912584", "70153297", "46686674"], "citation_count": "2492", "reference_count": "15", "references": ["3124955340", "2912934387", "2112076978", "1594031697", "1676820704", "1530699444", "2134696506", "1567276288", "1539741229", "1510806966"], "date": "1996"}, {"id": "1984186949", "title": "Emotion and Adaptation", "abstract": "Part I: BACKGROUND: About emotion Issues of research, classification and measurements Part II: THE COGNITIVE-MOTIVATIONAL-RELATIONAL THEORY: The person-environment relationship: motivation and coping Cognition and emotion Issues of causality Part III: INDIVIDUAL EMOTIONS: Goal incongruent (negative) emotions Goal congruent (positive) and problematic emotions Part IV: EMOTIONAL DEVELOPMENT: Individual development Social influence Part V: PRACTICAL APPLICATIONS: Emotions and health Implications for research, assessment, treatment and disease prevention References Index.", "authors": ["Richard S. Lazarus"], "related_topics": ["206310091", "128534915", "71742726"], "citation_count": "7497", "reference_count": "0", "references": ["2007445014", "2315207768", "2123791568", "2150375089", "1746951143", "2134031328", "2102998034", "1595732857", "2117645142", "2134419850"], "date": "1990"}, {"id": "2042243448", "title": "Scale-Space Theory : A Basic Tool for Analysing Structures at Different Scales", "abstract": "An inherent property of objects in the world is that they only exist as meaningful entities over certain ranges of scale. If one aims at describing the structure of unknown real-world signals, then ...", "authors": ["Tony Lindeberg"], "related_topics": ["2778755073", "99102927", "189950617"], "citation_count": "1918", "reference_count": "97", "references": ["2132984323", "2145023731", "2150134853", "2004217976", "2120062331", "2103504761", "2109863423", "2003370853", "2112328181", "2166982406"], "date": "1993"}, {"id": "2113945798", "title": "Image denoising using scale mixtures of Gaussians in the wavelet domain", "abstract": "We describe a method for removing noise from digital images, based on a statistical model of the coefficients of an overcomplete multiscale oriented basis. Neighborhoods of coefficients at adjacent positions and scales are modeled as the product of two independent random variables: a Gaussian vector and a hidden positive scalar multiplier. The latter modulates the local variance of the coefficients in the neighborhood, and is thus able to account for the empirically observed correlation between the coefficient amplitudes. Under this model, the Bayesian least squares estimate of each coefficient reduces to a weighted average of the local linear estimates over all possible values of the hidden multiplier variable. We demonstrate through simulations with images contaminated by additive white Gaussian noise that the performance of this method substantially surpasses that of previously published methods, both visually and in terms of mean squared error.", "authors": ["J. Portilla", "V. Strela", "M.J. Wainwright", "E.P. Simoncelli"], "related_topics": ["139945424", "169334058", "167928553"], "citation_count": "2959", "reference_count": "60", "references": ["2132984323", "2158940042", "2053691921", "2132680427", "2145889472", "2129276048", "2134929491", "2127006916", "1991605728", "2137234026"], "date": "2003"}, {"id": "2135572147", "title": "The neural basis of human error processing: Reinforcement learning, dopamine, and the error-related negativity.", "abstract": "The authors present a unified account of 2 neural systems concerned with the development and expression of adaptive behaviors: a mesencephalic dopamine system for reinforcement learning and a \u201cgeneric\u201d error-processing system associated with the anterior cingulate cortex. The existence of the error-processing system has been inferred from the error-related negativity (ERN), a component of the event-related brain potential elicited when human participants commit errors in reaction-time tasks. The authors propose that the ERN is generated when a negative reinforcement learning signal is conveyed to the anterior cingulate cortex via the mesencephalic dopamine system and that this signal is used by the anterior cingulate cortex to modify performance on the task at hand. They provide support for this proposal using both computational modeling and psychophysiological experimentation.", "authors": ["Clay B. Holroyd", "Michael G. H. Coles"], "related_topics": ["8784161", "2781210436", "2778402161"], "citation_count": "4153", "reference_count": "272", "references": ["2121863487", "1581387623", "2000998192", "2153134014", "2117726420", "2100677568", "2109059823", "2057046889", "2006633893", "2114207481"], "date": "2002"}, {"id": "2004763266", "title": "Design Challenges and Misconceptions in Named Entity Recognition", "abstract": "We analyze some of the fundamental design challenges and misconceptions that underlie the development of an efficient and robust NER system. In particular, we address issues such as the representation of text chunks, the inference approach needed to combine local NER decisions, the sources of prior knowledge and how to use them within an NER system. In the process of comparing several solutions to these challenges we reach some surprising conclusions, as well as develop an NER system that achieves 90.8 F1 score on the CoNLL-2003 NER shared task, the best reported result for this dataset.", "authors": ["Lev Ratinov", "Dan Roth"], "related_topics": ["2779135771", "2776214188", "148524875"], "citation_count": "1573", "reference_count": "32", "references": ["2147880316", "2125838338", "2096765155", "2008652694", "1996430422", "2148540243", "2144578941", "2121227244", "2128634885", "1979711143"], "date": "2009"}, {"id": "2157475639", "title": "Neural Network Recognizer for Hand-Written Zip Code Digits", "abstract": "This paper describes the construction of a system that recognizes handprinted digits, using a combination of classical techniques and neural-net methods. The system has been trained and tested on real-world data, derived from zip codes seen on actual U.S. Mail. The system rejects a small percentage of the examples as unclassifiable, and achieves a very low error rate on the remaining examples. The system compares favorably with other state-of-the art recognizers. While some of the methods are specific to this task, it is hoped that many of the techniques will be applicable to a wide range of recognition tasks.", "authors": ["John S. Denker", "W. R. Gardner", "Hans Peter Graf", "Donnie Henderson", "R. E. Howard", "W. Hubbard", "L. D. Jackel", "Henry S. Baird", "Isabelle Guyon"], "related_topics": ["40969351", "50644808", "28490314"], "citation_count": "178", "reference_count": "11", "references": ["3017143921", "1655554306", "2155818555", "2116360511", "2058841211", "1501657095", "131259011", "2062361515", "2044630651", "2002448074"], "date": "1987"}, {"id": "938539187", "title": "Algorithms on Strings, Trees, and Sequences: Suffix Trees and Their Uses", "abstract": "", "authors": ["Dan Gusfield"], "related_topics": ["2781166958", "2779259728", "118146561"], "citation_count": "3685", "reference_count": "0", "references": ["2153233077", "2107282968", "2001496424", "2144544802", "2099256741", "2137786570", "2072193858", "2000041758", "2081028405", "2137721714"], "date": "1996"}, {"id": "1922192126", "title": "Resilience in Development", "abstract": "", "authors": ["Ann S Masten", "J. J. Cutuli", "Janette E. Herbers", "Marie Gabrielle J Reed"], "related_topics": ["2781089502", "15744967", "12505134"], "citation_count": "2997", "reference_count": "0", "references": ["2020137493", "119793660", "2164976997", "2160505695", "2475692488", "1933550849", "2155711087", "2116245877", "2095743514", "2080570400"], "date": "2009"}, {"id": "2085288146", "title": "Requirements interaction management", "abstract": "Requirements interaction management (RIM) is the set of activities directed toward the discovery, management, and disposition of critical relationships among sets of requirements, which has become a critical area of requirements engineering. This survey looks at the evolution of supporting concepts and their related literature, presents an issues-based framework for reviewing processes and products, and applies the framework in a review of RIM state-of-the-art. Finally, it presents seven research projects that exemplify this emerging discipline.", "authors": ["William N. Robinson", "Suzanne D. Pawlowski", "Vecheslav Volkov"], "related_topics": ["173577280", "2779718183", "6604083"], "citation_count": "313", "reference_count": "300", "references": ["2340735175", "2913459036", "2105539612", "2115309705", "2115179079", "1503170978", "1559870885", "1538749659", "1895273801", "2117189826"], "date": "2003"}, {"id": "2042264548", "title": "An introduction to computing with neural nets", "abstract": "Artificial neural net models have been studied for many years in the hope of achieving human-like performance in the fields of speech and image recognition. These models are composed of many nonlinear computational elements operating in parallel and arranged in patterns reminiscent of biological neural nets. Computational elements or nodes are connected via weights that are typically adapted during use to improve performance. There has been a recent resurgence in the field of artificial neural nets caused by new net topologies and algorithms, analog VLSI implementation techniques, and the belief that massive parallelism is essential for high performance speech and image recognition. This paper provides an introduction to the field of artificial neural nets by reviewing six important neural net models that can be used for pattern classification. These nets are highly parallel building blocks that illustrate neural net components and design principles and can be used to construct more complex systems. In addition to describing these nets, a major emphasis is placed on exploring how some existing classification and clustering algorithms can be performed using simple neuron-like components. Single-layer nets can implement algorithms required by Gaussian maximum-likelihood classifiers and optimum minimum-error classifiers for binary patterns corrupted by noise. More generally, the decision regions required by any classification algorithm can be generated in a straightforward manner by three-layer feed-forward nets.", "authors": ["Richard P. Lippmann"], "related_topics": ["50644808", "73555534", "34127721"], "citation_count": "12289", "reference_count": "0", "references": ["2156562940", "2017224880", "3001909141", "2015634532", "2016812413", "2132832266", "2113229797", "1973070179", "2536517113", "35336130"], "date": "1988"}, {"id": "2141282920", "title": "Labeling images with a computer game", "abstract": "We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.", "authors": ["Luis von Ahn", "Laura Dabbish"], "related_topics": ["3020701032", "503285160", "35674477"], "citation_count": "2875", "reference_count": "10", "references": ["1666447063", "1934863104", "2166770390", "1587328194", "2293605478", "2970081408", "2055225264", "2050457084", "181417509", "2612148268"], "date": "2004"}, {"id": "2149706766", "title": "Induction of Decision Trees", "abstract": "The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.", "authors": ["J. R. Quinlan"], "related_topics": ["56397880", "20837028", "135115379"], "citation_count": "25324", "reference_count": "24", "references": ["2159047538", "1527883571", "3021257214", "2067642555", "1488252886", "2026319679", "1693339475", "1483128843", "2894813436", "18968369"], "date": "1986"}, {"id": "1484228140", "title": "Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons", "abstract": "We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof. Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions. Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions. We also illustrate how the 3D texton model can be used to predict the appearance of materials under novel conditions.", "authors": ["Thomas Leung", "Jitendra Malik"], "related_topics": ["2779934759", "160497039", "50494287"], "citation_count": "2049", "reference_count": "44", "references": ["2170120409", "2117812871", "2138451337", "2130416410", "1997063559", "1634005169", "2116013899", "1481646516", "2123977795", "3017143921"], "date": "2001"}, {"id": "2170781632", "title": "Music synchronization arrangement", "abstract": "The invention generally pertains to a hand-held computing device. More particularly, the invention pertains to a computing device that is capable of controlling the speed of the music so as to affect the mood and behavior of the user during an activity such as exercise. By way of example, the speed of the music can be controlled to match the pace of the activity (synching the speed of the music to the activity of the user) or alternatively it can be controlled to drive the pace of the activity (increasing or decreasing the speed of the music to encourage a greater or lower pace). One aspect of the invention relates to adjusting the tempo (or some other attribute) of the music being outputted from the computing device. By way of example, a songs tempo may be increased or decreased before or during playing. Another aspect of the invention relates to selecting music for outputting based on tempo (or some other attribute). For example, the computing device may only play songs having a particular tempo. Yet another aspect of the invention relates to both selecting music based on tempo and adjusting the tempo of the music.", "authors": ["Adam Bowen"], "related_topics": ["10784920", "2777526511", "49774154"], "citation_count": "444", "reference_count": "99", "references": ["2103805423", "975671655", "1906732131", "1892925033", "1587730881", "2956259864", "1922204132", "1704430194", "2145786715", "1910000781"], "date": "2009"}, {"id": "3041304715", "title": "Intrinsic motivation and its role in psychological development", "abstract": "", "authors": ["J. McV. Hunt"], "related_topics": ["15744967", "180747234", "2985564149"], "citation_count": "473", "reference_count": "0", "references": ["1967489368", "2168076769", "2002022377", "2000514530", "2120864000", "2160269795", "1972888601", "2484231675", "2058495902", "2061557449"], "date": "1964"}, {"id": "2114207481", "title": "What is the role of dopamine in reward: hedonic impact, reward learning, or incentive salience?", "abstract": "What roles do mesolimbic and neostriatal dopamine systems play in reward? Do they mediate the hedonic impact of rewarding stimuli? Do they mediate hedonic reward learning and associati\u02dde prediction? Our review of the literature, together with results of a new study of residual reward capacity after dopamine depletion, indicates the answer to both questions is 'no'. Rather, dopamine systems may mediate the incenti\u02dde salience of rewards, modulating their motivational value in a manner separable from hedonia and reward learning. In a study of the consequences of dopamine loss, rats were depleted of dopamine in the nucleus accumbens and neostriatum by up to 99% using 6-hydroxydopamine. In a series of experiments, we applied the 'taste reactivity' measure of affective reactions gapes, .. . . etc. to assess the capacity of dopamine-depleted rats for: 1 normal affect hedonic and aversive reactions , 2 modulation of hedonic . . affect by associative learning taste aversion conditioning , and 3 hedonic enhancement of affect by non-dopaminergic pharmacological . manipulation of palatability benzodiazepine administration . We found normal hedonic reaction patterns to sucrose vs. quinine, normal . learning of new hedonic stimulus values a change in palatability based on predictive relations , and normal pharmacological hedonic enhancement of palatability. We discuss these results in the context of hypotheses and data concerning the role of dopamine in reward. We review neurochemical, electrophysiological, and other behavioral evidence. We conclude that dopamine systems are not needed either to mediate the hedonic pleasure of reinforcers or to mediate predictive associations involved in hedonic reward learning. We conclude instead that dopamine may be more important to incenti\u02dde salience attributions to the neural representations of reward-related stimuli. Incentive salience, we suggest, is a distinct component of motivation and reward. In other words, dopamine systems are necessary for ' wanting' incenti\u02ddes, but not for 'liking' them or for learning new 'likes' and 'dislikes'. q 1998 Elsevier Science B.V. All rights reserved.", "authors": ["Kent C Berridge", "Terry E Robinson"], "related_topics": ["143661069", "2780160660", "2983526489"], "citation_count": "4807", "reference_count": "500", "references": ["1748703215", "2117726420", "1966797434", "1849553904", "2106862702", "2006633893", "2164558494", "1977343123", "2042276900", "2090931660"], "date": "1998"}, {"id": "2085529605", "title": "Cognition in the wild", "abstract": "Welcome aboard navigation as computation the implementation of contemporary pilotage the organization of team performances communication navigation as a context for learning learning in context organizational learning cultural cognition.", "authors": ["Edwin Hutchins"], "related_topics": ["169735623", "2780591729", "80944243"], "citation_count": "16249", "reference_count": "0", "references": ["2112665591", "2153791616", "2163284576", "2139894798", "1500842519", "1996293917", "1787211267", "2109151141", "2113352630", "393180982"], "date": "1994"}, {"id": "3097096317", "title": "Robust Real-Time Face Detection", "abstract": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.", "authors": ["Paul Viola", "Michael J. Jones"], "related_topics": ["71681937", "4641261", "182521987"], "citation_count": "18902", "reference_count": "21", "references": ["3124955340", "2128272608", "2217896605", "2149706766", "2115763357", "1975846642", "2124351082", "2159686933", "2155511848", "2101522199"], "date": "2004"}, {"id": "255396808", "title": "Context in Web Search.", "abstract": "Web search engines generally treat search requests in isolation. The results for a given query are identical, independent of the user, or the context in which the user made the request. Nextgeneration search engines will make increasing use of context information, either by using explicit or implicit context information from users, or by implementing additional functionality within restricted contexts. Greater use of context in web search may help increase competition and diver-", "authors": ["Steve Lawrence"], "related_topics": ["164120249", "521815418", "166423231"], "citation_count": "509", "reference_count": "55", "references": ["2008620264", "3013264884", "2138621811", "2107252390", "2006119904", "2147164982", "1833785989", "1489992655", "2089192108", "2029341294"], "date": "1999"}, {"id": "2103212315", "title": "Receptive fields of single neurones in the cat's striate cortex", "abstract": "", "authors": ["D. H. Hubel", "T. N. Wiesel"], "related_topics": ["163931696", "168860233", "2779345533"], "citation_count": "5801", "reference_count": "12", "references": ["2253776861", "2037316494", "2212384750", "2110121211", "2010554296", "2110185620", "2027446612", "1999239216", "2009585478", "2419410066"], "date": "1959"}, {"id": "2108204150", "title": "Language support for lightweight transactions", "abstract": "Concurrent programming is notoriously difficult. Current abstractions are intricate and make it hard to design computer systems that are reliable and scalable. We argue that these problems can be addressed by moving to a declarative style of concurrency control in which programmers directly indicate the safety properties that they require. In our scheme the programmer demarks sections of code which execute within lightweight software-based transactions that commit atomically and exactly once. These transactions can update shared data, instantiate objects, invoke library features and so on. They can also block, waiting for arbitrary boolean conditions to become true. Transactions which do not access the same shared memory locations can commit concurrently. Furthermore, in general, no performance penalty is incurred for memory accesses outside transactions.We present a detailed design of this proposal along with an implementation and evaluation. We argue that the resulting system (i) is easier for mainstream programmers to use, (ii) prevents lock-based priority-inversion and deadlock problems and (iii) can offer performance advantages.", "authors": ["Tim Harris", "Keir Fraser"], "related_topics": ["167149655", "134277064", "84511453"], "citation_count": "998", "reference_count": "35", "references": ["1555915743", "3144368627", "1514258760", "2105055683", "2914559425", "2113751407", "2167282885", "2769656678", "2029601347", "2083803628"], "date": "2003"}, {"id": "2138442469", "title": "Carrier-phase inter-frequency biases of GLONASS receivers", "abstract": "The frequency division multiplexing of the GLONASS signals causes inter-frequency biases in the receiving equipment. These biases vary considerably for receivers from different manufacturers and thus complicate or prevent carrier-phase ambiguity fixing. Complete and reliable ambiguity fixing requires a priori information of the carrier-phase inter-frequency bias differences of the receivers involved. GLONASS carrier-phase inter-frequency biases were estimated for 133 individual receivers from 9 manufacturers. In general, receivers of the same type and even receivers from the same manufacturer show similar biases, whereas the differences among manufacturers can reach up to 0.2 ns (more than 5 cm) for adjacent frequencies and thus up to 2.4 ns (73 cm) for the complete L1 or L2 frequency bands. A few individual receivers were identified whose inter-frequency biases behave differently as compared to other receivers of the same type or whose biases vary with time.", "authors": ["Lambert Wanninger"], "related_topics": ["89061704", "102451475", "92545706"], "citation_count": "215", "reference_count": "12", "references": ["2140050818", "1671302640", "1545923740", "2291985881", "2127397868", "2728658870", "2586001072", "2210911943", "593810833", "2464126377"], "date": "2012"}, {"id": "1959608418", "title": "Auto-Encoding Variational Bayes", "abstract": "Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.", "authors": ["Diederik P Kingma", "Max Welling"], "related_topics": ["2777472644", "2776214188", "185429906"], "citation_count": "13487", "reference_count": "15", "references": ["2146502635", "2163922914", "2145094598", "2166851633", "2097268041", "2963173382", "2951493172", "2171490498", "2119196781", "3104819538"], "date": "2013"}, {"id": "2153233077", "title": "Survey of clustering algorithms", "abstract": "Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. The diversity, on one hand, equips us with many tools. On the other hand, the profusion of options causes confusion. We survey clustering algorithms for data sets appearing in statistics, computer science, and machine learning, and illustrate their applications in some benchmark data sets, the traveling salesman problem, and bioinformatics, a new field attracting intensive efforts. Several tightly related topics, proximity measure, and cluster validation, are also discussed.", "authors": ["Rui Xu", "D. Wunsch"], "related_topics": ["73555534", "34127721", "2522767166"], "citation_count": "6785", "reference_count": "287", "references": ["2912565176", "2158714788", "2148603752", "2124776405", "2055043387", "1497256448", "1554663460", "2168909179", "2139212933", "2053186076"], "date": "2005"}, {"id": "2082092506", "title": "THE POPULATION FREQUENCIES OF SPECIES AND THE ESTIMATION OF POPULATION PARAMETERS", "abstract": "", "authors": ["I. J. Good"], "related_topics": ["2908647359", "96250715", "105795698"], "citation_count": "4448", "reference_count": "20", "references": ["2037959956", "1995875735", "1680579736", "2079656678", "2087189381", "2146368895", "1981778072", "3015462599", "2153478504", "2021262032"], "date": "1953"}, {"id": "2164740236", "title": "Data center TCP (DCTCP)", "abstract": "Cloud data centers host diverse applications, mixing workloads that require small predictable latency with others requiring large sustained throughput. In this environment, today's state-of-the-art TCP protocol falls short. We present measurements of a 6000 server production cluster and reveal impairments that lead to high application latencies, rooted in TCP's demands on the limited buffer space available in data center switches. For example, bandwidth hungry \"background\" flows build up queues at the switches, and thus impact the performance of latency sensitive \"foreground\" traffic.To address these problems, we propose DCTCP, a TCP-like protocol for data center networks. DCTCP leverages Explicit Congestion Notification (ECN) in the network to provide multi-bit feedback to the end hosts. We evaluate DCTCP at 1 and 10Gbps speeds using commodity, shallow buffered switches. We find DCTCP delivers the same or better throughput than TCP, while using 90% less buffer space. Unlike TCP, DCTCP also provides high burst tolerance and low latency for short flows. In handling workloads derived from operational measurements, we found DCTCP enables the applications to handle 10X the current background traffic, without impacting foreground traffic. Further, a 10X increase in foreground traffic does not cause any timeouts, thus largely eliminating incast problems.", "authors": ["Mohammad Alizadeh", "Albert Greenberg", "David A. Maltz", "Jitendra Padhye", "Parveen Patel", "Balaji Prabhakar", "Sudipta Sengupta", "Murari Sridharan"], "related_topics": ["101452262", "33588617", "61298376"], "citation_count": "2023", "reference_count": "32", "references": ["2130531694", "2055176966", "2158733823", "2126210439", "2022844530", "2062832101", "2133581580", "1867902620", "2145942024", "1965095275"], "date": "2010"}, {"id": "2042986967", "title": "An Effective Heuristic Algorithm for the Traveling-Salesman Problem", "abstract": "This paper discusses a highly effective heuristic procedure for generating optimum and near-optimum solutions for the symmetric traveling-salesman problem. The procedure is based on a general approach to heuristics that is believed to have wide applicability in combinatorial optimization problems. The procedure produces optimum solutions for all problems tested, \"classical\" problems appearing in the literature, as well as randomly generated test problems, up to 110 cities. Run times grow approximately as n2; in absolute terms, a typical 100-city problem requires less than 25 seconds for one case GE635, and about three minutes to obtain the optimum with above 95 per cent confidence.", "authors": ["S. Lin", "B. W. Kernighan"], "related_topics": ["103888782", "51823790", "106472803"], "citation_count": "4727", "reference_count": "11", "references": ["2161455936", "2148673189", "2009803313", "1969186119", "2037455079", "2058937865", "2056898464", "1992928037", "2106378689", "2142022975"], "date": "1973"}, {"id": "2131806657", "title": "Three-dimensional object recognition from single two-dimensional images", "abstract": "Abstract A computer vision system has been implemented that can recognize three-dimensional objects from unknown viewpoints in single gray-scale images. Unlike most other approaches, the recognition is accomplished without any attempt to reconstruct depth information bottom-up from the visual input. Instead, three other mechanisms are used that can bridge the gap between the two-dimensional image and knowledge of three-dimensional objects. First, a process of perceptual organization is used to form groupings and structures in the image that are likely to be invariant over a wide range of viewpoints. Second, a probabilistic ranking method is used to reduce the size of the search space during model-based matching. Finally, a process of spatial correspondence brings the projections of three-dimensional models into direct correspondence with the image by solving for unknown viewpoint and model parameters. A high level of robustness in the presence of occlusion and missing data can be achieved through full application of a viewpoint consistency constraint. It is argued that similar mechanisms and constraints form the basis for recognition in human vision.", "authors": ["D G Lowe"], "related_topics": ["64876066", "49937458", "49209780"], "citation_count": "1994", "reference_count": "30", "references": ["2085261163", "1933657216", "2003370853", "1532977286", "1513966746", "2337770697", "2125756925", "2130355536", "2037732452", "2943272530"], "date": "1987"}, {"id": "1983078185", "title": "Feature selection, perceptron learning, and a usability case study for text categorization", "abstract": "", "authors": ["Hwee Tou Ng", "Wei Boon Goh", "Kok Leong Low"], "related_topics": ["170130773", "60908668", "148483581"], "citation_count": "739", "reference_count": "11", "references": ["1969572066", "2060216474", "2094934653", "2058982198", "3037715718", "1594962278", "1993934121", "1539741229", "2049384587", "2127994451"], "date": "1997"}, {"id": "2152578812", "title": "Thematic Relations as Links between Nominal Reference and Temporal Constitution", "abstract": "This paper treats the correspondence between the reference type of NPs (i.e., mass nouns, count nouns, measure constructions, plurals) and the temporal constitution of verbal predicates (i.e., activities, accomplishments). A theory will be developed that handles the well known influence of the reference type of NPs in argument positions on the temporal constitution of the verbal expressions, assuming an event semantics with lattice structures and thematic roles as primitive relations between events and objects. Some consequences for the theory of thematic roles will be discussed, and the effect of partitive case marking on the verbal aspect, as in Finnish, and of aspectual marking on the definiteness of NPs, like in Slavic, will be explained.", "authors": ["Manfred Krifka"], "related_topics": ["2781128744", "15262923", "2779056149"], "citation_count": "690", "reference_count": "23", "references": ["1687416839", "2025589690", "2134199742", "1522746076", "172114924", "1526125566", "1980491396", "2150613911", "1990673309", "14213647"], "date": "1991"}, {"id": "2040336387", "title": "On the structure of vector quantizers", "abstract": "Vector quantization is intrinsically superior to predictive coding, transform coding, and other suboptimal and {\\em ad hoc} procedures since it achieves optimal rate distortion performance subject only to a constraint on memory or block length of the observable signal segment being encoded. The key limitation of existing techniques is the very large randomly generated code books which must be stored, and the computational complexity of the associated encoding procedures. The quantization operation is decomposed into its rudimentary structural components. This leads to a simple and elegant approach to derive analytical properties of optimal quantizers. Some useful properties of quantizers and algorithmic approaches are given, which are relevant to the complexity of both storage and processing in the encoding operation. Highly disordered quantizers, which have been designed using a clustering algorithm, are considered. Finally, lattice quantizers are examined which circumvent the need for a code book by using a highly structured code based on lattices. The code vectors are algorithmically generated in a simple manner rather than stored in a code book, and fast algorithms perform the encoding algorithm with negligible complexity.", "authors": ["A. Gersho"], "related_topics": ["199833920", "93372532", "28855332"], "citation_count": "472", "reference_count": "17", "references": ["2134383396", "2127218421", "2583466288", "2142228262", "1973387369", "1489608363", "2120788459", "2010140249", "1631408262", "1773793659"], "date": "1982"}, {"id": "2005522417", "title": "The Strong Limits of Random Matrix Spectra for Sample Matrices of Independent Elements", "abstract": "This paper proves almost-sure convergence of the empirical measure of the normalized singular values of increasing rectangular submatrices of an infinite random matrix of independent elements. The limit is the limit as both dimensions grow large in some ratio. The matrix elements are required to have uniformly bounded central $2 + \\delta$th moments, and the same means and variances within a row. The first section (relaxing the restriction on variances) proves any limit-in-distribution to be a constant measure rather than a random measure, establishes the existence of subsequences convergent in probability, and gives a criterion for almost-sure convergence. The second section proves the almost-sure limit to exist whenever the distribution of the row variances converges. It identifies the limit as a nonrandom probability measure which may be evaluated as a function of the limiting distribution of row variances and the dimension ratio. These asymptotic formulae underlie recently developed methods of probability plotting for principal components and have applications to multiple discriminant ratios and other linear multivariate statistics.", "authors": ["Kenneth W. Wachter"], "related_topics": ["95763700", "166785042", "138405894"], "citation_count": "335", "reference_count": "13", "references": ["614206231", "2800778781", "2314942319", "2165918462", "1972337487", "1516255585", "2159394808", "2105077595", "2033227498", "2016728083"], "date": "1978"}, {"id": "2008114373", "title": "Tensor decomposition of EEG signals: A brief review", "abstract": "Electroencephalography (EEG) is one fundamental tool for functional brain imaging. EEG signals tend to be represented by a vector or a matrix to facilitate data processing and analysis with generally understood methodologies like time-series analysis, spectral analysis and matrix decomposition. Indeed, EEG signals are often naturally born with more than two modes of time and space, and they can be denoted by a multi-way array called as tensor. This review summarizes the current progress of tensor decomposition of EEG signals with three aspects. The first is about the existing modes and tensors of EEG signals. Second, two fundamental tensor decomposition models, canonical polyadic decomposition (CPD, it is also called parallel factor analysis-PARAFAC) and Tucker decomposition, are introduced and compared. Moreover, the applications of the two models for EEG signals are addressed. Particularly, the determination of the number of components for each mode is discussed. Finally, the N-way partial least square and higher-order partial least square are described for a potential trend to process and analyze brain signals of two modalities simultaneously.", "authors": ["Fengyu Cong", "", "Qiu-Hua Lin", "Li-Dan Kuang", "Xiao-Feng Gong", "Piia Astikainen", "Tapani Ristaniemi"], "related_topics": ["42704193", "42355184", "107180903"], "citation_count": "232", "reference_count": "99", "references": ["1663973292", "2024165284", "1548802052", "2128495200", "2099741732", "2153134014", "1246381107", "1755563775", "1536620489", "2119412403"], "date": "2015"}, {"id": "2611015177", "title": "Generalized Low Rank Approximations of Matrices", "abstract": "The problem of computing low rank approximations of matrices is considered. The novel aspect of our approach is that the low rank approximations are on a collection of matrices. We formulate this as an optimization problem, which aims to minimize the reconstruction (approximation) error. To the best of our knowledge, the optimization problem proposed in this paper does not admit a closed form solution. We thus derive an iterative algorithm, namely GLRAM, which stands for the Generalized Low Rank Approximations of Matrices. GLRAM reduces the reconstruction error sequentially, and the resulting approximation is thus improved during successive iterations. Experimental results show that the algorithm converges rapidly. We have conducted extensive experiments on image data to evaluate the effectiveness of the proposed algorithm and compare the computed low rank approximations with those obtained from traditional Singular Value Decomposition (SVD) based methods. The comparison is based on the reconstruction error, misclassification error rate, and computation time. Results show that GLRAM is competitive with SVD for classification, while it has a much lower computation cost. However, GLRAM results in a larger reconstruction error than SVD. To further reduce the reconstruction error, we study the combination of GLRAM and SVD, namely GLRAM + SVD, where SVD is preceded by GLRAM. Results show that when using the same number of reduced dimensions, GLRAM + SVD achieves significant reduction of the reconstruction error as compared to GLRAM, while keeping the computation cost low.", "authors": ["Jieping Ye"], "related_topics": ["22789450", "1026927", "159694833"], "citation_count": "655", "reference_count": "28", "references": ["2798909945", "2147152072", "2102544846", "1770825568", "2994340921", "2006793117", "2045512849", "2063392856", "2072773380", "1790954942"], "date": "2005"}, {"id": "3005363104", "title": "Biorthogonal bases of compactly supported wavelets", "abstract": "Orthonormal bases of compactly supported wavelet bases correspond to subband coding schemes with exact reconstruction in which the analysis and synthesis filters coincide. We show here that under fairly general conditions, exact reconstruction schemes with synthesis filters different from the analysis filters give rise: to two dual Riesz bases of compactly supported wavelets. We give necessary and sufficient conditions for biorthogonality of the corresponding scaling functions, and we present a sufficient condition for the decay of their Fourier transforms. We study the regularity of these biorthogonal bases. We provide several families of examples, all symmetric (corresponding to \u201clinear phase\u201d filters). In particular we can construct symmetric biorthogonal wavelet bases with arbitrarily high preassigned regularity; we also show how to construct symmetric biorthogonal wavelet bases \u201cclose\u201d to a (nonsymmetric) orthonormal basis.", "authors": ["A. Cohen", "Ingrid Daubechies", "J.-C. Feauveau"], "related_topics": ["2778869661", "158453530", "180493991"], "citation_count": "4062", "reference_count": "25", "references": ["2098914003", "1996021349", "2148593155", "1980149518", "2149072817", "3132971798", "2087377426", "1975474302", "2140832824", "2088277224"], "date": "1992"}, {"id": "2006119904", "title": "Automatic resource compilation by analyzing hyperlink structure and associated text", "abstract": "We describe the design, prototyping and evaluation of ARC, a system for automatically compiling a list of authoritative Web resources on any (sufficiently broad) topic. The goal of ARC is to compile resource lists similar to those provided by Yahoo! or Infoseek. The fundamental difference is that these services construct lists either manually or through a combination of human and automated effort, while ARC operates fully automatically. We describe the evaluation of ARC, Yahoo!, and Infoseek resource lists by a panel of human users. This evaluation suggests that the resources found by ARC frequently fare almost as well as, and sometimes better than, lists of resources that are manually compiled or classified into a topic. We also provide examples of ARC resource lists for the reader to examine.", "authors": ["Soumen Chakrabarti", "Byron Dom", "Prabhakar Raghavan", "Sridhar Rajagopalan", "David Gibson", "Jon Kleinberg"], "related_topics": ["195409031", "65603577", "30088001"], "citation_count": "1136", "reference_count": "11", "references": ["3013264884", "2138621811", "2798909945", "2037498077", "2145311040", "2095150974", "2051804774", "2028406909", "2059275719", "2041333730"], "date": "1998"}, {"id": "1555915743", "title": "Computer Architecture: A Quantitative Approach", "abstract": "This best-selling title, considered for over a decade to be essential reading for every serious student and practitioner of computer design, has been updated throughout to address the most important trends facing computer designers today. In this edition, the authors bring their trademark method of quantitative analysis not only to high-performance desktop machine design, but also to the design of embedded and server systems. They have illustrated their principles with designs from all three of these domains, including examples from consumer electronics, multimedia and Web technologies, and high-performance computing.", "authors": ["John L. Hennessy", "David A. Patterson"], "related_topics": ["2779027411", "49774154", "123657996"], "citation_count": "19245", "reference_count": "0", "references": ["2606722458", "2169875292", "1992876548", "2133865602", "2002555321", "2076257979", "2170382128", "1686420892", "2079942837", "2397423248"], "date": "1989"}, {"id": "2038281539", "title": "A foundation for the study of group decision support systems", "abstract": "Technical developments in electronic communication, computing, and decision support, coupled with new interest on the part of organizations to improve meeting effectiveness, are spurring research in the area of group decision support systems GDSS. A GDSS combines communication, computing, and decision support technologies to facilitate formulation and solution of unstructured problems by a group of people. This paper presents a conceptual overview of GDSS based on an information-exchange perspective of decision making, Three levels of systems are described, representing varying degrees of intervention into the decision process. Research on GDSS is conceived as evolving over time from the study of simple \"shell\" systems, consisting of menus of features available for selection by a group, to consideration of sophisticated rule-based systems that enable a group to pursue highly structured and novel decision paths. A multi-dimensional taxonomy of systems is proposed as an organizing framework for research in the area. Three environmental contingencies are identified as critical to GDSS design: group size, member proximity, and the task confronting the group. Potential impacts of GDSS on group processes and outcomes are discussed, and important constructs in need of study are identified.", "authors": ["Gerardine DeSanctis", "R. Brent Gallupe"], "related_topics": ["107327155", "20701700", "28901747"], "citation_count": "3155", "reference_count": "70", "references": ["1978133464", "1975273460", "1971167516", "2023380077", "1489270652", "2070509150", "2118847637", "1967315595", "1527944521", "2066699491"], "date": "1987"}, {"id": "2058815839", "title": "Information Theory and an Extension of the Maximum Likelihood Principle", "abstract": "In this paper it is shown that the classical maximum likelihood principle can be considered to be a method of asymptotic realization of an optimum estimate with respect to a very general information theoretic criterion. This observation shows an extension of the principle to provide answers to many practical problems of statistical model fitting.", "authors": ["Hirotogu Akaike"], "related_topics": ["189559763", "89106044", "168136583"], "citation_count": "28611", "reference_count": "23", "references": ["1995875735", "2110429782", "2123838014", "2045638068", "2070681743", "2061317273", "1965761421", "2993383518", "1965555277", "2092369573"], "date": "1972"}, {"id": "1996293917", "title": "Using Technology and Constituting Structures: A Practice Lens for Studying Technology in Organizations", "abstract": "As both technologies and organizations undergo dramatic changes in form and function, organizational researchers are increasingly turning to concepts of innovation, emergence, and improvisation to help explain the new ways of organizing and using technology evident in practice. With a similar intent, I propose an extension to the structurational perspective on technology that develops a practice lens to examine how people, as they interact with a technology in their ongoing practices, enact structures which shape their emergent and situated use of that technology. Viewing the use of technology as a process of enactment enables a deeper understanding of the constitutive role of social practices in the ongoing use and change of technologies in the workplace. After developing this lens, I offer an example of its use in research, and then suggest some implications for the study of technology in organizations.", "authors": ["Wanda J. Orlikowski"], "related_topics": ["547231352", "121017731", "3020028006"], "citation_count": "5974", "reference_count": "97", "references": ["201578715", "2085529605", "2101419153", "2150587481", "1515810707", "2026645894", "2118243939", "3126349953", "2134230545", "2108752510"], "date": "2000"}, {"id": "2012903341", "title": "On the capabilities of multilayer perceptrons", "abstract": "Abstract What is the smallest multilayer perceptron able to compute arbitrary and random functions? Previous results show that a net with one hidden layer containing N \u2212 1 threshold units is capable of implementing an arbitrary dichotomy of N points. A construction is presented here for implementing an arbitrary dichotomy with one hidden layer containing [ N d ] units, for any set of N points in general position in d dimensions. This is in fact the smallest such net as dichotomies which cannot be implemented by any net with fewer units are described. Several constructions are presented of one-hidden-layer nets implementing arbitrary functions into the e-dimensional hypercube. One of these has only [ 4N d ][ e [ log 2 ( N d) ]] units in its hidden layer. Arguments based on a function counting theorem of Cover establish that any net implementing arbitrary functions must have at least Ne log 2 (N) weights, so that no net with one hidden layer containing less than Ne/(d log2(N)) units will suffice. Simple counts also show that if the weights are only allowed to assume one of ng possible values, no net with fewer than Ne log 2 (n g ) weights will suffice. Thus the gain coming from using real valued synapses appears to be only logarithmic. The circuit implementing functions into the e hypercube realizes such logarithmic gains. Since the counting arguments limit below only the number of weights, the possibility is suggested that, if suitable restrictions are imposed on the input vector set to avoid topological obstructions, two-hidden-layer nets with O(N) weights but only O(\u221aN) threshold units might suffice for arbitrary dichotomies. Interesting and potentially sufficient restrictions include (a) if the vectors are binary, i.e., lie on the d hypercube or (b) if they are randomly and uniformly selected from a bounded region.", "authors": ["Eric B. Baum"], "related_topics": ["50820777", "34388435", "58442840"], "citation_count": "387", "reference_count": "29", "references": ["2154642048", "2293063825", "1554576613", "1507849272", "3036751298", "2178806388", "1547224907", "2414319931", "3121926921", "1977827719"], "date": "1988"}, {"id": "2167077256", "title": "Robust analysis of feature spaces: color image segmentation", "abstract": "A general technique for the recovery of significant image features is presented. The technique is based on the mean shift algorithm, a simple nonparametric procedure for estimating density gradients. Drawbacks of the current methods (including robust clustering) are avoided. Feature space of any nature can be processed, and as an example, color image segmentation is discussed. The segmentation is completely autonomous, only its class is chosen by the user. Thus, the same program can produce a high quality edge image, or provide, by extracting all the significant colors, a preprocessor for content-based query systems. A 512/spl times/512 color image is analyzed in less than 10 seconds on a standard workstation. Gray level images are handled as color images having only the lightness coordinate.", "authors": ["D. Comaniciu", "P. Meer"], "related_topics": ["124504099", "142616399", "12043971"], "citation_count": "1148", "reference_count": "10", "references": ["1971784203", "2160066518", "2022686119", "2129249398", "2008297189", "2098152234", "2051826135", "2171124048", "1974684941", "31292679"], "date": "1997"}, {"id": "2070681743", "title": "Fitting autoregressive models for prediction", "abstract": "This is a preliminary report on a newly developed simple and practical procedure of statistical identification of predictors by using autoregressive models. The use of autoregressive representation of a stationary time series (or the innovations approach) in the analysis of time series has recently been attracting attentions of many research workers and it is expected that this time domain approach will give answers to many problems, such as the identification of noisy feedback systems, which could not be solved by the direct application of frequency domain approach [1], [2], [3], [9].", "authors": ["Hirotugu Akaike"], "related_topics": ["30795276", "194657046", "24338571"], "citation_count": "3500", "reference_count": "10", "references": ["2060605975", "1587896874", "399411018", "2590182569", "2079270725", "2030933600", "2949303161", "2156921055", "2097431296", "2077193525"], "date": "1969"}, {"id": "2060968961", "title": "The processing of hexagonally sampled two-dimensional signals", "abstract": "Two-dimensional signals are normally processed as rectangularly sampled arrays; i.e., they are periodically sampled in each of two orthogonal independent variables. Another form of periodic sampling, hexagonal sampling, offers substantial savings in machine storage and arithmetic computations for many signal processing operations. In this paper, methods for the processing of two-dimensional signals which have been sampled as two-dimensional hexagonal arrays are presented. Included are methods for signal representation, linear system implementation, frequency response calculation, DFT calculation, filter design, and filter implementation. These algorithms bear strong resemblances to the corresponding results for rectangular arrays; however, there are also many important differences. Some comparisons between the two methods for representing planar data will also be presented.", "authors": ["R.M. Mersereau"], "related_topics": ["2778707140", "36390408", "22597639"], "citation_count": "534", "reference_count": "26", "references": ["1622620102", "1976678415", "1996342882", "2040612424", "2139117407", "1975048877", "2172247275", "1988501608", "2114190335", "2086704454"], "date": "1979"}, {"id": "2137676365", "title": "Nonlinear anisotropic filtering of MRI data", "abstract": "In contrast to acquisition-based noise reduction methods a postprocess based on anisotropic diffusion is proposed. Extensions of this technique support 3-D and multiecho magnetic resonance imaging (MRI), incorporating higher spatial and spectral dimensions. The procedure overcomes the major drawbacks of conventional filter methods, namely the blurring of object boundaries and the suppression of fine structural details. The simplicity of the filter algorithm permits an efficient implementation, even on small workstations. The efficient noise reduction and sharpening of object boundaries are demonstrated by applying this image processing technique to 2-D and 3-D spin echo and gradient echo MR data. The potential advantages for MRI, diagnosis, and computerized analysis are discussed in detail. >", "authors": ["G. Gerig", "O. Kubler", "R. Kikinis", "F.A. Jolesz"], "related_topics": ["203504353", "204036478", "163294075"], "citation_count": "1511", "reference_count": "12", "references": ["2145023731", "2150134853", "2105364438", "2629881577", "2035246484", "2067676439", "2021444775", "2084814298", "1551993394", "2569565593"], "date": "1991"}, {"id": "2004617458", "title": "Metaheuristics in combinatorial optimization: Overview and conceptual comparison", "abstract": "The field of metaheuristics for the application to combinatorial optimization problems is a rapidly growing field of research. This is due to the importance of combinatorial optimization problems for the scientific as well as the industrial world. We give a survey of the nowadays most important metaheuristics from a conceptual point of view. We outline the different components and concepts that are used in the different metaheuristics in order to analyze their similarities and differences. Two very important concepts in metaheuristics are intensification and diversification. These are the two forces that largely determine the behavior of a metaheuristic. They are in some way contrary but also complementary to each other. We introduce a framework, that we call the I&D frame, in order to put different intensification and diversification components into relation with each other. Outlining the advantages and disadvantages of different metaheuristic approaches we conclude by pointing out the importance of hybridization of metaheuristics as well as the integration of metaheuristics and other methods for optimization.", "authors": ["Christian Blum", "Andrea Roli"], "related_topics": ["28767586", "109718341", "52692508"], "citation_count": "4380", "reference_count": "168", "references": ["1639032689", "1497256448", "1573676079", "2107941094", "2581275558", "2097571405", "2011039300", "2154929945", "2152150600", "2339500526"], "date": "2003"}, {"id": "3012789146", "title": "The effect of control strategies to reduce social mixing on outcomes of the COVID-19 epidemic in Wuhan, China: a modelling study.", "abstract": "BACKGROUND: In December, 2019, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), a novel coronavirus, emerged in Wuhan, China. Since then, the city of Wuhan has taken unprecedented measures in response to the outbreak, including extended school and workplace closures. We aimed to estimate the effects of physical distancing measures on the progression of the COVID-19 epidemic, hoping to provide some insights for the rest of the world. METHODS: To examine how changes in population mixing have affected outbreak progression in Wuhan, we used synthetic location-specific contact patterns in Wuhan and adapted these in the presence of school closures, extended workplace closures, and a reduction in mixing in the general community. Using these matrices and the latest estimates of the epidemiological parameters of the Wuhan outbreak, we simulated the ongoing trajectory of an outbreak in Wuhan using an age-structured susceptible-exposed-infected-removed (SEIR) model for several physical distancing measures. We fitted the latest estimates of epidemic parameters from a transmission model to data on local and internationally exported cases from Wuhan in an age-structured epidemic framework and investigated the age distribution of cases. We also simulated lifting of the control measures by allowing people to return to work in a phased-in way and looked at the effects of returning to work at different stages of the underlying outbreak (at the beginning of March or April). FINDINGS: Our projections show that physical distancing measures were most effective if the staggered return to work was at the beginning of April; this reduced the median number of infections by more than 92% (IQR 66-97) and 24% (13-90) in mid-2020 and end-2020, respectively. There are benefits to sustaining these measures until April in terms of delaying and reducing the height of the peak, median epidemic size at end-2020, and affording health-care systems more time to expand and respond. However, the modelled effects of physical distancing measures vary by the duration of infectiousness and the role school children have in the epidemic. INTERPRETATION: Restrictions on activities in Wuhan, if maintained until April, would probably help to delay the epidemic peak. Our projections suggest that premature and sudden lifting of interventions could lead to an earlier secondary peak, which could be flattened by relaxing the interventions gradually. However, there are limitations to our analysis, including large uncertainties around estimates of R0 and the duration of infectiousness. FUNDING: Bill & Melinda Gates Foundation, National Institute for Health Research, Wellcome Trust, and Health Data Research UK.", "authors": ["Kiesha Prem", "Yang Liu", "Timothy W Russell", "Adam J Kucharski", "Rosalind M Eggo", "Nicholas Davies", "Mark Jit", "Petra Klepac"], "related_topics": ["27415008", "116675565", "149923435"], "citation_count": "1361", "reference_count": "43", "references": ["3001897055", "3003668884", "3002539152", "3003573988", "3006659024", "3009577418", "3009468976", "3004912618", "3004026249", "3020184843"], "date": "2020"}, {"id": "2052207834", "title": "Universal classes of hash functions", "abstract": "Abstract This paper gives an input independent average linear time algorithm for storage and retrieval on keys. The algorithm makes a random choice of hash function from a suitable class of hash functions. Given any sequence of inputs the expected time (averaging over all functions in the class) to store and retrieve elements is linear in the length of the sequence. The number of references to the data base required by the algorithm for any input is extremely close to the theoretical minimum for any possible hash function with randomly distributed inputs. We present three suitable classes of hash functions which also can be evaluated rapidly. The ability to analyze the cost of storage and retrieval without worrying about the distribution of the input allows as corollaries improvements on the bounds of several algorithms.", "authors": ["J.Lawrence Carter", "Mark N. Wegman"], "related_topics": ["99138194", "138111711", "108546238"], "citation_count": "3731", "reference_count": "15", "references": ["1655990431", "2752853835", "1600795850", "1964053266", "2087966340", "2059442002", "1994556169", "2027085566", "1568754185", "2118132754"], "date": "1979"}, {"id": "1902027874", "title": "Learning the parts of objects by non-negative matrix factorization", "abstract": "Is perception of the whole based on perception of its parts? There is psychological1 and physiological2,3 evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations4,5. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.", "authors": ["Daniel D. Lee", "H. Sebastian Seung", ""], "related_topics": ["152671427", "42355184", "68841619"], "citation_count": "12805", "reference_count": "23", "references": ["2138451337", "2108384452", "2049633694", "1956559956", "2145889472", "1983578042", "1996355918", "1993845689", "2156406284", "2180838288"], "date": "1999"}, {"id": "2126641717", "title": "Graph bisection algorithms with good average case behavior", "abstract": "In the paper, we describe a polynomial time algorithm that, for every input graph, either outputs the minimum bisection of the graph or halts without output. More importantly, we show that the algorithm chooses the former course with high probability for many natural classes of graphs. In particular, for every fixedd\u22673, all sufficiently largen and allb=o(n 1\u22121/[(d+1)/2]), the algorithm finds the minimum bisection for almost alld-regular labelled simple graphs with 2n nodes and bisection widthb. For example, the algorithm succeeds for almost all 5-regular graphs with 2n nodes and bisection widtho(n 2/3). The algorithm differs from other graph bisection heuristics (as well as from many heuristics for other NP-complete problems) in several respects. Most notably:", "authors": ["Thang Nguyen Bui", "F. Thomson Leighton", "Soma Chaudhuri", "Michael Sipser"], "related_topics": ["88230418", "134727501", "311688"], "citation_count": "458", "reference_count": "14", "references": ["2581275558", "2011039300", "2095117703", "2161455936", "2030087828", "2038643780", "2156760067", "1982180670", "2029282358", "2091476183"], "date": "1987"}, {"id": "2143801939", "title": "Time in the mind: Using space to think about time", "abstract": "How do we construct abstract ideas like justice, mathematics, or time-travel? In this paper we investigate whether mental representations that result from physical experience underlie people's more abstract mental representations, using the domains of space and time as a testbed. People often talk about time using spatial language (e.g., a long vacation, a short concert). Do people also think about time using spatial representations, even when they are not using language? Results of six psychophysical experiments revealed that people are unable to ignore irrelevant spatial information when making judgments about duration, but not the converse. This pattern, which is predicted by the asymmetry between space and time in linguistic metaphors, was demonstrated here in tasks that do not involve any linguistic stimuli or responses. These findings provide evidence that the metaphorical relationship between space and time observed in language also exists in our more basic representations of distance and duration. Results suggest that our mental representations of things we can never see or touch may be built, in part, out of representations of physical experiences in perception and motor action.", "authors": ["Daniel Casasanto", "", "Lera Boroditsky"], "related_topics": ["96199812", "2778662690", "48164120"], "citation_count": "1729", "reference_count": "36", "references": ["1968060331", "2052417512", "2133735566", "1968133283", "2164442644", "2105799497", "2123987305", "2040300040", "1517744545", "2134968220"], "date": "2008"}, {"id": "1805475080", "title": "An application of least squares fit mapping to clinical classification.", "abstract": "Abstract This paper describes a unique approach, \"Least Square Fit Mapping,\" to clinical data classification. We use large collections of human-assigned text-to-category matches as training sets to compute the correlations between physicians' terms and canonical concepts. A Linear Least Squares Fit (LLSF) technique is employed to obtain a mapping function which optimally fits the known matches given in a training set and probabilistically captures the unknown matches for arbitrary texts. We tested our method with 16,032 texts from the Mayo Clinic, and judged the results using human-assigned answers. In a test for comparison, the LLSF mapping achieved a precision rate of 89% at 100% recall, outperforming alternative approaches including string matching (36% precision), string matching enhanced by morphological parsing (51% precision), and statistical weighting (61% precision).", "authors": ["Y. Yang", "C. G. Chute"], "related_topics": ["7757238", "2780724565", "183115368"], "citation_count": "17", "reference_count": "0", "references": ["2012560661", "1605641357", "2090756040", "2121869529", "2122793307", "1921911983", "1936921604", "2121267030", "2142292312", "2294015730"], "date": "1991"}, {"id": "2103559027", "title": "Nonlinear total variation based noise removal algorithms", "abstract": "A constrained optimization type of numerical algorithm for removing noise from images is presented. The total variation of the image is minimized subject to constraints involving the statistics of the noise. The constraints are imposed using Lagrange multipliers. The solution is obtained using the gradient-projection method. This amounts to solving a time dependent partial differential equation on a manifold determined by the constraints. As t---~ 0o the solution converges to a steady state which is the denoised image. The numerical algorithm is simple and relatively fast. The results appear to be state-of-the-art for very noisy images. The method is noninvasive, yielding sharp edges in the image. The technique could be interpreted as a first step of moving each level set of the image normal to itself with velocity equal to the curvature of the level set divided by the magnitude of the gradient of the image, and a second step which projects the image back onto the constraint set.", "authors": ["Leonid I. Rudin", "Stanley Osher", "Emad Fatemi"], "related_topics": ["9417928", "207282899", "55660270"], "citation_count": "16252", "reference_count": "13", "references": ["1991113069", "2146052399", "2080744942", "2057220024", "1970169482", "1867833861", "2078403926", "2035097277", "2005140191", "2143101939"], "date": "1992"}, {"id": "1572948005", "title": "The generative lexicon", "abstract": "In this paper, I will discuss four major topics relating to current research in lexical semantics: methodology, descriptive coverage, adequacy of the representation, and the computational usefulness of representations. In addressing these issues, I will discuss what I think are some of the central problems facing the lexical semantics community, and suggest ways of best approaching these issues. Then, I will provide a method for the decomposition of lexical categories and outline a theory of lexical semantics embodying a notion of cocompositionality and type coercion, as well as several levels of semantic description, where the semantic load is spread more evenly throughout the lexicon. I argue that lexical decomposition is possible if it is performed generatively. Rather than assuming a fixed set of primitives. I will assume a fixed number of generative devices that can be seen as constructing semantic expressions. I develop a theory of Qualia Structure, a representation language for lexical items, which renders much lexical ambiguity in the lexicon unnecessary, while still explaining the systematic polysemy that words carry. Finally, I discuss how individual lexical structures can be integrated into the larger lexical knowledge base through a theory of lexical inheritance. This provides us with the necessary principles of global organization for the lexicon, enabling us to fully integrate our natural language lexicon into a conceptual whole.", "authors": ["James Pustejovsky"], "related_topics": ["126706616", "55343584", "98954769"], "citation_count": "7697", "reference_count": "80", "references": ["1586060904", "2159525276", "2132513611", "2017668967", "1972573551", "2123987305", "2027657506", "2032527312", "1491525124", "2070939632"], "date": "1995"}, {"id": "2110505738", "title": "An EM algorithm for wavelet-based image restoration", "abstract": "This paper introduces an expectation-maximization (EM) algorithm for image restoration (deconvolution) based on a penalized likelihood formulated in the wavelet domain. Regularization is achieved by promoting a reconstruction with low-complexity, expressed in the wavelet coefficients, taking advantage of the well known sparsity of wavelet representations. Previous works have investigated wavelet-based restoration but, except for certain special cases, the resulting criteria are solved approximately or require demanding optimization methods. The EM algorithm herein proposed combines the efficient image representation offered by the discrete wavelet transform (DWT) with the diagonalization of the convolution operator obtained in the Fourier domain. Thus, it is a general-purpose approach to wavelet-based image restoration with computational complexity comparable to that of standard wavelet denoising schemes or of frequency domain deconvolution methods. The algorithm alternates between an E-step based on the fast Fourier transform (FFT) and a DWT-based M-step, resulting in an efficient iterative process requiring O(NlogN) operations per iteration. The convergence behavior of the algorithm is investigated, and it is shown that under mild conditions the algorithm converges to a globally optimal restoration. Moreover, our new approach performs competitively with, in some cases better than, the best existing methods in benchmark tests.", "authors": ["M.A.T. Figueiredo", "R.D. Nowak"], "related_topics": ["73339587", "155777637", "46286280"], "citation_count": "1333", "reference_count": "35", "references": ["2115755118", "2100115174", "2117853077", "2079724595", "2134929491", "59771946", "2065391104", "2050880896", "3129711340", "2124335859"], "date": "2003"}, {"id": "2067976091", "title": "Spectral partitioning works: planar graphs and finite element meshes", "abstract": "Spectral partitioning methods use the Fiedler vector-the eigenvector of the second-smallest eigenvalue of the Laplacian matrix-to find a small separator of a graph. These methods are important components of many scientific numerical algorithms and have been demonstrated by experiment to work extremely well. In this paper, we show that spectral partitioning methods work well on bounded-degree planar graphs and finite element meshes-the classes of graphs to which they are usually applied. While active spectral bisection does not necessarily work, we prove that spectral partitioning techniques can be used to produce separators whose ratio of vertices removed to edges cut is O(/spl radic/n) for bounded-degree planar graphs and two-dimensional meshes and O(n/sup 1/d/) for well-shaped d-dimensional meshes. The heart of our analysis is an upper bound on the second-smallest eigenvalues of the Laplacian matrices of these graphs: we prove a bound of O(1/n) for bounded-degree planar graphs and O(1/n/sup 2/d/) for well-shaped d-dimensional meshes.", "authors": ["D.A. Spielmat", "Shang-Hua Teng"], "related_topics": ["160446614", "74133993", "101837359"], "citation_count": "565", "reference_count": "68", "references": ["1578099820", "1589331344", "1995990042", "2083206954", "2114030927", "2022266599", "100944330", "2151417892", "2044355921", "2912202394"], "date": "1996"}, {"id": "2056452769", "title": "TG-FTIR analysis of biomass pyrolysis", "abstract": "Abstract A great need exists for comprehensive biomass-pyrolysis models that could predict yields and evolution patterns of selected volatile products as a function of feedstock characteristics and process conditions. A thermogravimetric analyzer coupled with Fourier transform infrared analysis of evolving products (TG-FTIR) can provide useful input to such models in the form of kinetic information obtained under low heating rate conditions. In this work, robust TG-FTIR quantification routines were developed for infrared analysis of volatile products relevant to biomass pyrolysis. The analysis was applied to wheat straw, three types of tobacco (Burley, Oriental, and Bright), and three biomass model compounds (xylan, chlorogenic acid, and d -glucose). Product yields were compared with literature data, and species potentially quantifiable by FT-IR are reviewed. Product-evolution patterns are reported for all seven biomass samples.", "authors": ["R Bassilakis", "R.M Carangelo", "M.A W\u00f3jtowicz"], "related_topics": ["2779371384", "206139338", "36759035"], "citation_count": "427", "reference_count": "26", "references": ["2078455576", "2000868500", "1970182524", "578630938", "2012113589", "2047017662", "2053652880", "2073629921", "2088518242", "2093391792"], "date": "2001"}, {"id": "2172000360", "title": "A comparison of methods for multiclass support vector machines", "abstract": "Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it for multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a multiclass classifier by combining several binary classifiers. Some authors also proposed methods that consider all classes at once. As it is computationally more expensive to solve multiclass problems, comparisons of these methods using large-scale problems have not been seriously conducted. Especially for methods solving multiclass SVM in one step, a much larger optimization problem is required so up to now experiments are limited to small data sets. In this paper we give decomposition implementations for two such \"all-together\" methods. We then compare their performance with three methods based on binary classifications: \"one-against-all,\" \"one-against-one,\" and directed acyclic graph SVM (DAGSVM). Our experiments indicate that the \"one-against-one\" and DAG methods are more suitable for practical use than the other methods. Results also show that for large problems methods by considering all data at once in general need fewer support vectors.", "authors": ["Chih-Wei Hsu", "Chih-Jen Lin"], "related_topics": ["123860398", "125168437", "12267149"], "citation_count": "9542", "reference_count": "24", "references": ["2153635508", "2148603752", "2119821739", "2084812512", "1512098439", "1576520375", "2124351082", "2282078507", "1602492977", "1543810117"], "date": "2002"}, {"id": "2145094598", "title": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion", "abstract": "We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.", "authors": ["Pascal Vincent", "Hugo Larochelle", "Isabelle Lajoie", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "related_topics": ["97385483", "12267149", "178980831"], "citation_count": "6141", "reference_count": "55", "references": ["2136922672", "2100495367", "2072128103", "2116064496", "2025768430", "2110798204", "1652505363", "2108384452", "1479807131", "1994197834"], "date": "2010"}, {"id": "2041563290", "title": "Determinants of consumer engagement in electronic word-of-mouth in social networking sites", "abstract": "As more and more marketers incorporate social media as an integral part of the promotional mix, rigorous investigation of the determinants that impact consumers\u2019 engagement in eWOM via social networks is becoming critical. Given the social and communal characteristics of social networking sites (SNSs) such as Facebook, MySpace and Friendster, this study examines how social relationship factors relate to eWOM transmitted via online social websites. Specifically, a conceptual model that identifies tie strength, homophily, trust, normative and informational interpersonal influence as an important antecedent to eWOM behaviour in SNSs was developed and tested. The results confirm that tie strength, trust, normative and informational influence are positively associated with users\u2019 overall eWOM behaviour, whereas a negative relationship was found with regard to homophily. This study suggests that product-focused eWOM in SNSs is a unique phenomenon with important social implications. The implications for research...", "authors": ["Shu-Chuan Chu"], "related_topics": ["2779812341", "2775995036", "518677369"], "citation_count": "2465", "reference_count": "163", "references": ["2121001699", "2134172592", "2099556653", "2130354913", "3149953018", "2108183214", "2085491458", "2129658695", "2153943092", "2139043937"], "date": "2010"}, {"id": "3022734214", "title": "The cathedral and the bazaar", "abstract": "I anatomize a successful open-source project, fetchmail, that was run as a deliberate test of some theories about software engineering suggested by the history of Linux. I discuss these theories in terms of two fundamentally different development styles, the \"cathedral\" model, representing most of the commercial world, versus the \"bazaar\" model of the Linux world. I show that these models derive from opposing assumptions about the nature of the software-debugging task. I then make a sustained argument from the Linux experience for the proposition that \"Given enough eyeballs, all bugs are shallow,\" suggest productive analogies with other self-correcting systems of selfish agents, and conclude with some exploration of the implications of this insight for the future of software.", "authors": ["Eric Raymond"], "related_topics": ["2778642129", "39462953", "2779522259"], "citation_count": "3168", "reference_count": "0", "references": ["2160697532", "3041188046", "2107294940", "2417863416", "3123336377", "3121257585", "2104357911", "1995054497", "2165775312", "1726621761"], "date": "1999"}, {"id": "2000950075", "title": "Class-indexing-based term weighting for automatic text classification", "abstract": "Most of the previous studies related on different term weighting emphasize on the document-indexing-based and four fundamental information elements-based approaches to address automatic text classification (ATC). In this study, we introduce class-indexing-based term-weighting approaches and judge their effects in high-dimensional and comparatively low-dimensional vector space over the TF.IDF and five other different term weighting approaches that are considered as the baseline approaches. First, we implement a class-indexing-based TF.IDF.ICF observational term weighting approach in which the inverse class frequency (ICF) is incorporated. In the experiment, we investigate the effects of TF.IDF.ICF over the Reuters-21578, 20 Newsgroups, and RCV1-v2 datasets as benchmark collections, which provide positive discrimination on rare terms in the vector space and biased against frequent terms in the text classification (TC) task. Therefore, we revised the ICF function and implemented a new inverse class space density frequency (ICS\"@dF), and generated the TF.IDF.ICS\"@dF method that provides a positive discrimination on infrequent and frequent terms. We present detailed evaluation of each category for the three datasets with term weighting approaches. The experimental results show that the proposed class-indexing-based TF.IDF.ICS\"@dF term weighting approach is promising over the compared well-known baseline term weighting approaches.", "authors": ["Fuji Ren", "Mohammad Golam Sohrab"], "related_topics": ["183115368", "148483581", "75165309"], "citation_count": "127", "reference_count": "48", "references": ["2118020653", "2149684865", "2142827986", "2435251607", "2150102617", "1956559956", "2114535528", "1978394996", "2140321362", "2060216474"], "date": "2013"}, {"id": "1583833196", "title": "Neuronlike adaptive elements that can solve difficult learning control problems", "abstract": "It is shown how a system consisting of two neuronlike adaptive elements can solve a difficult learning control problem. The task is to balance a pole that is hinged to a movable cart by applying forces to the cart's base. It is argued that the learning problems faced by adaptive elements that are components of adaptive networks are at least as difficult as this version of the pole-balancing problem. The learning system consists of a single associative search element (ASE) and a single adaptive critic element (ACE). In the course of learning to balance the pole, the ASE constructs associations between input and output by searching under the influence of reinforcement feedback, and the ACE constructs a more informative evaluation function than reinforcement feedback alone can provide. The differences between this approach and other attempts to solve problems using neurolike elements are discussed, as is the relation of this work to classical and instrumental conditioning in animal learning studies and its possible implications for research in the neurosciences.", "authors": ["Andrew G. Barto", "Richard S. Sutton", "Charles W. Anderson"], "related_topics": ["131806220", "25343380", "119857082"], "citation_count": "4306", "reference_count": "0", "references": ["2170227253", "1602079996", "212314082", "1481405077", "1504806788", "2038584310", "1971728746", "2834852173", "2293846015", "2001185203"], "date": "1990"}, {"id": "2046097442", "title": "How hard is it to marry at random? (On the approximation of the permanent)", "abstract": "", "authors": ["A Z Broder"], "related_topics": ["2780878606", "125565743", "118615104"], "citation_count": "237", "reference_count": "10", "references": ["2752853835", "2006912660", "3111890340", "2057512592", "2056389572", "2066720893", "2014603110", "2058006306", "1998798613", "1967660742"], "date": "1986"}, {"id": "2106136173", "title": "Handbook of American Indian languages", "abstract": "A Key into the Language of America [1643] Roger Williams 205pp, The Indian Grammar Begun [1666] John Eliot 70pp Observations on the Language of the Muhhekaneew Indians [1787] Jonathan Edwards 20pp, Dissertations on the English Language [1789] Noah Webster 410pp, A Vocabulary or Collection of Words and Phrases which have been suppposed to be Peculiar to the United States of America [1816] John Pickering 206pp, A Treatise on Language [1836] Alexander Bryan Johnson 276pp, Ethnography and Philology [1846] Horatio Hale Lectures on the English Language [1860] George P Marsh 697pp, Language and the Study of Language [1867] William D Whitney 498pp, Introduction to the Study of Indian Languages [1877] Indian Linguistic Families [1891] John W Powell 104pp, 142pp, Handbook of American Indian Languages [1911] Franz Boas (ed) 1972pp, An Introduction to the Study of Language [1914] Leonard Bloomfield 335pp", "authors": ["Franz Boas"], "related_topics": ["2779313563", "2779650838", "26022165"], "citation_count": "353", "reference_count": "0", "references": ["87185752", "35599901", "2124669395", "2104420809", "1970481396", "1507558854", "2050580244", "2765318410", "2017271336", "2130771178"], "date": "2002"}, {"id": "2168904555", "title": "An analysis of Internet based collaborative knowledge environments for critical digital media autonomy", "abstract": "This study examines the interactive features of Internet based collaborative knowledge environments from a democratic media perspective. Structuralist and semiotic media analysis methods are applied to develop a model of interaction for the investigation of social and cultural perspectives on knowledge construction and learning with digital media. Questions for problematizing common sense interface constructions are proposed for critical participation and to inform democratic educational practice. Quotes Joe has tackled a truly significant topic in his dissertation, namely, a grammar of interactive digital media. The ideas and approaches presented embody a substantial humanistic as well as scientific orientation and a value stance that fosters democratic media education. -Michael Streibel, Program Chair University of Wisconsin-Madison, Educational Communications and Technology Program At the 1998 IEEE Semiotics and Intelligent Systems conference, Joe introduced original semiotic models for analyzing interaction, content and user activity in digital media for social and cultural investigations. Mr. Tojek's work is well thought out and impressed me with a deep level of coverage of a wide field. - Leonid I. Perlovsky PhD, Author of Neural Networks and Intellect, Inventor of Modeling Field Theory Get Smart Fast An analysis of Internet based collaborative knowledge environments for critical digital media autonomy", "authors": ["Joe Tojek"], "related_topics": ["17632256", "139997677", "549568155"], "citation_count": "0", "reference_count": "83", "references": ["2164599981", "1841352775", "2158685692", "1631767606", "1568713441", "2026645894", "1987562626", "2175951718", "2489865376", "1518671722"], "date": "2008"}, {"id": "2032401773", "title": "Cilk: An Efficient Multithreaded Runtime System", "abstract": "Abstract Cilk (pronounced \u201csilk\u201d) is a C-based runtime system for multithreaded parallel programming. In this paper, we document the efficiency of the Cilk work-stealing scheduler, both empirically and analytically. We show that on real and synthetic applications, the \u201cwork\u201d and \u201ccritical-path length\u201d of a Cilk computation can be used to model performance accurately. Consequently, a Cilk programmer can focus on reducing the computation's work and critical-path length, insulated from load balancing and other runtime scheduling issues. We also prove that for the class of \u201cfully strict\u201d (well-structured) programs, the Cilk scheduler achieves space, time, and communication bounds all within a constant factor of optimal. The Cilk runtime system currently runs on the Connection Machine CM5 MPP, the Intel Paragon MPP, the Sun Sparcstation SMP, and the Cilk-NOW network of workstations. Applications written in Cilk include protein folding, graphic rendering, backtrack search, and the \u2605Socrates chess program, which won second prize in the 1995 ICCA World Computer Chess Championship.", "authors": ["Robert D. Blumofe", "Christopher F. Joerg", "Bradley C. Kuszmaul", "Charles E. Leiserson", "Keith H. Randall", "Yuli Zhou"], "related_topics": ["2778522416", "2778076476", "2780870223"], "citation_count": "5276", "reference_count": "0", "references": ["2169150396", "2101431901", "2096070062", "2000041758", "2026015769", "2036551003", "2072725684", "2016559894", "2103460560", "2021978684"], "date": "1996"}, {"id": "2083042078", "title": "Making data maximally available.", "abstract": "Science is driven by data. New technologies have vastly increased the ease of data collection and consequently the amount of data collected, while also enabling data to be independently mined and reanalyzed by others. And society now relies on scientific data of diverse kinds; for example, in responding to disease outbreaks, managing resources, responding to climate change, and improving transportation. It is obvious that making data widely available is an essential element of scientific research. The scientific community strives to meet its basic responsibilities toward transparency, standardization, and data archiving. Yet, as pointed out in a special section of this issue (pp. 692\u2013729), scientists are struggling with the huge amount, complexity, and variety of the data that are now being produced.", "authors": ["Brooks Hanson", "Andrew Sugden", "Bruce Alberts"], "related_topics": ["207267971", "2780233690", "133462117"], "citation_count": "166", "reference_count": "0", "references": ["2008985174", "2748184272", "1995054497", "2003423696", "2062836608", "2045005060", "3123868826", "2031934506", "2793993424", "2128349406"], "date": "2011"}, {"id": "2816155880", "title": "APPARATUS AND METHOD FOR UNLOCKING A LOCKING MODE OF PORTABLE TERMINAL", "abstract": "A method of unlocking a locking mode of a portable terminal, which includes sensing a user's gesture input which is set in a locking mode of the portable terminal. The locking mode is unlocked in response to the user's gesture input, and a function mapped to the user's gesture can be executed when unlocking the locking mode. A portable terminal compares gestures among predefined sets of gesture information in order to check whether there is a gesture that coincides with the analyzed gesture.", "authors": ["\uc2ec\uc218\ubbf8", "\uc724\uc218\uc815"], "related_topics": ["48677424", "2777782449", "207347870"], "citation_count": "255", "reference_count": "0", "references": ["2816155880", "1814413626", "2832041150", "3141862763", "2927266147", "3147861039", "2817766753", "2820296949", "2766770548", "3017642303"], "date": "2015"}, {"id": "2170112109", "title": "Learning Bayesian Networks: The Combination of Knowledge and Statistical Data", "abstract": "We describe a Bayesian approach for learning Bayesian networks from a combination of prior knowledge and statistical data. First and foremost, we develop a methodology for assessing informative priors needed for learning. Our approach is derived from a set of assumptions made previously as well as the assumption of likelihood equivalence, which says that data should not help to discriminate network structures that represent the same assertions of conditional independence. We show that likelihood equivalence when combined with previously made assumptions implies that the user's priors for network parameters can be encoded in a single Bayesian network for the next case to be seen\u2014a prior network\u2014and a single measure of confidence for that network. Second, using these priors, we show how to compute the relative posterior probabilities of network structures given data. Third, we describe search methods for identifying network structures with high posterior probabilities. We describe polynomial algorithms for finding the highest-scoring network structures in the special case where every node has at most k e 1 parent. For the general case (k > 1), which is NP-hard, we review heuristic search algorithms including local search, iterative local search, and simulated annealing. Finally, we describe a methodology for evaluating Bayesian-network learning algorithms, and apply this approach to a comparison of various approaches.", "authors": ["David Heckerman", "Dan Geiger", "David M. Chickering"], "related_topics": ["33724603", "57830394", "177769412"], "citation_count": "5035", "reference_count": "45", "references": ["2159080219", "2049633694", "2170112109", "2008906462", "1524326598", "3129711340", "2111051773", "2069469807", "2019963883", "1568555062"], "date": "1995"}, {"id": "2082354253", "title": "Raising the bar for cancer therapy models.", "abstract": "", "authors": ["Giulio Francia", "Robert S Kerbel"], "related_topics": ["535046627", "2779473830", "71924100"], "citation_count": "70", "reference_count": "11", "references": ["2145835533", "1895993106", "1967600348", "2053277232", "2035971989", "2012084975", "2111489144", "2102119680", "1990275745", "1977674993"], "date": "2010"}, {"id": "1976379365", "title": "An overview of the Andrew message system", "abstract": "lIntroduction This paper provides an overview of the Andrew Message System, which is in operation within the Andrew project at Carnegie Mellon University. The Andrew environment currently consists of 300 highfunction workstations (typified by the IBM RT-PC) each running Berkeley Unix and attached to a large campus-wide network. A central file system provides transparently the appearance of a large, monolithic Unix file system. In addition, there are approximately 600 IBM PC\u2019s and 300 (University-owned) Apple Macintoshes that may also participate in the network.", "authors": ["J. Rosenberg", "C. F. Everhart", "N. S. Borenstein"], "related_topics": ["2780975111", "546350949", "77741850"], "citation_count": "210", "reference_count": "10", "references": ["2037717074", "2001438822", "2043671329", "2111223826", "2035379912", "2108179552", "63241962", "2050923818", "2149767258", "2111944991"], "date": "1987"}, {"id": "1608462934", "title": "A Trainable System for Object Detection", "abstract": "This paper presents a general, trainable system for object detection in unconstrained, cluttered scenes. The system derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform. This example-based learning approach implicitly derives a model of an object class by training a support vector machine classifier using a large set of positive and negative examples. We present results on face, people, and car detection tasks using the same architecture. In addition, we quantify how the representation affects detection performance by considering several alternate representations including pixels and principal components. We also describe a real-time application of our person detection system as part of a driver assistance system.", "authors": ["Constantine Papageorgiou", "Tomaso Poggio"], "related_topics": ["71681937", "2776151529", "182521987"], "citation_count": "1779", "reference_count": "33", "references": ["2156909104", "2148603752", "2139212933", "2132984323", "2128272608", "2217896605", "2140235142", "2124351082", "2159686933", "26816478"], "date": "2000"}, {"id": "2109910161", "title": "Between MDPs and semi-MDPs: a framework for temporal abstraction in reinforcement learning", "abstract": "Learning, planning, and representing knowledge at multiple levels of temporal ab- straction are key, longstanding challenges for AI. In this paper we consider how these challenges can be addressed within the mathematical framework of reinforce- ment learning and Markov decision processes (MDPs). We extend the usual notion of action in this framework to include options\u2014closed-loop policies for taking ac- tion over a period of time. Examples of options include picking up an object, going to lunch, and traveling to a distant city, as well as primitive actions such as mus- cle twitches and joint torques. Overall, we show that options enable temporally abstract knowledge and action to be included in the reinforcement learning frame- work in a natural and general way. In particular, we show that options may be used interchangeably with primitive actions in planning methods such as dynamic pro- gramming and in learning methods such as Q-learning. Formally, a set of options defined over an MDP constitutes a semi-Markov decision process (SMDP), and the theory of SMDPs provides the foundation for the theory of options. However, the most interesting issues concern the interplay between the underlying MDP and the SMDP and are thus beyond SMDP theory. We present results for three such cases: 1) we show that the results of planning with options can be used during execution to interrupt options and thereby perform even better than planned, 2) we introduce new intra-option methods that are able to learn about an option from fragments of its execution, and 3) we propose a notion of subgoal that can be used to improve the options themselves. All of these results have precursors in the existing literature; the contribution of this paper is to establish them in a simpler and more general setting with fewer changes to the existing reinforcement learning framework. In particular, we show that these results can be obtained without committing to (or ruling out) any particular approach to state abstraction, hierarchy, function approximation, or the macro-utility problem.", "authors": ["Richard S. Sutton", "Doina Precup", "Satinder Singh"], "related_topics": ["97541855", "106189395", "51917952"], "citation_count": "2884", "reference_count": "75", "references": ["2121863487", "2131600418", "2009533501", "73143588", "2911432472", "2017103958", "1595483645", "2333196491", "1979071892", "1598634407"], "date": "1999"}, {"id": "2110121211", "title": "Single unit activity in striate cortex of unrestrained cats.", "abstract": "A beginning has recently been made in recording single neurone activity from animals with chronically implanted electrodes (Hubel, 1957a; Gusel'nikov, 1957; Ricci, Doane & Jasper, 1957; Strumwasser, 1958). These methods eliminate anaesthetics, paralysing drugs, brain-stem lesions, and other acute experimental procedures. They make it possible to record electrical events in the higher central nervous system with the animal in a normal state, and to correlate these electrical events with such variables as waking state, attention, learning, and motor activity. The present paper describes a method for unit recording from the cortex of unanaesthetized, unrestrained cats, and presents some observations from the striate cortex. The objectives have been (1) to observe maintained unit activity under various conditions such as sleep and wakefulness, and (2) to find for each unit the natural stimuli which most effectively influence firing. Of 400 units observed, some 200 are presented here because of their common characteristics. Since there is reason to believe that the remainiing 200 units were afferent fibres from the lateral geniculate nucleus, these will be described in a separate paper. A preliminary account of some of this work has been given elsewhere (Hubel, 1958).", "authors": ["D. H. Hubel"], "related_topics": ["2779345533", "2777348757", "2776362945"], "citation_count": "548", "reference_count": "19", "references": ["2037316494", "2212384750", "2027446612", "2059829044", "2166984318", "2009585478", "2034108404", "2418648566", "2070201674", "2088448188"], "date": "1959"}, {"id": "1557517019", "title": "Technical Note Q-Learning", "abstract": "Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states. This paper presents and proves in detail a convergence theorem for Q,-learning based on that outlined in Watkins (1989). We show that Q-learning converges to the optimum action-values with probability 1 so long as all actions are repeatedly sampled in all states and the action-values are represented discretely. We also sketch extensions to the cases of non-discounted, but absorbing, Markov environments, and where many Q values can be changed each iteration, rather than just one.", "authors": ["Christopher J.C.H. Watkins", "Peter Dayan"], "related_topics": ["188116033", "159886148", "97541855"], "citation_count": "4980", "reference_count": "12", "references": ["2100677568", "3011120880", "2141559645", "1491843047", "2035446426", "1569296262", "1979071892", "2015667537", "1640646391", "2235056388"], "date": "1992"}, {"id": "2620619910", "title": "Determining optical flow", "abstract": "Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantified rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image.", "authors": ["Berthold K. P. Horn", "Brian G. Schunck"], "related_topics": ["155542232", "9417928", "199681165"], "citation_count": "32937", "reference_count": "16", "references": ["2611560603", "1994552597", "2032075694", "2074798463", "2025943913", "2060968961", "2015157402", "2131729179", "2052670720", "2150464846"], "date": "1992"}, {"id": "2144226312", "title": "Pronunciation Modeling for Improved Spelling Correction", "abstract": "This paper presents a method for incorporating word pronunciation information in a noisy channel model for spelling correction. The proposed method builds an explicit error model for word pronunciations. By modeling pronunciation similarities between words we achieve a substantial performance improvement over the previous best performing models for spelling correction.", "authors": ["Kristina Toutanova", "Robert Moore"], "related_topics": ["2780844864", "2777801307", "120400215"], "citation_count": "249", "reference_count": "10", "references": ["3036751298", "2010595692", "2057900969", "2016871293", "1972099155", "2018616927", "2144639996", "109079948", "2066792529", "3022051027"], "date": "2002"}, {"id": "168564468", "title": "Software Framework for Topic Modelling with Large Corpora", "abstract": "Large corpora are ubiquitous in today's world and memory quickly becomes the limiting factor in practical applications of the Vector Space Model (VSM). We identify gap in existing VSM implementations, which is their scalability and ease of use. We describe a Natural Language Processing software framework which is based on the idea of document streaming, i.e. processing corpora document after document, in a memory independent fashion. In this framework, we implement several popular algorithms for topical inference, including Latent Semantic Analysis and Latent Dirichlet Allocation, in a way that makes them completely independent of the training corpus size. Particular emphasis is placed on straightforward and intuitive framework design, so that modifications and extensions of the methods and/or their application by interested practitioners are effortless. We demonstrate the usefulness of our approach on a real-world scenario of computing document similarities within an existing digital library DML-CZ.", "authors": ["Radim \u0158eh\u016f\u0159ek", "Petr Sojka"], "related_topics": ["500882744", "171686336", "76518257"], "citation_count": "3281", "reference_count": "25", "references": ["1880262756", "2170120409", "2001082470", "2147152072", "2158266063", "2047804403", "2143017621", "2159426623", "2334889010", "2063392856"], "date": "2010"}, {"id": "1726621761", "title": "The future of open innovation", "abstract": "Institutional openness is becoming increasingly popular in practice and academia: open innovation, open R&D and open business models. Our special issue builds on the concepts, underlying assumptions and implications discussed in two previous R&D Management special issues (2006, 2009). This overview indicates nine perspectives needed to develop an open innovation theory more fully. It also assesses some of the recent evidence that has come to light about open innovation, in theory and in practice.", "authors": ["Oliver Gassmann", "Ellen Enkel", "Henry Chesbrough"], "related_topics": ["148415826", "2779370449", "4216890"], "citation_count": "2047", "reference_count": "43", "references": ["1551905080", "1493688518", "2108795964", "3022734214", "1511351087", "2087712586", "1542405687", "2402811117", "1550832676", "2118243939"], "date": "2010"}, {"id": "2119565742", "title": "The Google file system", "abstract": "We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.", "authors": ["Sanjay Ghemawat", "Howard Gobioff", "Shun-Tak Leung"], "related_topics": ["82820731", "2780940931", "152043487"], "citation_count": "9611", "reference_count": "14", "references": ["2073965851", "2131645490", "2147504831", "2007807439", "2005373714", "2133338501", "1566984846", "2025413686", "2137808089", "2157737097"], "date": "2003"}, {"id": "2798766386", "title": "Nonlinear Programming", "abstract": "", "authors": ["Dimitri Bertsekas"], "related_topics": ["115527620", "32834798", "41008148"], "citation_count": "17017", "reference_count": "0", "references": ["2164278908", "2146502635", "2100556411", "2067191022", "1964357740", "607505555", "2109449402", "2132870739", "2120340025", "2030723843"], "date": "1994"}, {"id": "1686420892", "title": "MiBench: A free, commercially representative embedded benchmark suite", "abstract": "This paper examines a set of commercially representative embedded programs and compares them to an existing benchmark suite, SPEC2000. A new version of SimpleScalar that has been adapted to the ARM instruction set is used to characterize the performance of the benchmarks using configurations similar to current and next generation embedded processors. Several characteristics distinguish the representative embedded programs from the existing SPEC benchmarks including instruction distribution, memory behavior, and available parallelism. The embedded benchmarks, called MiBench, are freely available to all researchers.", "authors": ["M.R. Guthaus", "J.S. Ringenberg", "D. Ernst", "T.M. Austin", "T. Mudge", "R.B. Brown"], "related_topics": ["202491316", "137955351", "26771161"], "citation_count": "4399", "reference_count": "10", "references": ["1555915743", "2032094184", "2117285153", "2135300639", "2149743155", "133977063", "2004340162", "1974598553", "1599203358", "2105860728"], "date": "2001"}, {"id": "1917380066", "title": "Image indexing using color correlograms", "abstract": "We define a new image feature called the color correlogram and use it for image indexing and comparison. This feature distills the spatial correlation of colors, and is both effective and inexpensive for content-based image retrieval. The correlogram robustly tolerates large changes in appearance and shape caused by changes in viewing positions, camera zooms, etc. Experimental evidence suggests that this new feature outperforms not only the traditional color histogram method but also the recently proposed histogram refinement methods for image indexing/retrieval.", "authors": ["Jing Huang", "S.R. Kumar", "M. Mitra", "Wei-Jing Zhu", "R. Zabih"], "related_topics": ["12043971", "2780052074", "142616399"], "citation_count": "2775", "reference_count": "37", "references": ["2914885528", "2160066518", "2129249398", "2008297189", "2118783153", "2059432853", "2102475035", "2084544490", "2132201434", "2032301237"], "date": "1997"}, {"id": "2170429824", "title": "Adaptation techniques for ambience and microphone compensation in the IBM Tangora speech recognition system", "abstract": "Conventional speech recognition systems such as the IBM Tangora tend to be adversely influenced by external factors such as background noise and microphone characteristics. This paper discusses some adaptation techniques to counteract such influences. We also consider ways to reduce computation so that the methods may be implemented for real time Tangora operation. The adaptation strategy utilized two sets of VQ codebooks derived from the training data, one representing the ambience and the other characterizing the speech domain. A speech versus ambience decision was made by examining several factors, such as a comparison of the overall energy in a frame with a percentile point of a running energy histogram. We include results to demonstrate the effectiveness of our approach. >", "authors": ["S. Das", "A. Nadas", "D. Nahamoo", "M. Picheny"], "related_topics": ["61328038", "204201278", "13895895"], "citation_count": "20", "reference_count": "11", "references": ["2069501481", "2157590573", "2113911479", "2130322773", "2029757964", "2061265788", "2096708175", "2399937484", "2056809970", "2123072056"], "date": "1994"}, {"id": "1930456798", "title": "Gestures for touch sensitive input devices", "abstract": "Methods and systems for processing touch inputs are disclosed. The invention in one respect includes reading data from a multipoint sensing device such as a multipoint touch screen where the data pertains to touch input with respect to the multipoint sensing device, and identifying at least one multipoint gesture based on the data from the multipoint sensing device.", "authors": ["Steve Hotelling", "Joshua A. Strickon", "Brian Q. Huppi", "Imran Chaudhri", "Greg Christie", "Bas Ording", "Duncan Robert Kerr", "Jonathan P. Ive"], "related_topics": ["121449826", "207347870", "554936623"], "citation_count": "4361", "reference_count": "500", "references": ["1584397650", "2914705496", "2134035885", "2113918921", "1893940590", "1901544345", "2126698653", "2005198142", "2930602263", "2107118797"], "date": "2008"}, {"id": "2166982098", "title": "Determinants of Perceived Ease of Use: Integrating Control, Intrinsic Motivation, and Emotion into the Technology Acceptance Model", "abstract": "Much previous research has established that perceived ease of use is an important factor influencing user acceptance and usage behavior of information technologies. However, very little research has been conducted to understand how that perception forms and changes over time. The current work presents and tests an anchoring and adjustment-based theoretical model of the determinants of system-specific perceived ease of use. The model proposes control (internal and external--conceptualized as computer self-efficacy and facilitating conditions, respectively), intrinsic motivation (conceptualized as computer playfulness), and emotion (conceptualized as computer anxiety) as anchors that determine early perceptions about the ease of use of a new system. With increasing experience, it is expected that system-specific perceived ease of use, while still anchored to the general beliefs regarding computers and computer use, will adjust to reflect objective usability, perceptions of external control specific to the new system environment, and system-specific perceived enjoyment. The proposed model was tested in three different organizations among 246 employees using three measurements taken over a three-month period. The proposed model was strongly supported at all points of measurement, and explained up to 60% of the variance in system-specific perceived ease of use, which is twice as much as our current understanding. Important theoretical and practical implications of these findings are discussed.", "authors": ["Viswanath Venkatesh"], "related_topics": ["2776185967", "170130773", "110131835"], "citation_count": "7737", "reference_count": "135", "references": ["2099697766", "1791587663", "2168569455", "2888190061", "2033943395", "1987198869", "2098685541", "1491644571", "1543526618", "1517229207"], "date": "2000"}, {"id": "2162409952", "title": "Sparse solutions to linear inverse problems with multiple measurement vectors", "abstract": "We address the problem of finding sparse solutions to an underdetermined system of equations when there are multiple measurement vectors having the same, but unknown, sparsity structure. The single measurement sparse solution problem has been extensively studied in the past. Although known to be NP-hard, many single-measurement suboptimal algorithms have been formulated that have found utility in many different applications. Here, we consider in depth the extension of two classes of algorithms-Matching Pursuit (MP) and FOCal Underdetermined System Solver (FOCUSS)-to the multiple measurement case so that they may be used in applications such as neuromagnetic imaging, where multiple measurement vectors are available, and solutions with a common sparsity structure must be computed. Cost functions appropriate to the multiple measurement problem are developed, and algorithms are derived based on their minimization. A simulation study is conducted on a test-case dictionary to show how the utilization of more than one measurement vector improves the performance of the MP and FOCUSS classes of algorithm, and their performances are compared.", "authors": ["S.F. Cotter", "B.D. Rao", "Kjersti Engan", "K. Kreutz-Delgado"], "related_topics": ["179690561", "156872377", "2778770139"], "citation_count": "1476", "reference_count": "57", "references": ["2078204800", "2798909945", "2116148865", "2099641086", "2151693816", "2154332973", "2145889472", "2136235822", "1514558801", "2167839759"], "date": "2005"}, {"id": "1990005915", "title": "Continuous speech recognition by statistical methods", "abstract": "Statistical methods useful in automatic recognition of continuous speech are described. They concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding. Experimental results are presented that indicate the power of the methods.", "authors": ["F. Jelinek"], "related_topics": ["133892786", "155635449", "61328038"], "citation_count": "1495", "reference_count": "19", "references": ["2142384583", "2142901448", "1562979145", "2045407304", "1991133427", "1969483458", "2086699924", "2007321142", "2157477135", "2134587001"], "date": "1976"}, {"id": "2163382882", "title": "Analysis of daily precipitation data by positive matrix factorization", "abstract": "A new factor analysis method called positive matrix factorization (PMF) has been applied to daily precipitation data from four Finnish EMEP stations. The aim of the analysis was to investigate the structure of the data matrices in order to find the apparent source profiles from which the precipitation samples are constituted. A brief description of PMF is given. PMF utilizes the known uncertainty of data values. The standard deviations were derived from the results of double sampling at one station during one year. A goodness-of-fit function Q was calculated for factor solutions with 1\u20138 factors. The shape of the residuals was useful in deciding the number of factors. The strongest factor found was that of sea-salt. The most dominant ions in the factor were sodium, chloride and magnesium. At the coastal stations the ratio Cl/Na of the mean concentrations in the factor was near the ratio found in sea water but at the inland stations the ratio was smaller. For most ions more than 90 per cent of the weighted variation was explained. The worst explained was potassium (at worst c. 60 per cent) which is possibly due to contamination problems in the laboratory. In most factors of different factorizations the anions and cations were fairly well balanced.", "authors": ["Sirkka Juntto", "Pentti Paatero"], "related_topics": ["22679943", "139018669", "187834632"], "citation_count": "151", "reference_count": "17", "references": ["2059745395", "2012470056", "1987695907", "2049743420", "1991514427", "1982974841", "1606493927", "2053160495", "2094860190", "2055285048"], "date": "1994"}, {"id": "2114998762", "title": "Interactive apparatus using print media", "abstract": "A method for producing an output in response to an interaction with a print element on a sheet is disclosed. In one embodiment, the method includes placing a sheet comprising a print element on a surface of a base unit. A user can then mark on the sheet in the vicinity of the print element with a marking instrument. An audio output that corresponds to the print element is generated.", "authors": ["Michael C. Wood", "Tracey Hope Jedrzejek", "Richard Glenn Freeman", "Mark Flowers", "Eric Thomas Shuler", "Margaret E. Grunert", "Jason Avery"], "related_topics": ["121684516", "199639397", "93566951"], "citation_count": "190", "reference_count": "353", "references": ["1612889131", "1920642251", "2845759377", "2165427071", "3150480527", "2171479002", "2171151894", "2857135804", "2129188911", "2156817076"], "date": "2003"}, {"id": "2087684630", "title": "Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays", "abstract": "Oligonucleotide arrays can provide a broad picture of the state of the cell, by monitoring the expression level of thousands of genes at the same time. It is of interest to develop techniques for extracting useful information from the resulting data sets. Here we report the application of a two-way clustering method for analyzing a data set consisting of the expression patterns of different cell types. Gene expres- sion in 40 tumor and 22 normal colon tissue samples was analyzed with an Affymetrix oligonucleotide array comple- mentary to more than 6,500 human genes. An efficient two- way clustering algorithm was applied to both the genes and the tissues, revealing broad coherent patterns that suggest a high degree of organization underlying gene expression in these tissues. Coregulated families of genes clustered together, as demonstrated for the ribosomal proteins. Clustering also separated cancerous from noncancerous tissue and cell lines from in vivo tissues on the basis of subtle distributed patterns of genes even when expression of individual genes varied only slightly between the tissues. Two-way clustering thus may be of use both in classifying genes into functional groups and in classifying tissues based on gene expression.", "authors": ["U. Alon", "N. Barkai", "D. A. Notterman", "K. Gish", "S. Ybarra", "D. Mack", "A. J. Levine", ""], "related_topics": ["150194340", "104317684", "197077220"], "citation_count": "5232", "reference_count": "16", "references": ["2150926065", "2130494035", "2109970232", "2135951244", "238668910", "2069271664", "2133241531", "2167395325", "2913066018", "1985064413"], "date": "1999"}, {"id": "2163455434", "title": "Scalable Optical Packet Switches for Multiple Data Formats and Data Rates Packets", "abstract": "We demonstrate an optical packet switch (OPS) subsystem employing in-band labeling to allow for transparent routing of packets with multiple data formats and data bit rates. Packets employing in-band labels can be processed without the need to reconfigure the label processor and the switch when changing data format and bit-rate. The label processor is based on asynchronous optical signal processing in combination with a simple electronic combinatory network. This makes the label processor capable to process a large number of labels with low latency time (<3 ns) without complicated and power-hungry high-speed packet clock recovery and serializer/deserializer circuits. Experimental results show error-free operation of 1 \u00d7 64 OPS subsystem for 160-Gb/s return-to-zero on-off keying and 120-Gb/s nonreturn-to-zero differential phase-shift keying multiwavelength packets.", "authors": ["N. Calabretta", "W. Wang", "T. Ditewig", "O. Raz", "F.G. Agis", "S.Z.H. de Waardt", "H.J.S. Dorren"], "related_topics": ["158379750", "113508815", "151319957"], "citation_count": "26", "reference_count": "12", "references": ["2161111878", "2087924620", "2270231497", "2099664567", "1982288607", "1527987129", "2141914860", "2066249680", "1502475382", "2160032728"], "date": "2010"}, {"id": "3121300207", "title": "The Small-World of Human Language", "abstract": "Words in human language interact within sentences in non-random ways, and allow humans to construct an astronomic variety of sentences from a limited number of discrete units. This construction process is extremely fast and robust. The coocurrence of words within sentences reflect language organization in a subttle manner which can be described in terms of a graph of word interactions. Here we show that such graph displays two important features recently found in a disparate number of complex systems: (a) The so called small world effect. In particular, the average distance between two words d (i.e. the average minimum number of jumps to be made from an arbitrary word to another) is shown to be d \\approx 2-3, in spite that the human brain can store many thousands. (b) A scale-free distribution of degrees. The known dramatic effects of disconnecting the most connected vertices in such networks can be identified in some language disorders. These observations suggest some unexpected features of language organization that might reflect the evolutionary and social history of lexicons and the origins of their flexibility and combinatorial nature.", "authors": ["Ramon Ferrer i Cancho", "Ricard V. Sol\u00e9"], "related_topics": ["2777757186", "136134403", "61249035"], "citation_count": "1332", "reference_count": "0", "references": ["1585976120", "2322241107", "2964299903", "2116795926", "2135287799", "2598592325", "1606885304", "2898810800", "1512042876", "2023271514"], "date": "2001"}, {"id": "2088616581", "title": "On the unification of line processes, outlier rejection, and robust statistics with applications in early vision", "abstract": "The modeling of spatial discontinuities for problems such as surface recovery, segmentation, image reconstruction, and optical flow has been intensely studied in computer vision. While \u201cline-process\u201d models of discontinuities have received a great deal of attention, there has been recent interest in the use of robust statistical techniques to account for discontinuities. This paper unifies the two approaches. To achieve this we generalize the notion of a \u201cline process\u201d to that of an analog \u201coutlier process\u201d and show how a problem formulated in terms of outlier processes can be viewed in terms of robust statistics. We also characterize a class of robust statistical problems for which an equivalent outlier-process formulation exists and give a straightforward method for converting a robust estimation problem into an outlier-process formulation. We show how prior assumptions about the spatial structure of outliers can be expressed as constraints on the recovered analog outlier processes and how traditional continuation methods can be extended to the explicit outlier-process formulation. These results indicate that the outlier-process approach provides a general framework which subsumes the traditional line-process approaches as well as a wide class of robust estimation problems. Examples in surface reconstruction, image segmentation, and optical flow are presented to illustrate the use of outlier processes and to show how the relationship between outlier processes and robust statistics can be exploited. An appendix provides a catalog of common robust error norms and their equivalent outlier-process formulations.", "authors": ["Michael J. Black", "Anand Rangarajan"], "related_topics": ["79337645", "67226441", "97970142"], "citation_count": "889", "reference_count": "43", "references": ["2145023731", "1997063559", "2150134853", "2129249398", "2620619910", "2913192828", "2012712694", "2100315781", "2080744942", "2139762693"], "date": "1996"}, {"id": "179212727", "title": "Shape representation in parallel systems", "abstract": "There has been a recent revival of interest in parallel systems in which computation is performed by excitatory and inhibitory interactions within a network of relatively simple, neuronlike units [1 2 3 4]. At the early stages of visual processing, individual units can represent hypotheses about how small local fragments of the visual input should be interpreted, and interactions between units can encode knowledge about the constraints between local interpretations. Higher up in the visual system, the representational issues are more complex. This paper considers the difficulties involved in representing shapes in parallel systems, and suggests ways of overcoming them. In doing so, it provides a mechanism for shape perception and visual attention which allows a novel interpretation of the Gestalt slogan that the whole is more than the sum of its parts.", "authors": ["Geoffrey F. Hinton"], "related_topics": ["2778251979", "27362006", "26760741"], "citation_count": "157", "reference_count": "15", "references": ["2121773050", "2048330959", "2130355536", "2081519360", "2322002063", "1594957066", "39428922", "2108729336", "1976645892", "112688168"], "date": "1981"}, {"id": "2104670598", "title": "Tabu Search\u2014Part II", "abstract": "This is the second half of a two part series devoted to the tabu search metastrategy for optimization problems. Part I introduced the fundamental ideas of tabu search as an approach for guiding other heuristics to overcome the limitations of local optimality, both in a deterministic and a probabilistic framework. Part I also reported successful applications from a wide range of settings, in which tabu search frequently made it possible to obtain higher quality solutions than previously obtained with competing strategies, generally with less computational effort. Part II, in this issue, examines refinements and more advanced aspects of tabu search. Following a brief review of notation, Part II introduces new dynamic strategies for managing tabu lists, allowing fuller exploitation of underlying evaluation functions. In turn, the elements of staged search and structured move sets are characterized, which bear on the issue of finiteness. Three ways of applying tabu search to the solution of integer programmin...", "authors": ["Fred W. Glover"], "related_topics": ["123370116", "90189156", "135450995"], "citation_count": "9401", "reference_count": "22", "references": ["2581275558", "2084792706", "307896644", "2143037347", "2016688797", "2047422346", "2168000780", "3139666781", "1513769081", "2164855953"], "date": "1989"}, {"id": "2111030512", "title": "An introduction to cybernetics", "abstract": "", "authors": ["William Ross Ashby"], "related_topics": ["198009544", "108426073", "2777743140"], "citation_count": "7424", "reference_count": "0", "references": ["2132454116", "2134732423", "2156665851", "2106980598", "2115374626", "2151020819", "2125789924", "2132924891", "2129700906", "1977308918"], "date": "1955"}, {"id": "1989582918", "title": "Towards an architecture-independent analysis of parallel algorithms", "abstract": "A simple and efficient method for evaluating the performance of an algorithm, rendered as a directed acyclic graph, on any parallel computer is presented. The crucial ingredient is an efficient approximation algorithm for a particular scheduling problem. The only parameter of the parallel computer needed by our method is the message-to-instruction ratio $\\tau$. Although the method used in this paper does not take into account the number of processors available, its application to several common algorithms shows that it is surprisingly accurate.", "authors": ["Christos H. Papadimitriou", "Mihalis Yannakakis"], "related_topics": ["538114610", "120373497", "148764684"], "citation_count": "739", "reference_count": "0", "references": ["2045271686", "2040466547", "2102061396", "2023753260", "2118396891", "2143062006", "1973531467", "1936679285", "2041327854", "2042120213"], "date": "1990"}, {"id": "2138764991", "title": "Comprehensive Approach for Correction of Motion and Distortion in Diffusion-Weighted MRI", "abstract": "Patient motion and image distortion induced by eddy currents cause artifacts in maps of diffusion parameters computed from diffusion-weighted (DW) images. A novel and comprehensive approach to correct for spatial misalignment of DW imaging (DWI) volumes acquired with different strengths and orientations of the diffusion sensitizing gradients is presented. This approach uses a mutual information-based registration technique and a spatial transformation model containing parameters that correct for eddy current-induced image distortion and rigid body motion in three dimensions. All parameters are optimized simultaneously for an accurate and fast solution to the registration problem. The images can also be registered to a normalized template with a single interpolation step without additional computational cost. Following registration, the signal amplitude of each DWI volume is corrected to account for size variations of the object produced by the distortion correction, and the b-matrices are properly recalculated to account for any rotation applied during registration. Both qualitative and quantitative results show that this approach produces a significant improvement of diffusion tensor imaging (DTI) data acquired in the human brain.", "authors": ["G.K. Rohde", "", "A.S. Barnett", "P.J. Basser", "S. Marenco", "C. Pierpaoli"], "related_topics": ["166704113", "115225779", "149550507"], "citation_count": "546", "reference_count": "27", "references": ["2170120409", "2034432063", "2120062331", "1874027545", "2063698478", "2105456967", "2139158372", "1964802316", "2110431535", "2004537679"], "date": "2003"}, {"id": "2103496339", "title": "Approximation by superpositions of a sigmoidal function", "abstract": "In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.", "authors": ["George Cybenko"], "related_topics": ["120264874", "47702885", "184825909"], "citation_count": "15140", "reference_count": "19", "references": ["1652505363", "2042264548", "2137983211", "1971735090", "2165758113", "2019363670", "3038830718", "2066789935", "18965947", "1594563152"], "date": "1989"}, {"id": "2143745167", "title": "Information-based syntax and semantics", "abstract": "A long-standing, near-universal, and erroneous practice of teaching syntax in a void exists, as if the communicative function of language had nothing to do with syntax. And semantics has customarily been taught in sequence after syntax, or else not at all. Based upon graduate courses taught at Stanford University, this work seeks to redress this situation by building up syntactic and semantic aspects of grammatical theory in an integrated way from the start, under the assumption that neither is of linguistic interest divorced from the other. The particular theory presented, head-driven phrase structure grammar (HPSG) - so-called because of its central notion of the grammatical head - is an information-based (or 'unification-based' theory that has its roots in a number of different research programs within linguistics and neighboring disciplines such as philosophy and computer science.Thus HPSG draws upon and attempts to synthesize insights and perspectives from several families of contemporary syntactic theories, such as categorial grammar, lexical-functional grammar, generalized phrase structure grammar, and government-binding theory; but many of its key ideas arise from semantic theories like situation semantics and discourse representation theory, and from computational work in such areas as knowledge representation, data type theory, and formalisms based upon the unification of partial information.", "authors": ["Carl Jesse Pollard", "Ivan A. Sag"], "related_topics": ["191563868", "39890363", "50227651"], "citation_count": "2465", "reference_count": "0", "references": ["2067551521", "1965696452", "2145465694", "1528941926", "157626857", "1574661744", "2011734523", "2135976285", "2132308445", "1999090433"], "date": "1986"}, {"id": "2139894798", "title": "Expansive learning at work: Toward an activity theoretical reconceptualization.", "abstract": "Cultural-historical activity theory has evolved through three generations of research. The emerging third generation of activity theory takes two interacting activity systems as its minimal unit of analysis, inviting us to focus research efforts on the challenges and possibilities of inter-organizational learning. Activity theory and its concept of expansive learning are examined with the help of four questions: 1. Who are the subjects of learning? 2. Why do they learn? 3. What do they learn? 4. How do they learn? Five central principles of activity theory are presented, namely activity system as unit of analysis, multi-voicedness of activity, historicity of activity, contradictions as driving force of change in activity, and expansive cycles as possible form of transformation in activity. Together the four questions and five principles form a matrix which is used to present a study of expansive learning in a hospital setting in Finland. In conclusion, implications of the framework for our understanding o...", "authors": ["Yrj\u00f6 Engestr\u00f6m"], "related_topics": ["159334719", "92393732", "54797493"], "citation_count": "7658", "reference_count": "34", "references": ["1780382453", "2116199508", "1992324015", "10833075", "2085529605", "2135943618", "1499005519", "1608124789", "2042349004", "1606108609"], "date": "2001"}, {"id": "2270231497", "title": "25.6-Tb/s C+L-band transmission of polarization-multiplexed RZ-DQPSK signals", "abstract": "We demonstrate record 25.6-Tb/s transmission over 240 km using 160 WDM channels on a 50-GHz grid in the C+L bands. Each channel contains two polarization-multiplexed 85.4-Gb/s RZ-DQPSK signals, yielding a spectral efficiency of 3.2 b/s/Hz.", "authors": ["Alan H. Gnauck", "Gabriel Charlet", "Patrice Tran", "Peter Winzer", "Chris Doerr", "Joe Centanni", "Ellsworth Burrows", "Tetsuya Kawanishi", "Takahide Sakamoto", "Kaoru Higuma"], "related_topics": ["160724564", "133969743", "54956558"], "citation_count": "156", "reference_count": "0", "references": ["2060093775", "2170798091", "1971918847", "2101046417", "2143842064", "2111911727", "2161973497", "2097629904", "2132117980", "2037115430"], "date": "2007"}, {"id": "2130494035", "title": "Expression monitoring by hybridization to high density oligonucleotide arrays", "abstract": "This invention provides methods of monitoring the expression levels of a multiplicity of genes. The methods involve hybridizing a nucleic acid sample to a high density array of oligonucleotide probes where the high density array contains oligonucleotide probes complementary to subsequences of target nucleic acids in the nucleic acid sample. In one embodiment, the method involves providing a pool of target nucleic acids comprising RNA transcripts of one or more target genes, or nucleic acids derived from the RNA transcripts, hybridizing said pool of nucleic acids to an array of oligonucleotide probes immobilized on surface, where the array comprising more than 100 different oligonucleotides and each different oligonucleotide is localized in a predetermined region of the surface, the density of the different oligonucleotides is greater than about 60 different oligonucleotides per 1 cm2, and the oligonucleotide probes are complementary to the RNA transcripts or nucleic acids derived from the RNA transcripts; and quantifying the hybridized nucleic acids in the array.", "authors": ["David J. Lockhart", "Eugene L. Brown", "Gordon G. Wong", "Mark S. Chee", "Thomas R. Gingeras"], "related_topics": ["119203544", "24107716", "129312508"], "citation_count": "7817", "reference_count": "288", "references": ["1970156673", "2010888033", "2030958510", "1978368163", "2037509330", "2159511216", "2161893150", "2094448442", "2140064832", "2059667789"], "date": "1996"}, {"id": "1537519384", "title": "Scales in Natural Images and a Consequence on their Bounded Variation Norm", "abstract": "This paper introduces a new method for analyzing scaling phenomena in natural images, and draws some consequences as to whether natural images belong to the space of functions with bounded variation.", "authors": ["Luis Alvarez", "Yann Gousseau", "Jean-Michel Morel"], "related_topics": ["27851653", "59372978", "99844830"], "citation_count": "26", "reference_count": "20", "references": ["2115755118", "2103559027", "2137234026", "1593038947", "1490632837", "2150920547", "2167034998", "1985517056", "2139643804", "2251490743"], "date": "1999"}, {"id": "196214544", "title": "Generating Text with Recurrent Neural Networks", "abstract": "Recurrent Neural Networks (RNNs) are very powerful sequence models that do not enjoy widespread use because it is extremely difficult to train them properly. Fortunately, recent advances in Hessian-free optimization have been able to overcome the difficulties associated with training RNNs, making it possible to apply them successfully to challenging sequence problems. In this paper we demonstrate the power of RNNs trained with the new Hessian-Free optimizer (HF) by applying them to character-level language modeling tasks. The standard RNN architecture, while effective, is not ideally suited for such tasks, so we introduce a new RNN variant that uses multiplicative (or \"gated\") connections which allow the current input character to determine the transition matrix from one hidden state vector to the next. After training the multiplicative RNN with the HF optimizer for five days on 8 high-end Graphics Processing Units, we were able to surpass the performance of the best previous single method for character-level language modeling \u2013 a hierarchical non-parametric sequence model. To our knowledge this represents the largest recurrent neural network application to date.", "authors": ["Ilya Sutskever", "James Martens", "Geoffrey E. Hinton"], "related_topics": ["147168706", "137293760", "154945302"], "citation_count": "1441", "reference_count": "23", "references": ["2064675550", "179875071", "1498436455", "196761320", "2131462252", "2118706537", "2107878631", "2110575115", "1408639475", "2170942820"], "date": "2011"}, {"id": "98436501", "title": "Current developments in expert systems", "abstract": "", "authors": ["Donald Michie"], "related_topics": ["58328972", "148043351", "41008148"], "citation_count": "64", "reference_count": "0", "references": ["2128420091", "2042385018", "2126151607", "1597910678", "1482451543", "1510806966", "1510644453", "2077422877", "2030091586", "1490514105"], "date": "1987"}, {"id": "2112090702", "title": "Collective dynamics of small-world networks", "abstract": "Networks of coupled dynamical systems have been used to model biological oscillators, Josephson junction arrays, excitable media, neural networks, spatial games, genetic control networks and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon (popularly known as six degrees of separation. The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.", "authors": ["Duncan J. Watts", "Steven H. Strogatz"], "related_topics": ["34947359", "36647736", "60723933"], "citation_count": "47081", "reference_count": "28", "references": ["2061901927", "2905110430", "2062663664", "111157985", "2025490132", "2079948225", "3049667020", "2088678566", "2026552514", "2017444605"], "date": "1998"}, {"id": "2923014074", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding", "abstract": "Human ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.", "authors": ["Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R. Bowman"], "related_topics": ["2779439875", "137955351", "169903167"], "citation_count": "1669", "reference_count": "16", "references": ["2962739339", "2251939518", "2963748441", "1486649854", "2963918774", "2963846996", "2525127255", "2962736243", "3104033643", "2130158090"], "date": "2018"}, {"id": "2108309071", "title": "A theory of diagnosis from first principles", "abstract": "Suppose one is given a description of a system, together with an observation of the system's behaviour which conflicts with the way the system is meant to behave. The diagnostic problem is to determine those components of the system which, when assumed to be functioning abnormally, will explain the discrepancy between the observed and correct system behaviour. We propose a general theory for this problem. The theory requires only that the system be described in a suitable logic. Moreover, there are many such suitable logics, e.g. first-order, temporal, dynamic, etc. As a result, the theory accommodates diagnostic reasoning in a wide variety of practical settings, including digital and analogue circuits, medicine, and database updates. The theory leads to an algorithm for computing all diagnoses, and to various results concerning principles of measurement for discriminating among competing diagnoses. Finally, the theory reveals close connections between diagnostic reasoning and nonmonotonic reasoning.", "authors": ["Raymond Reiter"], "related_topics": ["159032336", "206880738", "136197465"], "citation_count": "4582", "reference_count": "15", "references": ["2155322595", "2144386448", "1549872659", "1983382292", "2140627345", "1998363560", "1562964770", "2032511848", "2038569232", "1520443109"], "date": "1987"}, {"id": "1515040589", "title": "A First Course in Information Theory", "abstract": "This book provides an up-to-date introduction to information theory. In addition to the classical topics discussed, it provides the first comprehensive treatment of the theory of I-Measure, network coding theory, Shannon and non-Shannon type information inequalities, and a relation between entropy and group theory. ITIP, a software package for proving information inequalities, is also included. With a large number of examples, illustrations, and original problems, this book is excellent as a textbook or reference book for a senior or graduate level course on the subject, as well as a reference for researchers in related fields.", "authors": ["Raymond W. Yeung"], "related_topics": ["52622258", "70567897", "33577790"], "citation_count": "647", "reference_count": "192", "references": ["2105831729", "2137813581", "2106403318", "2138928022", "2049633694", "2987657883", "2135764410", "1634005169", "1638203394", "2120085609"], "date": "2001"}, {"id": "1532852017", "title": "Combining collaborative filtering with personal agents for better recommendations", "abstract": "Information filtering agents and collaborative filtering both attempt to alleviate information overload by identifying which items a user will find worthwhile. Information filtering (IF) focuses on the analysis of item content and the development of a personal user interest profile. Collaborative filtering (CF) focuses on identification of other users with similar tastes and the use of their opinions to recommend items. Each technique has advantages and limitations that suggest that the two could be beneficially combined.This paper shows that a CF framework can be used to combine personal IF agents and the opinions of a community of users to produce better recommendations than either agents or users can produce alone. It also shows that using CF to create a personal combination of a set of agents produces better results than either individual agents or other combination mechanisms. One key implication of these results is that users can avoid having to select among agents; they can use them all and let the CF framework select the best ones for them.", "authors": ["Nathaniel Good", "J. Ben Schafer", "Joseph A. Konstan", "Al Borchers", "Badrul Sarwar", "Jon Herlocker", "John Riedl"], "related_topics": ["21569690", "178674793", "78646695"], "citation_count": "1316", "reference_count": "19", "references": ["2110325612", "3121531027", "2124591829", "1966553486", "1999047234", "2043403353", "1978394996", "175500210", "1670263352", "2030144199"], "date": "1999"}, {"id": "3134959276", "title": "Bottlenecks in Blockchain Consensus Protocols.", "abstract": "Most of the Blockchain permissioned systems employ Byzantine fault-tolerance (BFT) consensus protocols to ensure that honest validators agree on the order for appending entries to their ledgers. In this paper, we study the performance and the scalability of prominent consensus protocols, namely PBFT, Tendermint, HotStuff, and Streamlet, both analytically via load formulas and practically via implementation and evaluation. Under identical conditions, we identify the bottlenecks of these consensus protocols and show that these protocols do not scale well as the number of validators increases. Our investigation points to the communication complexity as the culprit. Even when there is enough network bandwidth, the CPU cost of serialization and deserialization of the messages limits the throughput and increases the latency of the protocols. To alleviate the bottlenecks, the most useful techniques include reducing the communication complexity, rotating the hotspot of communications, and pipelining across consensus instances.", "authors": ["Salem Alqahtani", "Murat Demirbas"], "related_topics": ["179145077", "48044578", "52723943"], "citation_count": "0", "reference_count": "21", "references": ["2156580773", "2486460265", "2126087831", "3021428210", "2120510885", "2726001757", "2964159515", "2794647042", "2003214215", "2981750966"], "date": "2021"}, {"id": "2159173611", "title": "Probabilistic visual learning for object detection", "abstract": "We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands. >", "authors": ["B. Moghaddam", "A. Pentland"], "related_topics": ["8038995", "2776151529", "189508267"], "citation_count": "558", "reference_count": "12", "references": ["2138451337", "2148694408", "2049633694", "2159686933", "2098947662", "2138313032", "1981367467", "1973436000", "2798461040", "2157418942"], "date": "1995"}, {"id": "1480519300", "title": "Translating collocations for bilingual lexicons: a statistical approach", "abstract": "Collocations are notoriously difficult for non-native speakers to translate, primarily because they are opaque and cannot be translated on a word-by-word basis. We describe a program named Champollion which, given a pair of parallel corpora in two different languages and a list of collocations in one of them, automatically produces their translations. Our goal is to provide a tool for compiling bilingual lexical information above the word level in multiple languages, for different domains. The algorithm we use is based on statistical methods and produces p-word translations of n-word collocations in which n and p need not be the same. For example, Champollion translates make...decision, employment equity, and stock market into prendre...decision, equite en matiere d'emploi, and bourse respectively. Testing Champollion on three years' worth of the Hansards corpus yielded the French translations of 300 collocations for each year, evaluated at 73% accuracy on average. In this paper, we describe the statistical measures used, the algorithm, and the implementation of Champollion, presenting our results and evaluation.", "authors": ["Frank Smadja", "Kathleen R. McKeown", "Vasileios Hatzivassiloglou"], "related_topics": ["2778000110", "204321447", "41895202"], "citation_count": "722", "reference_count": "60", "references": ["2099111195", "2006969979", "1956559956", "1997841190", "2099247782", "2097333193", "1593045043", "1489181569", "1667165204", "2147632348"], "date": "1996"}, {"id": "157626857", "title": "A linguistic ontology for the semantic web", "abstract": "", "authors": ["Scott Farrar", "Terry Langendoen"], "related_topics": ["167379230", "115408247", "50382505"], "citation_count": "235", "reference_count": "12", "references": ["2038721957", "23685451", "168676630", "87648833", "2143745167", "2012896854", "2060667324", "78386069", "2910955212", "2740947391"], "date": "2002"}, {"id": "2047804403", "title": "Modular toolkit for Data Processing (MDP): a Python data processing framework", "abstract": "Modular toolkit for Data Processing (MDP) is a data processing framework written in Python. From the user's perspective, MDP is a collection of supervised and unsupervised learning algorithms and other data processing units that can be combined into data processing sequences and more complex feed-forward network architectures. Computations are performed efficiently in terms of speed and memory requirements. From the scientific developer's perspective, MDP is a modular framework, which can easily be expanded. The implementation of new algorithms is easy and intuitive. The new implemented units are then automatically integrated with the rest of the library. MDP has been written in the context of theoretical research in neuroscience, but it has been designed to be helpful in any context where trainable data processing algorithms are used. Its simplicity on the user's side, the variety of readily available algorithms, and the reusability of the implemented units make it also a useful educational tool.", "authors": ["Tiziano Zito", "Niko Wilbert", "Laurenz Wiskott", "Pietro Berkes"], "related_topics": ["519991488", "101468663", "138827492"], "citation_count": "145", "reference_count": "11", "references": ["1663973292", "2136922672", "1554663460", "2156838815", "2167217202", "2138754805", "2148856562", "1511812886", "2102724320", "2156141384"], "date": "2007"}, {"id": "607505555", "title": "Understanding Machine Learning: From Theory to Algorithms", "abstract": "Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering.", "authors": ["Shai Shalev-Shwartz", "Shai Ben-David"], "related_topics": ["32254414", "50292564", "77967617"], "citation_count": "3469", "reference_count": "191", "references": ["2296319761", "2156909104", "2911964244", "1663973292", "2136922672", "2296616510", "2148603752", "2072128103", "1480376833", "2147880316"], "date": "2014"}, {"id": "2148143831", "title": "SMOTE: synthetic minority over-sampling technique", "abstract": "An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of \"normal\" examples with only a small percentage of \"abnormal\" or \"interesting\" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of oversampling the minority (abnormal)cla ss and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space)tha n only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space)t han varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC)and the ROC convex hull strategy.", "authors": ["Nitesh V. Chawla", "Kevin W. Bowyer", "Lawrence O. Hall", "W. Philip Kegelmeyer"], "related_topics": ["52001869", "58471807", "95623464"], "citation_count": "14620", "reference_count": "29", "references": ["2084812512", "2125055259", "1670263352", "2170654002", "2155653793", "2058732827", "1588282782", "1990748933", "2096942889", "2799061466"], "date": "2001"}, {"id": "1979675141", "title": "How to use expert advice", "abstract": "We analyze algorithms that predict a binary value by combining the predictions of several prediction strategies, called experts. Our analysis is for worst-case situations, i.e., we make no assumptions about the way the sequence of bits to be predicted is generated. We measure the performance of the algorithm by the difference between the expected number of mistakes it makes on the bit sequence and the expected number of mistakes made by the best expert on this sequence, where the expectation is taken with respect to the randomization in the predictins. We show that the minimum achievable difference is on the order of the square root of the number of mistakes of the best expert, and we give efficient algorithms that achieve this. Our upper and lower bounds have matching leading constants in most cases. We then show how this leads to certain kinds of pattern recognition/learning algorithms with performance bounds that improve on the best results currently know in this context. We also compare our analysis to the case in which log loss is used instead of the expected number of mistakes.", "authors": ["Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "David Haussler", "David P. Helmbold", "Robert E. Schapire", "Manfred K. Warmuth"], "related_topics": ["2780049985", "77553402", "37724570"], "citation_count": "905", "reference_count": "43", "references": ["2124776405", "1530699444", "2019363670", "3124873412", "2154952480", "2054658115", "2611627047", "2050660892", "2972424502", "1968908999"], "date": "1997"}, {"id": "2142069714", "title": "Online and off-line handwriting recognition: a comprehensive survey", "abstract": "Handwriting has continued to persist as a means of communication and recording information in day-to-day life even with the introduction of new technologies. Given its ubiquity in human transactions, machine recognition of handwriting has practical significance, as in reading handwritten notes in a PDA, in postal addresses on envelopes, in amounts in bank checks, in handwritten fields in forms, etc. This overview describes the nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms. Both the online case (which pertains to the availability of trajectory data during writing) and the off-line case (which pertains to scanned images) are considered. Algorithms for preprocessing, character and word recognition, and performance with practical systems are indicated. Other fields of application, like signature verification, writer authentification, handwriting learning tools are also considered.", "authors": ["R. Plamondon", "S.N. Srihari"], "related_topics": ["44868376", "2779386606", "112640561"], "citation_count": "3475", "reference_count": "215", "references": ["1554663460", "2125838338", "2046079134", "2133059825", "2102734279", "1970800786", "1549285799", "2010595692", "1885639605", "2178432768"], "date": "1999"}, {"id": "2006969979", "title": "The mathematics of statistical machine translation: parameter estimation", "abstract": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus.", "authors": ["Peter F. Brown", "Vincent J. Della Pietra", "Stephen A. Della Pietra", "Robert L. Mercer"], "related_topics": ["2780206684", "24687705", "51802942"], "citation_count": "5827", "reference_count": "15", "references": ["2049633694", "2121227244", "2097333193", "1489181569", "2117652747", "2129139611", "2154384676", "2138584836", "1575431606", "2048390999"], "date": "1993"}, {"id": "2002182716", "title": "Vector quantization in speech coding", "abstract": "Quantization, the process of approximating continuous-amplitude signals by digital (discrete-amplitude) signals, is an important aspect of data compression or coding, the field concerned with the reduction of the number of bits necessary to transmit or store analog data, subject to a distortion or fidelity criterion. The independent quantization of each signal value or parameter is termed scalar quantization, while the joint quantization of a block of parameters is termed block or vector quantization. This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization. Vector quantization is presented as a process of redundancy removal that makes effective use of four interrelated properties of vector parameters: linear dependency (correlation), nonlinear dependency, shape of the probability density function (pdf), and vector dimensionality itself. In contrast, scalar quantization can utilize effectively only linear dependency and pdf shape. The basic concepts are illustrated by means of simple examples and the theoretical limits of vector quantizer performance are reviewed, based on results from rate-distortion theory. Practical issues relating to quantizer design, implementation, and performance in actual applications are explored. While many of the methods presented are quite general and can be used for the coding of arbitrary signals, this paper focuses primarily on the coding of speech signals and parameters.", "authors": ["J. Makhoul", "S. Roucos", "H. Gish"], "related_topics": ["199833920", "28855332", "93372532"], "citation_count": "1314", "reference_count": "125", "references": ["3017143921", "2134383396", "2150593711", "2913399920", "2913066018", "2069501481", "2151626637", "2022554507", "1966264494", "2127218421"], "date": "1985"}, {"id": "2161111878", "title": "Optical Packet and Burst Switching Technologies for the Future Photonic Internet", "abstract": "This paper reviews advanced optical burst switching (OBS) and optical packet switching (OPS) technologies and discusses their roles in the future photonic Internet. Discussions include optoelectronic and optical systems technologies as well as systems integration into viable network elements (OBS and OPS routers). Optical label switching (OLS) offers a unified multiple-service platform with effective and agile utilization of the available optical bandwidth in support of voice, data, and multimedia services on the Internet Protocol. In particular, OLS routers with wavelength routing switching fabrics and parallel optical labeling allow forwarding of asynchronously arriving variable-length packets, bursts, and circuits. By exploiting contention resolution in wavelength, time, and space domains, the OLS routers can achieve high throughput without resorting to a store-and-forward method associated with large buffer requirements. Testbed demonstrations employing OLS edge routers show high-performance networking in support of multimedia and data communications applications over the photonic Internet with optical packets and bursts switched directly at the optical layer", "authors": ["S.J.B. Yoo"], "related_topics": ["197417287", "180026317", "26840048"], "citation_count": "584", "reference_count": "173", "references": ["1588462524", "2140562769", "2074064356", "1965095275", "2165334967", "2139653117", "2141217973", "2154559785", "2036840069", "2116150950"], "date": "2006"}, {"id": "2134895902", "title": "Method and apparatus for indexing, searching and displaying data", "abstract": "A computer research tool for indexing, searching and displaying data is disclosed. Specifically, a computer research tool for performing computerized research of data including textual objects in a database or a network and for providing a user interface that significantly enhances data presentation is described. Textual objects and other data in a database or network is indexed by creating a numerical representation of the data. The indexing technique called proximity indexing generates a quick-reference of the relations, patterns and similarity found among the data in the database. Proximity indexing indexes the data by using statistical techniques and empirically developed algorithms. Using this proximity index, an efficient search for pools of data having a particular relation, pattern or characteristic can be effectuated. The Computer Search program, called the Computer Search Program for Data represented in Matrices (CSPDM), provides efficient computer search methods. The CSPDM rank orders data in accordance with the data's relationship to time, a paradigm datum, or any similar reference. An alternative embodiment of the invention employs a cluster link generation algorithm which uses links and nodes to index and search a database or network. The algorithm searches for direct and indirect links to a search node and retrieves the nodes which are most closely related to the search node. The user interface program, called the Graphical User Interface (GUI), provides a user friendly method of interacting with the CSPDM program and prepares and presents a visual graphical display. The graphical display provides the user with a two or three dimensional spatial orientation of the data.", "authors": ["Daniel Egger", "Shawn Cannon", "Ronald D. Sauers"], "related_topics": ["75165309", "89505385", "2780717508"], "citation_count": "837", "reference_count": "136", "references": ["1971784203", "2999729612", "1956559956", "1978394996", "1655990431", "2882023975", "2158046522", "2117085788", "2753176400", "110443600"], "date": "1994"}, {"id": "2963855133", "title": "Bag of Tricks for Image Classification with Convolutional Neural Networks", "abstract": "Much of the recent progress made in image classification research can be credited to training procedure refinements, such as changes in data augmentations and optimization methods. In the literature, however, most refinements are either briefly mentioned as implementation details or only visible in source code. In this paper, we will examine a collection of such refinements and empirically evaluate their impact on the final model accuracy through ablation study. We will show that, by combining these refinements together, we are able to improve various CNN models significantly. For example, we raise ResNet-50's top-1 validation accuracy from 75.3% to 79.29% on ImageNet. We will also demonstrate that improvement on image classification accuracy leads to better transfer learning performance in other application domains such as object detection and semantic segmentation.", "authors": ["Tong He", "Zhi Zhang", "Hang Zhang", "Zhongyue Zhang", "Junyuan Xie", "Mu Li"], "related_topics": ["108583219", "81363708", "75294576"], "citation_count": "384", "reference_count": "22", "references": ["2194775991", "2618530766", "2962835968", "639708223", "1903029394", "2183341477", "2963911037", "1533861849", "2963420686", "2560023338"], "date": "2019"}, {"id": "2107726111", "title": "Reinforcement learning: a survey", "abstract": "This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word \"reinforcement.\" The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.", "authors": ["Leslie Pack Kaelbling", "Michael L. Littman", "Andrew W. Moore"], "related_topics": ["199190896", "97541855", "188888258"], "citation_count": "8679", "reference_count": "110", "references": ["1639032689", "1497256448", "1652505363", "2098432798", "2119567691", "2100677568", "2000836282", "2119717200", "1963547452", "2019363670"], "date": "1995"}, {"id": "1520963883", "title": "AIR/X - A rule-based multistage indexing system for Iarge subject fields.", "abstract": "", "authors": ["Norbert Fuhr", "Stephan Hartmann", "Gerhard Lustig", "Michael Schwantner", "Kostas Tzeras", "Gerhard Knorz"], "related_topics": ["149271511", "2777855551", "75165309"], "citation_count": "204", "reference_count": "0", "references": ["2118020653", "2047221353", "2114535528", "2005422315", "2170654002", "2024228866", "2063862666", "2063198646", "1986913017", "2126502509"], "date": "1990"}, {"id": "2130158090", "title": "The Third PASCAL Recognizing Textual Entailment Challenge", "abstract": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year's dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges.", "authors": ["Danilo Giampiccolo", "Bernardo Magnini", "Ido Dagan", "Bill Dolan"], "related_topics": ["95318506", "94176051", "44291984"], "citation_count": "767", "reference_count": "28", "references": ["2912565176", "2525127255", "2115792525", "2396767181", "2102065370", "2002664886", "1990524510", "137514618", "2182572585", "2134061542"], "date": "2007"}, {"id": "1795234945", "title": "Comparative Experiments on Disambiguating Word Senses: An Illustration of the Role of Bias in Machine Learning", "abstract": "This paper describes an experimental comparison of seven different learning algorithms on the problem of learning to disambiguate the meaning of a word from context. The algorithms tested include statistical, neural-network, decision-tree, rule-based, and case-based classification techniques. The specific problem tested involves disambiguating six senses of the word ``line'' using the words in the current and proceeding sentence as context. The statistical and neural-network methods perform the best on this particular problem and we discuss a potential reason for this observed difference. We also discuss the role of bias in machine learning and its importance in explaining performance differences observed on specific problems.", "authors": ["Raymond J. Mooney"], "related_topics": ["32254414", "24138899", "77967617"], "citation_count": "313", "reference_count": "47", "references": ["2154642048", "1632114991", "3017143921", "2147169507", "2099247782", "1994851566", "2136000097", "2132166479", "1999138184", "2132513611"], "date": "1995"}, {"id": "2133581580", "title": "Safe and effective fine-grained TCP retransmissions for datacenter communication", "abstract": "This paper presents a practical solution to a problem facing high-fan-in, high-bandwidth synchronized TCP workloads in datacenter Ethernets---the TCP incast problem. In these networks, receivers can experience a drastic reduction in application throughput when simultaneously requesting data from many servers using TCP. Inbound data overfills small switch buffers, leading to TCP timeouts lasting hundreds of milliseconds. For many datacenter workloads that have a barrier synchronization requirement (e.g., filesystem reads and parallel data-intensive queries), throughput is reduced by up to 90%. For latency-sensitive applications, TCP timeouts in the datacenter impose delays of hundreds of milliseconds in networks with round-trip-times in microseconds.Our practical solution uses high-resolution timers to enable microsecond-granularity TCP timeouts. We demonstrate that this technique is effective in avoiding TCP incast collapse in simulation and in real-world experiments. We show that eliminating the minimum retransmission timeout bound is safe for all environments, including the wide-area.", "authors": ["Vijay Vasudevan", "Amar Phanishayee", "Hiral Shah", "Elie Krevat", "David G. Andersen", "Gregory R. Ganger", "Garth A. Gibson", "Brian Mueller"], "related_topics": ["101452262", "162030245", "30305156"], "citation_count": "540", "reference_count": "31", "references": ["2173213060", "2119565742", "2158733823", "2753542457", "2303054358", "1807779280", "2071314114", "2112495447", "1668270659", "2163404313"], "date": "2009"}, {"id": "2137309058", "title": "A hierarchical decision approach to large-vocabulary discrete utterance recognition", "abstract": "Very short response time is a critical requirement for automatic discrete utterance recognition. The real-time vocabulary size of most of today's commercially available recognizers is limited to several hundreds of utterances, primarily due to the fact that detailed acoustic matching involves considerable computation. The method presented here offers an economical solution to the real-time large-vocabulary recognition problem by carrying out recognition in two stages. In the initial stage, the incoming utterance is linearly matched against the entire vocabulary using only two features-utterance duration and either two or three average spectra for each utterance. While the number of prototypes matched is large, the time required per match is substantially reduced. During this initial stage, a preset number of best-match prototypes is determined for each unknown input. In the second stage, matching is performed for the best-match list based upon more detailed features (e.g., 10-ms log-power spectra), using more elaborate matching methodology, e.g., dynamic programming. Evaluation experiments were conducted using the 2000 most frequent words in an office-correspondence corpus and three normal adult-male talkers. It was observed that first-stage best-match lists of 30-50 items included the \"correct\" words between 99.0 and 99.5 percent of the time. Using DP on 10-ms spectral samples for the second stage, recognition accuracy ranged from 86.5 to 94.5 percent. A match-limiter, when used with a 50-64-word, commercially available recognizer for the second stage, makes near-real-time large-vocabulary recognition feasible.", "authors": ["T. Kaneko", "N. Dixon"], "related_topics": ["2777601683", "2775852435", "59883199"], "citation_count": "53", "reference_count": "14", "references": ["2128160875", "2137089646", "2123783347", "2065387773", "2056536278", "2144195083", "1579558060", "2037543635", "2120996511", "2036318925"], "date": "1983"}, {"id": "2107878631", "title": "Learning long-term dependencies with gradient descent is difficult", "abstract": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered. >", "authors": ["Y. Bengio", "P. Simard", "P. Frasconi"], "related_topics": ["2778149865", "153258448", "147168706"], "citation_count": "6898", "reference_count": "19", "references": ["2581275558", "2154642048", "2016589492", "19621276", "2128499899", "2088978850", "2148099973", "1996741810", "2125329357", "1527772862"], "date": "1994"}, {"id": "2303054358", "title": "A comparison of mechanisms for improving TCP performance over wireless links", "abstract": "Reliable transport protocols such as TCP are tuned to perform well in traditional networks where packet losses occur mostly because of congestion. However, networks with wireless and other lossy links also suffer from significant non-congestion-related losses due to reasons such as bit errors and handoffs. TCP responds to all losses by invoking congestion control and avoidance algorithms, resulting in degraded end-to-end performance in wireless and lossy systems. In this paper, we compare several schemes designed to improve the performance of TCP in such networks. These schemes are classified into three broad categories: end-to-end protocols, where the sender is aware of the wireless link; link-layer protocols, that provide local reliability; and split-connection protocols, that break the end-to-end connection into two parts at the base station. We present the results of several experiments performed in both LAN and WAN environments, using throughput and goodput as the metrics for comparison.Our results show that a reliable link-layer protocol with some knowledge of TCP provides very good performance. Furthermore, it is possible to achieve good performance without splitting the end-to-end connection at the base station. We also demonstrate that selective acknowledgments and explicit loss notifications result in significant performance improvements.", "authors": ["Hari Balakrishnan", "Venkata N. Padmanabhan", "Srinivasan Seshan", "Randy H. Katz"], "related_topics": ["101452262", "120837960", "30305156"], "citation_count": "2909", "reference_count": "0", "references": ["2149863032", "1537198022", "2118760020", "2148658274", "1968589086", "2278646759", "2151214689", "2142845194", "1978005952", "2072880733"], "date": "1999"}, {"id": "2168463792", "title": "The pothole patrol: using a mobile sensor network for road surface monitoring", "abstract": "This paper investigates an application of mobile sensing: detecting and reporting the surface conditions of roads. We describe a system and associated algorithms to monitor this important civil infrastructure using a collection of sensor-equipped vehicles. This system, which we call the Pothole Patrol (P2), uses the inherent mobility of the participating vehicles, opportunistically gathering data from vibration and GPS sensors, and processing the data to assess road surface conditions. We have deployed P2 on 7 taxis running in the Boston area. Using a simple machine-learning approach, we show that we are able to identify potholes and other severe road surface anomalies from accelerometer data. Via careful selection of training data and signal features, we have been able to build a detector that misidentifies good road segments as having potholes less than 0.2% of the time. We evaluate our system on data from thousands of kilometers of taxi drives, and show that it can successfully detect a number of real potholes in and around the Boston area. After clustering to further reduce spurious detections, manual inspection of reported potholes shows that over 90% contain road anomalies in need of repair.", "authors": ["Jakob Eriksson", "Lewis Girod", "Bret Hull", "Ryan Newton", "Samuel Madden", "Hari Balakrishnan"], "related_topics": ["2780042925", "2776306092", "24590314"], "citation_count": "1264", "reference_count": "22", "references": ["2167396179", "2170918595", "1568630508", "2162226564", "1977656351", "1607207171", "2126711172", "1501296238", "1973758813", "2106028863"], "date": "2008"}, {"id": "1980384741", "title": "Recognition memory for words, sentences, and pictures", "abstract": "The S s looked through a series of about 600 stimuli selected at random from an initially larger population. They were then tested for their ability to recognize these \u201cold\u201d stimuli in pairs in which the alternative was always a \u201cnew\u201d stimulus selected at random from the stimuli remaining in the original population. Depending upon whether this original population consisted solely of words, sentences, or pictures, median Ss were able correctly to recognize the \u201cold\u201d stimulus in 90, 88, or 98% of the test pairs, respectively. Estimated lower bounds on the informational capacity of human memory considerably exceed previously published estimates.", "authors": ["Roger N. Shepard"], "related_topics": ["2908647359", "147004232", "90269970"], "citation_count": "2070", "reference_count": "23", "references": ["1995875735", "1984314602", "1738233868", "2053566542", "2059711617", "2019894050", "2081839681", "2057507047", "2493377199", "2045501802"], "date": "1967"}, {"id": "2091886411", "title": "Projection Pursuit Regression", "abstract": "Abstract A new method for nonparametric multiple regression is presented. The procedure models the regression surface as a sum of general smooth functions of linear combinations of the predictor variables in an iterative manner. It is more general than standard stepwise and stagewise regression procedures, does not require the definition of a metric in the predictor space, and lends itself to graphical interpretation.", "authors": ["Jerome H. Friedman", "Werner Stuetzle"], "related_topics": ["74127309", "32224588", "162948026"], "citation_count": "2972", "reference_count": "12", "references": ["2319794630", "2024081693", "2059507684", "2026258334", "2082612735", "1979519992", "2478937241", "168150807", "2146434287", "1994753884"], "date": "1981"}, {"id": "1955828807", "title": "Touch screen device, method, and graphical user interface for determining commands by applying heuristics", "abstract": "A computer-implemented method for use in conjunction with a computing device with a touch screen display comprises: detecting one or more finger contacts with the touch screen display, applying one or more heuristics to the one or more finger contacts to determine a command for the device, and processing the command. The one or more heuristics comprise: a heuristic for determining that the one or more finger contacts correspond to a one- dimensional vertical screen scrolling command, a heuristic for determining that the one or more finger contacts correspond to a two-dimensional screen translation command, and a heuristic for determining that the one or more finger contacts correspond to a command to transition from displaying a respective item in a set of items to displaying a next item in the set of items.", "authors": ["Steven P. Jobs", "Scott Forstall", "Greg Christie", "Stephen O. Lemay", "Scott Herz", "Os Marcel Van", "Bas Ording", "Gregory Novick", "Wayne C. Westerman", "Imran Chaudhri", "Patrick Lee Coffman", "Kenneth Kocienda", "Nitin K. Ganatra", "Jeremy A. Wyld", "Jeffrey Bush", "Freddy Allen Anzures", "Michael Matas", "Paul D. Marcos", "Charles J. Pisula", "Virgil Scott King", "Chris Blumenberg", "Francisco Ryan Tolmasky", "Richard Williamson", "Andre M.J. Boule", "Henri C. Lamiraux"], "related_topics": ["59046462", "127705205", "37789001"], "citation_count": "3474", "reference_count": "164", "references": ["1930456798", "2914705496", "1893940590", "1607518450", "2102038340", "2925818728", "2170249432", "2816984649", "2130010617", "1033150858"], "date": "2007"}, {"id": "2118706537", "title": "Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication", "abstract": "We present a method for learning nonlinear systems, echo state networks (ESNs). ESNs employ artificial recurrent neural networks in a way that has recently been proposed independently as a learning mechanism in biological brains. The learning method is computationally efficient and easy to use. On a benchmark task of predicting a chaotic time series, accuracy is improved by a factor of 2400 over previous techniques. The potential for engineering applications is illustrated by equalizing a communication channel, where the signal error rate is improved by two orders of magnitude.", "authors": ["Herbert Jaeger", "Harald Haas"], "related_topics": ["147168706", "172025690", "135796866"], "citation_count": "2662", "reference_count": "12", "references": ["2103179919", "2016589492", "1543237449", "2166322089", "2134514463", "2094631910", "2058580716", "2143879519", "2045182040", "1943433854"], "date": "2004"}, {"id": "1624854622", "title": "Object recognition with features inspired by visual cortex", "abstract": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex.", "authors": ["T. Serre", "L. Wolf", "T. Poggio"], "related_topics": ["64876066", "14551309", "40608802"], "citation_count": "1203", "reference_count": "24", "references": ["3097096317", "2124386111", "2057175746", "2154422044", "2134557905", "2152473410", "2155511848", "1949116567", "2149194912", "2171188998"], "date": "2005"}, {"id": "2134419850", "title": "What Good Are Positive Emotions", "abstract": "This article opens by noting that positive emotions do not fit existing models of emotions. Consequently, a new model is advanced to describe the form and function of a subset of positive emotions, including joy, interest, contentment, and love. This new model posits that these positive emotions serve to broaden an individual's momentary thought-action repertoire, which in turn has the effect of building that individual's physical, intellectual, and social resources. Empirical evidence to support this broadenand-build model of positive emotions is reviewed, and implications for emotion regulation and health promotion are discussed. Even though research on emotions has this new perspective are featured. My hope is flourished in recent years, investigations that that this article will unlock scientific curiosity expressly target positive emotions remain few and far between. Any review of the psychological literature on emotions will show that psychologists have typically favored negative emotions in theory building and hypothesis testing. In so doing, psychologists have inadvertently marginalized the emotions, such as joy, about positive emotions, not only to test the ideas presented here, but also to build other new models that might illuminate the nature and value of positive emotions. Psychology sorely needs more studies on positive emotions, not simply to level the uneven knowledge bases between negative and positive emotions, but interest, contentment, and love, that share a more critically, to guide applications and pleasant subjective feel. To date, then, psychology's knowledge base regarding positive emotions is so thin that satisfying answers to the question \"What good are positive emotions?\" have yet to be articulated. This is unfortunate. Experiences of positive emotion are central to human nature and contribute richly to the quality of people's lives (Diener & Larsen,", "authors": ["Barbara L. Fredrickson"], "related_topics": ["2775896857", "90386246", "107088065"], "citation_count": "6995", "reference_count": "115", "references": ["2159061031", "2140205964", "3019273456", "1984186949", "1966797434", "2045565604", "2108800498", "1659631989", "2119927950", "2107984537"], "date": "1998"}, {"id": "2125899728", "title": "Comparison of Multiobjective Evolutionary Algorithms: Empirical Results", "abstract": "In this paper, we provide a systematic comparison of various evolutionary approaches to multiobjective optimization using six carefully chosen test functions. Each test function involves a particular feature that is known to cause difficulty in the evolutionary optimization process, mainly in converging to the Pareto-optimal front (e.g., multimodality and deception). By investigating these different problem features separately, it is possible to predict the kind of problems to which a certain technique is or is not well suited. However, in contrast to what was suspected beforehand, the experimental results indicate a hierarchy of the algorithms under consideration. Furthermore, the emerging effects are evidence that the suggested test functions provide sufficient complexity to compare multiobjective optimizers. Finally, elitism is shown to be an important factor for improving evolutionary multiobjective search.", "authors": ["Eckart Zitzler", "Kalyanmoy Deb", "Lothar Thiele"], "related_topics": ["121835503", "159149176", "150185637"], "citation_count": "6179", "reference_count": "32", "references": ["1639032689", "2152150600", "2106334424", "2116661285", "1504943474", "2102248717", "1905847227", "2121365620", "2261054240", "2152551290"], "date": "2000"}, {"id": "1586060904", "title": "Lectures on Government and Binding", "abstract": "", "authors": ["Noam Chomsky"], "related_topics": ["2778137410", "71009995", "41008148"], "citation_count": "12582", "reference_count": "0", "references": ["2969165671", "1508977358", "1562911371", "1572948005", "2038248725", "2159398820", "2147218300", "2000196122", "1962622193", "3100307207"], "date": "1980"}, {"id": "2149644771", "title": "Connection Machine Lisp: fine-grained parallel symbolic processing", "abstract": "Connection Machine Lisp is a dialect of Lisp extended to al- low a fine.grained, data-oriented style of parallel execution. We introduce a new data structure, the xapping, that is like a sparse array whose elements can be processed in parallel. This kind of processing is suitable for implementation by such fine.grained parallel computers as the Connection Machine System and NON- VON. Additional program notation is introduced to indicate var- ious parallel operations. The symbols st andare used, in a manner syntactically reminiscent of the backquote notation used in Common Lisp, to indicate what parts of an expression are to be executed in parallel. Ths symbol fl is used to indicate permu- tation and reduction of sets of data. Connection Machine Lisp in practice leans heavily on APL and FP and their descendants. Many ideas and stylistic idioms can be carried over directly. Some idioms of Connection Machine Lisp are difficult to render in APL because Connection Machine Lisp xappings may be sparse while APL vectors are not sparse. We give many small examples of programming in Connection Machine Lisp. Two metcircular interpreters for a subset of Connection Ma- chine Lisp are presented. One is concise but suffers from defining a in terms of itself in such a way as to obscure its essential prop- erties. The other is longer but facilitates presentation of these properties.", "authors": ["Guy L. Steele", "W. Daniel Hillis"], "related_topics": ["190883126", "2779353305", "127436386"], "citation_count": "222", "reference_count": "23", "references": ["2987803397", "2158365276", "2113547509", "2177745862", "2172307690", "1983587324", "3159585669", "2126126443", "2017586706", "2127114597"], "date": "1986"}, {"id": "2020822911", "title": "Canonical Typology, Suppletion, and Possible Words", "abstract": "We specify a typology for the extreme of inflectional morphology, namely suppletion (as in go ~ went). This is an unusual enterprise within typology, and it requires a \u2018canonical\u2019 approach. That is, we define the canonical or best instance, through a set of converging criteria, and use this point in theoretical space to locate the various occurring types. Thus the criteria establish the dimensions along which we find the specific instances of suppletion, allowing us to calibrate examples out from the canonical. The criteria fall into two main areas, those internal to the lexeme and those external to it. Moreover, we find interactions with other morphological phenomena, and discuss four of them: syncretism, periphrasis, overdifferentiation and reduplication. These remarkable instances of suppletion, particularly when in interaction with other phenomena, extend the boundary of the notion \u2018possible word\u2019. Besides laying out the possibilities for the specific phenomenon of suppletion, we show how a canonical approach allows us to make progress in typology, even in the most challenging areas.", "authors": ["Greville G. Corbett"], "related_topics": ["2778617226", "2775837122", "2778740521"], "citation_count": "347", "reference_count": "98", "references": ["239563548", "1521255875", "1536822721", "1516286893", "602086463", "2060667324", "1822002357", "2028176807", "592384517", "1534300969"], "date": "2007"}, {"id": "2115647291", "title": "Direct manipulation interfaces", "abstract": "Direct manipulation has been lauded as a good form of interface design, and some interfaces that have this property have been well received by users. In this article we seek a cognitive account of both the advantages and disadvantages of direct manipulation interfaces. We identify two underlying phenomena that give rise to the feeling of directness. One deals with the information processing distance between the user's intentions and the facilities provided by the machine. Reduction of this distance makes the interface feel direct by reducing the effort required of the user to accomplish goals. The second phenomenon concerns the relation between the input and output vocabularies of the interface language. In particular, direct manipulation requires that the system provide representations of objects that behave as if they are the objects themselves. This provides the feeling of directness of manipulation.", "authors": ["Edwin L. Hutchins", "James D. Hollan", "Donald A. Norman"], "related_topics": ["2780968085", "25621077", "87868495"], "citation_count": "2231", "reference_count": "20", "references": ["2099305423", "2021878536", "2175030280", "2005639687", "1539777654", "1979887415", "2954951251", "2037893691", "121934918", "2064302241"], "date": "1985"}, {"id": "2106053110", "title": "Distance Metric Learning for Large Margin Nearest Neighbor Classification", "abstract": "The accuracy of k-nearest neighbor (kNN) classification depends significantly on the metric used to compute distances between different examples. In this paper, we show how to learn a Mahalanobis distance metric for kNN classification from labeled examples. The Mahalanobis metric can equivalently be viewed as a global linear transformation of the input space that precedes kNN classification using Euclidean distances. In our approach, the metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin. As in support vector machines (SVMs), the margin criterion leads to a convex optimization based on the hinge loss. Unlike learning in SVMs, however, our approach requires no modification or extension for problems in multiway (as opposed to binary) classification. In our framework, the Mahalanobis distance metric is obtained as the solution to a semidefinite program. On several data sets of varying size and difficulty, we find that metrics trained in this way lead to significant improvements in kNN classification. Sometimes these results can be further improved by clustering the training examples and learning an individual metric within each cluster. We show how to learn and combine these local metrics in a globally integrated manner.", "authors": ["Kilian Q. Weinberger", "Lawrence K. Saul"], "related_topics": ["94475309", "205617318", "2779597229"], "citation_count": "3585", "reference_count": "30", "references": ["2296319761", "2121947440", "2138451337", "2057175746", "2140095548", "2148694408", "2147717514", "2108995755", "2117154949", "2912522929"], "date": "2009"}, {"id": "2020432066", "title": "Vector quality measure of lossy compressed medical images.", "abstract": "A numerical measure, which is able to predict diagnostic accuracy rather than subjective quality, is required for compressed medical image assessment. The objective of this study is to present a proposal for a new vector measure of image quality, reflecting diagnostic accuracy. Construction of such measure includes the formation of a diagnostic quality pattern based on the subjective ratings of local image features playing an essential role in the detection and classification of any lesion. Experimental results contain the opinions of 9 radiologists: 2 test designers and 7 observers who rated digital mammograms. The correlation coefficient between the numerical equivalent of the vector measure and subjective pattern is over 0.9.", "authors": ["Artur Przelaskowski"], "related_topics": ["55020928", "143001347", "2776013501"], "citation_count": "21", "reference_count": "10", "references": ["2153777140", "2127007691", "2060136512", "1487065163", "2111216493", "2120401253", "2099274934", "2038346186", "2063797216", "1667214750"], "date": "2004"}, {"id": "2252143850", "title": "Training recurrent neural networks", "abstract": "Recurrent Neural Networks (RNNs) are powerful sequence models that were believed to be difficult to train, and as a result they were rarely used in machine learning applications. This thesis presents methods that overcome the difficulty of training RNNs, and applications of RNNs to challenging problems. We first describe a new probabilistic sequence model that combines Restricted Boltzmann Machines and RNNs. The new model is more powerful than similar models while being less difficult to train. Next, we present a new variant of the Hessian-free (HF) optimizer and show that it can train RNNs on tasks that have extreme long-range temporal dependencies, which were previously considered to be impossibly hard. We then apply HF to character-level language modelling and get excellent results. We also apply HF to optimal control and obtain RNN control laws that can successfully operate under conditions of delayed feedback and unknown disturbances. Finally, we describe a random parameter initialization scheme that allows gradient descent with momentum to train RNNs on problems with long-term dependencies. This directly contradicts widespread beliefs about the inability of first-order methods to do so, and suggests that previous attempts at training RNNs failed partly due to flaws in the random initialization.", "authors": ["Geoffrey Hinton", "Ilya Sutskever"], "related_topics": ["147168706", "192576344", "114466953"], "citation_count": "465", "reference_count": "96", "references": ["2156909104", "2136922672", "2310919327", "2100495367", "3029645440", "1904365287", "2064675550", "2072128103", "2101105183", "2546302380"], "date": "2012"}, {"id": "2098613108", "title": "Novel approach to nonlinear/non-Gaussian Bayesian state estimation", "abstract": "An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linear- ity or Gaussian noise: it may be applied to any state transition or measurement model. A simula- tion example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter.", "authors": ["N. J. Gordon", "D. J. Salmond", "A. F. M. Smith"], "related_topics": ["206833254", "8639503", "157286648"], "citation_count": "10157", "reference_count": "11", "references": ["2129905273", "2331182131", "2277000961", "1977569390", "2122512809", "1980792219", "2039921094", "2093871828", "2099867508", "2171618211"], "date": "1993"}, {"id": "2118243939", "title": "The sources of innovation", "abstract": "Chapter 1: The functional source of innovation general patterns economic explanation shifting and predicting the sources of innovation innovation as a distributed process. Chapter 2: Users as innovators. Chapter 3: Variations in the functional source of innovation. Chapter 4: Why does the functional source of innovation vary? How do innovators benefit from innovations? Do benefit expectations differ? Chapter 5: The hypothesis in testable form methods five empirical studies discussion. Chapter 6: Shifting the functional source of innovation. Chapter 7: Root of the problem: market research constrained by user experience Lead users as a solution testing the method discussion. Chapter 8: Innovation cooperation between competing firms applications for innovation management.", "authors": ["Eric von Hippel"], "related_topics": ["2777347882", "75434695", "186037533"], "citation_count": "9937", "reference_count": "0", "references": ["2342091124", "2132081716", "2129444086", "2087712586", "2099330597", "2002779084", "2012370212", "1983895294", "2150587481", "1996293917"], "date": "1987"}, {"id": "2137516955", "title": "A call for transparent reporting to optimize the predictive value of preclinical research", "abstract": "The US National Institute of Neurological Disorders and Stroke convened major stakeholders in June 2012 to discuss how to improve the methodological reporting of animal studies in grant applications and publications. The main workshop recommendation is that at a minimum studies should report on sample-size estimation, whether and how animals were randomized, whether investigators were blind to the treatment, and the handling of data. We recognize that achieving a meaningful improvement in the quality of reporting will require a concerted effort by investigators, reviewers, funding agencies and journal editors. Requiring better reporting of animal studies will raise awareness of the importance of rigorous study design to accelerate scientific progress.", "authors": ["Story C. Landis", "Susan G. Amara", "Khusru Asadullah", "Chris P. Austin", "Robi Blumenstein", "Eileen W. Bradley", "Ronald G. Crystal", "Robert B. Darnell", "Robert J. Ferrante", "Howard Fillit", "Robert Finkelstein", "Marc Fisher", "Howard E. Gendelman", "Robert M. Golub", "John L. Goudreau", "Robert A. Gross", "Amelie K. Gubitz", "Sharon E. Hesterlee", "David W. Howells", "John Huguenard", "Katrina Kelner", "Walter Koroshetz", "Dimitri Krainc", "Stanley E. Lazic", "Michael S. Levine", "Malcolm R. Macleod", "John M. McCall", "Richard T. Moxley", "Kalyani Narasimhan", "Linda J. Noble", "Steve Perrin", "John D. Porter", "Oswald Steward", "Ellis Unger", "Ursula Utz", "Shai D. Silberberg"], "related_topics": ["49290038", "2779318504", "2780439572"], "citation_count": "935", "reference_count": "68", "references": ["2481029616", "2243629635", "2032541700", "2161498332", "1501619595", "1998734009", "2142960568", "1987777080", "2011932878", "2170302543"], "date": "2012"}, {"id": "2039921094", "title": "Utilization of modified polar coordinates for bearings-only tracking", "abstract": "Previous studies have shown that the Cartesian coordinate extended Kalman filter exhibits unstable behavior characteristics when utilized for bearings-only target motion analysis (TMA). In contrast, formulating the TMA estimation problem in modified polar (MP) coordinates leads to an extended Kalman filter which is both stable and asymptotically unbiased. Exact state equations for the MP filter are derived without imposing any restrictions on own-ship motion; thus, prediction accuracy inherent in the traditional Cartesian formulation is completely preserved. In addition, these equations reveal that MP coordinates are well-suited for bearings-only TMA because they automatically decouple observable and unobservable components of the estimated state vector. Such decoupling is shown to prevent covariance matrix ill-conditioning, which is the primary cause of filter instability. Further investigation also confirms that the MP state estimates are asymptotically unbiased. Realistic simulation data are presented to support these findings and to compare algorithm performance with respect to the Cramer-Rao lower bound (ideal) as well as the Cartesian and pseudolinear filters.", "authors": ["V. Aidala", "S. Hammel"], "related_topics": ["8639503", "206833254", "2780365227"], "citation_count": "644", "reference_count": "13", "references": ["2154347068", "2009568893", "1983765397", "2089286422", "2051749895", "2169345425", "2096491782", "1981261515", "2171818998", "2077084893"], "date": "1983"}, {"id": "2002022377", "title": "Research on Interest in Science: Theories, methods, and findings", "abstract": "This article presents an overview of interest research and describes the theoretical and methodological background for the assessment of interest in science in large\u2010scale assessments like the \u2018Programme for International Student Assessment\u2019 (PISA). The paper starts with a short retrospective on the history of interest, bringing out theoretical roots that help to understand recent discussions on interest in science education. As interest is a widely used concept with manifold facets, it is essential to discuss different ways of modelling the relationship between a person and a comprehensive object like science with all of its different aspects, including wide ranges of content as well as contexts. Models that can be used for describing the content structure of science interest and the process of interest development are presented. Based on an overview of typical methods for assessing interests, exemplary findings on students\u2019 interest in science are presented, which play an important role in the current s...", "authors": ["Andreas Krapp", "Manfred Prenzel"], "related_topics": ["44877443", "2779011557", "55587333"], "citation_count": "816", "reference_count": "69", "references": ["2140205964", "2057673348", "1763311249", "2159539728", "1883291571", "22546692", "2064809032", "1562584391", "2886921147", "1741920700"], "date": "2011"}, {"id": "2043583598", "title": "Exact reconstruction techniques for tree-structured subband coders", "abstract": "In recent years, tree-structured analysis/reconstruction systems have been extensively studied for use in subband coders for speech. In such systems, it is imperative that the individual channel signals be decimated in such a way that the number of samples coded and transmitted do not exceed the number of samples in the original speech signal. Under this constraint, the systems presented in the past have sought to remove the aliasing distortion while minimizing the overall analysis/reconstruction distortion. In this paper, it is shown that it is possible to design tree-structured analysis/reconstruction systems which meet the sampling rate condition and which result in exact reconstruction of the input signal. The conditions for exact reconstruction are developed and presented. Furthermore, it is shown that these conditions are not overly restrictive and high-quality frequency division may be performed in the analysis section. A filter design procedure is presented which allows high-quality filters to be easily designed.", "authors": ["M. Smith", "T. Barnwell"], "related_topics": ["57747864", "22597639", "13895895"], "citation_count": "1110", "reference_count": "16", "references": ["2153639720", "1690240707", "2128395221", "2014944438", "2118907275", "2026855132", "1602592328", "2153540021", "2014419911", "2064724015"], "date": "1986"}, {"id": "2104210894", "title": "OceanStore: an architecture for global-scale persistent storage", "abstract": "OceanStore is a utility infrastructure designed to span the globe and provide continuous access to persistent information. Since this infrastructure is comprised of untrusted servers, data is protected through redundancy and cryptographic techniques. To improve performance, data is allowed to be cached anywhere, anytime. Additionally, monitoring of usage patterns allows adaptation to regional outages and denial of service attacks; monitoring also enhances performance through pro-active movement of data. A prototype implementation is currently under development.", "authors": ["John Kubiatowicz", "David Bindel", "Yan Chen", "Steven Czerwinski", "Patrick Eaton", "Dennis Geels", "Ramakrishna Gummadi", "Sean Rhea", "Hakim Weatherspoon", "Westley Weimer", "Chris Wells", "Ben Zhao"], "related_topics": ["93996380", "38822068", "2148693"], "citation_count": "3491", "reference_count": "52", "references": ["2104532741", "2126087831", "2126540423", "2000876023", "2115599946", "2170496240", "1539259921", "3145637508", "2104112849", "196539227"], "date": "2000"}, {"id": "2120340025", "title": "Graphical Models, Exponential Families, and Variational Inference", "abstract": "The formalism of probabilistic graphical models provides a unifying framework for capturing complex dependencies among random variables, and building large-scale multivariate statistical models. Graphical models have become a focus of research in many statistical, computational and mathematical fields, including bioinformatics, communication theory, statistical physics, combinatorial optimization, signal and image processing, information retrieval and statistical machine learning. Many problems that arise in specific instances \u2014 including the key problems of computing marginals and modes of probability distributions \u2014 are best studied in the general setting. Working with exponential family representations, and exploiting the conjugate duality between the cumulant function and the entropy for exponential families, we develop general variational representations of the problems of computing likelihoods, marginal probabilities and most probable configurations. We describe how a wide variety of algorithms \u2014 among them sum-product, cluster variational methods, expectation-propagation, mean field methods, max-product and linear programming relaxation, as well as conic programming relaxations \u2014 can all be understood in terms of exact or approximate forms of these variational representations. The variational approach provides a complementary alternative to Markov chain Monte Carlo as a general source of approximation methods for inference in large-scale statistical models.", "authors": ["Martin J. Wainwright", "Michael I. Jordan"], "related_topics": ["13778685", "30549945", "155846161"], "citation_count": "4334", "reference_count": "260", "references": ["2296319761", "1880262756", "3145128584", "2099111195", "1574901103", "2752885492", "2798909945", "2798766386", "2137813581", "2610857016"], "date": "2008"}, {"id": "1992876548", "title": "Power-aware routing in mobile ad hoc networks", "abstract": "b this paper we present a case for using new power-aware metn.cs for determining routes in wireless ad hoc networks. We present five ~erent metriw based on battery power consumption at nodw. We show that using th=e metrics in a shortest-cost routing algorithm reduces the cost/packet of routing packets by 5-30% over shortwt-hop routing (this cost reduction is on top of a 40-70% reduction in energy consumption obtained by using PAMAS, our MAC layer prtocol). Furthermore, using these new metrics ensures that the mean time to node failure is increased si~cantly. An interesting property of using shortest-cost routing is that packet delays do not increase. Fintiy, we note that our new metrim can be used in most tradition routing protocols for ad hoc networks.", "authors": ["Suresh Singh", "Mike Woo", "C. S. Raghavendra"], "related_topics": ["204739117", "47318570", "9659607"], "citation_count": "2925", "reference_count": "28", "references": ["2157457404", "1555915743", "2135035173", "2905110430", "2099057525", "2086976228", "2017333190", "2148099880", "1994980566", "2055654205"], "date": "1998"}, {"id": "2052670720", "title": "Segmentation through the detection of changes due to motion", "abstract": "Abstract This paper discusses a scheme for extracting the images of moving objects in dynamic scenes. Differencing operations are used to identify areas containing moving objects. The images of the moving objects can then be obtained by focusing the segmentation processes on these restricted areas. Thus motion is used as a cue to segmentation.", "authors": ["Ramesh Jain", "W.N. Martin", "J.K. Aggarwal"], "related_topics": ["65885262", "89600930", "31972630"], "citation_count": "204", "reference_count": "14", "references": ["3017143921", "2130355536", "1994552597", "39428922", "2015157402", "2131729179", "1974560436", "2082917807", "1980484931", "1587153270"], "date": "1979"}, {"id": "2117400858", "title": "Transformation-based error-driven learning and natural language processing: a case study in part-of-speech tagging", "abstract": "Recently, there has been a rebirth of empiricism in the field of natural language processing. Manual encoding of linguistic information is being challenged by automated corpus-based learning as a method of providing a natural language processing system with linguistic knowledge. Although corpus-based approaches have been successful in many different areas of natural language processing, it is often the case that these methods capture the linguistic information they are modelling indirectly in large opaque tables of statistics. This can make it difficult to analyze, understand and improve the ability of these approaches to model underlying linguistic behavior. In this paper, we will describe a simple rule-based approach to automated learning of linguistic knowledge. This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance. We present a detailed case study of this learning method applied to part-of-speech tagging.", "authors": ["Eric Brill"], "related_topics": ["64249296", "129792486", "2776426008"], "citation_count": "2315", "reference_count": "40", "references": ["1594031697", "2149706766", "1632114991", "2102381086", "2099247782", "2097333193", "2081687495", "1489181569", "2046224275", "2170381724"], "date": "1995"}, {"id": "3147861039", "title": "Unlocking method and device", "abstract": "The invention discloses an unlocking method and an unlocking device. The unlocking method comprises the following steps: obtaining a user gesture by virtue of an ultrasonic sensor in a mobile terminal; matching the obtained user gesture with each standard gesture in a standard gesture base, and determining a to-be-unlocked object, which corresponds to the user gesture, of the mobile terminal after the obtained user gesture is matched with any standard gesture successfully; unlocking the to-be-unlocked object of the mobile terminal. The device comprises a gesture obtaining module, a to-be-unlocked object determining module and an unlocking module, wherein the gesture obtaining module is used for obtaining the user gesture by virtue of the ultrasonic sensor in the mobile terminal; the to-be-unlocked object determining module is used for matching the obtained user gesture with each standard gesture in the standard gesture base, and determining the to-be-unlocked object, which corresponds to the user gesture, of the mobile terminal after the obtained user gesture is matched with any standard gesture successfully; the unlocking module is used for unlocking the determined to-be-unlocked object of the mobile terminal. According to the unlocking method and the unlocking device, an unlocking process is simplified and operation convenience of the mobile terminal is strengthened.", "authors": ["Zhang Haiping", "Zhou Yibao"], "related_topics": ["207347870", "2777782449", "64729616"], "citation_count": "8", "reference_count": "10", "references": ["2849021222", "3020031967", "2927784224", "2934965531", "2307742679", "1592828884", "2864493746", "2850032351", "2856076970", "971962980"], "date": "2016"}, {"id": "1483307070", "title": "Sequential Monte Carlo methods in practice", "abstract": "Monte Carlo methods are revolutionizing the on-line analysis of data in fields as diverse as financial modeling, target tracking and computer vision. These methods, appearing under the names of bootstrap filters, condensation, optimal Monte Carlo filters, particle filters and survival of the fittest, have made it possible to solve numerically many complex, non-standard problems that were previously intractable. This book presents the first comprehensive treatment of these techniques, including convergence results and applications to tracking, guidance, automated target recognition, aircraft navigation, robot navigation, econometrics, financial modeling, neural networks, optimal control, optimal filtering, communications, reinforcement learning, signal enhancement, model averaging and selection, computer vision, semiconductor design, population biology, dynamic Bayesian networks, and time series analysis. This will be of great value to students, researchers and practitioners, who have some basic knowledge of probability. Arnaud Doucet received the Ph. D. degree from the University of Paris-XI Orsay in 1997. From 1998 to 2000, he conducted research at the Signal Processing Group of Cambridge University, UK. He is currently an assistant professor at the Department of Electrical Engineering of Melbourne University, Australia. His research interests include Bayesian statistics, dynamic models and Monte Carlo methods. Nando de Freitas obtained a Ph.D. degree in information engineering from Cambridge University in 1999. He is presently a research associate with the artificial intelligence group of the University of California at Berkeley. His main research interests are in Bayesian statistics and the application of on-line and batch Monte Carlo methods to machine learning. Neil Gordon obtained a Ph.D. in Statistics from Imperial College, University of London in 1993. He is with the Pattern and Information Processing group at the Defence Evaluation and Research Agency in the United Kingdom. His research interests are in time series, statistical data analysis, and pattern recognition with a particular emphasis on target tracking and missile guidance.", "authors": ["Arnaud Doucet", "Nando De Freitas", "Neil Gordon", "Adrian Smith"], "related_topics": ["52421305", "101112237", "97541855"], "citation_count": "8580", "reference_count": "0", "references": ["2336416123", "2144898279", "1501586228", "2038420319", "2130422193", "1521785144", "2110575115", "2160584648", "2113577207", "2148820580"], "date": "2000"}, {"id": "2045182040", "title": "WINNING ENTRY OF THE K. U. LEUVEN TIME-SERIES PREDICTION COMPETITION", "abstract": "In this paper we describe the winning entry of the time-series prediction competition which was part of the International Workshop on Advanced Black-Box Techniques for Nonlinear Modeling, held at K. U. Leuven, Belgium on July 8\u201310, 1998. We also describe the source of the data set, a nonlinear transform of a 5-scroll generalized Chua's circuit. Participants were given 2000 data points and were asked to predict the next 200 points in the series. The winning entry exploited symmetry that was discovered during exploratory data analysis and a method of local modeling designed specifically for the prediction of chaotic time-series. This method includes an exponentially weighted metric, a nearest trajectory algorithm, integrated local averaging, and a novel multistep ahead cross-validation estimation of model error for the purpose of parameter optimization.", "authors": ["J McNames", "Johan Suykens", "Joos Vandewalle"], "related_topics": ["151406439", "205617318", "120894424"], "citation_count": "60", "reference_count": "42", "references": ["1689445748", "1549386224", "2034099719", "2024668293", "1599681710", "2129287653", "2171987742", "3036383388", "2136038769", "2496842803"], "date": "1999"}, {"id": "2169585233", "title": "Drug development and clinical trials\u2014the path to an approved cancer drug", "abstract": "Advances in our understanding of cancer biology have led to the discovery of a spectrum of new therapeutic targets. However, despite remarkable progress in the identification and characterization of novel mechanisms of the oncogenic process, the success rate for approval of oncology drugs remains low relative to other therapeutic areas. Innovative preclinical and clinical approaches, such as the use of advanced genomic technologies, as well as branched adaptive clinical trial designs, have the potential to accelerate the development and approval of highly effective oncology drugs, along with a matching diagnostic test to identify those patients most likely to benefit from the new treatment. To maximize the effectiveness of these new strategies, close collaboration between academic, industry, and regulatory agencies will be required. In this Review, we highlight new approaches in preclinical and clinical drug development that will help accelerate approval of drugs, and aim to provide more-effective treatments alongside companion diagnostic tests to ensure the right treatment is given to the right patient.", "authors": ["Eric H. Rubin", "D. Gary Gilliland"], "related_topics": ["64903051", "2780416959", "2776336576"], "citation_count": "125", "reference_count": "47", "references": ["2097995306", "2128542677", "2104830962", "1999966467", "2067833766", "2016086822", "2065812641", "2158863975", "2066135299", "1969525589"], "date": "2012"}, {"id": "2100664567", "title": "On Using Very Large Target Vocabulary for Neural Machine Translation", "abstract": "Neural machine translation, a recently proposed approach to machine translation based purely on neural networks, has shown promising results compared to the existing approaches such as phrase-based statistical machine translation. Despite its recent success, neural machine translation has its limitation in handling a larger vocabulary, as training complexity as well as decoding complexity increase proportionally to the number of target words. In this paper, we propose a method based on importance sampling that allows us to use a very large target vocabulary without increasing training complexity. We show that decoding can be efficiently done even with the model having a very large target vocabulary by selecting only a small subset of the whole target vocabulary. The models trained by the proposed approach are empirically found to outperform the baseline models with a small vocabulary as well as the LSTM-based neural machine translation models. Furthermore, when we use the ensemble of a few models with very large target vocabularies, we achieve the state-of-the-art translation performance (measured by BLEU) on the English!German translation and almost as high performance as state-of-the-art English!French translation system.", "authors": ["S\u00e9bastien Jean", "Kyunghyun Cho", "Roland Memisevic", "Yoshua Bengio"], "related_topics": ["130597682", "53893814", "203005215"], "citation_count": "870", "reference_count": "20", "references": ["2964308564", "1614298861", "2130942839", "2157331557", "2101105183", "1753482797", "2964199361", "2153653739", "1606347560", "2118434577"], "date": "2015"}, {"id": "1980491396", "title": "Word and Object", "abstract": "Language consists of dispositions, socially instilled, to respond observably to socially observable stimuli. Such is the point of view from which a noted philosopher and logician examines the notion of meaning and the linguistic mechanisms of objective reference. In the course of the discussion, Professor Quine pinpoints the difficulties involved in translation, brings to light the anomalies and conflicts implicit in our language's referential apparatus, clarifies semantic problems connected with the imputation of existence, and marshals reasons for admitting or repudiating each of various categories of supposed objects. He argues that the notion of a language-transcendent \"sentence-meaning\" must on the whole be rejected; meaningful studies in the semantics of reference can only be directed toward substantially the same language in which they are conducted.", "authors": ["Willard Van Orman Quine"], "related_topics": ["2779121694", "2779286777", "161431488"], "citation_count": "15558", "reference_count": "0", "references": ["1983578042", "2150375089", "1608805534", "657137669", "2121765158", "2248695218", "2165683312", "1482796826", "2025605773", "1731244441"], "date": "1959"}, {"id": "2083875149", "title": "Sampling-Based Approaches to Calculating Marginal Densities", "abstract": "Abstract Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions. The three approaches will be reviewed, compared, and contrasted in relation to various joint probability structures frequently encountered in applications. In particular, the relevance of the approaches to calculating Bayesian posterior densities for a variety of structured models will be discussed and illustrated.", "authors": ["Alan E. Gelfand", "Adrian F. M. Smith"], "related_topics": ["158424031", "52740198", "19499675"], "citation_count": "9041", "reference_count": "23", "references": ["1997063559", "2049633694", "2152828142", "2615953416", "2152977846", "3129711340", "2156273867", "2017696952", "2114220616", "2138309709"], "date": "1990"}, {"id": "2106028863", "title": "XStream: a Signal-Oriented Data Stream Management System", "abstract": "Sensors capable of sensing phenomena at high data rates on the order of tens to hundreds of thousands of samples per second are now widely deployed in many industrial, civil engineering, scientific, networking, and medical applications. In aggregate, these sensors easily generate several million samples per second that must be processed within milliseconds or seconds. The computation required includes both signal processing and event stream processing. XStream is a stream processing system for such applications. XStream introduces a new data type, the signal segment, which allows applications to manipulate isochronous (regularly spaced in time) collections of sensor samples more conveniently and efficiently than the asynchronous representation used in previous work. XStream includes a memory manager and scheduler optimizations tuned for processing signal segments at high speeds. In benchmark comparisons, we show that XStream outperforms a leading commercial stream processing system by more than three orders of magnitude. On one application, the commercial system processed 72.7 Ksamples/sec, while XStream processed 97.6 Msamples/sec.", "authors": ["L. Girod", "Yuan Mei", "R. Newton", "S. Rost", "A. Thiagarajan", "H. Balakrishnan", "S. Madden"], "related_topics": ["2780171727", "2778654863", "107027933"], "citation_count": "117", "reference_count": "17", "references": ["2157578436", "2115503987", "2161569281", "2118828104", "1568192366", "2144261930", "2120117050", "2123536775", "1831560769", "2162553498"], "date": "2008"}, {"id": "2158905201", "title": "Large vocabulary continuous speech recognition of Wall Street Journal data", "abstract": "We report on recent developments of the Philips large vocabulary speech recognition system and on our experiments with the Wall Street Journal (WSJ) corpus. A two-pass decoding has been devised that allows an easy integration of more complex language models. First, a word lattice is produced using a time synchronous beam search with a bigram language model. Next, a higher-order language model is applied to the lattice at the phrase level. The conditions insuring the validity of this approach are explained and practical results for trigram demonstrate its usefulness. The main system development stages on WSJ data are presented and our final recognizers are evaluated on Nov. '92 and Nov. '93 test-data for both 5 K and 20 K vocabularies. >", "authors": ["X. Aubert", "C. Dugast", "H. Ney", "V. Steinbiss"], "related_topics": ["108757681", "2777601683", "137293760"], "citation_count": "81", "reference_count": "10", "references": ["2024490156", "2022951240", "1977434607", "2152051032", "15592790", "2166480741", "2130266733", "2151135538", "167038073", "117546234"], "date": "1994"}, {"id": "2145295623", "title": "Learning the Kernel Matrix with Semidefinite Programming", "abstract": "Kernel-based learning algorithms work by embedding the data into a Euclidean space, and then searching for linear relations among the embedded data points. The embedding is performed implicitly, by specifying the inner products between each pair of points in the embedding space. This information is contained in the so-called kernel matrix, a symmetric and positive semidefinite matrix that encodes the relative positions of all points. Specifying this matrix amounts to specifying the geometry of the embedding space and inducing a notion of similarity in the input space---classical model selection problems in machine learning. In this paper we show how the kernel matrix can be learned from data via semidefinite programming (SDP) techniques. When applied to a kernel matrix associated with both training and test data this gives a powerful transductive algorithm---using the labeled part of the data one can learn an embedding also for the unlabeled part. The similarity between test points is inferred from training points and their labels. Importantly, these learning problems are convex, so we obtain a method for learning both the model class and the function without local minima. Furthermore, this approach leads directly to a convex method for learning the 2-norm soft margin parameter in support vector machines, solving an important open problem.", "authors": ["Gert R. G. Lanckriet", "Nello Cristianini", "Peter Bartlett", "Laurent El Ghaoui", "Michael I. Jordan"], "related_topics": ["206818286", "122280245", "134517425"], "citation_count": "2930", "reference_count": "24", "references": ["2296319761", "1563088657", "3023786531", "1510073064", "1967073510", "1601740268", "1956559956", "2912522929", "2087064593", "2579923771"], "date": "2004"}, {"id": "1531743498", "title": "FOIL: A Midterm Report", "abstract": "FOIL is a learning system that constructs Horn clause programs from examples. This paper summarises the development of FOIL from 1989 up to early 1993 and evaluates its effectiveness on a non-trivial sequence of learning tasks taken from a Prolog programming text. Although many of these tasks are handled reasonably well, the experiment highlights some weaknesses of the current implementation. Areas for further research are identified.", "authors": ["J. Ross Quinlan", "R. Mike Cameron-Jones"], "related_topics": ["189790780", "81721847", "115903868"], "citation_count": "825", "reference_count": "19", "references": ["2125055259", "1594031697", "1999138184", "1565236324", "1570286060", "1523712082", "1514468887", "177590838", "2037689320", "2484153108"], "date": "1993"}, {"id": "2115763357", "title": "A general framework for object detection", "abstract": "This paper presents a general trainable framework for object detection in static images of cluttered scenes. The detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instances. By learning an object class in terms of a subset of an overcomplete dictionary of wavelet basis functions, we derive a compact representation of an object class which is used as an input to a support vector machine classifier. This representation overcomes both the problem of in-class variability and provides a low false detection rate in unconstrained environments. We demonstrate the capabilities of the technique in two domains whose inherent information content differs significantly. The first system is face detection and the second is the domain of people which, in contrast to faces, vary greatly in color, texture, and patterns. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or motion-based segmentation. The paper also presents a motion-based extension to enhance the performance of the detection algorithm over video sequences. The results presented here suggest that this architecture may well be quite general.", "authors": ["C.P. Papageorgiou", "M. Oren", "T. Poggio"], "related_topics": ["71681937", "2776151529", "182521987"], "citation_count": "2123", "reference_count": "16", "references": ["2132984323", "2087347434", "2124351082", "2125848778", "2104671481", "2159173611", "2137346077", "2056695679", "1676612073", "2030989822"], "date": "1998"}, {"id": "1500256440", "title": "Modern Quantum Mechanics", "abstract": "Modern Quantum Mechanics is a classic graduate level textbook, covering the main quantum mechanics concepts in a clear, organized and engaging manner. The author, Jun John Sakurai, was a renowned theorist in particle theory. The second edition, revised by Jim Napolitano, introduces topics that extend the text's usefulness into the twenty-first century, such as advanced mathematical techniques associated with quantum mechanical calculations, while at the same time retaining classic developments such as neutron interferometer experiments, Feynman path integrals, correlation measurements, and Bell's inequality. A solution manual for instructors using this textbook can be downloaded from www.cambridge.org/9781108422413.", "authors": ["Jun John Sakurai", "Jim Napolitano"], "related_topics": ["190474826", "177414767", "120239472"], "citation_count": "5445", "reference_count": "0", "references": ["1516111018", "2011208902", "2030867075", "2146051607", "2132568564", "2417863416", "245337057", "2137084802", "2093942696", "1576246962"], "date": "1984"}, {"id": "2137305553", "title": "Two-dimensional position sensor", "abstract": "A capacitive position sensor for determining the position of an object along first and second directions is described. The sensor comprises a substrate having an arrangement of electrodes mounted on a single surface thereof. The electrodes are arranged so as to define an array of sensing cells arranged in columns and rows to form a sensing area. Each of the sensing cell including a column sensing electrode and a row sensing electrode with the column sensing electrodes of sensing cells in the same column being electrically coupled together and the row sensing electrodes of sensing cells in the same row also being electrically coupled together. Row sensing electrodes of sensing cells at opposing ends of at least one of the rows are connected together by an electrical connection made outside of the sensing area so that there is no requirement for electrical connections to cross within the sensing area, thus providing a capacitive position sensor having a sensing area with electrodes on only one side of a substrate.", "authors": ["Luben Hristov"], "related_topics": ["206755178", "29258643", "135598885"], "citation_count": "901", "reference_count": "93", "references": ["2165432612", "2096605459", "2258130146", "1886112015", "2849334407", "2162399989", "1936978992", "2111725493", "2103081962", "3142604055"], "date": "2008"}, {"id": "2069501481", "title": "Digital Processing of Speech Signals", "abstract": "1. Introduction. 2. Fundamentals of Digital Speech Processing. 3. Digital Models for the Speech Signal. 4. Time-Domain Models for Speech Processing. 5. Digital Representation of the Speech Waveform. 6. Short-Time Fourier Analysis. 7. Homomorphic Speech Processing. 8. Linear Predictive Coding of Speech. 9. Digital Speech Processing for Man-Machine Communication by Voice.", "authors": ["Lawrence R. Rabiner", "Ronald W. Schafer"], "related_topics": ["61328038", "204201278", "13895895"], "citation_count": "4844", "reference_count": "0", "references": ["2139356617", "2159390040", "2074788634", "1755563775", "2014683958", "2078528584", "2129244720", "353562331", "1553004968", "1508471544"], "date": "1978"}, {"id": "2144544802", "title": "Biclustering Algorithms for Biological Data Analysis: A Survey", "abstract": "A large number of clustering approaches have been proposed for the analysis of gene expression data obtained from microarray experiments. However, the results from the application of standard clustering methods to genes are limited. This limitation is imposed by the existence of a number of experimental conditions where the activity of genes is uncorrelated. A similar limitation exists when clustering of conditions is performed. For this reason, a number of algorithms that perform simultaneous clustering on the row and column dimensions of the data matrix has been proposed. The goal is to find submatrices, that is, subgroups of genes and subgroups of conditions, where the genes exhibit highly correlated activities for every condition. In this paper, we refer to this class of algorithms as biclustering. Biclustering is also referred in the literature as coclustering and direct clustering, among others names, and has also been used in fields such as information retrieval and data mining. In this comprehensive survey, we analyze a large number of existing approaches to biclustering, and classify them in accordance with the type of biclusters they can find, the patterns of biclusters that are discovered, the methods used to perform the search, the approaches used to evaluate the solution, and the target applications.", "authors": ["Sara C. Madeira", "Arlindo L. Oliveira"], "related_topics": ["144817290", "94641424", "184509293"], "citation_count": "2500", "reference_count": "53", "references": ["3145128584", "2109363337", "2752885492", "2147246240", "2103453943", "2087684630", "301824129", "2109970232", "1990061958", "2008233728"], "date": "2003"}, {"id": "2115599946", "title": "Feasibility of a serverless distributed file system deployed on an existing set of desktop PCs", "abstract": "We consider an architecture for a serverless distributed file system that does not assume mutual trust among the client computers. The system provides security, availability, and reliability by distributing multiple encrypted replicas of each file among the client machines. To assess the feasibility of deploying this system on an existing desktop infrastructure, we measure and analyze a large set of client machines in a commercial environment. In particular, we measure and report results on disk usage and content; file activity; and machine uptimes, lifetimes, and loads. We conclude that the measured desktop infrastructure would passably support our proposed system, providing availability on the order of one unfilled file request per user per thousand days.", "authors": ["William J. Bolosky", "John R. Douceur", "David Ely", "Marvin Theimer"], "related_topics": ["82820731", "88520388", "58861120"], "citation_count": "792", "reference_count": "26", "references": ["2112053513", "2147504831", "196539227", "2005373714", "2135131646", "2025413686", "2007415020", "2124288146", "2115457697", "2070834743"], "date": "2000"}, {"id": "2159277521", "title": "System for disposing a proximity sensitive touchpad behind a mobile phone keymat", "abstract": "A proximity-based mutually capacitance-sensitive touchpad (26) that is disposed directly beneath a keypad keymat (22) of a mobile telephone (10), wherein posts (24) associated with each key (20) pass through a mutually capacitance-sensitive sensor electrode grid of the touchpad such that the keypad posts (24) do not interface with touchpad detection and tracking of pointing object that moves along the keypad surface, to thereby enable touchpad data entry, cursor control, and scroll bar control on a display of the mobile telephone, wherein the keypad posts actuate mechanical switches (32) underneath the touchpad.", "authors": ["Brian Taylor", "Michael D. Layton", "David Taylor"], "related_topics": ["43199551", "2780140372", "2776561805"], "citation_count": "495", "reference_count": "16", "references": ["1886112015", "2748264430", "2611215833", "3100249869", "161820527", "1760990003", "131663217", "1555317068", "2148855229", "1873691688"], "date": "2002"}, {"id": "3121147667", "title": "Self-Nonself Discrimination in a Computer", "abstract": "The problem of protecting computer systems can be viewed generally as the problem of learning to distinguish {\\it self} from {\\it other}. We describe a method for change detection which is based on the gereration of T cells in the immune system. Mathematical analysis reveals computational costs of the system, and preliminary experiments illustrate how the method might be applied to the problem of computer viruses.", "authors": ["Stephanie Forrest", "Alan S. Perelson", "Lawrence Allen", "Rajesh Cherukuri"], "related_topics": ["203595873", "19407854", "80444323"], "citation_count": "5083", "reference_count": "0", "references": ["2122646361", "3136767761", "1941427975", "2139669429", "2058657545", "2105779206", "2135143063", "2108398740", "2107676921", "1567102157"], "date": "1994"}, {"id": "2124192278", "title": "Numerical heat transfer and fluid flow", "abstract": "This book focuses on heat and mass transfer, fluid flow, chemical reaction, and other related processes that occur in engineering equipment, the natural environment, and living organisms. Using simple algebra and elementary calculus, the author develops numerical methods for predicting these processes mainly based on physical considerations. Through this approach, readers will develop a deeper understanding of the underlying physical aspects of heat transfer and fluid flow as well as improve their ability to analyze and interpret computed results.", "authors": ["Suhas V. Patankar"], "related_topics": ["90278072", "50517652", "204561356"], "citation_count": "23692", "reference_count": "0", "references": ["2151080396", "2762367303", "2343951702", "2140796340", "2132130554", "2141870784", "2136719269", "2733062301", "2171303908", "1549748890"], "date": "1979"}, {"id": "2132870739", "title": "Estimating the Support of a High-Dimensional Distribution", "abstract": "Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a \"simple\" subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1. We propose a method to approach this problem by trying to estimate a function f that is positive on S and negative on the complement. The functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the length of the weight vector in an associated feature space. The expansion coefficients are found by solving a quadratic programming problem, which we do by carrying out sequential optimization over pairs of input patterns. We also provide a theoretical analysis of the statistical performance of our algorithm. The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data.", "authors": ["Bernhard Sch\u00f6lkopf", "John C. Platt", "John C. Shawe-Taylor", "Alex J. Smola", "Robert C. Williamson"], "related_topics": ["149441793", "58442840", "98234853"], "citation_count": "5456", "reference_count": "56", "references": ["2156909104", "2148603752", "2099111195", "2798766386", "1512098439", "1576520375", "2087347434", "1604938182", "2108995755", "2161920802"], "date": "2001"}, {"id": "2097356832", "title": "Systems and Methods for Secure Transaction Management and Electronic Rights Protection", "abstract": "PROBLEM TO BE SOLVED: To solve the problem, wherein it is impossible for an electronic content information provider to provide commercially secure and effective method, for a configurable general-purpose electronic commercial transaction/distribution control system. SOLUTION: In this system, having at least one protected processing environment for safely controlling at least one portion of decoding of digital information, a secure content distribution method comprises a process for encapsulating digital information in one or more digital containers; a process for encrypting at least a portion of digital information; a process for associating at least partially secure control information for managing interactions with encrypted digital information and/or digital container; a process for delivering one or more digital containers to a digital information user; and a process for using a protected processing environment, for safely controlling at least a portion of the decoding of the digital information. COPYRIGHT: (C)2006,JPO&NCIPI", "authors": ["Karl L. Ginter", "Victor H. Shear", "Francis J. Spahn", "David M. Van Wie"], "related_topics": ["2780795517", "527648132", "148730421"], "citation_count": "14718", "reference_count": "500", "references": ["2150010995", "2140471436", "2159390040", "1996360405", "2152592781", "2156186849", "1585665690", "1999047234", "2341865734", "2170496240"], "date": "2010"}, {"id": "2081839681", "title": "A threshold theory for simple detection experiments.", "abstract": "The two-state \"high\" threshold model is generalized by assuming that (with low probability) the threshold may be exceeded when there is no stimulus. Existing Yes-No data (that rejected the high threshold theory) are compatible with the resulting isosensitivity (ROC) curves, namely, 2 line segments that intersect at the true threshold probabilities. The corresponding 2-alternative forced-choice curve is a 45\u00b0 line through this intersection. A simple learning process is suggested to predict S's location along these curves, asymptotic means are derived, and comparisons are made with data. These asymptotic biases are coupled with the von Bdk&y-Stevens neural quantum model to show how the theoretical linear psychometric functions are distorted into nonsymmetric, nonlinear response curves.", "authors": ["R. Duncan Luce"], "related_topics": ["202632270", "158622935", "182124507"], "citation_count": "373", "reference_count": "32", "references": ["3149412023", "2319178748", "2058653372", "2024453660", "2797620854", "2095683621", "2038371355", "2050985708", "2126800224", "2056669483"], "date": "1962"}, {"id": "2006258746", "title": "Optimal Statistical Decisions", "abstract": "Foreword.Preface.PART ONE. SURVEY OF PROBABILITY THEORY.Chapter 1. Introduction.Chapter 2. Experiments, Sample Spaces, and Probability.2.1 Experiments and Sample Spaces.2.2 Set Theory.2.3 Events and Probability.2.4 Conditional Probability.2.5 Binomial Coefficients.Exercises.Chapter 3. Random Variables, Random Vectors, and Distributions Functions.3.1 Random Variables and Their Distributions.3.2 Multivariate Distributions.3.3 Sums and Integrals.3.4 Marginal Distributions and Independence.3.5 Vectors and Matrices.3.6 Expectations, Moments, and Characteristic Functions.3.7 Transformations of Random Variables.3.8 Conditional Distributions.Exercises.Chapter 4. Some Special Univariate Distributions.4.1 Introduction.4.2 The Bernoulli Distributions.4.3 The Binomial Distribution.4.4 The Poisson Distribution.4.5 The Negative Binomial Distribution.4.6 The Hypergeometric Distribution.4.7 The Normal Distribution.4.8 The Gamma Distribution.4.9 The Beta Distribution.4.10 The Uniform Distribution.4.11 The Pareto Distribution.4.12 The t Distribution.4.13 The F Distribution.Exercises.Chapter 5. Some Special Multivariate Distributions.5.1 Introduction.5.2 The Multinomial Distribution.5.3 The Dirichlet Distribution.5.4 The Multivariate Normal Distribution.5.5 The Wishart Distribution.5.6 The Multivariate t Distribution.5.7 The Bilateral Bivariate Pareto Distribution.Exercises.PART TWO. SUBJECTIVE PROBABILITY AND UTILITY.Chapter 6. Subjective Probability.6.1 Introduction.6.2 Relative Likelihood.6.3 The Auxiliary Experiment.6.4 Construction of the Probability Distribution.6.5 Verification of the Properties of a Probability Distribution.6.6 Conditional Likelihoods.Exercises.Chapter 7. Utility.7.1 Preferences Among Rewards.7.2 Preferences Among Probability Distributions.7.3 The Definitions of a Utility Function.7.4 Some Properties of Utility Functions.7.5 The Utility of Monetary Rewards.7.6 Convex and Concave Utility Functions.7.7 The Anxiomatic Development of Utility.7.8 Construction of the Utility Function.7.9 Verification of the Properties of a Utility Function.7.10 Extension of the Properties of a Utility Function to the Class ?E.Exercises.PART THREE. STATISTICAL DECISION PROBLEMS.Chapter 8. Decision Problems.8.1 Elements of a Decision Problem.8.2 Bayes Risk and Bayes Decisions.8.3 Nonnegative Loss Functions.8.4 Concavity of the Bayes Risk.8.5 Randomization and Mixed Decisions.8.6 Convex Sets.8.7 Decision Problems in Which ~2 and D Are Finite.8.8 Decision Problems with Observations.8.9 Construction of Bayes Decision Functions.8.10 The Cost of Observation.8.11 Statistical Decision Problems in Which Both ? and D contains Two Points.8.12 Computation of the Posterior Distribution When the Observations Are Made in More Than One Stage.Exercises.Chapter 9. Conjugate Prior Distributions.9.1 Sufficient Statistics.9.2 Conjugate Families of Distributions.9.3 Construction of the Conjugate Family.9.4 Conjugate Families for Samples from Various Standard Distributions.9.5 Conjugate Families for Samples from a Normal Distribution.9.6 Sampling from a Normal Distribution with Unknown Mean and Unknown Precision.9.7 Sampling from a Uniform Distribution.9.8 A Conjugate Family for Multinomial Observations.9.9 Conjugate Families for Samples from a Multivariate Normal Distribution.9.10 Multivariate Normal Distributions with Unknown Mean Vector and Unknown Precision matrix.9.11 The Marginal Distribution of the Mean Vector.9.12 The Distribution of a Correlation.9.13 Precision Matrices Having an Unknown Factor.Exercises.Chapter 10. Limiting Posterior Distributions.10.1 Improper Prior Distributions.10.2 Improper Prior Distributions for Samples from a Normal Distribution.10.3 Improper Prior Distributions for Samples from a Multivariate Normal Distribution.10.4 Precise Measurement.10.5 Convergence of Posterior Distributions.10.6 Supercontinuity.10.7 Solutions of the Likelihood Equation.10.8 Convergence of Supercontinuous Functions.10.9 Limiting Properties of the Likelihood Function.10.10 Normal Approximation to the Posterior Distribution.10.11 Approximation for Vector Parameters.10.12 Posterior Ratios.Exercises.Chapter 11. Estimation, Testing Hypotheses, and linear Statistical Models.11.1 Estimation.11.2 Quadratic Loss.11.3 Loss Proportional to the Absolute Value of the Error.11.4 Estimation of a Vector.11.5 Problems of Testing Hypotheses.11.6 Testing a Simple Hypothesis About the Mean of a Normal Distribution.11.7 Testing Hypotheses about the Mean of a Normal Distribution.11.8 Deciding Whether a Parameter Is Smaller or larger Than a Specific Value.11.9 Deciding Whether the Mean of a Normal Distribution Is Smaller or larger Than a Specific Value.11.10 Linear Models.11.11 Testing Hypotheses in Linear Models.11.12 Investigating the Hypothesis That Certain Regression Coefficients Vanish.11.13 One-Way Analysis of Variance.Exercises.PART FOUR. SEQUENTIAL DECISIONS.Chapter 12. Sequential Sampling.12.1 Gains from Sequential Sampling.12.2 Sequential Decision Procedures.12.3 The Risk of a Sequential Decision Procedure.12.4 Backward Induction.12.5 Optimal Bounded Sequential Decision procedures.12.6 Illustrative Examples.12.7 Unbounded Sequential Decision Procedures.12.8 Regular Sequential Decision Procedures.12.9 Existence of an Optimal Procedure.12.10 Approximating an Optimal Procedure by Bounded Procedures.12.11 Regions for Continuing or Terminating Sampling.12.12 The Functional Equation.12.13 Approximations and Bounds for the Bayes Risk.12.14 The Sequential Probability-ratio Test.12.15 Characteristics of Sequential Probability-ratio Tests.12.16 Approximating the Expected Number of Observations.Exercises.Chapter 13. Optimal Stopping.13.1 Introduction.13.2 The Statistician's Reward.13.3 Choice of the Utility Function.13.4 Sampling Without Recall.13.5 Further Problems of Sampling with Recall and Sampling without Recall.13.6 Sampling without Recall from a Normal Distribution with Unknown Mean.13.7 Sampling with Recall from a Normal Distribution with Unknown Mean.13.8 Existence of Optimal Stopping Rules.13.9 Existence of Optimal Stopping Rules for Problems of Sampling with Recall and Sampling without Recall.13.10 Martingales.13.11 Stopping Rules for Martingales.13.12 Uniformly Integrable Sequences of Random Variables.13.13 Martingales Formed from Sums and Products of Random Variables.13.14 Regular Supermartingales.13.15 Supermartingales and General Problems of Optimal Stopping.13.16 Markov Processes.13.17 Stationary Stopping Rules for Markov Processes.13.18 Entrance-fee Problems.13.19 The Functional Equation for a Markov Process.Exercises.Chapter 14. Sequential Choice of Experiments.14.1 Introduction.14.2 Markovian Decision Processes with a Finite Number of Stages.14.3 Markovian Decision Processes with an Infinite Number of Stages.14.4 Some Betting Problems.14.5 Two-armed-bandit Problems.14.6 Two-armed-bandit Problems When the Value of One Parameter Is Known.14.7 Two-armed-bandit Problems When the Parameters Are Dependent.14.8 Inventory Problems.14.9 Inventory Problems with an Infinite Number of Stages.14.10 Control Problems.14.11 Optimal Control When the Process Cannot Be Observed without Error.14.12 Multidimensional Control Problems.14.13 Control Problems with Actuation Errors.14.14 Search Problems.14.15 Search Problems with Equal Costs.14.16 Uncertainty Functions and Statistical Decision Problems.14.17 Sufficient Experiments.14.18 Examples of Sufficient Experiments.Exercises.References.Supplementary Bibliography.Name Index.Subject Index.", "authors": ["Morris Herman DeGroot"], "related_topics": ["91395904", "79708077", "55974624"], "citation_count": "6074", "reference_count": "0", "references": ["1479807131", "1817561967", "2171265988", "2110575115", "2008906462", "2028995298", "1593793857", "2044535354", "3122042041", "2147664181"], "date": "1970"}, {"id": "2172188317", "title": "Scale & Affine Invariant Interest Point Detectors", "abstract": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix. Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point. We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.", "authors": ["Krystian Mikolajczyk", "Cordelia Schmid"], "related_topics": ["6408098", "18516315", "153077589"], "citation_count": "5436", "reference_count": "43", "references": ["2033819227", "2124386111", "2012778485", "2124404372", "1676552347", "2124087378", "2119747362", "2109200236", "2111308925", "2165497495"], "date": "2004"}, {"id": "2112447569", "title": "Online Learning for Matrix Factorization and Sparse Coding", "abstract": "Sparse coding--that is, modelling data vectors as sparse linear combinations of basis elements--is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on the large-scale matrix factorization problem that consists of learning the basis set in order to adapt it to specific data. Variations of this problem include dictionary learning in signal processing, non-negative matrix factorization and sparse principal component analysis. In this paper, we propose to address these tasks with a new online optimization algorithm, based on stochastic approximations, which scales up gracefully to large data sets with millions of training samples, and extends naturally to various matrix factorization formulations, making it suitable for a wide range of learning problems. A proof of convergence is presented, along with experiments with natural images and genomic data demonstrating that it leads to state-of-the-art performance in terms of speed and optimization for both small and large data sets.", "authors": ["Julien Mairal", "Francis Bach", "Jean Ponce", "Guillermo Sapiro"], "related_topics": ["124066611", "24252448", "152671427"], "citation_count": "2829", "reference_count": "83", "references": ["2115755118", "2135046866", "2054141820", "2122825543", "2160547390", "2063978378", "2078204800", "2097018403", "2798909945", "2798766386"], "date": "2010"}, {"id": "1969486090", "title": "Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora", "abstract": "A significant portion of the world's text is tagged by readers on social bookmarking websites. Credit attribution is an inherent problem in these corpora because most pages have multiple tags, but the tags do not always apply with equal specificity across the whole document. Solving the credit attribution problem requires associating each word in a document with the most appropriate tags and vice versa. This paper introduces Labeled LDA, a topic model that constrains Latent Dirichlet Allocation by defining a one-to-one correspondence between LDA's latent topics and user tags. This allows Labeled LDA to directly learn word-tag correspondences. We demonstrate Labeled LDA's improved expressiveness over traditional LDA with visualizations of a corpus of tagged web pages from del.icio.us. Labeled LDA outperforms SVMs by more than 3 to 1 when extracting tag-specific document snippets. As a multi-label text classifier, our model is competitive with a discriminative baseline on a variety of datasets.", "authors": ["Daniel Ramage", "David Hall", "Ramesh Nallapati", "Christopher D. Manning"], "related_topics": ["500882744", "171686336", "97931131"], "citation_count": "1561", "reference_count": "14", "references": ["1880262756", "2001082470", "2150102617", "1550206324", "2098062695", "2112050062", "2106490775", "2124916819", "2066340877", "2113855231"], "date": "2009"}, {"id": "1885251535", "title": "Method and apparatus for automatic placement of advertising", "abstract": "A computer system for automatic replacement of direct advertisements in scarce media includes an advertising server for selecting a direct advertisement based on certain criteria. Transaction results of the direct advertisement placement are reported back to the advertising server, and an associated accounting system. In one embodiment, the direct advertiser's server reports transactions back to the advertising server by email. In a second embodiment, a direct proxy server brokers the user's session (or interaction) with the direct advertiser's server, including transaction processing and the direct proxy server reports the results of transactions back to the advertising server and its associated accounting system. A direct proxy provides an independent audit of transactions at a remote direct advertiser's web site. The feedback of the results of direct advertisement transactions provides an efficient utilization of direct advertising space by way of an automated computer system with a predictive model for selection and distribution of direct advertising.", "authors": ["Dwight A. Merriman", "Kevin O'connor"], "related_topics": ["512338625", "2779298391", "72108876"], "citation_count": "1045", "reference_count": "154", "references": ["2152592781", "2161461831", "2150169316", "2870688700", "2126825876", "2101304210", "2139020969", "1921020360", "2162310432", "2160566752"], "date": "1998"}, {"id": "2963846996", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference", "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.", "authors": ["Adina Williams", "Nikita Nangia", "Samuel R. Bowman"], "related_topics": ["95318506", "2776214188", "2777530160"], "citation_count": "1340", "reference_count": "29", "references": ["2618530766", "2964121744", "2095705004", "2250539671", "1849277567", "2064675550", "2155541015", "1840435438", "2963918774", "1632114991"], "date": "2018"}, {"id": "2170302543", "title": "CONSORT 2010 statement: updated guidelines for reporting parallel group randomised trials.", "abstract": "The CONSORT statement is used worldwide to improve the reporting of randomised controlled trials. Kenneth Schulz and colleagues describe the latest version, CONSORT 2010, which updates the reporting guideline based on new methodological evidence and accumulating experience. To encourage dissemination of the CONSORT 2010 Statement, this article is freely accessible on bmj.com and will also be published in the Lancet, Obstetrics and Gynecology, PLoS Medicine, Annals of Internal Medicine, Open Medicine, Journal of Clinical Epidemiology, BMC Medicine, and Trials.", "authors": ["Kenneth F Schulz", "Douglas G Altman", "David Moher", ""], "related_topics": ["49290038", "2780182762", "2779473830"], "citation_count": "14436", "reference_count": "35", "references": ["2007872832", "2156098321", "2105625949", "2032541700", "1501619595", "2142960568", "2478623089", "2011932878", "2172631095", "2152740900"], "date": "2010"}, {"id": "2802112837", "title": "Class-constraint similarity queries", "abstract": "Similarity searching is a widely applied concept on multimedia or complex data, such as images, videos, time-series, among others. Therefore, it is important to look at the execution of specific query types, e.g., constrained k-nearest neighbor that is directly based on bounded regions. In this paper, we present the Class-Constraint k-Nearest Neighbor (CCkNN) query, which goes beyond the traditional constrained k-nearest neighbor, because our CCkNN works for any specific categories of data points. The proposed CCkNN aims at accelerating the process of class-constraint similarity query execution by taking advantage of performing queries on multiple metric access methods regarding the class dimensions of the objects of each index. Additionally, this strategy identifies which index is more appropriate to run class-constraint on the k-nearest neighbor queries. Experimental results based on several datasets, including synthetic and real ones, show that our strategy can reduce the number of distance calculations in up to two orders of magnitude while keeping a high-quality retrieval, according to the classes of the objects queried.", "authors": ["Jessica A. de Souza", "Agma J. M. Traina", "Sebastian Michel"], "related_topics": ["130590232", "89604369", "205617318"], "citation_count": "1", "reference_count": "14", "references": ["1497953515", "177004468", "2157092487", "299839057", "182666420", "2229332794", "2049797265", "1562873932", "2911265074", "2342159830"], "date": "2018"}, {"id": "2136000097", "title": "The CN2 Induction Algorithm", "abstract": "Systems for inducing concept descriptions from examples are valuable tools for assisting in the task of knowledge acquisition for expert systems. This paper presents a description and empirical evaluation of a new induction system, CN2, designed for the efficient induction of simple, comprehensible production rules in domains where problems of poor description language and/or noise may be present. Implementations of the CN2, ID3, and AQ algorithms are compared on three medical classification tasks.", "authors": ["Peter Clark", "Tim Niblett"], "related_topics": ["2781129481", "2777220311", "2776780472"], "citation_count": "3428", "reference_count": "17", "references": ["2128420091", "1596324102", "2159047538", "2428981601", "1570286060", "128754594", "1567276288", "177590838", "3021257214", "2131722136"], "date": "1989"}, {"id": "110443600", "title": "Finding What People Want : Experiences with the WebCrawler", "abstract": "", "authors": ["B. Pinkerton"], "related_topics": ["41008148"], "citation_count": "405", "reference_count": "0", "references": ["3013264884", "2029341294", "2036120890", "2095150974", "1976959760", "1613836731", "2068272887", "2911388033", "1550771877", "2295141584"], "date": "1993"}, {"id": "1551905080", "title": "Open Innovation: The New Imperative for Creating and Profiting from Technology", "abstract": "", "authors": ["Serdar S. Durmusoglu"], "related_topics": ["2780431167", "2778626457", "186037533"], "citation_count": "13387", "reference_count": "0", "references": ["2169667133", "2136071264", "2132789787", "1553746973", "2100967449", "167368901", "1986342936", "2018915326", "271526086", "1964487809"], "date": "2004"}, {"id": "2021626442", "title": "A generalized canonical formalism and quantization of reducible gauge theories", "abstract": "Abstract A general solution for the S -matrix of relativistic dynamical systems subject to Bose and Fermi first and second class constraints is obtained by canonical quantization in the case of reducibility, i.e. when the first class constraints are linearly dependent. The null-eigenvectors of the constraints may also be linearly dependent and possess null-eigenvectors of their own, which, in their turn, may be linearly dependent, etc. The solution obtained remains valid in the present case of multistage reducibility of constraints.", "authors": ["I.A. Batalin", "E.S. Fradkin"], "related_topics": ["158913796", "39366733", "120239472"], "citation_count": "521", "reference_count": "22", "references": ["2078426698", "2083407626", "2005196146", "2026169595", "2074120956", "2584039307", "2050206614", "2016939318", "2089754965", "1972342483"], "date": "1983"}, {"id": "2020795663", "title": "Approaches to collection selection and results merging for distributed information retrieval", "abstract": "We have investigated two major issues in Distributed Information Retrieval (DIR), namely: collection selection and search results merging. While most published works on these two issues are based on pre-stored metadata, the approaches described in this paper involve extracting the required information at the time the query is processed. In order to predict the relevance of collections to a given query, we analyse a limited number of full documents (e.g., the top five documents) retrieved from each collection and then consider term proximity within them. On the other hand, our merging technique is rather simple since input only requires document scores and lengths of results lists. Our experiments evaluate the retrieval effectiveness of these approaches and compare them with centralised indexing and various other DIR techniques (e.g., CORI). We conducted our experiments using two testbeds: one containing news articles extracted from four different sources (2 GB) and another containing 10 GB of Web pages. Our evaluations demonstrate that the retrieval effectiveness of our simple approaches is worth considering.", "authors": ["Yves Rasolofo", "Fa\u00efza Abbaci", "Jacques Savoy"], "related_topics": ["87546605", "90288658", "75165309"], "citation_count": "102", "reference_count": "27", "references": ["166263196", "103650626", "232533489", "2086253379", "2054805201", "1572257961", "1990388042", "2016892599", "1759973002", "2070620842"], "date": "2001"}, {"id": "2137639365", "title": "Emotional speech recognition: Resources, features, and methods", "abstract": "In this paper we overview emotional speech recognition having in mind three goals. The first goal is to provide an up-to-date record of the available emotional speech data collections. The number of emotional states, the language, the number of speakers, and the kind of speech are briefly addressed. The second goal is to present the most frequent acoustic features used for emotional speech recognition and to assess how the emotion affects them. Typical features are the pitch, the formants, the vocal tract cross-section areas, the mel-frequency cepstral coefficients, the Teager energy operator-based features, the intensity of the speech signal, and the speech rate. The third goal is to review appropriate techniques in order to classify speech into emotional states. We examine separately classification techniques that exploit timing information from which that ignore it. Classification techniques based on hidden Markov models, artificial neural networks, linear discriminant analysis, k-nearest neighbors, support vector machines are reviewed.", "authors": ["Dimitrios Ververidis", "Constantine Kotropoulos"], "related_topics": ["61328038", "54953205", "23224414"], "citation_count": "1034", "reference_count": "104", "references": ["2124776405", "1995945562", "1510073064", "1560013842", "2049633694", "2285257517", "2032254851", "1770825568", "2142635246", "2120945046"], "date": "2006"}, {"id": "2087360383", "title": "Comparative concepts and descriptive categories in crosslinguistic studies", "abstract": "In this paper I argue that cross-linguistic grammatical comparison cannot be based on grammatical categories, because these are language-specific. Instead, typology must be (and usually is) based on a special set of comparative concepts that are specifically created by typologists for the purposes of comparison. Descriptive formal categories cannot be equated across languages because the criteria for category-assignment are different from language to language. This old structuralist insight (called categorial particularism) has recently been emphasized again by several linguists, but the idea that typologists need to identify \"crosslinguistic categories\" before they can compare languages is still widespread. Instead, what they have to do (and normally do in practice) is to create comparative concepts that help them to identify comparable phenomena across languages and to formulate cross-linguistic generalizations. Comparative concepts have to be universally applicable, so they can only be based on other universally applicable concepts: conceptual-semantic concepts, formal concepts, general concepts, and other comparative concepts. If, by contrast, one espouses categorial universalism and assumes crosslinguistic categories, as many generative linguists do, typology works by equating comparable categories in different languages, which are said to \"instantiate\" a cross-linguistic category. But in typological practice, all that is required is that a language-specific category matches a comparative concept. For example, the Russian Dative, the Turkish Dative and the Finnish Allative all match the comparative concept 'dative case', but they are very different distributionally and semantically and therefore cannot be equated and cannot instantiate a cross-linguistic category 'dative'. Comparative concepts are not always purely semantically-based concepts, but outside of phonology they usually contain some semantic components. If one is not confident about the universality of meanings, one can substitute extralinguistic contexts for universal meanings. The view that descriptive categories are different across languages and different from comparative concepts leads to terminological problems, which are also discussed here. Finally, I observe that the adoption of categorial universalism has actually impeded, not facilitated, cross-linguistic research.", "authors": ["Martin Haspelmath"], "related_topics": ["29417503", "206977991", "154524226"], "citation_count": "741", "reference_count": "123", "references": ["2013833248", "2796493717", "196354989", "1597993529", "1586060904", "239563548", "2062837929", "2337762945", "2170716495", "2038542953"], "date": "2009"}, {"id": "2130325614", "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "abstract": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.", "authors": ["Honglak Lee", "Roger Grosse", "Rajesh Ranganath", "Andrew Y. Ng"], "related_topics": ["2777579346", "97385483", "108583219"], "citation_count": "2986", "reference_count": "26", "references": ["2136922672", "2100495367", "2162915993", "2116064496", "2110798204", "2166049352", "2147800946", "2145889472", "2122922389", "2139427956"], "date": "2009"}, {"id": "1944213880", "title": "The role of quality in providing seamless access to information and data in e-science; the experience gained in crystallography", "abstract": "The determination of molecular structures of biological and chemical interest is a major role of applied crystallography worldwide today. Where once each new structure represented a hard-won research result, improvements in technique, technology and computational power have brought large-scale structure determination efforts well into the realm of e-science. Half a million crystal structures of 'small' molecules and over 35,000 protein and nucleic-acid crystal structures are publicly available. Many more structures have been determined but never published; increasingly these are being disseminated over the web. The crystallographic community is energetic through the activities of the International Union of Crystallography (IUCr) in its efforts to uphold quality standards in a diverse scientific environment. The IUCr has developed a data exchange standard, the crystallographic information file (CIF), and associated data dictionaries. These have allowed the seamless transfer of information from the experimental apparatus, through computation analysis, to database deposition and publication. The formal data language of CIF also allows the definition of quality standards for data deposition and publication, and the deployment of mechanisms for checking compliance with such standards, such as the checkCIF web service. This article discusses the role of the crystallographic journals owned by the IUCr in maintaining quality of information and data for effective peer-reviewed publishing of advances in crystallographic science, and the possibilities provided by the CIF dictionaries for future semantic web applications.", "authors": ["John R. Helliwell", "Peter R. Strickland", "Brian McMahon"], "related_topics": ["117170267", "45983554", "2776543384"], "citation_count": "5", "reference_count": "10", "references": ["2032842297", "2070942956", "2047544230", "2112845989", "2047600440", "2912794555", "2064270057", "2163363362", "2070889570", "2161400087"], "date": "2005"}, {"id": "2116150950", "title": "Optical switching: switch fabrics, techniques, and architectures", "abstract": "The switching speeds of electronics cannot keep up with the transmission capacity offered by optics. All-optical switch fabrics play a central role in the effort to migrate the switching functions to the optical layer. Optical packet switching provides an almost arbitrary fine granularity but faces significant challenges in the processing and buffering of bits at high speeds. Generalized multiprotocol label switching seeks to eliminate the asynchronous transfer mode and synchronous optical network layers, thus implementing Internet protocol over wavelength-division multiplexing. Optical burst switching attempts to minimize the need for processing and buffering by aggregating flows of data packets into bursts. In this paper, we present an extensive overview of the current technologies and techniques concerning optical switching.", "authors": ["G.I. Papadimitriou", "C. Papazoglou", "A.S. Pomportsis"], "related_topics": ["197417287", "123467649", "182437060"], "citation_count": "691", "reference_count": "44", "references": ["1536656161", "2165334967", "27073611", "2003886474", "2112170768", "2161518197", "2056665251", "2135526244", "2109103540", "1572000546"], "date": "2003"}, {"id": "2063978378", "title": "Least angle regression", "abstract": "The purpose of model selection algorithms such as All Subsets, Forward Selection and Backward Elimination is to choose a linear model on the basis of the same set of data to which the model will be applied. Typically we have available a large collection of possible covariates from which we hope to select a parsimonious set for the efficient prediction of a response variable. Least Angle Regression (LARS), a new model selection algorithm, is a useful and less greedy version of traditional forward selection methods. Three main properties are derived: (1) A simple modification of the LARS algorithm implements the Lasso, an attractive version of ordinary least squares that constrains the sum of the absolute regression coefficients; the LARS modification calculates all possible Lasso estimates for a given problem, using an order of magnitude less computer time than previous methods. (2) A different LARS modification efficiently implements Forward Stagewise linear regression, another promising new model selection method; this connection explains the similar numerical results previously observed for the Lasso and Stagewise, and helps us understand the properties of both methods, which are seen as constrained versions of the simpler LARS algorithm. (3) A simple approximation for the degrees of freedom of a LARS estimate is available, from which we derive a Cp estimate of prediction error; this allows a principled choice among the range of possible LARS estimates. LARS and its variants are computationally efficient: the paper describes a publicly available algorithm that requires only the same order of magnitude of computational effort as ordinary least squares applied to the full set of covariates.", "authors": ["Bradley Efron", "Trevor Hastie", "Iain Johnstone", "Robert Tibshirani", "Hemant Ishwaran", "Keith Knight", "Jean Michel Loubes", "", "Pascal Massart", "", "David Madigan", "Greg Ridgeway", "", "Saharon Rosset", "", "J. I. Zhu", "Robert A. Stine", "Berwin A. Turlach", "Sanford Weisberg"], "related_topics": ["203868755", "93959086", "163175372"], "citation_count": "10437", "reference_count": "39", "references": ["1554944419", "2110065044", "2135046866", "3124955340", "2912934387", "1678356000", "2798909945", "1594031697", "2158940042", "2982720039"], "date": "2004"}, {"id": "2106378689", "title": "A Method for Solving Traveling-Salesman Problems", "abstract": "The traveling-salesman problem is a generalized form of the simple problem to find the smallest closed loop that connects a number of points in a plane. Efforts in the past to find an efficient met...", "authors": ["G. A. Croes"], "related_topics": ["106472803", "175859090", "17825722"], "citation_count": "1643", "reference_count": "0", "references": ["2118051273", "2310612427", "2167920923", "187767610", "1586677474", "2042986967", "1975671633", "1559582792", "2137849348", "2146004814"], "date": "1958"}, {"id": "2089468765", "title": "Principal component analysis", "abstract": "Principal Component Analysis (PCA) is a multivariate exploratory analysis method, useful to separate systematic variation from noise. It allows to define a space of reduced dimensions that preserve ...", "authors": ["Svante Wold", "Kim Esbensen", "", "Paul Geladi", ""], "related_topics": ["27438332", "161584116", "151405878"], "citation_count": "9279", "reference_count": "29", "references": ["2112440119", "2158863190", "2000868500", "2166446427", "1973967548", "2005051528", "2157895715", "2055703272", "2125334673", "2221625877"], "date": "1987"}, {"id": "2137775453", "title": "The capacity of wireless networks", "abstract": "When n identical randomly located nodes, each capable of transmitting at W bits per second and using a fixed range, form a wireless network, the throughput /spl lambda/(n) obtainable by each node for a randomly chosen destination is /spl Theta/(W//spl radic/(nlogn)) bits per second under a noninterference protocol. If the nodes are optimally placed in a disk of unit area, traffic patterns are optimally assigned, and each transmission's range is optimally chosen, the bit-distance product that can be transported by the network per second is /spl Theta/(W/spl radic/An) bit-meters per second. Thus even under optimal circumstances, the throughput is only /spl Theta/(W//spl radic/n) bits per second for each node for a destination nonvanishingly far away. Similar results also hold under an alternate physical model where a required signal-to-interference ratio is specified for successful receptions. Fundamentally, it is the need for every node all over the domain to share whatever portion of the channel it is utilizing with nodes in its local neighborhood that is the reason for the constriction in capacity. Splitting the channel into several subchannels does not change any of the results. Some implications may be worth considering by designers. Since the throughput furnished to each user diminishes to zero as the number of users is increased, perhaps networks connecting smaller numbers of users, or featuring connections mostly with nearby neighbors, may be more likely to be find acceptance.", "authors": ["P. Gupta", "P.R. Kumar"], "related_topics": ["157764524", "46135064", "97744766"], "citation_count": "10911", "reference_count": "16", "references": ["2099057525", "2092924973", "2148099880", "1918250237", "1530699444", "2019363670", "2048843394", "1973613705", "2124110518", "2107403526"], "date": "2000"}, {"id": "2160126058", "title": "Face recognition based on fitting a 3D morphable model", "abstract": "This paper presents a method for face recognition across variations in pose, ranging from frontal to profile views, and across a wide range of illuminations, including cast shadows and specular reflections. To account for these variations, the algorithm simulates the process of image formation in 3D space, using computer graphics, and it estimates 3D shape and texture of faces from single images. The estimate is achieved by fitting a statistical, morphable model of 3D faces to images. The model is learned from a set of textured 3D scans of heads. We describe the construction of the morphable model, an algorithm to fit the model to images, and a framework for face identification. In this framework, faces are represented by model parameters for 3D shape and texture. We present results obtained with 4,488 images from the publicly available CMU-PIE database and 1,940 images from the FERET database.", "authors": ["V. Blanz", "T. Vetter"], "related_topics": ["137087632", "63099799", "31510193"], "citation_count": "2622", "reference_count": "38", "references": ["2170120409", "1554663460", "1989702938", "1490482062", "2123921160", "2237250383", "1874027545", "1564419782", "2098947662", "1997011019"], "date": "2003"}, {"id": "2170654002", "title": "Inductive learning algorithms and representations for text categorization", "abstract": "1. ABSTRACT Text categorization \u2013 the assignment of natural language texts to one or more predefined categories based on their content \u2013 is an important component in many information organization and management tasks. We compare the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed, realtime classification speed, and classification accuracy. We also examine training set size, and alternative document representations. Very accurate text classifiers can be learned automatically from training examples. Linear Support Vector Machines (SVMs) are particularly promising because they are very accurate, quick to train, and quick to evaluate. 1.1", "authors": ["Susan Dumais", "John Platt", "David Heckerman", "Mehran Sahami"], "related_topics": ["94124525", "28006648", "58973888"], "citation_count": "2343", "reference_count": "28", "references": ["2156909104", "2119821739", "2149684865", "2087347434", "2435251607", "1975846642", "740415", "2124351082", "1956559956", "2114535528"], "date": "1998"}, {"id": "35599901", "title": "Talking Science: Language, Learning, and Values", "abstract": "", "authors": ["Jay L. Lemke"], "related_topics": ["44877443", "129353971", "120912362"], "citation_count": "7024", "reference_count": "48", "references": ["2019413183", "1533200881", "2000138195", "2015933299", "1984218255", "2159866583", "143125967", "1541456364", "2044950274", "1589878313"], "date": "1985"}, {"id": "1978349032", "title": "Detailed error analysis for a fractional Adams method", "abstract": "We investigate a method for the numerical solution of the nonlinear fractional differential equation D * \u03b1 y(t)=f(t,y(t)), equipped with initial conditions y (k)(0)=y 0 (k), k=0,1,...,\u2308\u03b1\u2309\u22121. Here \u03b1 may be an arbitrary positive real number, and the differential operator is the Caputo derivative. The numerical method can be seen as a generalization of the classical one-step Adams\u2013Bashforth\u2013Moulton scheme for first-order equations. We give a detailed error analysis for this algorithm. This includes, in particular, error bounds under various types of assumptions on the equation. Asymptotic expansions for the error are also mentioned briefly. The latter may be used in connection with Richardson's extrapolation principle to obtain modified versions of the algorithm that exhibit faster convergence behaviour.", "authors": ["Kai Diethelm", "Neville J. Ford", "Alan D. Freed"], "related_topics": ["48753275", "70915906", "132459708"], "citation_count": "804", "reference_count": "35", "references": ["2787959293", "1995504856", "2111271983", "1530054495", "1975670568", "1509923322", "2042388195", "1550268283", "1523640391", "9124626"], "date": "2004"}, {"id": "2796533261", "title": "An Introduction to the Theory of Numbers", "abstract": "", "authors": ["G. H. Hardy", "E. M. Wright"], "related_topics": ["162270659", "68625148", "169654258"], "citation_count": "13454", "reference_count": "0", "references": ["2137147061", "2168676717", "2169071224", "2081193615", "2089674328", "2096551755", "1537136047", "2005936791", "2141040012", "2127106339"], "date": "1939"}, {"id": "1987803162", "title": "Inquiry-based science instruction\u2014what is it and does it matter? Results from a research synthesis years 1984 to 2002", "abstract": "The goal of the Inquiry Synthesis Project was to synthesize findings from research conducted between 1984 and 2002 to address the research question, What is the impact of inquiry science instruction on K-12 student outcomes? The timeframe of 1984 to 2002 was selected to continue a line of synthesis work last completed in 1983 by Bredderman (Bredderman (1983) Review of Educational Research 53: 499-518) and Shymansky, Kyle, and Alport (Shymansky et al. (1983) Journal of Research in Science Teaching 20: 387-404), and to accommodate a practicable cut- off date given the research project timeline, which ran from 2001 to 2006. The research question for the project was addressed by developing a conceptual framework that clarifies and specifies what is meant by ''inquiry-based science instruction,'' and by using a mixed-methodology approach to analyze both numerical and text data describing the impact of instruction on K-12 student science conceptual learning. Various findings across 138 analyzed studies indicate a clear, positive trend favoring inquiry-based instructional practices, particularly instruction that emphasizes student active thinking and drawing conclusions from data. Teaching strategies that actively engage students in the learning process through scientific investigations are more likely to increase conceptual understanding than are strategies that rely on more passive techniques, which are often necessary in the current standardized-assessment laden educational environment.", "authors": ["Daphne D. Minner", "Abigail Jurist Levy", "Jeanne Century"], "related_topics": ["44877443", "36727532", "88610354"], "citation_count": "1331", "reference_count": "30", "references": ["2520660681", "1976637107", "131038430", "1965299423", "1979349344", "2001005524", "2160446473", "2142505685", "1995434502", "2118173122"], "date": "2010"}, {"id": "15592790", "title": "Improvements in beam search.", "abstract": "", "authors": ["Volker Steinbiss", "Bach-Hiep Tran", "Hermann Ney"], "related_topics": ["19889080", "41008148", "24326235"], "citation_count": "190", "reference_count": "0", "references": ["2119168550", "2963035145", "2164579587", "2520160253", "2626190081", "2016185147", "1583620810", "2149910633", "2492919981", "3035131109"], "date": "1993"}, {"id": "2063332351", "title": "A bit more to it: scholarly communication forums as socio-technical interaction networks", "abstract": "In this article, we examine the conceptual models that help us understand the development and sustainability of scholarly and professional communication forums on the Internet, such as conferences, pre-print servers, field-wide data sets, and collaboratories. We first present and document the information processing model that is implicitly advanced in most discussions about scholarly communications-the \"Standard Model.\" Then we present an alternative model, one that considers information technologies as Socio-Technical Interaction Networks (STINs). STIN models provide a richer understanding of human behavior with online scholarly communications forums. They also help to further a more complete understanding of the conditions and activities that support the sustainability of these forums within a field than does the Standard Model. We illustrate the significance of STIN models with examples of scholarly communication forums drawn from the fields of high-energy physics, molecular biology, and information systems. The article also includes a method for modeling electronic forums as STINs.", "authors": ["Rob Kling", "Geoffrey McKim", "Adam King"], "related_topics": ["2777462167", "2781419009", "180198813"], "citation_count": "317", "reference_count": "55", "references": ["1985707021", "2042349004", "2044509498", "1964450454", "2143969326", "2114133419", "1979731710", "1837830691", "2124431800", "2126974659"], "date": "2002"}, {"id": "2125848778", "title": "Feature extraction from faces using deformable templates", "abstract": "A method for detecting and describing the features of faces using deformable templates is described. The feature of interest, an eye for example, is described by a parameterized template. An energy function is defined which links edges, peaks, and valleys in the image intensity to corresponding properties of the template. The template then interacts dynamically with the image, by altering its parameter values to minimize the energy function, thereby deforming itself to find the best fit. The final parameter values can be used as descriptors for the features. This method is demonstrated by showing deformable templates detecting eyes and mouths in real images. >", "authors": ["A.L. Yuille", "D.S. Cohen", "P.W. Hallinan"], "related_topics": ["7374053", "52622490", "176258234"], "citation_count": "2707", "reference_count": "20", "references": ["2104095591", "2164741953", "2740373864", "2082206048", "2051719061", "1574225613", "2107198582", "2045798786", "1481387016", "1977699267"], "date": "1989"}, {"id": "128740895", "title": "Bayes Estimates for the Linear Model", "abstract": "", "authors": ["D. V. Lindley", "A. F. M. Smith"], "related_topics": ["143809311", "185207860", "52001869"], "citation_count": "2384", "reference_count": "31", "references": ["2047028564", "2403035479", "2014725748", "2069271851", "2100561985", "2092369573", "2092755314", "1598266570", "2029323145", "2061444428"], "date": "1972"}, {"id": "1983403768", "title": "Random Walk and the Theory of Brownian Motion", "abstract": "(1947). Random Walk and the Theory of Brownian Motion. The American Mathematical Monthly: Vol. 54, No. 7P1, pp. 369-391.", "authors": ["Mark Kac"], "related_topics": ["154072304", "118918019", "121194460"], "citation_count": "586", "reference_count": "0", "references": ["2135764410", "2169071224", "2103799649", "2027808858", "1596709027", "2043694962", "1999762141", "2126276563", "2291592414", "1793936018"], "date": "1947"}, {"id": "2184188583", "title": "Multimodal Deep Learning", "abstract": "Deep networks have been successfully applied to unsupervised feature learning for single modalities (e.g., text, images or audio). In this work, we propose a novel application of deep networks to learn features over multiple modalities. We present a series of tasks for multimodal learning and show how to train deep networks that learn features to address these tasks. In particular, we demonstrate cross modality feature learning, where better features for one modality (e.g., video) can be learned if multiple modalities (e.g., audio and video) are present at feature learning time. Furthermore, we show how to learn a shared representation between modalities and evaluate it on a unique task, where the classifier is trained with audio-only data but tested with video-only data and vice-versa. Our models are validated on the CUAVE and AVLetters datasets on audio-visual speech classification, demonstrating best published visual speech classification on AVLetters and effective shared representation learning.", "authors": ["Jiquan Ngiam", "Aditya Khosla", "Mingyu Kim", "Juhan Nam", "Honglak Lee", "Andrew Y. Ng"], "related_topics": ["59404180", "2780660688", "28006648"], "citation_count": "2685", "reference_count": "26", "references": ["2161969291", "2136922672", "2100495367", "2116064496", "2025768430", "2913932916", "2122922389", "2133257461", "2100235303", "2914746235"], "date": "2011"}, {"id": "2130142026", "title": "THE UNBEARABLE AUTOMATICITY OF BEING", "abstract": "What was noted by E. J. hanger (1978) remains true today: that much of contemporary psychological research is based on the assumption that people are consciously and systematically processing incoming information in order to construe and interpret their world and to plan and engage in courses of action. As did E. J. hanger, the authors question this assumption. First, they review evidence that the ability to exercise such conscious, intentional control is actually quite limited, so that most of moment-to-mom ent psychological life must occur through nonconscious means if it is to occur at all. The authors then describe the different possible mechanisms that produce automatic, environmental control over these various phenomena and review evidence establishing both the existence of these mechanisms as well as their consequences for judgments, emotions, and behavior. Three major forms of automatic self-regulation are identified: an automatic effect of perception on action, automatic goal pursuit, and a continual automatic evaluation of one's experience. From the accumulating evidence, the authors conclude that these various nonconscious mental systems perform the lion's share of the self-regulatory burden, beneficently keeping the individual grounded in his or her current environment. The strongest knowledge\u2014that of the total unfreedom of the human will\u2014is nonetheless the poorest in successes, for it always has the strongest opponent: human vanity. \u2014Nietzsche, Human, All Too Human", "authors": ["John A. Bargh", "Tanya L. Chartrand"], "related_topics": ["2778032263", "33002781", "2776614971"], "citation_count": "6204", "reference_count": "151", "references": ["2888190061", "1581387623", "1708874574", "2040993216", "2011744324", "3019273456", "2179683524", "1984186949", "2613529509", "1832238961"], "date": "1999"}, {"id": "3106250896", "title": "SSD: Single Shot MultiBox Detector", "abstract": "We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For \\(300 \\times 300\\) input, SSD achieves 74.3 % mAP on VOC2007 test at 59 FPS on a Nvidia Titan X and for \\(512 \\times 512\\) input, SSD achieves 76.9 % mAP, outperforming a comparable state of the art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/tree/ssd.", "authors": ["Wei Liu", "Dragomir Anguelov", "Dumitru Erhan", "Christian Szegedy", "Scott E. Reed", "Cheng-Yang Fu", "Alexander C. Berg"], "related_topics": ["147037132", "81363708", "160633673"], "citation_count": "14661", "reference_count": "29", "references": ["2194775991", "2618530766", "2962835968", "2097117768", "639708223", "1836465849", "2102605133", "2117539524", "1903029394", "2155893237"], "date": "2016"}, {"id": "2153889650", "title": "A Taxonomy of Recommender Agents on theInternet", "abstract": "Recently, Artificial Intelligence techniques have proved useful in helping users to handle the large amount of information on the Internet. The idea of personalized search engines, intelligent software agents, and recommender systems has been widely accepted among users who require assistance in searching, sorting, classifying, filtering and sharing this vast quantity of information. In this paper, we present a state-of-the-art taxonomy of intelligent recommender agents on the Internet. We have analyzed 37 different systems and their references and have sorted them into a list of 8 basic dimensions. These dimensions are then used to establish a taxonomy under which the systems analyzed are classified. Finally, we conclude this paper with a cross-dimensional analysis with the aim of providing a starting point for researchers to construct their own recommender system.", "authors": ["Miquel Montaner", "Beatriz L\u00f3pez", "Josep Llu\u00eds De La Rosa"], "related_topics": ["557471498", "183003079", "2776945383"], "citation_count": "1033", "reference_count": "74", "references": ["2110325612", "3121531027", "2085937320", "2124591829", "1966553486", "1956559956", "1999047234", "2043403353", "1978394996", "2171265988"], "date": "2003"}, {"id": "1973758813", "title": "A sensor network application construction kit (SNACK)", "abstract": "We propose a new configuration language, component and service library, and compiler that make it easier to develop efficient sensor network applications. Our goal is the construction of smart application service libraries: high-level libraries that implement concepts like routing trees and periodic sensing, and that combine automatically into efficient programs. Important language features include flexible control over component sharing and transitive arrow connections, which let independently-implemented services knit themselves into integrated control flow paths. Our language, library, and compiler are collectively called SNACK (Sensor Network Application Construction Kit). We describe them, and present and evaluate a simple SNACK-based multihop data collection application. This application uses SNACK language features to provide both simplicity (excluding reusable service definitions, its description is three lines long) and efficiency (it performs comparably to the well-known Surge application).", "authors": ["Ben Greenstein", "Eddie Kohler", "Deborah Estrin"], "related_topics": ["169590947", "24590314", "49585438"], "citation_count": "191", "reference_count": "20", "references": ["2121255383", "2127949150", "2150039965", "2167396179", "2010365467", "2169458211", "2171427043", "1971903460", "2135401919", "2136982937"], "date": "2004"}, {"id": "2056536278", "title": "A parametrically controlled spectral analysis system for speech", "abstract": "The parametrically controlled analyzer (PCA) is a large PL/I program which has been designed to perform spectral analysis of speech signals. PCA features parametric selection of several analysis methods, including discrete Fourier transformation and linear predictive coding. Also, selection may be made among various smoothing, normalization, and interpolation methods. PCA develops high-quality spectrographic representations of speech for standard line printers and CRT displays. The PCA is described and numerous examples of various parameter settings are presented and discussed.", "authors": ["H. Silverman", "N. Dixon"], "related_topics": ["59883199", "13895895", "27438332"], "citation_count": "65", "reference_count": "17", "references": ["2097645910", "2073086065", "2129015742", "2084044763", "2019183077", "2062625208", "2103030298", "1979871770", "2296520333", "2121469013"], "date": "1974"}, {"id": "2011932878", "title": "Empirical evidence of bias. Dimensions of methodological quality associated with estimates of treatment effects in controlled trials.", "abstract": "Objective. \u2014To determine if inadequate approaches to randomized controlled trial design and execution are associated with evidence of bias in estimating treatment effects. Design. \u2014An observational study in which we assessed the methodological quality of 250 controlled trials from 33 meta-analyses and then analyzed, using multiple logistic regression models, the associations between those assessments and estimated treatment effects. Data Sources. \u2014Meta-analyses from the Cochrane Pregnancy and Childbirth Database. Main Outcome Measures. \u2014The associations between estimates of treatment effects and inadequate allocation concealment, exclusions after randomization, and lack of double-blinding. Results. \u2014Compared with trials in which authors reported adequately concealed treatment allocation, trials in which concealment was either inadequate or unclear (did not report or incompletely reported a concealment approach) yielded larger estimates of treatment effects ( P P =.01), with odds ratios being exaggerated by 17%. Conclusions. \u2014This study provides empirical evidence that inadequate methodological approaches in controlled trials, particularly those representing poor allocation concealment, are associated with bias. Readers of trial reports should be wary of these pitfalls, and investigators must improve their design, execution, and reporting of trials. ( JAMA . 1995;273:408-412)", "authors": ["Kenneth F. Schulz", "Iain Chalmers", "Richard J. Hayes", "Douglas G. Altman"], "related_topics": ["168563851", "49290038", "23131810"], "citation_count": "7290", "reference_count": "23", "references": ["2087851547", "2140359845", "1994898034", "1971785694", "2169997396", "2057212716", "2083081439", "1953850870", "2059356295", "2082942950"], "date": "1995"}, {"id": "1716383435", "title": "The Theory of Probabilistic Databases", "abstract": "ABS!l\u2019RACT A theory of probabilistic databases is outlined. This theory is one component of an integrated approach to data-modelling that accomodates both probabilistic and relational data. In fact, many of the results presented here were developed in the context of a framework for structural modelling of systems. Much that is fundamental to relational database theory was also developed in this context, and previous to the introduction by Codd of the relational model of data. Probabilistic databases can store types of information that cannot be represented using the relational model. Probabilistic databases may also be viewed as generalisations of relational databases; any relational database can be represented without loss of information by a probabilistic database. A number of relational database concepts are shown to have probabilistic counterparts. In many cases, it is preferable to deal with the probabilistic formulation of a concept even when applying it to a relational database. For example, we define a new project-join mapping for relational databases that is based on transf orming a relational to a probabilistic database. This mapping is shown to have more fmed points than the standard one.", "authors": ["Roger Cavallo", "Michael Pittarelli"], "related_topics": ["174539288", "5655090", "40207289"], "citation_count": "406", "reference_count": "20", "references": ["1882297107", "2327022120", "2074673068", "2988119170", "2123838014", "2110810394", "2005097301", "2039610696", "2104498537", "2111030512"], "date": "1987"}, {"id": "2047221353", "title": "Optimizing search engines using clickthrough data", "abstract": "This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples.", "authors": ["Thorsten Joachims"], "related_topics": ["86037889", "189430467", "124975894"], "citation_count": "5105", "reference_count": "29", "references": ["2156909104", "2148603752", "2119821739", "1660390307", "1576520375", "2087347434", "1978394996", "2107890099", "2988119488", "2162077280"], "date": "2002"}, {"id": "2154579312", "title": "Handwritten Digit Recognition with a Back-Propagation Network", "abstract": "We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service.", "authors": ["Yann LeCun", "Bernhard E. Boser", "John S. Denker", "", "Donnie Henderson", "R. E. Howard", "Wayne E. Hubbard", "Lawrence D. Jackel"], "related_topics": ["40969351", "2780451532", "155032097"], "citation_count": "4098", "reference_count": "11", "references": ["2154642048", "2147800946", "2114766824", "169539560", "56903235", "2157475639", "1965770722", "2091987367", "2153988646", "2058841211"], "date": "1988"}, {"id": "2081780875", "title": "Some Sphere Packings in Higher Space", "abstract": "This paper is concerned with the packing of equal spheres in Euclidean spaces [n] of n > 8 dimensions. To be precise, a packing is a distribution of spheres any two of which have at most a point of contact in common. If the centres of the spheres form a lattice, the packing is said to be a lattice packing. The densest lattice packings are known for spaces of up to eight dimensions (1, 2), but not for any space of more than eight dimensions. Further, although non-lattice packings are known in [3] and [5] which have the same density as the densest lattice packings, none is known which has greater density than the densest lattice packings in any space of up to eight dimensions, neither, for any space of more than two dimensions, has it been shown that they do not exist.", "authors": ["John Leech"], "related_topics": ["183893376", "110161667", "123115066"], "citation_count": "155", "reference_count": "11", "references": ["3119473442", "1970966506", "2089279557", "2322463333", "2313497592", "2079429310", "1990789529", "2331079728", "2092390447", "2069182668"], "date": "1963"}, {"id": "2117189826", "title": "Automatic verification of finite-state concurrent systems using temporal logic specifications", "abstract": "We give an efficient procedure for verifying that a finite-state concurrent system meets a specification expressed in a (propositional, branching-time) temporal logic. Our algorithm has complexity linear in both the size of the specification and the size of the global state graph for the concurrent system. We also show how this approach can be adapted to handle fairness. We argue that our technique can provide a practical alternative to manual proof construction or use of a mechanical theorem prover for verifying many finite-state concurrent systems. Experimental results show that state machines with several hundred states can be checked in a matter of seconds.", "authors": ["E. M. Clarke", "E. A. Emerson", "A. P. Sistla"], "related_topics": ["110251889", "198008173", "25016198"], "citation_count": "5533", "reference_count": "20", "references": ["3144368627", "1589421353", "1501731334", "2003227046", "2166656159", "2004306067", "1593428110", "2157319504", "2040127143", "50233445"], "date": "1986"}, {"id": "1963623641", "title": "A survey of image registration techniques", "abstract": "Registration is a fundamental task in image processing used to match two or more pictures taken, for example, at different times, from different sensors, or from different viewpoints. Virtually all large systems which evaluate images require the registration of images, or a closely related operation, as an intermediate step. Specific examples of systems where image registration is a significant component include matching a target with a real-time image of a scene for target recognition, monitoring global land usage using satellite images, matching stereo images to recover shape for autonomous navigation, and aligning images from different medical modalities for diagnosis.Over the years, a broad range of techniques has been developed for various types of data and problems. These techniques have been independently studied for several different applications, resulting in a large body of research. This paper organizes this material by establishing the relationship between the variations in the images and the type of registration techniques which can most appropriately be applied. Three major types of variations are distinguished. The first type are the variations due to the differences in acquisition which cause the images to be misaligned. To register images, a spatial transformation is found which will remove these variations. The class of transformations which must be searched to find the optimal transformation is determined by knowledge about the variations of this type. The transformation class in turn influences the general technique that should be taken. The second type of variations are those which are also due to differences in acquisition, but cannot be modeled easily such as lighting and atmospheric conditions. This type usually effects intensity values, but they may also be spatial, such as perspective distortions. The third type of variations are differences in the images that are of interest such as object movements, growths, or other scene changes. Variations of the second and third type are not directly removed by registration, but they make registration more difficult since an exact match is no longer possible. In particular, it is critical that variations of the third type are not removed. Knowledge about the characteristics of each type of variation effect the choice of feature space, similarity measure, search space, and search strategy which will make up the final technique. All registration techniques can be viewed as different combinations of these choices. This framework is useful for understanding the merits and relationships between the wide variety of existing techniques and for assisting in the selection of the most suitable technique for a specific problem.", "authors": ["Lisa Gottesfeld Brown"], "related_topics": ["166704113", "158096908", "9417928"], "citation_count": "6702", "reference_count": "82", "references": ["2105536892", "3017143921", "22745672", "1487563192", "147723833", "2044719420", "2007153649", "2138943050", "2050405342", "1964262399"], "date": "1992"}, {"id": "2105539612", "title": "On Non-Functional Requirements in Software Engineering", "abstract": "Essentially a software system's utility is determined by both its functionality and its non-functional characteristics, such as usability, flexibility, performance, interoperability and security. Nonetheless, there has been a lop-sided emphasis in the functionality of the software, even though the functionality is not useful or usable without the necessary non-functional characteristics. In this chapter, we review the state of the art on the treatment of non-functional requirements (hereafter, NFRs), while providing some prospects for future directions.", "authors": ["Lawrence Chung", "Julio Cesar Prado Leite"], "related_topics": ["102780508", "54534927", "76518257"], "citation_count": "2035", "reference_count": "63", "references": ["2151451947", "1578960547", "2134934846", "2157437711", "1504045958", "2177007941", "2091579301", "2301605390", "2285568936", "2110157102"], "date": "2009"}, {"id": "2033693394", "title": "Tensorial resolution: A direct trilinear decomposition", "abstract": "Modern instrumentation in chemistry routinely generates two-dimensional (second-order) arrays of data. Considering that most analyses need to compare several samples, the analyst ends up with a three-dimensional (third-order) array which is difficult to visualize or interpret with the conventional statistical tools. Some of these data arrays follow the so-called trilinear model, These trilinear arrays of data are known to have unique factor analysis decompositions which correspond to the true physical factors that form the data, i.e. given the array \u211d, a unique solution can be found in many cases for each order X, Y and Z. This is in contrast to the well-known second-order bilinear data factor analysis, where the abstract solutions obtained are not unique and at best cannot be easily compared with the underlying physical factors owing to a rotational ambiguity. Trilinear decompositions have had the disadvantage, however, that a non-linear optimization with many parameters is necessary to reach a least-squares solution. This paper will introduce a method for reducing the problem to a rectangular generalized eigenvalue\u2013eigenvector equation where the eigenvectors are the contravariant form (pseudo-inverse) of the actual factors. It is shown that the method works well when the factors are linearly independent in at least two orders (e.g. Xir and Yjr are full rank matrices). Finally, it is shown how trilinear decompositions relate to multicomponent calibration, curve resolution and chemical analysis.", "authors": ["Eugenio Sanchez", "Bruce R. Kowalski"], "related_topics": ["205203396", "158693339", "206236147"], "citation_count": "531", "reference_count": "19", "references": ["2000215628", "2055703272", "2018347513", "2162521467", "1989615359", "2033716058", "1969296026", "2012374358", "1499594892", "1978632288"], "date": "1989"}, {"id": "2165334967", "title": "Terabit burst switching", "abstract": "Demand for network bandwidth is growing at unprecedented rates, placing growing demands on switching and transmission technologies. Wavelength division multiplexing will soon make it possible to combine hundreds of gigabit channels on a single fiber. This paper presents an architecture for Burst Switching Systems designed to switch data among WDM links, treating each link as a shared resource rather than just a collection of independent channels. The proposed network architecture separates burst level data and control, allowing major simplifications in the data path in order to facilitate all-optical implementations. To handle short data bursts efficiently, the burst level control mechanisms in burst switching systems must keep track of future resource availability when assigning arriving data bursts to channels or storage locations. The resulting Lookahead Resource Management problems raise new issues and require the invention of completely new types of high speed control mechanisms. This paper introduces these problems and describes approaches to burst level resource management that attempt to strike an appropriate balance between high speed operation and efficiency of resource usage.", "authors": ["Jonathan S. Turner"], "related_topics": ["180026317", "197417287", "9765861"], "citation_count": "1288", "reference_count": "14", "references": ["2752885492", "2122836959", "1523640816", "2148628983", "2100616966", "2097856725", "1522017465", "2166626969", "1537640744", "1587547058"], "date": "1999"}, {"id": "2078500988", "title": "Computer Networks: A Systems Approach", "abstract": "Computer Networks: A Systems Approach, Fifth Edition, discusses the key principles of computer networking. It focuses on the underlying concepts and technologies that make the Internet work. Topics covered include network design and architecture; the ways users can connect to a network; the concepts of switching, routing, and internetworking; end-to-end protocols; congestion control and resource allocation; end-to-end data; network security; and network applications such as e-mail and the Web, IP telephony and video streaming, and peer-to-peer file sharing. Each chapter includes a problem statement, which introduces issues to be examined; shaded sidebars that elaborate on a topic or introduce a related advanced topic; What's Next? discussions that deal with emerging issues in research, the commercial world, or society; and exercises. This book is written for graduate or upper-division undergraduate classes in computer networking. It will also be useful for industry professionals retraining for network-related assignments, as well as network practitioners seeking to understand the workings of network protocols and the big picture of networking. * Completely updated content with expanded coverage of the topics of utmost importance to networking professionals and students, including P2P, wireless, security, and applications* Increased focus on application layer issues where innovative and exciting research and design is currently the center of attention* Free downloadable network simulation software and lab experiments manual available", "authors": ["L.L. Peterson", "B.S. Davie"], "related_topics": ["182590292", "110875604", "139940560"], "citation_count": "3077", "reference_count": "0", "references": ["2052334067", "1501077214", "2138993731", "2095206774", "1664011265", "1850405760", "2146487252", "1174849168", "1492601037", "47957325"], "date": "1995"}, {"id": "99914202", "title": "12 On the assessment of visual communication", "abstract": "", "authors": ["Friedrich O. Huck", "Carl L. Fales", "Rachel Alter-Gartenberg", "Zia-ur Rahman"], "related_topics": ["105842133", "41008148", "107457646"], "citation_count": "5", "reference_count": "90", "references": ["2132984323", "2098914003", "2100115174", "2103504761", "2129652681", "2003370853", "2166982406", "2186435531", "1622620102", "2107745473"], "date": "1992"}, {"id": "1659631989", "title": "The Adapted mind : evolutionary psychology and the generation of culture", "abstract": "Although researchers have long been aware that the species-typical architecture of the human mind is the product of our evolutionary history, it has only been in the last three decades that advances in such fields as evolutionary biology, cognitive psychology, and paleoanthropology have made the fact of our evolution illuminating. Converging findings from a variety of disciplines are leading to the emergence of a fundamentally new view of the human mind, and with it a new framework for the behavioral and social sciences. First, with the advent of the cognitive revolution, human nature can finally be defined precisely as the set of universal, species-typical information-processing programs that operate beneath the surface of expressed cultural variability. Second, this collection of cognitive programs evolved in the Pleistocene to solve the adaptive problems regularly faced by our hunter-gatherer ancestors--problems such as mate selection, language acquisition, cooperation, and sexual infidelity. Consequently, the traditional view of the mind as a general-purpose computer, tabula rasa, or passive recipient of culture is being replaced by the view that the mind resembles an intricate network of functionally specialized computers, each of which imposes contentful structure on human mental organization and culture. The Adapted Mind explores this new approach--evolutionary psychology--and its implications for a new view of culture.", "authors": ["Jerome H. Barkow", "Leda Cosmides", "John Tooby"], "related_topics": ["2777583129", "55520563", "92150231"], "citation_count": "5410", "reference_count": "0", "references": ["2007445014", "113511247", "2134419850", "2075585362", "2009158552", "3000418590", "2170689222", "2099334376", "1508207006", "22546692"], "date": "1991"}, {"id": "2029757964", "title": "Reduced channel dependence for speech recognition", "abstract": "Speech recognition systems tend to be sensitive to unimportant steady-state variation in speech spectra (i.e. those caused by varying the microphone or channel characteristics). There have been many attempts to solve this problem; however, these techniques are often computationally burdensome, especially for real-time implementation. Recently, Hermansy et al. [1] and Hirsch et al. [2] have suggested a simple technique that removes slow-moving linear channel variation with little adverse effect on speech recognition performance. In this paper we examine this technique, known as RASTA filtering, and evaluate its performance when applied to SRI's DECIPHER\u2122 speech recognition system [3]. We show that RASTA filtering succeeds in reducing DECIPHER\u2122's dependence on the channel.", "authors": ["Hy Murveit", "John Butzberger", "Mitch Weintraub"], "related_topics": ["9357232", "2778263558", "28490314"], "citation_count": "53", "reference_count": "15", "references": ["2122797512", "2157590573", "48303286", "157872538", "2056986588", "29686801", "1978094888", "2049894045", "2093800004", "2071579316"], "date": "1992"}, {"id": "2962706453", "title": "Recent developments in graph Ramsey theory.", "abstract": "Abstract Given a graph H , the Ramsey number r ( H ) is the smallest natural number N such that any two-colouring of the edges of K N contains a monochromatic copy of H . The existence of these numbers has been known since 1930 but their quantitative behaviour is still not well understood. Even so, there has been a great deal of recent progress on the study of Ramsey numbers and their variants, spurred on by the many advances across extremal combinatorics. In this survey, we will describe some of this progress. 1 Introduction In its broadest sense, the term Ramsey theory refers to any mathematical statement which says that a structure of a given kind is guaranteed to contain a large well-organised substructure. There are examples of such statements in many areas, including geometry, number theory, logic and analysis. For example, a key ingredient in the proof of the Bolzano\u2013Weierstrass theorem in real analysis is a lemma showing that any infinite sequence must contain an infinite monotone subsequence. A classic example from number theory, proved by van der Waerden [212] in 1927, says that if the natural numbers are coloured in any fixed number of colours then one of the colour classes contains arbitrarily long arithmetic progressions. This result has many generalisations. The most famous, due to Szemeredi [206], says that any subset of the natural numbers of positive upper density contains arbitrarily long arithmetic progressions. This result has many generalisations. The most famous, due to Szemeredi [206], says that any subset of the natural numbers of positive upper density contains arbitrarily long arithmetic progressions.", "authors": ["David Conlon", "Jacob Fox", "Benny Sudakov"], "related_topics": ["112291201", "44115641", "116493835"], "citation_count": "97", "reference_count": "179", "references": ["247697463", "2905110430", "2068871408", "1487872891", "2097673562", "1604945782", "2034838716", "2798428635", "2106456894", "2342433841"], "date": "2014"}, {"id": "189596042", "title": "Deep Boltzmann machines", "abstract": "We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are estimated using a variational approximation that tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer \u201cpre-training\u201d phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and NORB datasets showing that deep Boltzmann machines learn good generative models and perform well on handwritten digit and visual object recognition tasks.", "authors": ["Ruslan Salakhutdinov", "Geoffrey E. Hinton"], "related_topics": ["192576344", "199354608", "190502265"], "citation_count": "1549", "reference_count": "21", "references": ["2136922672", "2100495367", "2116064496", "2134557905", "2096192494", "2613634265", "2116825644", "2567948266", "2159737176", "2124914669"], "date": "2009"}, {"id": "2129276048", "title": "Complex Wavelets for Shift Invariant Analysis and Filtering of Signals", "abstract": "This paper describes a form of discrete wavelet transform, which generates complex coefficients by using a dual tree of wavelet filters to obtain their real and imaginary parts. This introduces limited redundancy (2m:1 for m-dimensional signals) and allows the transform to provide approximate shift invariance and directionally selective filters (properties lacking in the traditional wavelet transform) while preserving the usual properties of perfect reconstruction and computational efficiency with good well-balanced frequency responses. Here we analyze why the new transform can be designed to be shift invariant and describe how to estimate the accuracy of this approximation and design suitable filters to achieve this. We discuss two different variants of the new transform, based on odd/even and quarter-sample shift (Q-shift) filters, respectively. We then describe briefly how the dual tree may be extended for images and other multi-dimensional signals, and finally summarize a range of applications of the transform that take advantage of its unique properties.", "authors": ["Nick Kingsbury"], "related_topics": ["2777885455", "46286280", "73339587"], "citation_count": "2194", "reference_count": "23", "references": ["2115755118", "2132984323", "2146842127", "2103504761", "2107790757", "2119445186", "2177031359", "2120041316", "2033966461", "1517207589"], "date": "2001"}, {"id": "2096016260", "title": "Heuristic Decision Making", "abstract": "As reflected in the amount of controversy, few areas in psychology have undergone such dramatic conceptual changes in the past decade as the emerging science of heuristics. Heuristics are efficient cognitive processes, conscious or unconscious, that ignore part of the information. Because using heuristics saves effort, the classical view has been that heuristic decisions imply greater errors than do \u201crational\u201d decisions as defined by logic or statistical models. However, for many decisions, the assumptions of rational models are not met, and it is an empirical rather than an a priori issue how well cognitive heuristics function in an uncertain world. To answer both the descriptive question (\u201cWhich heuristics do people use in which situations?\u201d) and the prescriptive question (\u201cWhen should people rely on a given heuristic rather than a complex strategy to make better judgments?\u201d), formal models are indispensable. We review research that tests formal models of heuristic inference, including in business organizations, health care, and legal institutions. This research indicates that (a) individuals and organizations often rely on simple heuristics in an adaptive way, and (b) ignoring part of the information can lead to more accurate judgments than weighting and adding all information, for instance for low predictability and small samples. The big future challenge is to develop a systematic theory of the building blocks of heuristics as well as the core capacities and environmental structures these exploit.", "authors": ["Gerd Gigerenzer", "Wolfgang Gaissmaier"], "related_topics": ["127705205", "139475501", "173801870"], "citation_count": "3377", "reference_count": "187", "references": ["3022808291", "2155479778", "2163969674", "2115281393", "2076118331", "158727920", "2153251261", "1843246605", "1993325457", "3121878117"], "date": "2011"}, {"id": "2160842254", "title": "Inducing features of random fields", "abstract": "We present a technique for constructing random fields from a set of training samples. The learning paradigm builds increasingly complex fields by allowing potential functions, or features, that are supported by increasingly large subgraphs. Each feature has a weight that is trained by minimizing the Kullback-Leibler divergence between the model and the empirical distribution of the training data. A greedy algorithm determines how features are incrementally added to the field and an iterative scaling algorithm is used to estimate the optimal values of the weights. The random field models and techniques introduced in this paper differ from those common to much of the computer vision literature in that the underlying random fields are non-Markovian and have a large number of parameters that must be estimated. Relations to other learning approaches, including decision trees, are given. As a demonstration of the method, we describe its application to the problem of automatic word classification in natural language processing.", "authors": ["S. Della Pietra", "V. Della Pietra", "J. Lafferty"], "related_topics": ["130402806", "52306562", "51823790"], "citation_count": "1626", "reference_count": "20", "references": ["1594031697", "1997063559", "2049633694", "2096175520", "2121227244", "2097333193", "107938046", "2167837909", "2089969354", "2035301451"], "date": "1997"}, {"id": "1984218255", "title": "Forms of talk", "abstract": "Forms of Talk extends Erving Goffman's interactional analyses of face-to-face communication to ordinary conversations and vebal exchanges. In this, his most sociolinguistic work, Goffman relates to certain forms of talk some of the issues that concerned him in his work on frame analysis. This book brings together five of Goffman's essays: \"Replies and Responses,\" \"Response Cries,\" \"Footing,\" \"The Lecture,\" and \"Radio Talk.\" Of lasting value in Goffman's work is his insistence that behavior-verbal or nonverbal-be examined along with the context of that behavior. In all of these classic essays, there is a \"topic\" at hand for discussion and analysis. In addition, as those familiar with Goffman's work have come to expect, there is the wider context in which the topic can be viewed and related to other topics-a characteristic move of Goffman's that has made his work so necessary for students of interaction in many disciplines.", "authors": ["Erving Goffman"], "related_topics": ["32143645", "146303308", "189634115"], "citation_count": "13770", "reference_count": "0", "references": ["2012909746", "2109151141", "1659145884", "2109983206", "87185752", "2143280167", "2114772011", "2063790518", "2043920660", "2046179518"], "date": "1980"}, {"id": "2545577367", "title": "Recommender systems \u2014 beyond matrix completion", "abstract": "", "authors": ["Dietmar Jannach", "Paul Resnick", "Alexander Tuzhilin", "Markus Zanker"], "related_topics": ["557471498", "2778459887", "41008148"], "citation_count": "124", "reference_count": "40", "references": ["2171960770", "2110325612", "2159094788", "3121531027", "2124591829", "1966553486", "1560147776", "2047756776", "2030144199", "1997136459"], "date": "2016"}, {"id": "2140627345", "title": "Diagnostic reasoning based on structure and behavior", "abstract": "Abstract We describe a system that reasons from first principles, i.e., using knowledge of structure and behavior. The system has been implemented and tested on several examples in the domain of troubleshooting digital electronic circuits. We give an example of the system in operation, illustrating that this approach provides several advantages, including a significant degree of device independence, the ability to constrain the hypotheses it considers at the outset, yet deal with a progressively wider range of problems, and the ability to deal with situations that are novel in the sense that their outward manifestations may not have been encountered previously. As background we review our basic approach to describing structure and behavior, then explore some of the technologies used previously in troubleshooting. Difficulties encountered there lead us to a number of new contributions, four of which make up the central focus of this paper. \u2022 \u2014 We describe a technique we call constraint suspension that provides a powerful tool for troubleshooting. \u2022 \u2014 We point out the importance of making explicit the assumptions underlying reasoning and describe a technique that helps enumerate assumptions methodically. \u2022 \u2014 The result is an overall strategy for troubleshooting based on the progressive relaxation of underlying assumptions. The system can focus its efforts initially, yet will methodically expand its focus to include a broad range of faults. \u2022 \u2014 Finally, abstracting from our examples, we find that the concept of adjacency proves to be useful in understanding why some faults are especially difficult to diagnose and why multiple representations are useful.", "authors": ["Randall Davis"], "related_topics": ["147494362", "191617201", "16963264"], "citation_count": "1591", "reference_count": "22", "references": ["2478175895", "2033755422", "2060482235", "2038118137", "2103766969", "2096620062", "2118387410", "2111994103", "1489174353", "2051747042"], "date": "1984"}, {"id": "2167034998", "title": "Relations between the statistics of natural images and the response properties of cortical cells.", "abstract": "The relative efficiency of any particular image-coding scheme should be defined only in relation to the class of images that the code is likely to encounter. To understand the representation of images by the mammalian visual system, it might therefore be useful to consider the statistics of images from the natural environment (i.e., images with trees, rocks, bushes, etc). In this study, various coding schemes are compared in relation to how they represent the information in such natural images. The coefficients of such codes are represented by arrays of mechanisms that respond to local regions of space, spatial frequency, and orientation (Gabor-like transforms). For many classes of image, such codes will not be an efficient means of representing information. However, the results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy (e.g., correlation between the intensities of neighboring pixels) into first-order redundancy (i.e., the response distribution of the coefficients). Such coding produces a relatively high signal-to-noise ratio and permits information to be transmitted with only a subset of the total number of cells. These results support Barlow's theory that the goal of natural vision is to represent the information in the natural environment with minimal redundancy.", "authors": ["David J. Field"], "related_topics": ["133219170", "9095184", "152124472"], "citation_count": "4010", "reference_count": "34", "references": ["2003370853", "2006500012", "1995875735", "2105672294", "2078498116", "1499486838", "2116360511", "2135587681", "2138100172", "1999908130"], "date": "1987"}, {"id": "2043166545", "title": "Theory of minimum mean-square-error QAM systems employing decision feedback equalization", "abstract": "Decision feedback equalization is presently of interest as a technique for reducing intersymbol interference in high-rate PAM data communications systems. The basic principle is to cancel out intersymbol interference arising from previously decided data symbols at the receiver, leaving remaining intersymbol interference components to be handled by linear equalization. In this work we consider the application of decision feedback equalization to quadrature-amplitude modulation (QAM) transmission, in which two independent information streams modulate quadrature carriers. Extending Salz's treatment in a companion paper of decision feedback for a baseband channel, we derive the form of the optimum receiver filters via a matrix Wiener-Hopf analysis. We obtain explicit analytical expressions for minimum mean-square error and optimum transmitting filters. The optimization is subject to a constraint on the transmitted signal power and assumes no prior decision errors. The class of QAM transmitter and receiver structures treated here is actually much larger than the class usually considered for QAM systems. However, our results for decision feedback equalization show that, for nonexcess bandwidth systems, optimum performance is achievable without taking advantage of the most general structure. If the transmitter is required to have the conventional QAM structure, study of the time continuous system that gives rise to the sampled data system considered here demonstrates that under quite general assumptions a nonexcess bandwidth system is optimum. Finally, the explicit description of the optimum transmitting matrix filter follows from an information-theoretic \u201cwater-pouring\u201d algorithm in conjunction with the determination of the form of the points of maxima of a determinant extremal problem.", "authors": ["D. D. Falconer", "G. J. Foschini"], "related_topics": ["59030546", "97812054", "75755367"], "citation_count": "81", "reference_count": "11", "references": ["2034274945", "1990144397", "2025879008", "2055256274", "2126259042", "2139724070", "2163729192", "1512002052", "1991969984", "2323737254"], "date": "1973"}, {"id": "1523640391", "title": "On the Solution of Nonlinear Fractional-Order Differential Equations Used in the Modeling of Viscoplasticity", "abstract": "The authors have recently developed a mathematical model for the description of the behavior of viscoplastic materials. The model is based on a nonlinear differential equation of order \u03b2, where \u03b2 is a material constant typically in the range 0 < \u03b2 < 1. This equation is coupled with a first-order differential equation. In the present paper, we introduce and discuss a numerical scheme for the numerical solution of these equations. The algorithm is based on a PECE-type approach.", "authors": ["Kai Diethelm", "Alan D. Freed"], "related_topics": ["78045399", "64057670", "93779851"], "citation_count": "553", "reference_count": "14", "references": ["1530054495", "1509923322", "2042388195", "1528987510", "9124626", "194858719", "1991982189", "2093478476", "2022072871", "2134837756"], "date": "1998"}, {"id": "1599406659", "title": "Updating and Querying Databases that Track Mobile Units", "abstract": "In this paper, we consider databases representing information about moving objects (e.g., vehicles), particularly their location. We address the problems of updating and querying such databases. Specifically, the update problem is to determine when the location of a moving object in the database (namely its database location) should be updated. We answer this question by proposing an information cost model that captures uncertainty, deviation, and communication. Then we analyze dead-reckoning policies, namely policies that update the database location whenever the distance between the actual location and the database location exceeds a given threshold, x. Dead-reckoning is the prevalent approach in military applications, and our cost model enables us to determine the threshold x. We propose several dead-reckoning policies and we compare their performance by simulation. Then we consider the problem of processing range queries in the database. An example of a range query is \u2018retrieve the objects that are currently inside a given polygon P\u2032. We propose a probabilistic approach to solve the problem. Namely, the DBMS will answer such a query with a set of objects, each of which is associated with a probability that the object is inside P.", "authors": ["Ouri Wolfson", "A. Prasad Sistla", "Sam Chamberlain", "Yelena Yesha"], "related_topics": ["110432227", "64729616", "49937458"], "citation_count": "594", "reference_count": "23", "references": ["1558832481", "2913677764", "2099397891", "2140460512", "2064975723", "1999981671", "1938177792", "2294081347", "1989609393", "1576280583"], "date": "1999"}, {"id": "2135976285", "title": "Satisfying constraints on extraction and adjunction", "abstract": "In this paper, we present a unified feature-based theory of complement, adjunct, and subject extraction, in which there is no need either for valence reducing lexical rules or for phonologically null traces. Our analysis rests on the assumption that the mapping between argument structure and valence is defined by realization constraints which are satisfied by all lexical heads. Arguments can be realized as local dependents, in which case they are selected via the head's valence features. Alternatively, arguments may be realized in a long-distance dependency construction, in which case they are selected via the head's slash features. Furthermore, we argue that English post-verbal adjuncts, as well as complements, are syntactic dependentsselected by the verb, thus providing a uniform analysis of complement andadjunct extraction. Finally, we show that our analysis provides analternative treatment of subject extraction and we offer a new account of thethat-trace effect.", "authors": ["Gosse Bouma", "Robert Malouf", "Ivan A. Sag"], "related_topics": ["2780580338", "2776397901", "85736272"], "citation_count": "494", "reference_count": "86", "references": ["2038248725", "2095589793", "1722351164", "1972573551", "1595210733", "1504955803", "2143745167", "2011734523", "25538197", "1568155371"], "date": "2001"}, {"id": "2087377426", "title": "PAINLESS NONORTHOGONAL EXPANSIONS", "abstract": "In a Hilbert space H, discrete families of vectors {hj} with the property that f=\u2211j\u3008hj\u2016\u2009f\u3009hj for every f in H are considered. This expansion formula is obviously true if the family is an orthonormal basis of H, but also can hold in situations where the hj are not mutually orthogonal and are \u2018\u2018overcomplete.\u2019\u2019 The two classes of examples studied here are (i) appropriate sets of Weyl\u2013Heisenberg coherent states, based on certain (non\u2010Gaussian) fiducial vectors, and (ii) analogous families of affine coherent states. It is believed, that such \u2018\u2018quasiorthogonal expansions\u2019\u2019 will be a useful tool in many areas of theoretical physics and applied mathematics.", "authors": ["Ingrid Daubechies", "A. Grossmann", "Y. Meyer"], "related_topics": ["5806529", "62799726", "2779277283"], "citation_count": "2034", "reference_count": "17", "references": ["2120062331", "2162870748", "2096684483", "2013987111", "2014757225", "2022096757", "2319308948", "2088753904", "42253355", "2137852732"], "date": "1986"}, {"id": "1499486838", "title": "Texture discrimination by Gabor functions", "abstract": "A 2D Gabor filter can be realized as a sinusoidal plane wave of some frequency and orientation within a two dimensional Gaussian envelope. Its spatial extent, frequency and orientation preferences as well as bandwidths are easily controlled by the parameters used in generating the filters. However, there is an \u201cuncertainty relation\u201d associated with linear filters which limits the resolution simultaneously attainable in space and frequency. Daugman (1985) has determined that 2D Gabor filters are members of a class of functions achieving optimal joint resolution in the 2D space and 2D frequency domains. They have also been found to be a good model for two dimensional receptive fields of simple cells in the striate cortex (Jones 1985; Jones et al. 1985).", "authors": ["M R Turner"], "related_topics": ["2779883129", "173149727", "136902061"], "citation_count": "800", "reference_count": "59", "references": ["2006500012", "2108992228", "2032533296", "2116360511", "2029683515", "3021628422", "2138100172", "1999908130", "1964415410", "2020459435"], "date": "1986"}, {"id": "2001438822", "title": "Andrew: a distributed personal computing environment", "abstract": "The Information Technology Center (ITC), a collaborative effort between IBM and Carnegie-Mellon University, is in the process of creating Andrew, a prototype computing and communication system for universities. This article traces the origins of Andrew, discusses its goals and strategies, and gives an overview of the current status of its implementation and usage.", "authors": ["James H. Morris", "Mahadev Satyanarayanan", "Michael H. Conner", "John H. Howard", "David S. Rosenthal", "F. Donelson Smith"], "related_topics": ["70388272", "121017731", "110354214"], "citation_count": "796", "reference_count": "21", "references": ["109793532", "1967141605", "41801118", "2111223826", "2117271294", "1605568660", "2075121558", "2035379912", "1969383031", "2070343246"], "date": "1986"}, {"id": "2042385018", "title": "Applications of machine learning and rule induction", "abstract": "Machine learning is the study of computational methods for improving performance by mechanizing the acquisition of knowledge from experience. Expert performance requires much domain-specific knowledge, and knowledge engineering has produced hundreds of AI expert systems that are now used regularly in industry. Machine learning aims to provide increasing levels of automation in the knowledge engineering process, replacing much time-consuming human activity with automatic techniques that improve accuracy or efficiency by discovering and exploiting regularities in training data. The ultimate test of machine learning is its ability to produce systems that are used regularly in industry, education, and elsewhere.", "authors": ["Pat Langley", "Herbert A. Simon"], "related_topics": ["84685590", "2777220311", "4554734"], "citation_count": "702", "reference_count": "16", "references": ["2125055259", "1594031697", "2008906462", "2988864014", "1567276288", "1966602182", "1511887321", "2162061564", "98436501", "2400138769"], "date": "1995"}, {"id": "1507770639", "title": "An IBM PC based large-vocabulary isolated-utterance speech recognizer", "abstract": "The Speech Recognition Group at IBM Research in Yorktown Heights has designed a real-time, isolated-utterance speech recognizer for natural language with a 5,000-word vocabulary based on the IBM Personal Computer (PC) AT model and two IBM Signal Processors realized in VLSI technology. The enrollment period for a new user is approximately 20 minutes. The basic vocabulary is chosen from the most common words in several collections of documents such as office memoranda and business letters. The system supports spelling and interactive personalization to augment this vocabulary. Signal processing, vector quantization, and acoustic matching algorithms are programmed on the IBM Signal Processors which fit into the PC AT chassis. The PC AT controls the Processors and implements the decoder stack search and the language model, as well as the application-specific interface. The modular architecture of the design is expandable to a 20,000-word vocabulary system by the addition of two more IBM Signal Processors housed in a PC Expansion Unit.", "authors": ["A. Averbuch", "L. Bahl", "R. Bakis", "P. Brown", "A. Cole", "G. Daggett", "S. Das", "K. Davies", "S. DeGennaro", "P. de Souza", "E. Epstein", "D. Fraleigh", "F. Jelinek", "S. Katz", "B. Lewis", "R. Mercer", "A. Nadas", "D. Nahamoo", "M. Picheny", "G. Shichman", "P. Spinelli"], "related_topics": ["77741850", "80785863", "108489637"], "citation_count": "77", "reference_count": "13", "references": ["1966812932", "1521239006", "2099074650", "2035227369", "2170967986", "1847689439", "1579558060", "1970531183", "2056809970", "1901281023"], "date": "1986"}, {"id": "2110499305", "title": "Mathematical Transform Of (R, G, B) Color Data To Munsell (H, V, C) Color Data", "abstract": "In studying new-generation color image codings, it is very effective 1) to code signals in the space of inherent tri-attributes of human color perception, and 2) to relate a coding error with perceptual degree of deteriorations. For these purpose, we have adopted the Munsell Renotation System in which color signals of tri-attributes of human color perception (Hue, Value and Chroma) and psychometrical color differences are defined. In the Munsell Renotation System, however, intertransformation between (RGB) data and corresponding color data is very cumbersome. Because the intertransformation depends on a look up table. This article presents a new method of mathematical transformation. The mathematical transformation is obtained by multiple regression analysis of 250 color samples, which are uniformly sampled from whole color ranges that a conventional NTSC color TV camera can present. The new method can transform (RGB) data to the data of the Munsell Renotation System far better than the conventional method given by the CIE(1976)L*a*b*.", "authors": ["Makoto Miyahara", "Yasuhiro Yoshida"], "related_topics": ["2961294", "82990744", "106730002"], "citation_count": "154", "reference_count": "0", "references": ["2093191240", "1975830550", "2134190498", "2082453965", "2118783153", "2085425470", "2106910805", "2021778442", "2125336854", "2063581492"], "date": "1988"}, {"id": "2167917621", "title": "Ensemble based systems in decision making", "abstract": "In matters of great importance that have financial, medical, social, or other implications, we often seek a second opinion before making a decision, sometimes a third, and sometimes many more. In doing so, we weigh the individual opinions, and combine them through some thought process to reach a final decision that is presumably the most informed one. The process of consulting \"several experts\" before making a final decision is perhaps second nature to us; yet, the extensive benefits of such a process in automated decision making applications have only recently been discovered by computational intelligence community. Also known under various other names, such as multiple classifier systems, committee of classifiers, or mixture of experts, ensemble based systems have shown to produce favorable results compared to those of single-expert systems for a broad range of applications and under a variety of scenarios. Design, implementation and application of such systems are the main topics of this article. Specifically, this paper reviews conditions under which ensemble based systems may be more beneficial than their single classifier counterparts, algorithms for generating individual components of the ensemble systems, and various procedures through which the individual classifiers can be combined. We discuss popular ensemble based algorithms, such as bagging, boosting, AdaBoost, stacked generalization, and hierarchical mixture of experts; as well as commonly used combination rules, including algebraic combination of outputs, voting based techniques, behavior knowledge space, and decision templates. Finally, we look at current and future research directions for novel applications of ensemble systems. Such applications include incremental learning, data fusion, feature selection, learning with missing features, confidence estimation, and error correcting output codes; all areas in which ensemble systems have shown great promise", "authors": ["R. Polikar"], "related_topics": ["45942800", "107327155", "46686674"], "citation_count": "2778", "reference_count": "91", "references": ["2911964244", "3124955340", "2912934387", "2158275940", "1975846642", "2097645701", "2151554678", "2152761983", "2113242816", "1605688901"], "date": "2006"}, {"id": "2034432063", "title": "Multimodality image registration by maximization of mutual information", "abstract": "A new approach to the problem of multimodality medical image registration is proposed, using a basic concept from information theory, mutual information (MI), or relative entropy, as a new matching criterion. The method presented in this paper applies MI to measure the statistical dependence or information redundancy between the image intensities of corresponding voxels in both images, which is assumed to be maximal if the images are geometrically aligned. Maximization of MI is a very general and powerful criterion, because no assumptions are made regarding the nature of this dependence and no limiting constraints are imposed on the image content of the modalities involved. The accuracy of the MI criterion is validated for rigid body registration of computed tomography (CT), magnetic resonance (MR), and photon emission tomography (PET) images by comparison with the stereotactic registration solution, while robustness is evaluated with respect to implementation issues, such as interpolation and optimization, and image content, including partial overlap and image degradation. Our results demonstrate that subvoxel accuracy with respect to the stereotactic reference solution can be achieved completely automatically and without any prior segmentation, feature extraction, or other preprocessing steps which makes this method very well suited for clinical applications.", "authors": ["F. Maes", "A. Collignon", "D. Vandermeulen", "G. Marchal", "P. Suetens"], "related_topics": ["166704113", "152139883", "52622490"], "citation_count": "5897", "reference_count": "28", "references": ["2099111195", "2981264952", "2408227189", "3017143921", "1874027545", "1963623641", "2004537679", "2051809205", "2134165173", "2138943050"], "date": "1997"}, {"id": "2150375089", "title": "Perceptual symbol systems.", "abstract": "Prior to the twentieth century, theories of knowledge were inherently perceptual. Since then, developments in logic, statis- tics, and programming languages have inspired amodal theories that rest on principles fundamentally different from those underlying perception. In addition, perceptual approaches have become widely viewed as untenable because they are assumed to implement record- ing systems, not conceptual systems. A perceptual theory of knowledge is developed here in the context of current cognitive science and neuroscience. During perceptual experience, association areas in the brain capture bottom-up patterns of activation in sensory-motor areas. Later, in a top-down manner, association areas partially reactivate sensory-motor areas to implement perceptual symbols. The stor- age and reactivation of perceptual symbols operates at the level of perceptual components - not at the level of holistic perceptual expe- riences. Through the use of selective attention, schematic representations of perceptual components are extracted from experience and stored in memory (e.g., individual memories of green, purr, hot). As memories of the same component become organized around a com- mon frame, they implement a simulator that produces limitless simulations of the component (e.g., simulations of purr). Not only do such simulators develop for aspects of sensory experience, they also develop for aspects of proprioception (e.g., lift, run) and introspec- tion (e.g., compare, memory, happy, hungry). Once established, these simulators implement a basic conceptual system that represents types, supports categorization, and produces categorical inferences. These simulators further support productivity, propositions, and ab- stract concepts, thereby implementing a fully functional conceptual system. Productivity results from integrating simulators combinato- rially and recursively to produce complex simulations. Propositions result from binding simulators to perceived individuals to represent type-token relations. Abstract concepts are grounded in complex simulations of combined physical and introspective events. Thus, a per- ceptual theory of knowledge can implement a fully functional conceptual system while avoiding problems associated with amodal sym- bol systems. Implications for cognition, neuroscience, evolution, development, and artificial intelligence are explored.", "authors": ["Lawrence W. Barsalou"], "related_topics": ["28063669", "22033958", "137323160"], "citation_count": "8817", "reference_count": "461", "references": ["1652505363", "1983578042", "1748703215", "1984186949", "1933657216", "2052417512", "2105291362", "1898014694", "1977308918", "2055460448"], "date": "1999"}, {"id": "2062361515", "title": "Automatic recognition of handprinted characters&#8212;The state of the art", "abstract": "Based on a study of the extensive literature in handprint recognition, this paper presents a survey in this challenging field. Recognition algorithms, data bases, character models, and handprint standards are examined. Achievements in the recognition of handprinted numerals, alphanumerics, Fortran, and Katakana characters are analyzed and compared. Data quality and constraints, as well as human and machine factors are also described. Characteristics, problems, and actual results on on-line recognition of handprinted characters for different applications are discussed. New emphases and directions are suggested.", "authors": ["C.Y. Suen", "M. Berthod", "S. Mori"], "related_topics": ["44868376", "17649283", "132900626"], "citation_count": "498", "reference_count": "117", "references": ["2008313333", "2155195832", "2088534753", "1966591781", "2070771945", "2000821228", "1979819178", "2065973527", "2002448074", "2120216197"], "date": "1980"}, {"id": "14213647", "title": "Distributive, Collective and Cumulative Quantification", "abstract": "", "authors": ["Remko J.H. Scha"], "related_topics": ["11821877", "144237770", "33923547"], "citation_count": "633", "reference_count": "0", "references": ["1687416839", "1955237540", "2740520478", "2116908653", "2152578812", "2266533293", "1511144591", "2092402298", "2496161879", "2034355597"], "date": "1984"}, {"id": "2912780347", "title": "Authorship Attribution", "abstract": "Authorship attribution, the science of inferring characteristics of the author from the characteristics of documents written by that author, is a problem with a long history and a wide range of application. Recent work in \"non-traditional\" authorship attribution demonstrates the practicality of automatically analyzing documents based on authorial style, but the state of the art is confusing. Analyses are difficult to apply, little is known about type or rate of errors, and few \"best practices\" are available. In part because of this confusion, the field has perhaps had less uptake and general acceptance than is its due. This review surveys the history and present state of the discipline, presenting some comparative results when available. It shows, first, that the discipline is quite successful, even in difficult cases involving small documents in unfamiliar and less studied languages; it further analyzes the types of analysis and features used and tries to determine characteristics of well-performing systems, finally formulating these in a set of recommendations for best practices.", "authors": ["Patrick Juola"], "related_topics": ["11192451", "184356942", "165120375"], "citation_count": "898", "reference_count": "107", "references": ["2156909104", "2139212933", "3097169496", "2133671888", "1638203394", "2097333193", "349770100", "1604792744", "2091034860", "1967461618"], "date": "2008"}, {"id": "2171343266", "title": "Topics over time: a non-Markov continuous-time model of topical trends", "abstract": "This paper presents an LDA-style topic model that captures not only the low-dimensional structure of data, but also how the structure changes over time. Unlike other recent work that relies on Markov assumptions or discretization of time, here each topic is associated with a continuous distribution over timestamps, and for each generated document, the mixture distribution over topics is influenced by both word co-occurrences and the document's timestamp. Thus, the meaning of a particular topic can be relied upon as constant, but the topics' occurrence and correlations change significantly over time. We present results on nine months of personal email, 17 years of NIPS research papers and over 200 years of presidential state-of-the-union addresses, showing improved topics, better timestamp prediction, and interpretable trends.", "authors": ["Xuerui Wang", "Andrew McCallum"], "related_topics": ["171686336", "181389423", "98763669"], "citation_count": "1670", "reference_count": "18", "references": ["1880262756", "2001082470", "2158266063", "2072644219", "1521478692", "2140124448", "2135194391", "2112971401", "2145677303", "1547561528"], "date": "2006"}, {"id": "3100307207", "title": "Experience Grounds Language", "abstract": "Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle tasks after being trained on text alone, successful linguistic communication relies on a shared experience of the world. It is this shared experience that makes utterances meaningful. Natural language processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication.", "authors": ["Yonatan Bisk", "Ari Holtzman", "Jesse Thomason", "Jacob Andreas", "Yoshua Bengio", "Joyce Chai", "Mirella Lapata", "Angeliki Lazaridou", "Jonathan May", "Aleksandr Nisnevich", "Nicolas Pinto", "Joseph P. Turian"], "related_topics": ["188147891", "59404180", "110379092"], "citation_count": "65", "reference_count": "181", "references": ["2618530766", "2963341956", "2963403868", "2117539524", "2153579005", "2250539671", "1880262756", "2962739339", "2117130368", "2132339004"], "date": "2020"}, {"id": "1549664537", "title": "Information Theory: Coding Theorems for Discrete Memoryless Systems", "abstract": "Csiszr and Krner's book is widely regarded as a classic in the field of information theory, providing deep insights and expert treatment of the key theoretical issues. It includes in-depth coverage of the mathematics of reliable information transmission, both in two-terminal and multi-terminal network scenarios. Updated and considerably expanded, this new edition presents unique discussions of information theoretic secrecy and of zero-error information theory, including the deep connections of the latter with extremal combinatorics. The presentations of all core subjects are self contained, even the advanced topics, which helps readers to understand the important connections between seemingly different problems. Finally, 320 end-of-chapter problems, together with helpful solving hints, allow readers to develop a full command of the mathematical techniques. It is an ideal resource for graduate students and researchers in electrical and electronic engineering, computer science and applied mathematics.", "authors": ["Imre Csiszar", "Janos Korner"], "related_topics": ["52622258", "549619432", "2776452267"], "citation_count": "4570", "reference_count": "0", "references": ["1667950888", "2133475491", "2098567664", "2147942702", "2102617152", "2072184935", "2107689535", "2098257210", "627952176", "1749807555"], "date": "2014"}, {"id": "2140833774", "title": "Exploring Strategies for Training Deep Neural Networks", "abstract": "Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms.", "authors": ["Hugo Larochelle", "Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Pascal Lamblin"], "related_topics": ["108583219", "97385483", "199354608"], "citation_count": "1068", "reference_count": "60", "references": ["2136922672", "2310919327", "2100495367", "2072128103", "2116064496", "2117130368", "2025768430", "2110798204", "2099741732", "2108384452"], "date": "2009"}, {"id": "2004306067", "title": "\u201cSometimes\u201d and \u201cnot never\u201d revisited: on branching versus linear time temporal logic", "abstract": "The differences between and appropriateness of branching versus linear time temporal logic for reasoning about concurrent programs are studied. These issues have been previously considered by Lamport. To facilitate a careful examination of these issues, a language, CTL*, in which a universal or existential path quantifier can prefix an arbitrary linear time assertion, is defined. The expressive power of a number of sublanguages is then compared. CTL* is also related to the logics MPL of Abrahamson and PL of Harel, Kozen, and Parikh. The paper concludes with a comparison of the utility of branching and linear time temporal logics.", "authors": ["E. Allen Emerson", "Joseph Y. Halpern"], "related_topics": ["4777664", "198008173", "11648818"], "citation_count": "1618", "reference_count": "37", "references": ["2023808162", "1501731334", "2003227046", "2166656159", "2069709605", "2157319504", "1970603830", "2806619258", "2040127143", "2048355938"], "date": "1986"}, {"id": "2138888471", "title": "COMPARATIVE AMINO ACID DECOMPOSITION ANALYSIS OF POTENT TYPE I P38\u03b1 INHIBITORS", "abstract": "p38\u03b1 is a member of mitogen-activated protein kinases (MAPK) considered as a prominent target in development of anti-inflammatory agents. Any abnormality in the phosphorylation process leads to the different human diseases such as cancer, diabetes and inflammatory diseases. Several small molecule p38\u03b1 inhibitors have been developed up to now. In this regard, structural elucidation of p38 inhibitors needs to be done enabling us in rational lead development strategies. Various interactions of three potent inhibitors with p38\u03b1 active site have been evaluated in terms of binding energies and bond lengths via density function theory and MD simulations. Our comparative study showed that both ab initio and MD simulation led to the relatively similar results in pharmacophore discrimination of p38\u03b1 inhibitors. The results of the present study may find their usefulness in pharmacophore based modification of p38\u03b1 inhibitors.", "authors": ["Ahmad Ebadi", "Nima Razzaghi-Asl", "Mehdi Khoshneviszadeh", "Ramin Miri"], "related_topics": ["56173144", "161624437", "57074206"], "citation_count": "4", "reference_count": "55", "references": ["2029667189", "2171268876", "2596156494", "2015642465", "1982356449", "2052750950", "2128572087", "1709109739", "2046822015", "2035266068"], "date": "2013"}, {"id": "2137239103", "title": "Tight Bounds on the Complexity of Parallel Sorting", "abstract": "In this paper, we prove tight upper and lower bounds on the number of processors, information transfer, wire area, and time needed to sort N numbers in a bounded-degree fixed-connection network. Our most important new results are: 1) the construction of an N-node degree-3 network capable of sorting N numbers in O(log N) word steps; 2) a proof that any network capable of sorting N (7 log N)-bit numbers in T bit steps requires area A where AT2 = ?(N2 log2 N); and 3) the construction of a ``small-constant-factor'' bounded-degree network that sorts N ?(log N)-bit numbers in T = ?(log N) bit steps with A = ?(N2) area.", "authors": ["Tom Leighton"], "related_topics": ["111696304", "77553402", "88548561"], "citation_count": "662", "reference_count": "19", "references": ["1976284552", "2141389982", "2076458424", "2069489095", "1988294273", "2067002313", "1977908721", "2066782398", "1530456100", "2134845208"], "date": "1985"}, {"id": "2096551755", "title": "Bulk Spin-Resonance Quantum Computation", "abstract": "Quantum computation remains an enormously appealing but elusive goal. It is appealing because of its potential to perform superfast algorithms, such as finding prime factors in polynomial time, but also elusive because of the difficulty of simultaneously manipulating quantum degrees of freedom while preventing environmentally induced decoherence. A new approach to quantum computing is introduced based on the use of multiple-pulse resonance techniques to manipulate the small deviation from equilibrium of the density matrix of a macroscopic ensemble so that it appears to be the density matrix of a much lower dimensional pure state. A complete prescription for quantum computing is given for such a system.", "authors": ["Neil A. Gershenfeld", "Isaac L. Chuang"], "related_topics": ["190474826", "137019171", "186468114"], "citation_count": "2386", "reference_count": "24", "references": ["2102008187", "1995412269", "2067763535", "1999706070", "2042474962", "2050334794", "2003992904", "1966533239", "2017156903", "1974875620"], "date": "1997"}, {"id": "2029323145", "title": "On the Admissibility of Invariant Estimators of One or More Location Parameters", "abstract": "", "authors": ["Lawrence David Brown"], "related_topics": ["190470478", "185429906", "202444582"], "citation_count": "263", "reference_count": "16", "references": ["1584444527", "2799137445", "2045638068", "1605283609", "2059944969", "2005172650", "1979185183", "1994232555", "2080857177", "2093579479"], "date": "1966"}, {"id": "2083081439", "title": "Randomisation and baseline comparisons in clinical trials.", "abstract": "80 reports of randomised clinical trials in four leading general medical journals were reviewed. The reporting of the methodology of randomisation was inadequate. In 30% of trials there was no clear evidence that the groups had been randomised. Among trials that used simple randomisation the sample sizes in the two groups were too often similar, and there was an unexpected small bias in favour of there being fewer patients in the experimental group. The handling of comparisons of baseline characteristics was inadequate in 41% of the trials. Suggestions are made for improving standards.", "authors": ["D.G. Altman", "C.J. Dor\u00e9"], "related_topics": ["535046627", "95190672", "129848803"], "citation_count": "570", "reference_count": "19", "references": ["2087425662", "1977833499", "2057212716", "1993398606", "2121361638", "2168485493", "2012947453", "2324671927", "1571179146", "2795972393"], "date": "1990"}, {"id": "1990061958", "title": "Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology", "abstract": "Part I. Exact String Matching: The Fundamental String Problem: 1. Exact matching: fundamental preprocessing and first algorithms 2. Exact matching: classical comparison-based methods 3. Exact matching: a deeper look at classical methods 4. Semi-numerical string matching Part II. Suffix Trees and their Uses: 5. Introduction to suffix trees 6. Linear time construction of suffix trees 7. First applications of suffix trees 8. Constant time lowest common ancestor retrieval 9. More applications of suffix trees Part III. Inexact Matching, Sequence Alignment and Dynamic Programming: 10. The importance of (sub)sequence comparison in molecular biology 11. Core string edits, alignments and dynamic programming 12. Refining core string edits and alignments 13. Extending the core problems 14. Multiple string comparison: the Holy Grail 15. Sequence database and their uses: the motherlode Part IV. Currents, Cousins and Cameos: 16. Maps, mapping, sequencing and superstrings 17. Strings and evolutionary trees 18. Three short topics 19. Models of genome-level mutations.", "authors": ["Dan Gusfield"], "related_topics": ["7757238", "2781166958", "32610155"], "citation_count": "7603", "reference_count": "0", "references": ["2122646361", "2153233077", "2132341951", "2107282968", "2186428165", "2142619120", "2001496424", "2138756793", "2144544802", "2121762798"], "date": "1996"}, {"id": "2122410182", "title": "Artificial Intelligence: A Modern Approach", "abstract": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence.", "authors": ["Stuart J. Russell", "Peter Norvig"], "related_topics": ["26205005", "30112582", "207453521"], "citation_count": "42568", "reference_count": "0", "references": ["2076063813", "1570448133", "2335728318", "2072955302", "2022166150", "2126316555", "2139356617", "2017337590", "2135790056", "2436001372"], "date": "2019"}, {"id": "2183707334", "title": "PAST: PALEONTOLOGICAL STATISTICAL SOFTWARE PACKAGE FOR EDUCATION AND DATA ANALYSIS", "abstract": "A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.", "authors": ["\u00d8yvind Hammer", "David A. T. Harper", "Paul D. Ryan"], "related_topics": ["199163554", "171730128", "161584116"], "citation_count": "18060", "reference_count": "18", "references": ["2170120409", "2798110564", "2164185981", "2157895715", "1968885401", "2051688318", "1517185106", "2032223644", "2928083819", "1216781333"], "date": "2000"}, {"id": "2482402870", "title": "Statistical Pattern Recognition", "abstract": "The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical ap...", "authors": ["K JainAnil", "P W DuinRobert", "MaoJianchang"], "related_topics": ["40608802", "52622490", "153180895"], "citation_count": "7074", "reference_count": "0", "references": ["2067191022", "2154053567", "2130660124", "2153233077", "2161160262", "2075647286", "2074788634", "2139479830", "2154278880", "2015245929"], "date": "1999"}, {"id": "2149173084", "title": "The Grid File: An Adaptable, Symmetric Multikey File Structure", "abstract": "Traditional file structures that provide multikey access to records, for example, inverted files, are extensions of file structures originally designed for single-key access. They manifest various deficiencies in particular for multikey access to highly dynamic files. We study the dynamic aspects of file structures that treat all keys symmetrically, that is, file structures which avoid the distinction between primary and secondary keys. We start from a bitmap approach and treat the problem of file design as one of data compression of a large sparse matrix. This leads to the notions of a grid partition of the search space and of a grid directory, which are the keys to a dynamic file structure called the grid file. This file system adapts gracefully to its contents under insertions and deletions, and thus achieves an upper bound of two disk accesses for single record retrieval; it also handles range queries and partially specified queries efficiently. We discuss in detail the design decisions that led to the grid file, present simulation results of its behavior, and compare it to other multikey access file structures.", "authors": ["J. Nievergelt", "Hans Hinterberger", "Kenneth C. Sevcik"], "related_topics": ["56317617", "166807848", "21729314"], "citation_count": "1777", "reference_count": "28", "references": ["2752853835", "2165558283", "2066799613", "2008196645", "2087966340", "2067021215", "2099117306", "2050708115", "2155631901", "2035419547"], "date": "1984"}, {"id": "2155806188", "title": "Ensemble-based classifiers", "abstract": "The idea of ensemble methodology is to build a predictive model by integrating multiple models. It is well-known that ensemble methods can be used for improving prediction performance. Researchers from various disciplines such as statistics and AI considered the use of ensemble methodology. This paper, review existing ensemble techniques and can be served as a tutorial for practitioners who are interested in building ensemble based systems.", "authors": ["Lior Rokach"], "related_topics": ["45942800", "106135958", "40651066"], "citation_count": "2272", "reference_count": "123", "references": ["2911964244", "2912934387", "2125055259", "2112076978", "2172000360", "2024046085", "2168936936", "2152761983", "2113242816", "2167917621"], "date": "2010"}, {"id": "2022204871", "title": "Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis", "abstract": "This paper presents a new approach to phrase-level sentiment analysis that first determines whether an expression is neutral or polar and then disambiguates the polarity of the polar expressions. With this approach, the system is able to automatically identify the contextual polarity for a large subset of sentiment expressions, achieving results that are significantly better than baseline.", "authors": ["Theresa Wilson", "Janyce Wiebe", "Paul Hoffmann"], "related_topics": ["98202634", "66402592", "2776224158"], "citation_count": "3963", "reference_count": "22", "references": ["2160660844", "3146306708", "2114524997", "2115023510", "2053463056", "2014902591", "2155328222", "2112422413", "2199803028", "2080558111"], "date": "2005"}, {"id": "2025588980", "title": "Towards a system for automatic facial feature detection", "abstract": "Abstract A model-based methodology is proposed to detect facial features from a front-view ID-type picture. The system is composed of three modules: context (i.e. face location), eye, and mouth. The context module is a low resolution module which defines a face template in terms of intensity valley regions. The valley regions are detected using morphological filtering and 8-connected blob coloring. The objective is to generate a list of hypothesized face locations ranked by face likelihood. The detailed analysis is left for the high resolution eye and mouth modules. The aim for both is to confirm as well as refine the locations and shapes of their respective features of interest. The detection is done via a two-step modelling approach based on the Hough transform and the deformable template technique. The results show that facial features can be located very quickly with Adequate or better fit in over 80% of the images with the proposed system.", "authors": ["Gloria Chow", "Xiaobo Li"], "related_topics": ["200518788", "126422989", "153180895"], "citation_count": "336", "reference_count": "24", "references": ["2170120409", "1490482062", "2164741953", "2740373864", "2130259898", "2171074980", "1507699566", "2032361618", "1600517698", "2017607294"], "date": "1993"}, {"id": "1584444527", "title": "Estimation with Quadratic Loss", "abstract": "It has long been customary to measure the adequacy of an estimator by the smallness of its mean squared error. The least squares estimators were studied by Gauss and by other authors later in the nineteenth century. A proof that the best unbiased estimator of a linear function of the means of a set of observed random variables is the least squares estimator was given by Markov [12], a modified version of whose proof is given by David and Neyman [4]. A slightly more general theorem is given by Aitken [1]. Fisher [5] indicated that for large samples the maximum likelihood estimator approximately minimizes the mean squared error when compared with other reasonable estimators. This paper will be concerned with optimum properties or failure of optimum properties of the natural estimator in certain special problems with the risk usually measured by the mean squared error or, in the case of several parameters, by a quadratic function of the estimators. We shall first mention some recent papers on this subject and then give some results, mostly unpublished, in greater detail.", "authors": ["W. James", "Charles Stein"], "related_topics": ["139945424", "185429906", "191393472"], "citation_count": "3426", "reference_count": "18", "references": ["2323136350", "1605283609", "1598266570", "2005172650", "2016274652", "1979185183", "1968979467", "1601791052", "2080857177", "2320103898"], "date": "1991"}, {"id": "1588462524", "title": "Optical burst switching (OBS) - a new paradigm for an optical Internet", "abstract": "To support bursty traffic on the Internet (and especially WWW) efficiently, optical burst switching (OBS) is proposed as a way to streamline both protocols and hardware in building the future generation Optical Internet. By leveraging the attractive properties of optical communications and at the same time, taking into account its limitations, OBS combines the best of optical circuit-switching and packet/cell switching. In this paper, the general concept of OBS protocols and in particular, those based on Just-Enough-Time (JET), is described, along with the applicability of OBS protocols to IP over WDM. Specific issues such as the use of fiber delay-lines (FDLs) for accommodating processing delay and/or resolving conflicts are also discussed. In addition, the performance of JET-based OBS protocols which use an offset time along with delayed reservation to achieve efficient utilization of both bandwidth and FDLs as well as to support priority-based routing is evaluated.", "authors": ["Chunming Qiao", "Myungsik Yoo"], "related_topics": ["197417287", "2781404978", "160724564"], "citation_count": "2975", "reference_count": "34", "references": ["2105818147", "2148275477", "2154323564", "2147092597", "2159048618", "2165385439", "2134502745", "2149008718", "2545473509", "2063657191"], "date": "1999"}, {"id": "2147194983", "title": "The Use of Twitter to Track Levels of Disease Activity and Public Concern in the U.S. during the Influenza A H1N1 Pandemic", "abstract": "Twitter is a free social networking and micro-blogging service that enables its millions of users to send and read each other's \u201ctweets,\u201d or short, 140-character messages. The service has more than 190 million registered users and processes about 55 million tweets per day. Useful information about news and geopolitical events lies embedded in the Twitter stream, which embodies, in the aggregate, Twitter users' perspectives and reactions to current events. By virtue of sheer volume, content embedded in the Twitter stream may be useful for tracking or even forecasting behavior if it can be extracted in an efficient manner. In this study, we examine the use of information embedded in the Twitter stream to (1) track rapidly-evolving public sentiment with respect to H1N1 or swine flu, and (2) track and measure actual disease activity. We also show that Twitter can be used as a measure of public interest or concern about health-related events. Our results show that estimates of influenza-like illness derived from Twitter chatter accurately track reported disease levels.", "authors": ["Alessio Signorini", "Alberto Maria Segre", "Philip M. Polgreen", ""], "related_topics": ["2776475305", "108827166", "2780378061"], "citation_count": "1431", "reference_count": "26", "references": ["2153635508", "1563088657", "2117239687", "2124499489", "2151932005", "2137226992", "2141701578", "1527532036", "1548404105", "2097045245"], "date": "2011"}, {"id": "2008164950", "title": "A generalized EM algorithm for 3-D Bayesian reconstruction from Poisson data using Gibbs priors", "abstract": "A generalized expectation-maximization (GEM) algorithm is developed for Bayesian reconstruction, based on locally correlated Markov random-field priors in the form of Gibbs functions and on the Poisson data model. For the M-step of the algorithm, a form of coordinate gradient ascent is derived. The algorithm reduces to the EM maximum-likelihood algorithm as the Markov random-field prior tends towards a uniform distribution. Three different Gibbs function priors are examined. Reconstructions of 3-D images obtained from the Poisson model of single-photon-emission computed tomography are presented. >", "authors": ["T. Hebert", "R. Leahy"], "related_topics": ["158424031", "182081679", "177769412"], "citation_count": "866", "reference_count": "15", "references": ["1997063559", "2049633694", "1554544485", "2033482494", "2053742104", "2114220616", "2044656938", "2049032689", "2077661028", "2140101900"], "date": "1989"}, {"id": "2066931954", "title": "Effects of signal\u2010to\u2010noise ratio on the accuracy and reproducibility of diffusion tensor imaging\u2013derived fractional anisotropy, mean diffusivity, and principal eigenvector measurements at 1.5T", "abstract": "Purpose To develop an experimental protocol to calculate the precision and accuracy of fractional anisotropy (FA), mean diffusivity (MD), and the orientation of the principal eigenvector (PEV) as a function of the signal to noise ratio (SNR) in vivo.", "authors": ["Jonathan A.D. Farrell", "Bennett A. Landman", "Craig K. Jones", "", "Seth A. Smith", "", "Jerry L. Prince", "", "Peter C.M. van Zijl", "", "Susumu Mori"], "related_topics": ["73836528", "89916169", "149550507"], "citation_count": "282", "reference_count": "40", "references": ["2052644075", "2145132952", "2063001897", "2142900310", "2139158372", "1964802316", "2110431535", "2170596158", "2036785860", "2157035009"], "date": "2007"}, {"id": "2118040894", "title": "Space-time codes for high data rate wireless communication: performance criterion and code construction", "abstract": "We consider the design of channel codes for improving the data rate and/or the reliability of communications over fading channels using multiple transmit antennas. Data is encoded by a channel code and the encoded data is split into n streams that are simultaneously transmitted using n transmit antennas. The received signal at each receive antenna is a linear superposition of the n transmitted signals perturbed by noise. We derive performance criteria for designing such codes under the assumption that the fading is slow and frequency nonselective. Performance is shown to be determined by matrices constructed from pairs of distinct code sequences. The minimum rank among these matrices quantifies the diversity gain, while the minimum determinant of these matrices quantifies the coding gain. The results are then extended to fast fading channels. The design criteria are used to design trellis codes for high data rate wireless communication. The encoding/decoding complexity of these codes is comparable to trellis codes employed in practice over Gaussian channels. The codes constructed here provide the best tradeoff between data rate, diversity advantage, and trellis complexity. Simulation results are provided for 4 and 8 PSK signal sets with data rates of 2 and 3 bits/symbol, demonstrating excellent performance that is within 2-3 dB of the outage capacity for these channels using only 64 state encoders.", "authors": ["V. Tarokh", "N. Seshadri", "A.R. Calderbank"], "related_topics": ["5546382", "157125643", "2400350"], "citation_count": "10086", "reference_count": "40", "references": ["2130509920", "1667950888", "2610857016", "2330078975", "2085099144", "1596939795", "2021573106", "2117507580", "1606480398", "2165205968"], "date": "1998"}, {"id": "2111797102", "title": "Localism Versus Globalism in Morphology and Phonology", "abstract": "In Localism versus Globalism in Morphology and Phonology, David Embick offers the first detailed examination of morphology and phonology from a phase-cyclic point of view (that is, one that takes into account recent developments in Distributed Morphology and the Minimalist program) and the only recent detailed treatment of allomorphy, a phenomenon that is central to understanding how the grammar of human language works. In addition to making new theoretical proposals about morphology and phonology in terms of a cyclic theory, Embick addresses a schism in the field between phonological theories such as Optimality Theory and other (mostly syntactic) theories such as those associated with the Minimalist program. He presents sustained empirical arguments that the Localist view of grammar associated with the Minimalist program (and Distributed Morphology in particular) is correct, and that the Globalism espoused by many forms of Optimality Theory is incorrect. In the \"derivational versus nonderivational\" debate in linguistic theory, Embick's arguments come down squarely on the derivational side. Determining how to make empirical comparisons between such large positions, and the different frameworks that embody them, is at the heart of the book. Embick argues that patterns of allomorphy implicate general questions about locality and specific questions about the manner in which (morpho)syntax relates to (morpho)phonology. Allomorphy thus provides a crucial test case for comparing Localist and Globalist approaches to grammar.", "authors": ["David Embick"], "related_topics": ["148934300", "2781082764", "153578388"], "citation_count": "381", "reference_count": "94", "references": ["1562911371", "1996672843", "352206829", "1551467849", "1565769722", "1575528222", "1543984587", "2142270908", "1559871997", "2112581312"], "date": "2010"}, {"id": "2010802462", "title": "Understanding supply chain management: Critical research and a theoretical framework", "abstract": "Increasing global cooperation, vertical disintegration and a focus on core activities have led to the notion that firms are links in a networked supply chain. This strategic viewpoint has created the challenge of coordinating effectively the entire supply chain, from upstream to downstream activities. While supply chains have existed ever since businesses have been organized to bring products and services to customers, the notion of their competitive advantage, and consequently supply chain management (SCM), is a relatively recent thinking in management literature. Although research interests in and the importance of SCM are growing, scholarly materials remain scattered and disjointed, and no research has been directed towards a systematic identification of the core initiatives and constructs involved in SCM. Thus, the purpose of this study is to develop a research framework that improves understanding of SCM and stimulates and facilitates researchers to undertake both theoretical and empirical investigat...", "authors": ["Injazz Chen", "Antony Paulraj"], "related_topics": ["192639820", "108713360", "44104985"], "citation_count": "968", "reference_count": "247", "references": ["2061977616", "3121398446", "1955934323", "1606925814", "2104925392", "2132081716", "1558046248", "122374401", "1998854584", "1535700698"], "date": "2003"}, {"id": "1647671624", "title": "Binary codes capable of correcting deletions, insertions, and reversals", "abstract": "", "authors": ["V. I. Levenshtein"], "related_topics": ["63435697", "41008148", "11413529"], "citation_count": "14806", "reference_count": "0", "references": ["1494198834", "2108991785", "2001496424", "1934458198", "2120111750", "2962717047", "2118371392", "2171104838", "2139747296", "2151164148"], "date": "1965"}, {"id": "2251939518", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank", "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.", "authors": ["Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Ng", "Christopher Potts"], "related_topics": ["206134035", "121375916", "186644900"], "citation_count": "5188", "reference_count": "42", "references": ["2146502635", "2097726431", "2117130368", "2132339004", "1423339008", "71795751", "1662133657", "1889268436", "2164019165", "2097606805"], "date": "2013"}, {"id": "1487563192", "title": "Digital Image Warping", "abstract": "From the Publisher: This book is intended to be a practical guide for eclectic scientists and engineers who find themselves in need of implementing warping algorithms and comprehending the underlying concepts.", "authors": ["George Wolberg"], "related_topics": ["157202957", "42781572", "121684516"], "citation_count": "2880", "reference_count": "0", "references": ["2137290314", "2157802523", "2103071307", "2097751916", "2159917172", "153034902", "2169218882", "1582101903", "2165290000", "2152501071"], "date": "1990"}, {"id": "1676820704", "title": "Solving multiclass learning problems via error-correcting output codes", "abstract": "Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k > 2 values (i.e., k \"classes\"). The definition is acquired by studying collections of training examples of the form (xi, f(xi)). Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that--like the other methods--the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems.", "authors": ["Thomas G. Dietterich", "Ghulum Bakiri"], "related_topics": ["123860398", "28006648", "58973888"], "citation_count": "3580", "reference_count": "23", "references": ["2154642048", "1594031697", "2147800946", "2173629880", "2019363670", "2093717447", "3036751298", "2176028050", "1667614912", "1980501707"], "date": "1994"}, {"id": "1971918847", "title": "Long-haul transmission of16\u00d752.5 Gbits/s polarization-division- multiplexed OFDM enabled by MIMO processing (Invited)", "abstract": "Focus Issue on Orthogonal-Frequency-Division Multiplexed Communications Systems and Networks We discuss the realization and performance of polarization-division-multiplexed orthogonal frequency division multiplexing (PDM-OFDM) for long-haul transmission systems. Polarization demultiplexing of the PDM signal at the receiver is realized by employing a multiple-input multiple-output (MIMO) detector. Using a recirculating loop a long-haul transmission experiment is reported of 52.5 Gbits/s PDM-OFDM (40 Gbits/s after coding) over 4160 km of standard single-mode fiber (SSMF). In this transmission experiment, 16 wavelength-division-multiplexed (WDM) channels are transmitted at 50 GHz channel spacing, and we show that MIMO processing in the receiver enables both polarization demultiplexing and a large PMD tolerance.", "authors": ["Sander L. Jansen", "Itsuro Morita", "Tim C. W. Schenk", "Hideaki Tanaka"], "related_topics": ["2780894989", "207987634", "160724564"], "citation_count": "270", "reference_count": "25", "references": ["2110774823", "2541204438", "1980502833", "2166873702", "2140650302", "2131399112", "2096645758", "2010162055", "2021183293", "1921119268"], "date": "2008"}, {"id": "1850405760", "title": "Parallel Computer Architecture: A Hardware/Software Approach", "abstract": "The most exciting development in parallel computer architecture is the convergence of traditionally disparate approaches on a common machine structure. This book explains the forces behind this convergence of shared-memory, message-passing, data parallel, and data-driven computing architectures. It then examines the design issues that are critical to all parallel architecture across the full range of modern design, covering data access, communication performance, coordination of cooperative work, and correct implementation of useful semantics. It not only describes the hardware and software techniques for addressing each of these issues but also explores how these techniques interact in the same system. Examining architecture from an application-driven perspective, it provides comprehensive discussions of parallel programming for high performance and of workload-driven evaluation, based on understanding hardware-software interactions. * synthesizes a decade of research and development for practicing engineers, graduate students, and researchers in parallel computer architecture, system software, and applications development * presents in-depth application case studies from computer graphics, computational science and engineering, and data mining to demonstrate sound quantitative evaluation of design trade-offs * describes the process of programming for performance, including both the architecture-independent and architecture-dependent aspects, with examples and case-studies * illustrates bus-based and network-based parallel systems with case studies of more than a dozen important commercial designs Table of Contents 1 Introduction 2 Parallel Programs 3 Programming for Performance 4 Workload-Driven Evaluation 5 Shared Memory Multiprocessors 6 Snoop-based Multiprocessor Design 7 Scalable Multiprocessors 8 Directory-based Cache Coherence 9 Hardware-Software Tradeoffs 10 Interconnection Network Design 11 Latency Tolerance 12 Future Directions APPENDIX A Parallel Benchmark Suites", "authors": ["David E. Culler", "Anoop Gupta", "Jaswinder Pal Singh"], "related_topics": ["55356503", "137364921", "37139622"], "citation_count": "2811", "reference_count": "378", "references": ["1981745143", "3144368627", "1589918049", "2145021036", "2114728910", "2155066383", "2045271686", "1538592187", "2140332639", "2120230074"], "date": "1998"}, {"id": "2120085609", "title": "Multilevel diversity coding with distortion", "abstract": "In a Diversity Coding System, an information source is encoded by a number of encoders. There are a number of decoders, each of which can access a certain subset of the encoders. We study a diversity coding problem in which there are two levels of decoders. The reconstructions of the source by decoders within the same level are identical, and are subject to the same distortion criterion. Our results imply a principle of superposition when the source consists of two independent data streams. Practical codes achieving zero error can easily be constructed for this special case. A class of open problems on this topic is also suggested. >", "authors": ["R.W. Yeung"], "related_topics": ["2777209859", "52622258", "115225779"], "citation_count": "164", "reference_count": "24", "references": ["1549664537", "2141420453", "2058972589", "1593683169", "2142901448", "2099213070", "2151252184", "1995875735", "2123095296", "2164647192"], "date": "1995"}, {"id": "1590495275", "title": "Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment", "abstract": "Twitter is a microblogging website where users read and write millions of short messages on a variety of topics every day. This study uses the context of the German federal election to investigate whether Twitter is used as a forum for political deliberation and whether online messages on Twitter validly mirror offline political sentiment. Using LIWC text analysis software, we conducted a content-analysis of over 100,000 messages containing a reference to either a political party or a politician. Our results show that Twitter is indeed used extensively for political deliberation. We find that the mere number of messages mentioning a party reflects the election result. Moreover, joint mentions of two parties are in line with real world political ties and coalitions. An analysis of the tweets\u2019 political sentiment demonstrates close correspondence to the parties' and politicians\u2019 political positions indicating that the content of Twitter messages plausibly reflects the offline political landscape. We discuss the use of microblogging message content as a valid indicator of political sentiment and derive suggestions for further research.", "authors": ["Andranik Tumasjan", "Timm Oliver Sprenger", "Philipp G. Sandner", "Isabell M. Welpe"], "related_topics": ["66402592", "143275388", "2776946740"], "citation_count": "3377", "reference_count": "23", "references": ["2046804949", "2140910804", "2139043937", "3122139608", "2140173168", "2152284345", "2281492572", "2136407110", "2130059493", "1994512679"], "date": "2010"}, {"id": "2109206786", "title": "Reconstructing the Past: Some Cognitive Consequences of Person Perception", "abstract": "An experiment was conducted to investigate systematic retrospective distortions of past events precipitated by one's current beliefs about another individual. Participants read an extensive narrative about the life of a woman named Betty K. Either immediately after reading the case history or 1 week later, some participants learned that she was currently living a lesbian life-style; others learned that she was currently living a heterosexual life-style; still others learned nothing about her life-style. The impact of this new information on recognition memory for factual events in Betty K.'s life was assessed 1 week after reading the case history. Participants selectively affirmed events that supported and bolstered their current interpretations of Betty K. Performance was the same whether participants learned this information immediately after reading the case history or 1 week later. Additional evidence suggests that these results are best characterized as the product of an interaction between stereotyped beliefs about sexuality and genuine memory for factual events. Implications of these findings for the nature, function, and consequences of social knowledge are discussed.", "authors": ["Mark Snyder", "Seymour W. Uranowitz"], "related_topics": ["129484327", "554936623", "199033989"], "citation_count": "673", "reference_count": "30", "references": ["2089016366", "2045178568", "1986936900", "2126368947", "2139121205", "2330690118", "2066057850", "2103430676", "2037417965", "2018507693"], "date": "1978"}, {"id": "1986701081", "title": "Aesthetics and apparent usability: empirically assessing cultural and methodological issues", "abstract": "", "authors": ["Noam Tractinsky"], "related_topics": ["100302975", "170130773", "107457646"], "citation_count": "821", "reference_count": "28", "references": ["2342091124", "2004603793", "2752491485", "2131664240", "2029709911", "93247917", "1499705153", "2024509488", "2178540965", "1999020641"], "date": "1997"}, {"id": "2074120956", "title": "Antisymmetric tensor gauge theories and non-linear \u03c3-models", "abstract": "Antisymmetric tensor fields B\u03bc\u03bd subject to the gauge transformation \u03b4B\u03bc\u03bd = \u03d6\u03bc\u03be\u03bd \u2212 \u03d6\u03bd\u03be\u03bc can describe spinless particles. We investigate the properties of field theories with a \u201cnon-abelian generalization\u201d of this invariance. One class of such theories is equivalent to non-linear principal chiral \u03c3-models, another to massive Yang-Mills theories. A supersymmetric analogue in 2 + 2 superspace is constructed and leads to the supersymmetric \u03c3-model defined on a general riemannian manifold.", "authors": ["Daniel Z. Freedman", "P.K. Townsend"], "related_topics": ["67503058", "65266758", "65211518"], "citation_count": "487", "reference_count": "15", "references": ["2060667737", "1514487823", "2197062852", "2052848944", "1972342483", "2123959047", "2026039129", "2082118678", "1981338116", "2087194769"], "date": "1981"}, {"id": "2124731682", "title": "Image compression via joint statistical characterization in the wavelet domain", "abstract": "We develop a probability model for natural images, based on empirical observation of their statistics in the wavelet transform domain. Pairs of wavelet coefficients, corresponding to basis functions at adjacent spatial locations, orientations, and scales, are found to be non-Gaussian in both their marginal and joint statistical properties. Specifically, their marginals are heavy-tailed, and although they are typically decorrelated, their magnitudes are highly correlated. We propose a Markov model that explains these dependencies using a linear predictor for magnitude coupled with both multiplicative and additive uncertainties, and show that it accounts for the statistics of a wide variety of images including photographic images, graphical images, and medical images. In order to directly demonstrate the power of the model, we construct an image coder called EPWIC (embedded predictive wavelet image coder), in which subband coefficients are encoded one bitplane at a time using a nonadaptive arithmetic encoder that utilizes conditional probabilities calculated from the model. Bitplanes are ordered using a greedy algorithm that considers the MSE reduction per encoded bit. The decoder uses the statistical model to predict coefficient values based on the bits it has received. Despite the simplicity of the model, the rate-distortion performance of the coder is roughly comparable to the best image coders in the literature.", "authors": ["R.W. Buccigrossi", "E.P. Simoncelli"], "related_topics": ["196216189", "47432892", "114289077"], "citation_count": "785", "reference_count": "39", "references": ["2132984323", "2151693816", "2053691921", "2408227189", "2148593155", "2156447271", "2103504761", "1490632837", "2107790757", "2180838288"], "date": "1999"}, {"id": "1604792668", "title": "SOCIAL EVALUATION OF THE USER INTERFACE: WHO DOES THE WORK AND WHO GETS THE BENEFIT?", "abstract": "When an application requires the involvement of several users, evaluating its functionality and interface becomes more complex: that which benefits one user might not benefit another. An application program written to support cooperative work may present a systematic imbalance in the efforts required of and benefits obtained by different categories of user. Such imbalances may affect the acceptance and use of a product in unforeseen ways. The collective benefit to the group may be difficult to measure, and even if established, may be difficult to communicate effectively to those who do not benefit directly. In weighing a potential development project, decision-makers may be inordinately influenced by the attractiveness of the system to managers such as themselves, and not perceive that the requisite cooperation of other users of the application will not be forthcoming when those users do not benefit equally. In the absence of careful analysis, decisions to build unworkable systems are not only possible, but likely. These points are elaborated through the examination of several multi-user application areas in the context of evolving technology trends, organizational practices, and social tendencies.", "authors": ["Jonathan Grudin"], "related_topics": ["89505385", "2780049985", "25621077"], "citation_count": "84", "reference_count": "10", "references": ["2068578624", "1972753943", "1978347212", "2121234354", "2050248089", "2035509502", "2094345647", "2167605437", "2056627764", "1491859783"], "date": "1986"}, {"id": "2111547563", "title": "Machine learning applications in cancer prognosis and prediction.", "abstract": "Cancer has been characterized as a heterogeneous disease consisting of many different subtypes. The early diagnosis and prognosis of a cancer type have become a necessity in cancer research, as it can facilitate the subsequent clinical management of patients. The importance of classifying cancer patients into high or low risk groups has led many research teams, from the biomedical and the bioinformatics field, to study the application of machine learning (ML) methods. Therefore, these techniques have been utilized as an aim to model the progression and treatment of cancerous conditions. In addition, the ability of ML tools to detect key features from complex datasets reveals their importance. A variety of these techniques, including Artificial Neural Networks (ANNs), Bayesian Networks (BNs), Support Vector Machines (SVMs) and Decision Trees (DTs) have been widely applied in cancer research for the development of predictive models, resulting in effective and accurate decision making. Even though it is evident that the use of ML methods can improve our understanding of cancer progression, an appropriate level of validation is needed in order for these methods to be considered in the everyday clinical practice. In this work, we present a review of recent ML approaches employed in the modeling of cancer progression. The predictive models discussed here are based on various supervised ML techniques as well as on different input features and data samples. Given the growing trend on the application of ML methods in cancer research, we present here the most recent publications that employ these techniques as an aim to model cancer risk or patient outcomes.", "authors": ["Konstantina Kourou", "Themis P. Exarchos", "Konstantinos P. Exarchos", "Michalis V. Karamouzis", "Dimitrios I. Fotiadis"], "related_topics": ["84525736", "121608353", "50644808"], "citation_count": "1521", "reference_count": "69", "references": ["2117692326", "1663973292", "1570448133", "1565377632", "2105882193", "2017337590", "2132619562", "2157239837", "1983024255", "2154362705"], "date": "2014"}, {"id": "2153653739", "title": "Statistical phrase-based translation", "abstract": "We propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several, previously proposed phrase-based translation models. Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models out-perform word-based models. Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations. Surprisingly, learning phrases longer than three words and learning phrases from high-accuracy word-level alignment models does not have a strong impact on performance. Learning only syntactically motivated phrases degrades the performance of our systems.", "authors": ["Philipp Koehn", "Franz Josef Och", "Daniel Marcu"], "related_topics": ["153962237", "2776224158", "88880766"], "citation_count": "3371", "reference_count": "15", "references": ["2101105183", "2006969979", "1508165687", "1973923101", "1986543644", "2116316001", "1517947178", "2161792612", "1549285799", "2158388102"], "date": "2003"}, {"id": "2118396891", "title": "DSC: scheduling parallel tasks on an unbounded number of processors", "abstract": "We present a low-complexity heuristic, named the dominant sequence clustering algorithm (DSC), for scheduling parallel tasks on an unbounded number of completely connected processors. The performance of DSC is on average, comparable to, or even better than, other higher-complexity algorithms. We assume no task duplication and nonzero communication overhead between processors. Finding the optimum solution for arbitrary directed acyclic task graphs (DAG's) is NP-complete. DSC finds optimal schedules for special classes of DAG's, such as fork, join, coarse-grain trees, and some fine-grain trees. It guarantees a performance within a factor of 2 of the optimum for general coarse-grain DAG's. We compare DSC with three higher-complexity general scheduling algorithms: the ETF by J.J. Hwang, Y.C. Chow, F.D. Anger, and C.Y. Lee (1989); V. Sarkar's (1989) clustering algorithm; and the MD by M.Y. Wu and D. Gajski (1990). We also give a sample of important practical applications where DSC has been found useful. >", "authors": ["Tao Yang", "A. Gerasoulis"], "related_topics": ["74197172", "120373497", "73555534"], "citation_count": "946", "reference_count": "20", "references": ["2151038512", "2065689629", "2125412556", "1989582918", "2043331236", "2110417760", "1549134103", "2031415642", "2084606150", "2098765821"], "date": "1994"}, {"id": "2010029425", "title": "Convergence of stochastic processes", "abstract": "I Functional on Stochastic Processes.- 1. Stochastic Processes as Random Functions.- Notes.- Problems.- II Uniform Convergence of Empirical Measures.- 1. Uniformity and Consistency.- 2. Direct Approximation.- 3. The Combinatorial Method.- 4. Classes of Sets with Polynomial Discrimination.- 5. Classes of Functions.- 6. Rates of Convergence.- Notes.- Problems.- III Convergence in Distribution in Euclidean Spaces.- 1. The Definition.- 2. The Continuous Mapping Theorem.- 3. Expectations of Smooth Functions.- 4. The Central Limit Theorem.- 5. Characteristic Functions.- 6. Quantile Transformations and Almost Sure Representations.- Notes.- Problems.- IV Convergence in Distribution in Metric Spaces.- 1. Measurability.- 2. The Continuous Mapping Theorem.- 3. Representation by Almost Surely Convergent Sequences.- 4. Coupling.- 5. Weakly Convergent Subsequences.- Notes.- Problems.- V The Uniform Metric on Spaces of Cadlag Functions.- 1. Approximation of Stochastic Processes.- 2. Empirical Processes.- 3. Existence of Brownian Bridge and Brownian Motion.- 4. Processes with Independent Increments.- 5. Infinite Time Scales.- 6. Functional of Brownian Motion and Brownian Bridge.- Notes.- Problems.- VI The Skorohod Metric on D(0, ?).- 1. Properties of the Metric.- 2. Convergence in Distribution.- Notes.- Problems.- VII Central Limit Theorems.- 1. Stochastic Equicontinuity.- 2. Chaining.- 3. Gaussian Processes.- 4. Random Covering Numbers.- 5. Empirical Central Limit Theorems.- 6. Restricted Chaining.- Notes.- Problems.- VIII Martingales.- 1. A Central Limit Theorem for Martingale-Difference Arrays.- 2. Continuous Time Martingales.- 3. Estimation from Censored Data.- Notes.- Problems.- Appendix A Stochastic-Order Symbols.- Appendix B Exponential Inequalities.- Notes.- Problems.- Appendix C Measurability.- Notes.- Problems.- References.- Author Index.", "authors": ["David Pollard"], "related_topics": ["95763700", "101775428", "157709441"], "citation_count": "3891", "reference_count": "0", "references": ["2168405694", "1944672", "1491711721", "2097580026", "2165758113", "2017170340", "2076118331", "2014165366", "2099579348", "2047278710"], "date": "1983"}, {"id": "1524408959", "title": "Blobworld: A System for Region-Based Image Indexing and Retrieval", "abstract": "Blobworld is a system for image retrieval based on finding coherent image regions which roughly correspond to objects. Each image is automatically segmented into regions (\"blobs\") with associated color and texture descriptors. Queryingi s based on the attributes of one or two regions of interest, rather than a description of the entire image. In order to make large-scale retrieval feasible, we index the blob descriptions usinga tree. Because indexing in the high-dimensional feature space is computationally prohibitive, we use a lower-rank approximation to the high-dimensional distance. Experiments show encouraging results for both queryinga nd indexing.", "authors": ["Chad Carson", "Megan Thomas", "Serge Belongie", "Joseph M. Hellerstein", "Jitendra Malik"], "related_topics": ["63099799", "189391414", "199579030"], "citation_count": "1248", "reference_count": "17", "references": ["2049633694", "2160066518", "2151135734", "2008297189", "2238624099", "1533169541", "2134814621", "2118783153", "2068272887", "2102475035"], "date": "1999"}, {"id": "2107118797", "title": "Object position detector with edge motion feature and gesture recognition", "abstract": "A method of generating a signal comprising providing a capacitive touch sensor pad including a matrix of X and Y conductors, developing capacitance profiles in one of an X direction and a Y direction from the matrix of X and Y conductors, determining an occurrence of a single gesture through an examination of the capacitance profiles, the single gesture including an application of at least two objects on the capacitive touch sensor pad, and generating a signal indicating the occurrence of the single gesture.", "authors": ["David W. Gillespie", "Timothy P. Allen", "Ralph C. Wolf", "Shawn P. Day"], "related_topics": ["159437735", "206755178", "113841659"], "citation_count": "2646", "reference_count": "172", "references": ["2103081962", "2110466690", "2108089445", "1937117163", "2872957943", "2875516510", "2048701870", "2611215833", "1904843846", "1886657390"], "date": "1995"}, {"id": "1565863475", "title": "Learning Subjective Adjectives from Corpora", "abstract": "Subjectivity tagging is distinguishing sentences used to present opinions and evaluations from sentences used to objectively present factual information. There are numerous applications for which subjectivity tagging is relevant, including information extraction and information retrieval. This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation. These features are then further refined with the addition of lexical semantic features of adjectives, specifically polarity and gradability (Hatzivassiloglou & McKeown 1997), which can be automatically learned from corpora. In 10-fold cross validation experiments, features based on both similarity clusters and the lexical semantic features are shown to have higher precision than features based on each alone.", "authors": ["Janyce Wiebe"], "related_topics": ["195807954", "2777743986", "73555534"], "citation_count": "792", "reference_count": "19", "references": ["2138621811", "1632114991", "2199803028", "2166776180", "1998442272", "3151392175", "2150098611", "2120084270", "2110529160", "2119610041"], "date": "2000"}, {"id": "1988520084", "title": "Statistical Decision Theory and Bayesian Analysis", "abstract": "1. Basic concepts 2. Utility and loss 3. Prior information and subjective probability 4. Bayesian analysis 5. Minimax analysis 6. Invariance 7. Preposterior and sequential analysis 8. Complete and essentially complete classes Appendices.", "authors": ["James O Berger"], "related_topics": ["2778963538", "160234255", "28901747"], "citation_count": "11345", "reference_count": "0", "references": ["1479807131", "1648445109", "46659105", "2030536784", "2110575115", "2136518234", "2149760002", "2008047653", "2004014148", "1608826770"], "date": "1993"}, {"id": "2115218409", "title": "PassPoints: design and longitudinal evaluation of a graphical password system", "abstract": "Computer security depends largely on passwords to authenticate human users. However, users have difficulty remembering passwords over time if they choose a secure password, i.e. a password that is long and random. Therefore, they tend to choose short and insecure passwords. Graphical passwords, which consist of clicking on images rather than typing alphanumeric strings, may help to overcome the problem of creating secure and memorable passwords. In this paper we describe PassPoints, a new and more secure graphical password system. We report an empirical study comparing the use of PassPoints to alphanumeric passwords. Participants created and practiced either an alphanumeric or graphical password. The participants subsequently carried out three longitudinal trials to input their password over the course of 6 weeks. The results show that the graphical password users created a valid password with fewer difficulties than the alphanumeric users. However, the graphical users took longer and made more invalid password inputs than the alphanumeric users while practicing their passwords. In the longitudinal trials the two groups performed similarly on memory of their password, but the graphical group took more time to input a password.", "authors": ["Susan Wiedenbeck", "Jim Waters", "Jean-Camille Birget", "Alex Brodskiy", "Nasir Memon"], "related_topics": ["23875713", "98705547", "108342627"], "citation_count": "999", "reference_count": "39", "references": ["2179427518", "1528027857", "2037202491", "1921097329", "1485033854", "1503108337", "2164789387", "1582830784", "128619364", "2169200398"], "date": "2005"}, {"id": "2169693117", "title": "Capacity scaling in MIMO wireless systems under correlated fading", "abstract": "Previous studies have shown that single-user systems employing n-element antenna arrays at both the transmitter and the receiver can achieve a capacity proportional to n, assuming independent Rayleigh fading between antenna pairs. We explore the capacity of dual-antenna-array systems under correlated fading via theoretical analysis and ray-tracing simulations. We derive and compare expressions for the asymptotic growth rate of capacity with n antennas for both independent and correlated fading cases; the latter is derived under some assumptions about the scaling of the fading correlation structure. In both cases, the theoretic capacity growth is linear in n but the growth rate is 10-20% smaller in the presence of correlated fading. We analyze our assumption of separable transmit/receive correlations via simulations based on a ray-tracing propagation model. Results show that empirical capacities converge to the limit capacity predicted from our asymptotic theory even at moderate n = 16. We present results for both the cases when the transmitter does and does not know the channel realization.", "authors": ["Chen-Nee Chuah", "D.N.C. Tse", "J.M. Kahn", "R.A. Valenzuela"], "related_topics": ["161126049", "81978471", "148063708"], "citation_count": "1194", "reference_count": "23", "references": ["2130509920", "2099111195", "1667950888", "2006309149", "2132818688", "2170738062", "2107689535", "1596939795", "2136979582", "2096927504"], "date": "2002"}, {"id": "2150997454", "title": "Discrimination Aware Decision Tree Learning", "abstract": "Recently, the following discrimination aware classification problem was introduced: given a labeled dataset and an attribute B, find a classifier with high predictive accuracy that at the same time does not discriminate on the basis of the given attribute B. This problem is motivated by the fact that often available historic data is biased due to discrimination, e.g., when B denotes ethnicity. Using the standard learners on this data may lead to wrongfully biased classifiers, even if the attribute B is removed from training data. Existing solutions for this problem consist in \u201ccleaning away\u201d the discrimination from the dataset before a classifier is learned. In this paper we study an alternative approach in which the non-discrimination constraint is pushed deeply into a decision tree learner by changing its splitting criterion and pruning strategy. Experimental evaluation shows that the proposed approach advances the state-of-the-art in the sense that the learned decision trees have a lower discrimination than models provided by previous methods, with little loss in accuracy.", "authors": ["Faisal Kamiran", "Toon Calders", "Mykola Pechenizkiy"], "related_topics": ["5481197", "84525736", "110083411"], "citation_count": "253", "reference_count": "14", "references": ["3120740533", "167016754", "2097246321", "2026019770", "2137560895", "2116666691", "2486715098", "2157928966", "1593806347", "2145234462"], "date": "2010"}, {"id": "1489181569", "title": "A program for aligning sentences in bilingual corpora", "abstract": "Researchers in both machine translation (e.g., Brown et al. 1990) and bilingual lexicography (e.g., Klavans and Tzoukermann 1990) have recently become interested in studying bilingual corpora, bodies of text such as the Canadian Hansards (parliamentary proceedings), which are available in multiple languages (such as French and English). One useful step is to align the sentences, that is, to identify correspondences between sentences in one language and sentences in the other language.This paper will describe a method and a program (align) for aligning sentences based on a simple statistical model of character lengths. The program uses the fact that longer sentences in one language tend to be translated into longer sentences in the other language, and that shorter sentences tend to be translated into shorter sentences. A probabilistic score is assigned to each proposed correspondence of sentences, based on the scaled difference of lengths of the two sentences (in characters) and the variance of this difference. This probabilistic score is used in a dynamic programming framework to find the maximum likelihood alignment of sentences.It is remarkable that such a simple approach works as well as it does. An evaluation was performed based on a trilingual corpus of economic reports issued by the Union Bank of Switzerland (UBS) in English, French, and German. The method correctly aligned all but 4% of the sentences. Moreover, it is possible to extract a large subcorpus that has a much smaller error rate. By selecting the best-scoring 80% of the alignments, the error rate is reduced from 4% to 0.7%. There were more errors on the English-French subcorpus than on the English-German subcorpus, showing that error rates will depend on the corpus considered; however, both were small enough to hope that the method will be useful for many language pairs.To further research on bilingual corpora, a much larger sample of Canadian Hansards (approximately 90 million words, half in English and and half in French) has been aligned with the align program and will be available through the Data Collection Initiative of the Association for Computational Linguistics (ACL/DCI). In addition, in order to facilitate replication of the align program, an appendix is provided with detailed c-code of the more difficult core of the align program.", "authors": ["William A. Gale", "Kenneth W. Church"], "related_topics": ["2777530160", "203005215", "155092808"], "citation_count": "1962", "reference_count": "11", "references": ["1973948212", "2120062331", "2099247782", "2097333193", "1501400124", "2801179766", "2117652747", "2048390999", "2028770325", "78534123"], "date": "1993"}, {"id": "2132663727", "title": "Tracking deformable objects in the plane using an active contour model", "abstract": "The problems of segmenting a noisy intensity image and tracking a nonrigid object in the plane are discussed. In evaluating these problems, a technique based on an active contour model commonly called a snake is examined. The technique is applied to cell locomotion and tracking studies. The snake permits both the segmentation and tracking problems to be simultaneously solved in constrained cases. A detailed analysis of the snake model, emphasizing its limitations and shortcomings, is presented, and improvements to the original description of the model are proposed. Problems of convergence of the optimization scheme are considered. In particular, an improved terminating criterion for the optimization scheme that is based on topographic features of the graph of the intensity image is proposed. Hierarchical filtering methods, as well as a continuation method based on a discrete sale-space representation, are discussed. Results for both segmentation and tracking are presented. Possible failures of the method are discussed. >", "authors": ["F. Leymarie", "M.D. Levine"], "related_topics": ["112353826", "124504099", "89600930"], "citation_count": "925", "reference_count": "43", "references": ["2104095591", "2086921140", "2031605731", "2913192828", "2978983090", "2131910503", "2132396702", "3121554115", "2135622428", "2582614493"], "date": "1993"}, {"id": "2152828142", "title": "Non-uniform random variate generation", "abstract": "", "authors": ["Luc Devroye"], "related_topics": ["141547133", "167680658", "130402806"], "citation_count": "5259", "reference_count": "46", "references": ["1997063559", "2037139490", "2138309709", "1564609383", "2056760934", "1515878031", "1992371956", "2045345437", "137653784", "1964919148"], "date": "1986"}, {"id": "1782590233", "title": "Labeled Faces in the Wild: A Database forStudying Face Recognition in Unconstrained Environments", "abstract": "Most face databases have been created under controlled conditions to facilitate the study of specific parameters on the face recognition problem. These parameters include such variables as position, pose, lighting, background, camera quality, and gender. While there are many applications for face recognition technology in which one can control the parameters of image acquisition, there are also many applications in which the practitioner has little or no control over such parameters. This database, Labeled Faces in the Wild, is provided as an aid in studying the latter, unconstrained, recognition problem. The database contains labeled face photographs spanning the range of conditions typically encountered in everyday life. The database exhibits \u201cnatural\u201d variability in factors such as pose, lighting, race, accessories, occlusions, and background. In addition to describing the details of the database, we provide specific experimental paradigms for which the database is suitable. This is done in an effort to make research performed with the database as consistent and comparable as possible. We provide baseline results, including results of a state of the art face recognition system combined with a face alignment system. To facilitate experimentation on the database, we provide several parallel databases, including an aligned version.", "authors": ["Gary B. Huang", "Marwan Mattar", "Tamara Berg", "Eric Learned-Miller"], "related_topics": ["88799230", "4641261", "31510193"], "citation_count": "5215", "reference_count": "40", "references": ["3097096317", "2121647436", "1999478155", "2033419168", "2123921160", "2137659841", "2098693229", "2125310925", "2994340921", "2006793117"], "date": "2008"}, {"id": "2155959613", "title": "SoCo: a social network aided context-aware recommender system", "abstract": "Contexts and social network information have been proven to be valuable information for building accurate recommender system. However, to the best of our knowledge, no existing works systematically combine diverse types of such information to further improve recommendation quality. In this paper, we propose SoCo, a novel context-aware recommender system incorporating elaborately processed social network information. We handle contextual information by applying random decision trees to partition the original user-item-rating matrix such that the ratings with similar contexts are grouped. Matrix factorization is then employed to predict missing preference of a user for an item using the partitioned matrix. In order to incorporate social network information, we introduce an additional social regularization term to the matrix factorization objective function to infer a user's preference for an item by learning opinions from his/her friends who are expected to share similar tastes. A context-aware version of Pearson Correlation Coefficient is proposed to measure user similarity. Real datasets based experiments show that SoCo improves the performance (in terms of root mean square error) of the state-of-the-art context-aware recommender system and social recommendation model by 15.7% and 12.2% respectively.", "authors": ["Xin Liu", "Karl Aberer"], "related_topics": ["557471498", "86256295", "42355184"], "citation_count": "213", "reference_count": "32", "references": ["2171960770", "2054141820", "2042281163", "2110325612", "2100235918", "1690919088", "1560147776", "2144487656", "2112430581", "2119825970"], "date": "2013"}, {"id": "2169415915", "title": "Constructing free-energy approximations and generalized belief propagation algorithms", "abstract": "Important inference problems in statistical physics, computer vision, error-correcting coding theory, and artificial intelligence can all be reformulated as the computation of marginal probabilities on factor graphs. The belief propagation (BP) algorithm is an efficient way to solve these problems that is exact when the factor graph is a tree, but only approximate when the factor graph has cycles. We show that BP fixed points correspond to the stationary points of the Bethe approximation of the free energy for a factor graph. We explain how to obtain region-based free energy approximations that improve the Bethe approximation, and corresponding generalized belief propagation (GBP) algorithms. We emphasize the conditions a free energy approximation must satisfy in order to be a \"valid\" or \"maxent-normal\" approximation. We describe the relationship between four different methods that can be used to generate valid approximations: the \"Bethe method\", the \"junction graph method\", the \"cluster variation method\", and the \"region graph method\". Finally, we explain how to tell whether a region-based approximation, and its corresponding GBP algorithm, is likely to be accurate, and describe empirical results showing that GBP can significantly outperform BP.", "authors": ["J.S. Yedidia", "W.T. Freeman", "Y. Weiss"], "related_topics": ["152948882", "148764684", "159246509"], "citation_count": "1756", "reference_count": "56", "references": ["2099111195", "2125838338", "2798766386", "2137813581", "2159080219", "2121606987", "2987657883", "1516111018", "1530042113", "1746680969"], "date": "2005"}, {"id": "2100967449", "title": "Developing a framework for responsible innovation", "abstract": "The governance of emerging science and innovation is a major challenge for contemporary democracies. In this paper we present a framework for understanding and supporting efforts aimed at \u2018responsible innovation\u2019. The framework was developed in part through work with one of the first major research projects in the controversial area of geoengineering, funded by the UK Research Councils. We describe this case study, and how this became a location to articulate and explore four integrated dimensions of responsible innovation: anticipation, reflexivity, inclusion and responsiveness. Although the framework for responsible innovation was designed for use by the UK Research Councils and the scientific communities they support, we argue that it has more general application and relevance.", "authors": ["Jack Stilgoe", "Richard J. Owen", "Phil Macnaghten"], "related_topics": ["2777720028", "207267971", "13200473"], "citation_count": "1770", "reference_count": "171", "references": ["1551905080", "2062199894", "1497177130", "1510316655", "1973459906", "2129261459", "2042349004", "2041145756", "1605878143", "2144768886"], "date": "2013"}, {"id": "2994340921", "title": "The AR face databasae", "abstract": "", "authors": ["A. M. Martinez"], "related_topics": ["2779304628", "41008148", "31972630"], "citation_count": "4961", "reference_count": "0", "references": ["2129812935", "1782590233", "2121601095", "2102544846", "2132467081", "2157364932", "2134262590", "1963932623", "3102431071", "2912990735"], "date": "1997"}, {"id": "2134170969", "title": "Self-projection and the brain", "abstract": "When thinking about the future or the upcoming actions of another person, we mentally project ourselves into that alternative situation. Accumulating data suggest that envisioning the future (prospection), remembering the past, conceiving the viewpoint of others (theory of mind) and possibly some forms of navigation reflect the workings of the same core brain network. These abilities emerge at a similar age and share a common functional anatomy that includes frontal and medial temporal systems that are traditionally associated with planning, episodic memory and default (passive) cognitive states. We speculate that these abilities, most often studied as distinct, rely on a common set of processes by which past experiences are used adaptively to imagine perspectives and events beyond those that emerge from the immediate environment.", "authors": ["Randy L. Buckner", "Daniel C. Carroll"], "related_topics": ["179833586", "2779560602", "88576662"], "citation_count": "2897", "reference_count": "86", "references": ["2162010696", "2129900561", "2099915326", "2117207767", "1558731210", "1984214648", "2136162329", "1574216169", "2066667961", "2110247644"], "date": "2007"}, {"id": "1994232555", "title": "ESTIMATORS OF A LOCATION PARAMETER IN THE ABSOLUTELY CONTINUOUS CASE", "abstract": "In the last decade there have been a number of papers dealing with the admissibility of translation invariant estimators of a location parameter. Blyth [2] treated sequential procedures in the case of normally or rectangularly distributed random variables. If $d$ is estimated and $\\theta$ is the actual parameter value, for Blyth, op. cit., loss was measured by $W(|d - \\theta|)$ where $W(\\cdot)$ was a nondecreasing function on $\\lbrack 0, \\infty)$. In the same year Blackwell [1] treated the fixed sample size problem in the case of discrete random variables taking only a finite number of values. For Blackwell, op. cit., loss was measured by $W(d - \\theta)$ where $W(\\cdot)$ was assumed continuous and bounded from below but otherwise arbitrary. Blackwell showed that if the discrete random variables (which could be vector valued) took values only on the integer lattice points and if there was a unique minimax translation invariant estimator then it was admissible. Later papers by Karlin [7] and Stein [11] discuss the admissibility of Pitman's estimator for square error. In reviewing these results we discovered that if the loss satisfied \\begin{equation*}\\tag{0.1}0 \\leqq x < y \\text{implies} W(x) < W(y),\\quad y < x \\leqq 0 \\text{implies} W(x) < W(y),\\end{equation*} and if there were several minimax translation invariant estimators then no translation invariant estimator could be admissible. This and a related result constitutes Section 4. It was logical to ask the converse question, does uniqueness imply admissibility? In the case of square error Pitman's estimator (except for changes on sets of measure zero) is necessarily unique since the loss function is strictly convex. In the case of normally distributed random variables and symmetrical loss functions as considered by Blyth, op. cit., the sample mean is the uniquely determined minimax translation invariant estimator. In this paper we have restricted the discussion to random variables which have density functions relative to Lebesgue measure. Since it proved possible to deal with the question of admissibility for a larger class of estimators than the translation invariant estimators, we define generalized Bayes estimators as the solution of a minimization problem. Section 2 deals with the question of the existence of measurable solutions to the minimization problem. Sections 5 and 6 deal with the question, does uniqueness imply admissibility? Section 3 deals with the question of whether generalized Bayes estimators are strongly consistent and shows that under mild restrictions this is the case. Section 8 is a generalization of the results of Katz [8] for minimax estimators of $\\theta \\varepsilon \\lbrack 0, \\infty)$. We show how to construct such estimators whenever loss is measured by $W(d - \\theta), W(\\cdot)$ strictly convex, non-negative, $W(0) = 0$. Blyth, op. cit., proved admissibility only within the class of continuous risk functions. In Section 9 we remove this restriction. We then show that if the loss function $W(\\cdot)$ is strictly convex and symmetrical then the sample mean based on $n$ observations is admissible, in the nonparametric context of estimating the mean of an unknown density function, within the class of all sequential procedures having expected sample size $\\leqq n$.", "authors": ["R H Farrell"], "related_topics": ["133939421", "38689907", "145446738"], "citation_count": "115", "reference_count": "10", "references": ["2799137445", "2005172650", "1979185183", "1601791052", "2080857177", "1989324623", "1985353418", "2094393870", "2092755067", "2077071171"], "date": "1964"}, {"id": "1587863748", "title": "Orthogonal transforms for digital signal processing", "abstract": "A tutorial-review paper on discrete orthogonal transforms and their applications in digital signal and image (both monochrome and color) processing is presented. Various transforms such as discrete Fourier, discrete cosine, Walsh-Hadamard, slant, Haar, discrete linear basis, Hadamard-Haar, rapid, lower triangular, generalized Haar, slant Haar and Karhunen-Loeve are defined and developed. Pertinent properties of these transforms such as power spectra, cyclic and dyadic convolution and correlation are outlined. Efficient algorithms for fast implementation of these transforms based on matrix partitioning or matrix factoring are presented. The application of these transforms in speech and image processing, spectral analysis, digital filtering (linear, nonlinear, optimal and suboptimal), nonlinear systems analysis, spectrography, digital holography, industrial testing, spectrometric imaging, feature selection, and patter recognition is presented. The utility and effectiveness of these transforms are evaluated in terms of some standard performance criteria such as computational complexity, variance distribution, mean-square error, correlated rms error, rate distortion, data compression, classification error, and digital hardware realization.", "authors": ["K. Rao", "N. Ahmed"], "related_topics": ["84462506", "2780588993", "152003226"], "citation_count": "1543", "reference_count": "0", "references": ["2130259898", "1553004968", "2162480849", "2003192648", "2092398714", "2123119012", "2008429100", "2155321485", "2148371116", "2017257315"], "date": "1976"}, {"id": "2065391104", "title": "Low-complexity image denoising based on statistical modeling of wavelet coefficients", "abstract": "We introduce a simple spatially adaptive statistical model for wavelet image coefficients and apply it to image denoising. Our model is inspired by a recent wavelet image compression algorithm, the estimation-quantization (EQ) coder. We model wavelet image coefficients as zero-mean Gaussian random variables with high local correlation. We assume a marginal prior distribution on wavelet coefficients variances and estimate them using an approximate maximum a posteriori probability rule. Then we apply an approximate minimum mean squared error estimation procedure to restore the noisy wavelet image coefficients. Despite the simplicity of our method, both in its concept and implementation, our denoising results are among the best reported in the literature.", "authors": ["M. Kivanc Mihcak", "I. Kozintsev", "K. Ramchandran", "P. Moulin"], "related_topics": ["196216189", "73339587", "155777637"], "citation_count": "1074", "reference_count": "13", "references": ["2132984323", "2158940042", "2053691921", "2101789093", "2134929491", "2163612361", "2124335859", "2168796889", "2168126647", "2113905985"], "date": "1999"}, {"id": "2153660465", "title": "The design of sigma-delta modulation analog-to-digital converters", "abstract": "The author examines the practical design criteria for implementing oversampled analog/digital converters based on second-order sigma-delta ( Sigma Delta ) modulation. Behavioral models that include representation of various circuit impairments are established for each of the functional building blocks comprising a second-order Sigma 2gD modulator. Extensive simulations based on these models are then used to establish the major design criteria for each of the building blocks. As an example, these criteria are applied to the design of a modulator that has been integrated in a 3- mu m CMOS technology. An experimental prototype operates from a single 5-V supply, dissipates 12 mW, occupies an area of 0.77 mm/sup 2/, and has achieved a measured dynamic range of 89 dB. >", "authors": ["B.E. Boser", "B.A. Wooley"], "related_topics": ["68754193", "110558960", "46362747"], "citation_count": "1058", "reference_count": "24", "references": ["2038068977", "2115724565", "2158335447", "2102634163", "1967807522", "2122794880", "2163811242", "2182773004", "2123423624", "1523390547"], "date": "1988"}, {"id": "2103081962", "title": "Multiple fingers contact sensing method for emulating mouse buttons and mouse operations on a touch sensor pad", "abstract": "Method and apparatus for detecting an operative coupling between one or more fingers or other appropriate objects and a touch pad includes processes for detection of multiple maxima with intermediate minima in appropriate sequences to emulate the operations of cursor control and button actuations in a pointing and control device.", "authors": ["Stephen J. Bisset", "Bernard Kasser"], "related_topics": ["43199551", "186633575", "9390403"], "citation_count": "2306", "reference_count": "24", "references": ["2107118797", "2108089445", "2048701870", "2611215833", "1904843846", "2626627692", "3105068503", "1834372499", "1869148059", "1957460085"], "date": "1996"}, {"id": "2098935637", "title": "Pig latin: a not-so-foreign language for data processing", "abstract": "There is a growing need for ad-hoc analysis of extremely large data sets, especially at internet companies where innovation critically depends on being able to analyze terabytes of data collected every day. Parallel database products, e.g., Teradata, offer a solution, but are usually prohibitively expensive at this scale. Besides, many of the people who analyze this data are entrenched procedural programmers, who find the declarative, SQL style to be unnatural. The success of the more procedural map-reduce programming model, and its associated scalable implementations on commodity hardware, is evidence of the above. However, the map-reduce paradigm is too low-level and rigid, and leads to a great deal of custom user code that is hard to maintain, and reuse.We describe a new language called Pig Latin that we have designed to fit in a sweet spot between the declarative style of SQL, and the low-level, procedural style of map-reduce. The accompanying system, Pig, is fully implemented, and compiles Pig Latin into physical plans that are executed over Hadoop, an open-source, map-reduce implementation. We give a few examples of how engineers at Yahoo! are using Pig to dramatically reduce the time required for the development and execution of their data analysis tasks, compared to using Hadoop directly. We also report on a novel debugging environment that comes integrated with Pig, that can lead to even higher productivity gains. Pig is an open-source, Apache-incubator project, and available for general use.", "authors": ["Christopher Olston", "Benjamin Reed", "Utkarsh Srivastava", "Ravi Kumar", "Andrew Tomkins"], "related_topics": ["510870499", "34165917", "2777123220"], "citation_count": "2594", "reference_count": "11", "references": ["2173213060", "1981420413", "2153704625", "2100830825", "2154894831", "2119714163", "2103201239", "2751199251", "1964857063", "2436525433"], "date": "2008"}, {"id": "2172195418", "title": "NONNEGATIVE APPROXIMATIONS OF NONNEGATIVE TENSORS", "abstract": "We study the decomposition of a nonnegative tensor into a minimal sum of outer product of nonnegative vectors and the associated parsimonious naive Bayes probabilistic model. We show that the corresponding approximation problem, which is central to nonnegative PARAFAC, will always have optimal solutions. The result holds for any choice of norms and, under a mild assumption, even Bregman divergences. Copyright \u00a9 2009 John Wiley & Sons, Ltd.", "authors": ["Lek-Heng Lim", "Pierre Comon"], "related_topics": ["149073432", "107180903", "180623205"], "citation_count": "185", "reference_count": "37", "references": ["1902027874", "2099741732", "2147152072", "2107743791", "2132267493", "2059745395", "2027559251", "2039748980", "1981663184", "3149756008"], "date": "2009"}, {"id": "2000196122", "title": "The myth of language universals: language diversity and its importance for cognitive science.", "abstract": "Talk of linguistic universals has given cognitive scientists the impression that languages are all built to a common pattern. In fact, there are vanishingly few universals of language in the direct sense that all languages exhibit them. Instead, diversity can be found at almost every level of linguistic organization. This fundamentally changes the object of enquiry from a cognitive science perspective. This target article summarizes decades of cross-linguistic work by typologists and descriptive linguists, showing just how few and unprofound the universal characteristics of language are, once we honestly confront the diversity offered to us by the world's 6,000 to 8,000 languages. After surveying the various uses of \"universal,\" we illustrate the ways languages vary radically in sound, meaning, and syntactic organization, and then we examine in more detail the core grammatical machinery of recursion, constituency, and grammatical relations. Although there are significant recurrent patterns in organization, these are better explained as stable engineering solutions satisfying multiple design constraints, reflecting both cultural-historical factors and the constraints of human cognition. Linguistic diversity then becomes the crucial datum for cognitive science: we are the only species with a communication system that is fundamentally variable at all levels. Recognizing the true extent of structural diversity in human language opens up exciting new research directions for cognitive scientists, offering thousands of different natural experiments given by different languages, with new opportunities for dialogue with biological paradigms concerned with change and diversity, and confronting us with the extraordinary plasticity of the highest human skills.", "authors": ["Nicholas Evans", "Stephen C. Levinson"], "related_topics": ["79078291", "1701360", "2777762164"], "citation_count": "2222", "reference_count": "422", "references": ["2883512297", "2081484203", "2110485445", "1562911371", "1996672843", "1980862600", "1540898082", "2010931158", "2165545766", "2123466824"], "date": "2009"}, {"id": "2296073425", "title": "Curriculum learning", "abstract": "Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them \"curriculum learning\". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).", "authors": ["Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Ronan Collobert", "Jason Weston"], "related_topics": ["26258499", "112972136", "24138899"], "citation_count": "2888", "reference_count": "31", "references": ["2136922672", "2100495367", "2072128103", "2117130368", "2025768430", "2110798204", "2099866409", "1994197834", "2172174689", "205159212"], "date": "2009"}, {"id": "2089754965", "title": "Feynman integral for singular Lagrangians", "abstract": "", "authors": ["L.D. Faddeev"], "related_topics": ["65574998", "48089519", "104416048"], "citation_count": "741", "reference_count": "18", "references": ["2026169595", "2016939318", "2232347689", "1997093580", "2062512625", "1968432004", "2227304090", "1979142071", "1974190488", "2055032331"], "date": "1968"}, {"id": "2122646361", "title": "Anomaly detection: A survey", "abstract": "Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.", "authors": ["Varun Chandola", "Arindam Banerjee", "Vipin Kumar"], "related_topics": ["739882", "169029474", "16963264"], "citation_count": "9735", "reference_count": "372", "references": ["2156909104", "1565377632", "2147880316", "1679913846", "1673310716", "2162800060", "2158454296", "2148694408", "2132870739", "1506281249"], "date": "2009"}, {"id": "2062270497", "title": "Information retrieval as statistical translation", "abstract": "We propose a new probabilistic approach to information retrieval based upon the ideas and methods of statistical machine translation. The central ingredient in this approach is a statistical model of how a user might distill or \"translate\" a given document into a query. To assess the relevance of a document to a user's query, we estimate the probability that the query would have been generated as a translation of the document, and factor in the user's general preferences in the form of a prior distribution over documents. We propose a simple, well motivated model of the document-to-query translation process, and describe an algorithm for learning the parameters of this model in an unsupervised manner from a collection of documents. As we show, one can view this approach as a generalization and justification of the \"language modeling\" strategy recently proposed by Ponte and Croft. In a series of experiments on TREC data, a simple translation-based retrieval system performs well in comparison to conventional retrieval techniques. This prototype system only begins to tap the full potential of translation-based retrieval.", "authors": ["Adam Berger", "John Lafferty"], "related_topics": ["99016210", "161156560", "24687705"], "citation_count": "858", "reference_count": "13", "references": ["2049633694", "2006969979", "1978394996", "2093390569", "1482214997", "2097333193", "2046325278", "2154384676", "2043909051", "36244633"], "date": "1999"}, {"id": "2963188634", "title": "Sharp vanishing thresholds for cohomology of random flag complexes", "abstract": "For every k 1, the k-th cohomology group H k (X;Q) of the random ag complex X X(n;p) passes through two phase transitions: one where it appears and one where it vanishes. We describe the vanishing threshold and show that it is sharp. Using the same spectral methods, we also nd a sharp threshold for the fundamental group 1(X) to have Kazhdan\u2019s property (T). Combining with earlier results, we obtain as a corollary that for every k 3, there is a regime in which the random ag complex is rationally homotopy equivalent to a bouquet of k-dimensional spheres.", "authors": ["Matthew Kahle"], "related_topics": ["78606066", "159876591", "5961521"], "citation_count": "74", "reference_count": "29", "references": ["3040586665", "2905110430", "2068871408", "3144881883", "390146837", "2478722229", "2977322974", "2018582120", "2911463656", "2097040817"], "date": "2014"}, {"id": "2000998192", "title": "Conflict monitoring and cognitive control.", "abstract": "A neglected question regarding cognitive control is how control processes might detect situations calling for their involvement. The authors propose here that the demand for control may be evaluated in part by monitoring for conflicts in information processing. This hypothesis is supported by data concerning the anterior cingulate cortex, a brain area involved in cognitive control, which also appears to respond to the occurrence of conflict. The present article reports two computational modeling studies, serving to articulate the conflict monitoring hypothesis and examine its implications. The first study tests the sufficiency of the hypothesis to account for brain activation data, applying a measure of conflict to existing models of tasks shown to engage the anterior cingulate. The second study implements a feedback loop connecting conflict monitoring to cognitive control, using this to simulate a number of important behavioral phenomena.", "authors": ["Matthew M. Botvinick", "Todd S. Braver", "Deanna M. Barch", "Cameron S. Carter", "Jonathan D. Cohen"], "related_topics": ["101744339", "2985799443", "8784161"], "citation_count": "7636", "reference_count": "150", "references": ["1554663460", "1652505363", "2293063825", "2120357670", "2118615399", "1763311249", "2013657375", "2057046889", "2156761163", "2150704745"], "date": "2001"}, {"id": "2157542520", "title": "Does Homework Improve Academic Achievement? A Synthesis of Research, 1987\u20132003:", "abstract": "In this article, research conducted in the United States since 1987 on the effects of homework is summarized. Studies are grouped into four research designs. The authors found that all studies, regardless of type, had design flaws. However, both within and across design types, there was generally consistent evidence for a positive influence of homework on achievement. Studies that reported simple homework\u2013achievement correlations revealed evidence that a stronger correlation existed (a) in Grades 7\u201312 than in K\u20136 and (b) when students rather than parents reported time on homework. No strong evidence was found for an association between the homework\u2013achievement link and the outcome measure (grades as opposed to standardized tests) or the subject matter (reading as opposed to math). On the basis of these results and others, the authors suggest future research.", "authors": ["Harris Cooper", "Jorgianne Civey Robinson", "Erika A Patall"], "related_topics": ["2781206393", "2779318504", "203151758"], "citation_count": "1710", "reference_count": "112", "references": ["1730782591", "2033585778", "1999649023", "2107031757", "1508379148", "2043565183", "1964605289", "2057563009", "2764311721", "2089382928"], "date": "2006"}, {"id": "2140235142", "title": "Pfinder: real-time tracking of the human body", "abstract": "Pfinder is a real-time system for tracking people and interpreting their behavior. It runs at 10 Hz on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multiclass statistical model of color and shape to obtain a 2D representation of head and hands in a wide range of viewing conditions. Pfinder has been successfully used in a wide range of applications including wireless interfaces, video databases, and low-bandwidth coding.", "authors": ["C.R. Wren", "A. Azarbayejani", "T. Darrell", "A.P. Pentland"], "related_topics": ["159437735", "2779769447", "32653426"], "citation_count": "7685", "reference_count": "14", "references": ["2157548127", "2069356045", "2144573889", "1635989058", "2119444142", "2131938593", "2042850474", "2178278515", "2140487300", "2034836133"], "date": "1997"}, {"id": "2103504761", "title": "The Laplacian Pyramid as a Compact Image Code", "abstract": "We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space. Pixel-to-pixel correlations are first removed by subtracting a lowpass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the low-pass image. Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus, the code tends to enhance salient image features. A further advantage of the present code is that it is well suited for many image analysis tasks as well as for image compression. Fast algorithms are described for coding and decoding.", "authors": ["P. Burt", "E. Adelson"], "related_topics": ["13481523", "9417928", "63099799"], "citation_count": "8776", "reference_count": "11", "references": ["1622620102", "2978983090", "2078498116", "2074163268", "2024397673", "2099590965", "2089975134", "1486071255", "2125311604", "118993750"], "date": "1983"}, {"id": "2033943395", "title": "User Acceptance of Computer Technology: A Comparison of Two Theoretical Models", "abstract": "Computer systems cannot improve organizational performance if they aren't used. Unfortunately, resistance to end-user systems by managers and professionals is a widespread problem. To better predict, explain, and increase user acceptance, we need to better understand why people accept or reject computers. This research addresses the ability to predict peoples' computer acceptance from a measure of their intentions, and the ability to explain their intentions in terms of their attitudes, subjective norms, perceived usefulness, perceived ease of use, and related variables. In a longitudinal study of 107 users, intentions to use a specific system, measured after a one-hour introduction to the system, were correlated 0.35 with system use 14 weeks later. The intention-usage correlation was 0.63 at the end of this time period. Perceived usefulness strongly influenced peoples' intentions, explaining more than half of the variance in intentions at the end of 14 weeks. Perceived ease of use had a small but significant effect on intentions as well, although this effect subsided over time. Attitudes only partially mediated the effects of these beliefs on intentions. Subjective norms had no effect on intentions. These results suggest the possibility of simple but powerful models of the determinants of user acceptance, with practical value for evaluating systems and guiding managerial interventions aimed at reducing the problem of underutilized computer technology.", "authors": ["Fred D. Davis", "Richard P. Bagozzi", "Paul R. Warshaw"], "related_topics": ["2780346085", "2776185967", "2986193123"], "citation_count": "30608", "reference_count": "75", "references": ["1491644571", "1982210139", "2036389121", "2111230857", "1557992034", "112089985", "3124865537", "1972888601", "2037021532", "1518638857"], "date": "1989"}, {"id": "2084761702", "title": "Query optimization in the presence of limited access patterns", "abstract": "We consider the problem of query optimization in the presence of limitations on access patterns to the data (i.e., when one must provide values for one of the attributes of a relation in order to obtain tuples). We show that in the presence of limited access patterns we must search a space of annotated query plans, where the annotations describe the inputs that must be given to the plan. We describe a theoretical and experimental analysis of the resulting search space and a novel query optimization algorithm that is designed to perform well under the different conditions that may arise. The algorithm searches the set of annotated query plans, pruning invalid and non-viable plans as early as possible in the search space, and it also uses a best-first search strategy in order to produce a first complete plan early in the search. We describe experiments to illustrate the performance of our algorithm.", "authors": ["Daniela Florescu", "Alon Levy", "Ioana Manolescu", "Dan Suciu"], "related_topics": ["157692150", "99016210", "118689300"], "citation_count": "268", "reference_count": "23", "references": ["1879587332", "2172549414", "1638026557", "2134876510", "1541672808", "2079329679", "2090438868", "2160967997", "2042570369", "2079806729"], "date": "1999"}, {"id": "1998442272", "title": "Effects of adjective orientation and gradability on sentence subjectivity", "abstract": "Subjectivity is a pragmatic, sentence-level feature that has important implications for text processing applications such as information extraction and information retrieval. We study the effects of dynamic adjectives, semantically oriented adjectives, and gradable adjectives on a simple subjectivity classifier, and establish that they are strong predictors of subjectivity. A novel trainable method that statistically combines two indicators of gradability is presented and evaluated, complementing existing automatic techniques for assigning orientation labels.", "authors": ["Vasileios Hatzivassiloglou", "Janyce M. Wiebe"], "related_topics": ["202889954", "2777683214", "2777530160"], "citation_count": "889", "reference_count": "16", "references": ["1632114991", "2313581450", "2199803028", "2099247782", "2070779353", "2150098611", "2062837929", "1548013757", "2138437366", "2128669672"], "date": "2000"}, {"id": "2052262800", "title": "The Structural Sources of Verb Meanings", "abstract": "If we will observe how children learn languages, we will find that, to make them understand what the names of simple ideas or substances stand for, people ordinarily show them the thing whereof they would have them have the idea; and then repeat to them the name that stands for it, as 'white', 'sweet', 'milk', 'sugar', 'cat', 'dog'.", "authors": ["Lila R. Gleitman"], "related_topics": ["2776397901", "2779930064", "55581612"], "citation_count": "1742", "reference_count": "63", "references": ["1586060904", "1594369375", "2123987305", "2094249282", "2059799772", "1551770093", "2134199742", "1982374456", "2009720124", "2169495103"], "date": "1989"}, {"id": "2124335859", "title": "Analysis of multiresolution image denoising schemes using generalized Gaussian and complexity priors", "abstract": "Research on universal and minimax wavelet shrinkage and thresholding methods has demonstrated near-ideal estimation performance in various asymptotic frameworks. However, image processing practice has shown that universal thresholding methods are outperformed by simple Bayesian estimators assuming independent wavelet coefficients and heavy-tailed priors such as generalized Gaussian distributions (GGDs). In this paper, we investigate various connections between shrinkage methods and maximum a posteriori (MAP) estimation using such priors. In particular, we state a simple condition under which MAP estimates are sparse. We also introduce a new family of complexity priors based upon Rissanen's universal prior on integers. One particular estimator in this class outperforms conventional estimators based on earlier applications of the minimum description length (MDL) principle. We develop analytical expressions for the shrinkage rules implied by GGD and complexity priors. This allows us to show the equivalence between universal hard thresholding, MAP estimation using a very heavy-tailed GGD, and MDL estimation using one of the new complexity priors. Theoretical analysis supported by numerous practical experiments shows the robustness of some of these estimates against mis-specifications of the prior-a basic concern in image processing applications.", "authors": ["P. Moulin", "Juan Liu"], "related_topics": ["87465248", "191178318", "9810830"], "citation_count": "694", "reference_count": "38", "references": ["2062024414", "2132984323", "2146842127", "2158940042", "2053691921", "1988520084", "2168175751", "1657347807", "2070094080", "2166087152"], "date": "1999"}, {"id": "2112328181", "title": "Scale-space theory in computer vision", "abstract": "A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over ...", "authors": ["Tony Lindeberg"], "related_topics": ["556297831", "27434737", "200220432"], "citation_count": "2943", "reference_count": "0", "references": ["2158592639", "1625255723", "1676552347", "2124087378", "2150769593", "2109200236", "2020163092", "2165497495", "2119799051", "2042316011"], "date": "1993"}, {"id": "2978983090", "title": "Fast Filter Transforms for Image Processing", "abstract": "", "authors": ["P. J. Burt"], "related_topics": ["14107862", "9417928", "31972630"], "citation_count": "528", "reference_count": "0", "references": ["2132984323", "2109200236", "2103504761", "2140257560", "1480546554", "1490632837", "2127230474", "2042243448", "2143753158", "2156053375"], "date": "1980"}, {"id": "2150874632", "title": "Toolglass and magic lenses: the see-through interface", "abstract": "Toolglass\u2122 widgets are new user interface tools that can appear, as though on a transparent sheet of glass, between an application and a traditional cursor. They can be positioned with one hand while the other positions the cursor. The widgets provide a rich and concise vocabulary for operating on application objects. These widgets may incorporate visual filters, called Magic Lens\u2122 filters, that modify the presentation of application objects to reveal hidden information, to enhance data of interest, or to suppress distracting information. Together, these tools form a see-through interface that offers many advantages over traditional controls. They provide a new style of interaction that better exploits the user\u2019 s everyday skills. They can reduce steps, cursor motion, and errors. Many widgets can be provided in a user inter face, by designers and by users, without requiring dedicated screen space. In addition, lenses provide rich context -dependent feedback and the ability to view details and context simultaneous ly. Our widgets and lenses can be combined to form operation and viewing macros, and can be used over multiple applications. CR Categories and Subject Descriptors: I.3.6 [Computer Graphics]: Methodology and Techniques- interaction techniques; H.5.2 [Information Interfaces and Presentation]: User Interfaces- interaction styles; I.3.3 [ Computer Graphics]: Picture/Image Generation- viewing algorithms; I.3.4 [Computer Graphics]: Graphics Utilities - graphics editors", "authors": ["Eric A. Bier", "Maureen C. Stone", "Ken Pier", "William Buxton", "Tony D. DeRose"], "related_topics": ["89505385", "77660652", "21442007"], "citation_count": "1883", "reference_count": "17", "references": ["1996974848", "2465771390", "2124262094", "2118580158", "2067870298", "2095956339", "2090702521", "2087747577", "2147771055", "2090293796"], "date": "1993"}, {"id": "2012778485", "title": "Invariant Features from Interest Point Groups", "abstract": "This paper approaches the problem of \u00afnding correspondences between images in which there are large changes in viewpoint, scale and illumi- nation. Recent work has shown that scale-space `interest points' may be found with good repeatability in spite of such changes. Further- more, the high entropy of the surrounding image regions means that local descriptors are highly discriminative for matching. For descrip- tors at interest points to be robustly matched between images, they must be as far as possible invariant to the imaging process. In this work we introduce a family of features which use groups of interest points to form geometrically invariant descriptors of image regions. Feature descriptors are formed by resampling the image rel- ative to canonical frames de\u00afned by the points. In addition to robust matching, a key advantage of this approach is that each match implies a hypothesis of the local 2D (projective) transformation. This allows us to immediately reject most of the false matches using a Hough trans- form. We reject remaining outliers using RANSAC and the epipolar constraint. Results show that dense feature matching can be achieved in a few seconds of computation on 1GHz Pentium III machines.", "authors": ["Matthew Brown", "David G. Lowe"], "related_topics": ["114744707", "23379248", "49209780"], "citation_count": "1141", "reference_count": "13", "references": ["2124386111", "2124087378", "2119747362", "2109200236", "2165497495", "2103504761", "1505641881", "2011891945", "22745672", "2005433550"], "date": "2002"}, {"id": "2109779438", "title": "The Cascade-Correlation Learning Architecture", "abstract": "Cascade-Correlation is a new architecture and supervised learning algorithm for artificial neural networks. Instead of just adjusting the weights in a network of fixed topology. Cascade-Correlation begins with a minimal network, then automatically trains and adds new hidden units one by one, creating a multi-layer structure. Once a new hidden unit has been added to the network, its input-side weights are frozen. This unit then becomes a permanent feature-detector in the network, available for producing outputs or for creating other, more complex feature detectors. The Cascade-Correlation architecture has several advantages over existing algorithms: it learns very quickly, the network determines its own size and topology, it retains the structures it has built even if the training set changes, and it requires no back-propagation of error signals through the connections of the network.", "authors": ["Scott E. Fahlman", "Christian Lebiere"], "related_topics": ["199845137", "139940560", "50644808"], "citation_count": "4321", "reference_count": "12", "references": ["2154642048", "1652505363", "2160208155", "19621276", "3121126077", "2160699933", "50076749", "2127385318", "2169163929", "2167277568"], "date": "1988"}, {"id": "1493892051", "title": "Finding Frequent Items in Data Streams", "abstract": "We present a 1-pass algorithm for estimating the most frequent items in a data stream using limited storage space. Our method relies on a data structure called a COUNT SKETCH, which allows us to reliably estimate the frequencies of frequent items in the stream. Our algorithm achieves better space bounds than the previously known best algorithms for this problem for several natural distributions on the item frequencies. In addition, our algorithm leads directly to a 2-pass algorithm for the problem of estimating the items with the largest (absolute) change in frequency between two data streams. To our knowledge, this latter problem has not been previously studied in the literature.", "authors": ["Moses Charikar", "Kevin Chen", "Martin Farach-Colton"], "related_topics": ["89198739", "187166803", "2780337507"], "citation_count": "1212", "reference_count": "17", "references": ["2080745194", "2053171205", "2069980026", "2100369465", "2045533739", "2047424291", "1993482412", "139562302", "2113139394", "2003262311"], "date": "2002"}, {"id": "232533489", "title": "DISTRIBUTED INFORMATION RETRIEVAL", "abstract": "A multi-database model of distributed information retrieval is presented, in which people are assumed to have access to many searchable text databases. In such an environment, full-text information retrieval consists of discovering database contents, ranking databases by their expected ability to satisfy the query, searching a small number of databases, and merging results returned by different databases. This paper presents algorithms for each task. It also discusses how to reorganize conventional test collections into multi-database testbeds, and evaluation methodologies for multi-database experiments. A broad and diverse group of experimental results is presented to demonstrate that the algorithms are effective, efficient, robust, and scalable.", "authors": ["Jamie Callan"], "related_topics": ["90288658", "189430467", "2778563054"], "citation_count": "593", "reference_count": "29", "references": ["2014415866", "2073788020", "2086253379", "1986828474", "2409356627", "1572257961", "1990388042", "1980515494", "2019976352", "2137845970"], "date": "2001"}, {"id": "2137808089", "title": "A cost-effective, high-bandwidth storage architecture", "abstract": "This paper describes the Network-Attached Secure Disk (NASD) storage architecture, prototype implementations oj NASD drives, array management for our architecture, and three, filesystems built on our prototype. NASD provides scalable storage bandwidth without the cost of servers used primarily, for transferring data from peripheral networks (e.g. SCSI) to client networks (e.g. ethernet). Increasing datuset sizes, new attachment technologies, the convergence of peripheral and interprocessor switched networks, and the increased availability of on-drive transistors motivate and enable this new architecture. NASD is based on four main principles: direct transfer to clients, secure interfaces via cryptographic support, asynchronous non-critical-path oversight, and variably-sized data objects. Measurements of our prototype system show that these services can be cost-effectively integrated into a next generation disk drive ASK. End-to-end measurements of our prototype drive andfilesysterns suggest that NASD cun support conventional distributed filesystems without performance degradation. More importantly, we show scaluble bandwidth for NASD-specialized filesystems. Using a parallel data mining application, NASD drives deliver u linear scaling of 6.2 MB/s per clientdrive pair, tested with up to eight pairs in our lab.", "authors": ["Garth A. Gibson", "David F. Nagle", "Khalil Amiri", "Jeff Butler", "Fay W. Chang", "Howard Gobioff", "Charles Hardin", "Erik Riedel", "David Rochberg", "Jim Zelenka"], "related_topics": ["2781430025", "93996380", "2776257435"], "citation_count": "579", "reference_count": "56", "references": ["1484413656", "1506285740", "1575350781", "2147504831", "2114728910", "2131300413", "2106539366", "2005373714", "2153131460", "2025413686"], "date": "1998"}, {"id": "2106525823", "title": "Do we need hundreds of classifiers to solve real world classification problems", "abstract": "We evaluate 179 classifiers arising from 17 families (discriminant analysis, Bayesian, neural networks, support vector machines, decision trees, rule-based classifiers, boosting, bagging, stacking, random forests and other ensembles, generalized linear models, nearest-neighbors, partial least squares and principal component regression, logistic and multinomial regression, multiple adaptive regression splines and other methods), implemented in Weka, R (with and without the caret package), C and Matlab, including all the relevant classifiers available today. We use 121 data sets, which represent the whole UCI data base (excluding the large-scale problems) and other own real problems, in order to achieve significant conclusions about the classifier behavior, not dependent on the data set collection. The classifiers most likely to be the bests are the random forest (RF) versions, the best of which (implemented in R and accessed via caret) achieves 94.1% of the maximum accuracy overcoming 90% in the 84.3% of the data sets. However, the difference is not statistically significant with the second best, the SVM with Gaussian kernel implemented in C using LibSVM, which achieves 92.3% of the maximum accuracy. A few models are clearly better than the remaining ones: random forest, SVM with Gaussian and polynomial kernels, extreme learning machine with Gaussian kernel, C5.0 and avNNet (a committee of multi-layer perceptrons implemented in R with the caret package). The random forest is clearly the best family of classifiers (3 out of 5 bests classifiers are RF), followed by SVM (4 classifiers in the top-10), neural networks and boosting ensembles (5 and 3 members in the top-20, respectively).", "authors": ["Manuel Fern\u00e1ndez-Delgado", "Eva Cernadas", "Sen\u00e9n Barro", "Dinani Amorim"], "related_topics": ["106135958", "189119545", "169258074"], "citation_count": "2451", "reference_count": "108", "references": ["2153635508", "2911964244", "3120740533", "2097360283", "1513618424", "1480376833", "2912934387", "2117812871", "2118585731", "2125055259"], "date": "2013"}, {"id": "1812582761", "title": "Polyglot: an extensible compiler framework for Java", "abstract": "Polyglot is an extensible compiler framework that supports the easy creation of compilers for languages similar to Java, while avoiding code duplication. The Polyglot framework is useful for domain-specific languages, exploration of language design, and for simplified versions of Java for pedagogical use. We have used Polyglot to implement several major and minor modifications to Java; the cost of implementing language extensions scales well with the degree to which the language differs from Java. This paper focuses on the design choices in Polyglot that are important for making the framework usable and highly extensible. Polyglot source code is available.", "authors": ["Nathaniel Nystrom", "Michael R. Clarkson", "Andrew C. Myers"], "related_topics": ["2780239667", "2778764840", "60945770"], "citation_count": "540", "reference_count": "50", "references": ["1649645444", "1644882639", "2143238865", "1993836075", "2066859698", "2158126684", "1998070736", "2113547509", "2133546079", "2109875364"], "date": "2003"}, {"id": "2124637492", "title": "Statistical mechanics of complex networks", "abstract": "The emergence of order in natural systems is a constant source of inspiration for both physical and biological sciences. While the spatial order characterizing for example the crystals has been the basis of many advances in contemporary physics, most complex systems in nature do not offer such high degree of order. Many of these systems form complex networks whose nodes are the elements of the system and edges represent the interactions between them. Traditionally complex networks have been described by the random graph theory founded in 1959 by Paul Erdohs and Alfred Renyi. One of the defining features of random graphs is that they are statistically homogeneous, and their degree distribution (characterizing the spread in the number of edges starting from a node) is a Poisson distribution. In contrast, recent empirical studies, including the work of our group, indicate that the topology of real networks is much richer than that of random graphs. In particular, the degree distribution of real networks is a power-law, indicating a heterogeneous topology in which the majority of the nodes have a small degree, but there is a significant fraction of highly connected nodes that play an important role in the connectivity of the network. The scale-free topology of real networks has very important consequences on their functioning. For example, we have discovered that scale-free networks are extremely resilient to the random disruption of their nodes. On the other hand, the selective removal of the nodes with highest degree induces a rapid breakdown of the network to isolated subparts that cannot communicate with each other. The non-trivial scaling of the degree distribution of real networks is also an indication of their assembly and evolution. Indeed, our modeling studies have shown us that there are general principles governing the evolution of networks. Most networks start from a small seed and grow by the addition of new nodes which attach to the nodes already in the system. This process obeys preferential attachment: the new nodes are more likely to connect to nodes with already high degree. We have proposed a simple model based on these two principles wich was able to reproduce the power-law degree distribution of real networks. Perhaps even more importantly, this model paved the way to a new paradigm of network modeling, trying to capture the evolution of networks, not just their static topology.", "authors": ["Reka Zsuzsanna Albert", "Albert-Laszlo Barabasi"], "related_topics": ["87414783", "36647736", "64900535"], "citation_count": "24997", "reference_count": "175", "references": ["2112090702", "2008620264", "2061901927", "2065769502", "2164727176", "2078206416", "1976969221", "2769133055", "3113109455", "2905110430"], "date": "2000"}, {"id": "2119567691", "title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming", "abstract": "From the Publisher: The past decade has seen considerable theoretical and applied research on Markov decision processes, as well as the growing use of these models in ecology, economics, communications engineering, and other fields where outcomes are uncertain and sequential decision-making processes are needed. A timely response to this increased activity, Martin L. Puterman's new work provides a uniquely up-to-date, unified, and rigorous treatment of the theoretical, computational, and applied research on Markov decision process models. It discusses all major research directions in the field, highlights many significant applications of Markov decision processes models, and explores numerous important topics that have previously been neglected or given cursory coverage in the literature. Markov Decision Processes focuses primarily on infinite horizon discrete time models and models with discrete time spaces while also examining models with arbitrary state spaces, finite horizon models, and continuous-time discrete state models. The book is organized around optimality criteria, using a common framework centered on the optimality (Bellman) equation for presenting results. The results are presented in a \"theorem-proof\" format and elaborated on through both discussion and examples, including results that are not available in any other book. A two-state Markov decision process model, presented in Chapter 3, is analyzed repeatedly throughout the book and demonstrates many results and algorithms. Markov Decision Processes covers recent research advances in such areas as countable state space models with average reward criterion, constrained models, and models with risk sensitive optimality criteria. It also explores several topics that have received little or no attention in other books, including modified policy iteration, multichain models with average reward criterion, and sensitive optimality. In addition, a Bibliographic Remarks section in each chapter comments on relevant historic", "authors": ["Martin L. Puterman"], "related_topics": ["17098449", "106189395", "163836022"], "citation_count": "15048", "reference_count": "12", "references": ["3038830718", "2035446426", "2341171179", "2096630263", "2130184319", "1571552128", "2319878520", "2067733412", "2036791211", "154446778"], "date": "1994"}, {"id": "1970352604", "title": "Wavelets and signal processing", "abstract": "A simple, nonrigorous, synthetic view of wavelet theory is presented for both review and tutorial purposes. The discussion includes nonstationary signal analysis, scale versus frequency, wavelet analysis and synthesis, scalograms, wavelet frames and orthonormal bases, the discrete-time case, and applications of wavelets in signal processing. The main definitions and properties of wavelet transforms are covered, and connections among the various fields where results have been developed are shown. >", "authors": ["O. Rioul", "M. Vetterli"], "related_topics": ["47432892", "46286280", "196216189"], "citation_count": "3919", "reference_count": "79", "references": ["2132984323", "2098914003", "1996021349", "2103504761", "2165878107", "3005363104", "1980149518", "2166982406", "2149072817", "1822629720"], "date": "1991"}, {"id": "2112325651", "title": "Connectionist models and their properties", "abstract": "Much of the progress in the fields constituting cognitive science has been based upon the use of explicit information processing models, almost exclusively patterned after conventional serial computers. An extension of these ideas to massively parallel, connectionist models appears to offer a number of advantages. After a preliminary discussion, this paper introduces a general connectionist model and considers how it might be used in cognitive science. Among the issues addressed are: stability and noise-sensitivity, distributed decision-making, time and sequence problems, and the representation of complex concepts.", "authors": ["J. A. Feldman", "D. H. Ballard"], "related_topics": ["8521452", "190475519", "87868495"], "citation_count": "2786", "reference_count": "0", "references": ["2118051273", "1507849272", "2046863527", "2176028050", "2089597841", "1497599070", "1731244441", "2118373646", "2004131797", "2125360619"], "date": "1988"}, {"id": "2139212933", "title": "A Tutorial on Support Vector Machines for Pattern Recognition", "abstract": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.", "authors": ["Christopher J. C. Burges"], "related_topics": ["173102733", "145828037", "14948415"], "citation_count": "30394", "reference_count": "54", "references": ["2156909104", "2148603752", "1554663460", "2119821739", "2610857016", "2140095548", "2981264952", "2087347434", "2432517183", "740415"], "date": "1998"}, {"id": "1593806347", "title": "Measuring Discrimination in Socially-Sensitive Decision Records", "abstract": "Discrimination in social sense (e.g., against minorities and disadvantaged groups) is the subject of many laws worldwide, and it has been extensively studied in the social and economic sciences. We tackle the problem of determining, given a dataset of historical decision records, a precise measure of the degree of discrimination suffered by a given group (e.g., an etnic minority) in a given context (e.g., a geographic area) with respect to the decision (e.g. credit denial). In our approach, this problem is rephrased in a classification rule based setting, and a collection of quantitative measures of discrimination is introduced, on the basis of existing norms and regulations. The measures are defined as functions of the contingency table of a classification rule, and their statistical significance is assessed, relying on a large body of statistical inference methods for proportions. Based on this basic method, we are then able to address the more general problems of: (1) unveiling all discriminatory decision patterns hidden in the historical data, combining discrimination analysis with association rule mining, (2) unveiling discrimination in classifiers that learn over training data biased by discriminatory decisions, and (3) in the case of rule-based classifiers, sanitizing discriminatory rules by correcting their confidence. Our approach is validated on the German credit dataset and on the CPAR classifier.", "authors": ["Dino Pedreschi", "Salvatore Ruggieri", "Franco Turini"], "related_topics": ["104317236", "193524817", "134261354"], "citation_count": "188", "reference_count": "19", "references": ["2084812512", "1506285740", "2076983043", "2313581450", "2026019770", "2096913021", "1623342295", "2091397788", "2099207046", "2796189892"], "date": "2008"}, {"id": "2166313543", "title": "Use of model predictive control and weather forecasts for energy efficient building climate control", "abstract": "This paper presents an investigation of how ModelPredictiveControl (MPC) and weatherpredictions can increase the energy efficiency in Integrated Room Automation (IRA) while respecting occupant comfort. IRA deals with the simultaneous control of heating, ventilation and air conditioning (HVAC) as well as blind positioning and electric lighting of a building zone such that the room temperature as well as CO2 and luminance levels stay within given comfort ranges. MPC is an advanced control technique which, when applied to buildings, employs a model of the building dynamics and solves an optimization problem to determine the optimal control inputs. In this paper it is reported on the development and analysis of a Stochastic ModelPredictiveControl (SMPC) strategy for buildingclimatecontrol that takes into account the uncertainty due to the use of weatherpredictions. As first step the potential of MPC was assessed by means of a large-scale factorial simulation study that considered different types of buildings and HVAC systems at four representative European sites. Then for selected representative cases the control performance of SMPC, the impact of the accuracy of weatherpredictions, as well as the tunability of SMPC were investigated. The findings suggest that SMPC outperforms current control practice.", "authors": ["Frauke Oldewurtel", "Alessandra Parisio", "Colin N. Jones", "Dimitrios Gyalistras", "Markus Gwerder", "Vanessa Stauch", "Beat Lehmann", "Manfred Morari"], "related_topics": ["172205157", "122346748", "2742236"], "citation_count": "1056", "reference_count": "19", "references": ["1561941139", "2029264889", "2166480912", "2110349823", "2293807537", "2065265184", "2798344481", "2050949442", "2127014113", "2088693678"], "date": "2012"}, {"id": "2059799772", "title": "Basic objects in natural categories", "abstract": "Abstract Categorizations which humans make of the concrete world are not arbitrary but highly determined. In taxonomies of concrete objects, there is one level of abstraction at which the most basic category cuts are made. Basic categories are those which carry the most information, possess the highest category cue validity, and are, thus, the most differentiated from one another. The four experiments of Part I define basic objects by demonstrating that in taxonomies of common concrete nouns in English based on class inclusion, basic objects are the most inclusive categories whose members: (a) possess significant numbers of attributes in common, (b) have motor programs which are similar to one another, (c) have similar shapes, and (d) can be identified from averaged shapes of members of the class. The eight experiments of Part II explore implications of the structure of categories. Basic objects are shown to be the most inclusive categories for which a concrete image of the category as a whole can be formed, to be the first categorizations made during perception of the environment, to be the earliest categories sorted and earliest named by children, and to be the categories most codable, most coded, and most necessary in language.", "authors": ["Eleanor Rosch", "Carolyn B Mervis", "Wayne D Gray", "David M Johnson", "Penny Boyes-Braem"], "related_topics": ["2777212361", "2776862593", "121934690"], "citation_count": "7979", "reference_count": "40", "references": ["2035782089", "1980054641", "1584697775", "2007780422", "2000255081", "2045830397", "2157904933", "2025668003", "2032946087", "2082550766"], "date": "1976"}, {"id": "2517104773", "title": "Calibrating noise to sensitivity in private data analysis", "abstract": "We continue a line of research initiated in [10, 11] on privacy-preserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function f mapping databases to reals, the so-called true answer is the result of applying f to the database. To protect privacy, the true answer is perturbed by the addition of random noise generated according to a carefully chosen distribution, and this response, the true answer plus noise, is returned to the user. Previous work focused on the case of noisy sums, in which f = \u03a3 i g(x i ), where x i denotes the ith row of the database and g maps database rows to [0,1]. We extend the study to general functions f, proving that privacy can be preserved by calibrating the standard deviation of the noise according to the sensitivity of the function f. Roughly speaking, this is the amount that any single argument to f can change its output. The new analysis shows that for several particular applications substantially less noise is needed than was previously understood to be the case. The first step is a very clean characterization of privacy in terms of indistinguishability of transcripts. Additionally, we obtain separation results showing the increased value of interactive sanitization mechanisms over non-interactive.", "authors": ["Cynthia Dwork", "Frank Mcsherry", "Kobbi Nissim", "Adam Smith"], "related_topics": ["151405878", "58442840", "123201435"], "citation_count": "5080", "reference_count": "0", "references": ["2007605181", "2263689172", "1975247808", "2115358662", "2995160698", "2809577165", "6683045", "2294415577", "3044891112", "3093150798"], "date": "2005"}, {"id": "2154118576", "title": "Sparse matrix solvers on the GPU: conjugate gradients and multigrid", "abstract": "Many computer graphics applications require high-intensity numerical simulation. We show that such computations can be performed efficiently on the GPU, which we regard as a full function streaming processor with high floating-point performance. We implemented two basic, broadly useful, computational kernels: a sparse matrix conjugate gradient solver and a regular-grid multigrid solver. Real time applications ranging from mesh smoothing and parameterization to fluid solvers and solid mechanics can greatly benefit from these, evidence our example applications of geometric flow and fluid simulation running on NVIDIA's GeForce FX.", "authors": ["Jeff Bolz", "Ian Farmer", "Eitan Grinspun", "Peter Schr\u00f6der"], "related_topics": ["137119250", "50630238", "81184566"], "citation_count": "1267", "reference_count": "43", "references": ["1760551737", "2295821368", "2000214666", "2132540527", "2098841537", "2237109911", "1575701986", "1997542937", "2118688057", "2117236520"], "date": "2003"}, {"id": "121934918", "title": "Display Managers as the Basis for User-Machine Communication", "abstract": "", "authors": ["Stephen W. Draper"], "related_topics": ["12426560", "41008148", "107457646"], "citation_count": "68", "reference_count": "0", "references": ["2115647291", "2294857847", "2469070852", "1591505171", "109413735", "1987831789", "2066258442", "2132271720", "2039411789", "2108148331"], "date": "1985"}, {"id": "103927176", "title": "Conversation analysis. Studies from the first generation.", "abstract": "Table of contents: Introductory remarks; Gene H. Lerner 1\u201311 Glossary of transcript symbols with an introduction; Gail Jefferson 13\u201331 Part I: Taking turns speaking An initial characterization of the organization of speaker turn-taking in conversation; Harvey Sacks 35\u201342 A sketch of some orderly aspects of overlap in natural conversation; Gail Jefferson 43\u201359 Part II: Implementing actions Answering the phone; Emanuel A. Schegloff 63\u2013107 Investigating reported absences: 'Neutrally' catching the truants; Anita Pomerantz 109\u2013129 \u201cAt first I thought\u201d: A normalizing device for extraordinary events; Gail Jefferson 131\u2013167 Part III: Sequencing actions Pre-announcement sequences in conversation; Alene Kiku Terasaki 171\u2013223 Collaborative turn sequences; Gene H. Lerner 225\u2013256 The amplitude shift mechanism in conversational closing sequences; Jo Ann Goldberg 257\u2013297 Index 299\u2013300", "authors": ["Gene H. Lerner"], "related_topics": ["2780829048", "2777200299", "68476402"], "citation_count": "339", "reference_count": "0", "references": ["2498260772", "2151369449", "2083046848", "1968344361", "2146584389", "1968517452", "2087636618", "2080344481", "2134875103", "2113836263"], "date": "2004"}, {"id": "1980054641", "title": "On the psychology of prediction", "abstract": "In this paper, we explore the rules that determine intuitive predictions and judgments of confidence and contrast these rules to the normative principles of statistical prediction. Two classes of prediction are discussed: category prediction and numerical prediction. In a categorical case, the prediction is given in nominal form, for example, the winner in an election, the diagnosis of a patient, or a person's future occupation. In a numerical case, the prediction is given in numerical form, for example, the future value of a particular stock or of a student's grade point average. In making predictions and judgments under uncertainty, people do not appear to follow the calculus of chance or the statistical theory of prediction. Instead, they rely on a limited number of heuristics which sometimes yield reasonable judgments and sometimes lead to severe and systematic errors (Kahneman & Tversky, 1972b, 3; Tversky & Kahneman, 1971, 2; 1973, 11). The present paper is concerned with the role of one of these heuristics \u2013 representativeness \u2013 in intuitive predictions. Given specific evidence (e.g., a personality sketch), the outcomes under consideration (e.g., occupations or levels of achievement) can be ordered by the degree to which they are representative of that evidence. The thesis of this paper is that people predict by representativeness, that is, they select or order outcomes by the degree to which the outcomes represent the essential features of the evidence.", "authors": ["Daniel Kahneman", "Amos Tversky"], "related_topics": ["37381756", "127705205", "53764606"], "citation_count": "8534", "reference_count": "11", "references": ["2035782089", "2016377072", "2079199322", "1976624377", "1996443718", "2026575291", "644417567", "1993037197", "2319506195", "1973836215"], "date": "1972"}, {"id": "2111366547", "title": "The iSLIP scheduling algorithm for input-queued switches", "abstract": "An increasing number of high performance internetworking protocol routers, LAN and asynchronous transfer mode (ATM) switches use a switched backplane based on a crossbar switch. Most often, these systems use input queues to hold packets waiting to traverse the switching fabric. It is well known that if simple first in first out (FIFO) input queues are used to hold packets then, even under benign conditions, head-of-line (HOL) blocking limits the achievable bandwidth to approximately 58.6% of the maximum. HOL blocking can be overcome by the use of virtual output queueing, which is described in this paper. A scheduling algorithm is used to configure the crossbar switch, deciding the order in which packets will be served. Previous results have shown that with a suitable scheduling algorithm, 100% throughput can be achieved. In this paper, we present a scheduling algorithm called iSLIP. An iterative, round-robin algorithm, iSLIP can achieve 100% throughput for uniform traffic, yet is simple to implement in hardware. Iterative and noniterative versions of the algorithms are presented, along with modified versions for prioritized traffic. Simulation results are presented to indicate the performance of iSLIP under benign and bursty traffic conditions. Prototype and commercial implementations of iSLIP exist in systems with aggregate bandwidths ranging from 50 to 500 Gb/s. When the traffic is nonuniform, iSLIP quickly adapts to a fair scheduling policy that is guaranteed never to starve an input queue. Finally, we describe the implementation complexity of iSLIP. Based on a two-dimensional (2-D) array of priority encoders, single-chip schedulers have been built supporting up to 32 ports, and making approximately 100 million scheduling decisions per second.", "authors": ["Nick McKeown"], "related_topics": ["2780768318", "29984679", "113200698"], "citation_count": "1669", "reference_count": "43", "references": ["2105818147", "2155303087", "2128796442", "2121523570", "2106522282", "2126169247", "1513400187", "2253956134", "2165551776", "2102396830"], "date": "1999"}, {"id": "2114772011", "title": "Media, tasks, and communication processes: a theory of media synchronicity", "abstract": "This paper expands, refines, and explicates media synchronicity theory, originally proposed in a conference proceeding in 1999 (Dennis and Valacich 1999). Media synchronicity theory (MST) focuses on the ability of media to support synchronicity, a shared pattern of coordinated behavior among individuals as they work together. We expand on the original propositions of MST to argue that communication is composed of two primary processes: conveyance and convergence. The familiarity of individuals with the tasks they are performing and with their coworkers will also affect the relative amounts of these two processes. Media synchronicity theory proposes that for conveyance processes, use of media supporting lower synchronicity should result in better communication performance. For convergence processes, use of media supporting higher synchronicity should result in better communication performance. We identify five capabilities of media (symbol sets, parallelism, transmission velocity, rehearsability, and reprocessability) that influence the development of synchronicity and thus the successful performance of conveyance and convergence communication processes. The successful completion of most tasks involving more than one individual requires both conveyance and convergence processes, thus communication performance will be improved when individuals use a variety of media to perform a task, rather than just one medium.", "authors": ["Alan R. Dennis", "Robert M. Fuller", "Joseph S. Valacich"], "related_topics": ["161394823", "136197465", "2780451532"], "citation_count": "1518", "reference_count": "125", "references": ["2108795964", "1487725643", "2576297379", "2108752510", "1741471588", "2169736278", "1981712955", "2024372407", "2133345793", "2172193860"], "date": "2008"}, {"id": "2054141820", "title": "Matrix Factorization Techniques for Recommender Systems", "abstract": "As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.", "authors": ["Y. Koren", "R. Bell", "C. Volinsky"], "related_topics": ["42355184", "557471498", "2778459887"], "citation_count": "8769", "reference_count": "10", "references": ["1994389483", "2137245235", "2101409192", "2341535507", "1966553486", "2057763140", "2172249709", "1832221731", "1511814458", "2056760161"], "date": "2009"}, {"id": "2089857781", "title": "A complexity theory based on Boolean algebra", "abstract": "A projection of a Boolean function is a function obtained by substituting for each of its variables a variable, the negation of a variable, or a constant. Reducibilities among computational problems under this relation of projection are considered. It is shown that much of what is of everyday relevance in Turing-machine-based complexity theory can be replicated easily and naturally in this elementary framework. Finer distinctions about the computational relationships among natural problems can be made than in previous formulations and some negative results are proved.", "authors": ["S. Skyum", "L. G. Valiant"], "related_topics": ["9429942", "141796577", "187455244"], "citation_count": "193", "reference_count": "24", "references": ["1975442866", "2036265926", "1530753374", "2033040247", "1535681052", "1982129592", "1533538517", "2113097540", "2170831059", "1999647826"], "date": "1985"}, {"id": "2078455576", "title": "Principal Components Analysis", "abstract": "Introduction Basic Concepts of Principal Components Geometrical Properties of Principal Components Decomposition Properties of Principal Components Principal Components of Patterned Correlation Matrices Rotation of Principal Components Using Principal Components to Select a Subset of Variables Principal Components Versus Factor Analysis Uses of Principal Components in Regression Analysis Using Principal Components to Detect Outlying and Influential Observations Use of Principal Components in Cluster Analysis Use of Principal Components Analysis in Conjunction with Other Multivariate Analysis Procedures Other Techniques Related to Principal Components Summary and Conclusions", "authors": ["George H. Dunteman"], "related_topics": ["27438332", "152877465", "74050887"], "citation_count": "3305", "reference_count": "0", "references": ["2132914434", "1484750607", "2166091242", "2152820192", "2941196361", "1914762032", "2073309755", "640156484", "2164128765", "2126133171"], "date": "1988"}, {"id": "2097995023", "title": "Model-driven data acquisition in sensor networks", "abstract": "Declarative queries are proving to be an attractive paradigm for ineracting with networks of wireless sensors. The metaphor that \"the sensornet is a database\" is problematic, however, because sensors do not exhaustively represent the data in the real world. In order to map the raw sensor readings onto physical reality, a model of that reality is required to complement the readings. In this paper, we enrich interactive sensor querying with statistical modeling techniques. We demonstrate that such models can help provide answers that are both more meaningful, and, by introducing approximations with probabilistic confidences, significantly more efficient to compute in both time and energy. Utilizing the combination of a model and live data acquisition raises the challenging optimization problem of selecting the best sensor readings to acquire, balancing the increase in the confidence of our answer against the communication and data acquisition costs in the network. We describe an exponential time algorithm for finding the optimal solution to this optimization problem, and a polynomial-time heuristic for identifying solutions that perform well in practice. We evaluate our approach on several real-world sensor-network data sets, taking into account the real measured data and communication quality, demonstrating that our model-based approach provides a high-fidelity representation of the real phenomena and leads to significant performance gains versus traditional data acquisition techniques.", "authors": ["Amol Deshpande", "Carlos Guestrin", "Samuel R. Madden", "Joseph M. Hellerstein", "Wei Hong"], "related_topics": ["163985040", "24590314", "137836250"], "citation_count": "1536", "reference_count": "24", "references": ["2168452204", "2148251644", "2122410182", "2121255383", "2153259545", "1513861746", "2116687437", "2296677182", "1603054560", "2171776999"], "date": "2004"}, {"id": "2139338362", "title": "Stability and generalization", "abstract": "We define notions of stability for learning algorithms and show how to use these notions to derive generalization error bounds based on the empirical error and the leave-one-out error. The methods we use can be applied in the regression framework as well as in the classification one when the classifier is obtained by thresholding a real-valued function. We study the stability properties of large classes of learning algorithms such as regularization based algorithms. In particular we focus on Hilbert space regularization and Kullback-Leibler regularization. We demonstrate how to apply the results to SVM for regression and classification.", "authors": ["Olivier Bousquet", "Andr\u00e9 Elisseeff"], "related_topics": ["141718189", "5465570", "12267149"], "citation_count": "1472", "reference_count": "26", "references": ["2148603752", "2099111195", "2912934387", "1564947197", "1530699444", "2099579348", "2154952480", "2073738917", "2084544490", "2086472796"], "date": "2002"}, {"id": "1985650793", "title": "A handbook of child psychology", "abstract": "", "authors": ["Carl Murchison"], "related_topics": ["172712801", "15744967", "11171543"], "citation_count": "220", "reference_count": "0", "references": ["1542722502", "3121217189", "2124481923", "2160010213", "2147832001", "2164017768", "2090491342", "2022362374", "1706385572", "642299002"], "date": "1930"}, {"id": "2065301447", "title": "Markov Random Field Texture Models", "abstract": "We consider a texture to be a stochastic, possibly periodic, two-dimensional image field. A texture model is a mathematical procedure capable of producing and describing a textured image. We explore the use of Markov random fields as texture models. The binomial model, where each point in the texture has a binomial distribution with parameter controlled by its neighbors and ``number of tries'' equal to the number of gray levels, was taken to be the basic model for the analysis. A method of generating samples from the binomial model is given, followed by a theoretical and practical analysis of the method's convergence. Examples show how the parameters of the Markov random field control the strength and direction of the clustering in the image. The power of the binomial model to produce blurry, sharp, line-like, and blob-like textures is demonstrated. Natural texture samples were digitized and their parameters were estimated under the Markov random field model. A hypothesis test was used for an objective assessment of goodness-of-fit under the Markov random field model. Overall, microtextures fit the model well. The estimated parameters of the natural textures were used as input to the generation procedure. The synthetic microtextures closely resembled their real counterparts, while the regular and inhomogeneous textures did not.", "authors": ["George R. Cross", "Anil K. Jain"], "related_topics": ["2778045648", "163836022", "54907487"], "citation_count": "2084", "reference_count": "38", "references": ["2044465660", "2059432853", "2179295257", "2130355536", "2063087073", "2056760934", "2117395697", "1988445395", "2120587770", "2542718019"], "date": "1982"}, {"id": "2987803397", "title": "The C++ Programming Language", "abstract": "From the Publisher: Written by Bjarne Stroustrup, the creator of C, this is the world's most trusted and widely read book on C. For this special hardcover edition, two new appendixes on locales and standard library exception safety have been added. The result is complete, authoritative coverage of the C language, its standard library, and key design techniques. Based on the ANSI/ISO C standard, The C Programming Language provides current and comprehensive coverage of all C language features and standard library components. For example: abstract classes as interfaces class hierarchies for object-oriented programming templates as the basis for type-safe generic software exceptions for regular error handling namespaces for modularity in large-scale software run-time type identification for loosely coupled systems the C subset of C for C compatibility and system-level work standard containers and algorithms standard strings, I/O streams, and numerics C compatibility, internationalization, and exception safety Bjarne Stroustrup makes C even more accessible to those new to the language, while adding advanced information and techniques that even expert C programmers will find invaluable.", "authors": ["Bjarne Stroustrup"], "related_topics": ["189384598", "114822604", "2777864811"], "citation_count": "11049", "reference_count": "0", "references": ["2056279562", "2580035316", "1971903460", "1610570299", "2136310957", "1997841190", "2786741601", "2169180789", "2167482691", "2110187357"], "date": "1984"}, {"id": "2113341759", "title": "Face recognition: features versus templates", "abstract": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >", "authors": ["R. Brunelli", "T. Poggio"], "related_topics": ["88799230", "14551309", "158096908"], "citation_count": "4190", "reference_count": "28", "references": ["2138451337", "1770825568", "2143956139", "2135463994", "2135346934", "2055712799", "1548502347", "2086479969", "2090196588", "2032361618"], "date": "1993"}, {"id": "90568776", "title": "PETSc Users Manual", "abstract": "The Portable, Extensible Toolkit for Scientific Computation (PETSc), is a suite of data structures and routines for the scalable (parallel) solution of scientific applications modeled by partial differential equations. It supports MPI, and GPUs through CUDA or OpenCL, as well as hybrid MPI-GPU parallelism. PETSc (sometimes called PETSc/Tao) also contains the Tao optimization software library.", "authors": ["S Balay", "S Abhyankar", "M Adams", "J Brown", "P Brune", "K Buschelman", "L Dalcin", "A Dener", "Eijkhout", "W Gropp", "D Karpeyev", "D Kaushik", "M Knepley", "D May", "L Curfman McInnes", "R Mills", "T Munson", "K Rupp", "P Sanan", "B Smith", "S Zampini", "H Zhang"], "related_topics": ["2778119891", "2781172179", "162319229"], "citation_count": "4243", "reference_count": "18", "references": ["1575350781", "1510543252", "2140153041", "2155216327", "2068484625", "1542243431", "1569090332", "2021810545", "2084073638", "2048369486"], "date": "2018"}, {"id": "2142505685", "title": "Constructivist Approaches to Learning in Science and Their Implications for Science Pedagogy: A Literature Review", "abstract": "This paper draws attention to the literature in the areas of learning, specifically, constructivism, conceptual change and cognitive development. It emphasizes the contribution of such research to our understanding of the learning process. This literature provides guidelines for teachers, at all levels, in their attempt to have their students achieve learning with understanding. Research about the constructive nature of students\u2019 learning processes, about students\u2019 mental models, and students\u2019 misconceptions have important implications for teachers who wish to model scientific reasoning in an effective fashion for their students. This paper aims to communicate this research to teachers, textbook authors, and college professors who involved in the preparation of science teachers. This paper is divided into two major parts. The first part concentrates on a critical review of the three most influential learning theories and constructivist view of learning and discusses the foundation upon which the constructivist theory of learning has been rooted. It seeks an answer to the question of \u201cWhat are some guiding principles of constructivist thinking that we must keep in mind when we consider our role as science teachers?\u201d. The second part of this paper moves toward describing the nature of students\u2019 alternative conceptions, the ways of changing cognitive structure, and cognitive aspects of learning and teaching science.", "authors": ["Mustafa Cakir"], "related_topics": ["25260931", "96427005", "26258499"], "citation_count": "437", "reference_count": "38", "references": ["2135943618", "2753533763", "2112959653", "1989748540", "253172632", "2044653300", "2124567236", "2036942355", "2569865790", "3021183163"], "date": "2008"}, {"id": "2250539671", "title": "Glove: Global Vectors for Word Representation", "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.", "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning"], "related_topics": ["2776461190", "2777462759", "56372850"], "citation_count": "21544", "reference_count": "28", "references": ["2153579005", "1614298861", "2146502635", "2158899491", "2072128103", "2117130368", "2141599568", "2132339004", "2118020653", "2158139315"], "date": "2014"}, {"id": "2963470893", "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network", "abstract": "Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.", "authors": ["Christian Ledig", "Lucas Theis", "Ferenc Huszar", "Jose Caballero", "Andrew Cunningham", "Alejandro Acosta", "Andrew Aitken", "Alykhan Tejani", "Johannes Totz", "Zehan Wang", "Wenzhe Shi"], "related_topics": ["63099799", "205372480", "81363708"], "citation_count": "5688", "reference_count": "68", "references": ["2194775991", "2618530766", "2962835968", "2964121744", "2097117768", "1836465849", "2117539524", "2099471712", "1677182931", "1849277567"], "date": "2017"}, {"id": "1562979145", "title": "Optimal decoding of linear codes for minimizing symbol error rate", "abstract": "", "authors": ["L. R. Bahl"], "related_topics": ["78944582", "74645175", "67692717"], "citation_count": "9075", "reference_count": "0", "references": ["2137813581", "2121606987", "2155174176", "2135764410", "2112772743", "2146694142", "2101394529", "2138208223", "2102251435", "2108656301"], "date": "1973"}, {"id": "2052334067", "title": "A Survey of Recent Results in Networked Control Systems", "abstract": "Networked control systems (NCSs) are spatially distributed systems for which the communication between sensors, actuators, and controllers is supported by a shared communication network. We review several recent results on estimation, analysis, and controller synthesis for NCSs. The results surveyed address channel limitations in terms of packet-rates, sampling, network delay, and packet dropouts. The results are presented in a tutorial fashion, comparing alternative methodologies", "authors": ["J.P. Hespanha", "P. Naghshtabrizi", "Yonggang Xu"], "related_topics": ["1759631", "152623178", "79699506"], "citation_count": "4090", "reference_count": "74", "references": ["2152520525", "1506119886", "2164522996", "1988098342", "2128969277", "2155024125", "2156216606", "2159826786", "1801704802", "2008151824"], "date": "2007"}, {"id": "2137813581", "title": "Factor graphs and the sum-product algorithm", "abstract": "Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of \"local\" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph, In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative \"turbo\" decoding algorithm, Pearl's (1988) belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms.", "authors": ["F.R. Kschischang", "B.J. Frey", "H.-A. Loeliger"], "related_topics": ["159246509", "196455857", "152948882"], "citation_count": "7543", "reference_count": "29", "references": ["2125838338", "2121606987", "2011039300", "2135764410", "1559536185", "2171265988", "1593793857", "7241855", "2129031807", "2150218618"], "date": "2001"}, {"id": "2419410066", "title": "Excitation, inhibition and coordination of cortical neurones.", "abstract": "", "authors": ["Jung R"], "related_topics": ["12554922", "86803240", "3018423376"], "citation_count": "22", "reference_count": "0", "references": ["939569654", "2103212315", "2059282215", "1503309142", "2153064551", "2737177917", "2394502729", "2060366807", "2037347995", "1979030748"], "date": "1957"}, {"id": "2129113961", "title": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm", "abstract": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space.", "authors": ["Nick Littlestone"], "related_topics": ["112972136", "247160", "158465420"], "citation_count": "2310", "reference_count": "17", "references": ["1652505363", "3017143921", "2019363670", "2154952480", "2139709458", "2009207944", "2070902649", "2066789935", "2061079066", "2029538739"], "date": "1988"}, {"id": "2913459036", "title": "Model checking", "abstract": "", "authors": ["E. Clarke", "O. Grumberg", "D. Long"], "related_topics": ["30888246", "110251889", "23123167"], "citation_count": "12738", "reference_count": "0", "references": ["2340735175", "1882012874", "2076285066", "2121805588", "2295903414", "1549166962", "2151164148", "2158914121", "2027986690", "2121337044"], "date": "1996"}, {"id": "2143842064", "title": "Ultra-High Capacity WDM Transmission Using Spectrally-Efficient PDM 16-QAM Modulation and C- and Extended L-Band Wideband Optical Amplification", "abstract": "This paper describes ultrahigh capacity transmission based on spectrally-efficient multi-level modulation and wideband optical amplification techniques. 21.4-Gbaud polarization-division multiplexed (PDM) 16-ary quadrature amplitude modulation (QAM) signals are generated by utilizing an optical synthesis technique, wavelength-multiplexed with 25-GHz spacing by optical pre-filtering, and received by an intradyne coherent receiver based on digital signal processing (DSP) with pilotless algorithms. These techniques realize a spectral efficiency (SE) of 6.4 b/s/Hz. Furthermore, a hybrid amplification technique that combines distributed Raman and dual-band erbium-doped amplifiers (EDFAs) realizes 10.8-THz signal bandwidth in C- and extended L-bands. By using these techniques, we successfully demonstrate 69.1 Tb/s transmission over 240 km of low loss pure silica core fibers.", "authors": ["Akihide Sano", "Hiroji Masuda", "Takayuki Kobayashi", "Masamichi Fujiwara", "Kengo Horikoshi", "Eiji Yoshida", "Yutaka Miyamoto", "Munehiro Matsui", "Masato Mizoguchi", "Hiroshi Yamazaki", "Yohei Sakamaki", "Hiroyuki Ishii"], "related_topics": ["50831002", "32409245", "2781393691"], "citation_count": "84", "reference_count": "34", "references": ["2102049403", "2129940694", "2123952224", "2045334278", "2145060714", "2150268976", "2000065113", "1572872292", "2130130244", "1799301229"], "date": "2011"}, {"id": "2070942956", "title": "The crystallographic information file (CIF) : a new standard archive file for crystallography", "abstract": "The specification of a new standard Crystallographic Information File (CIF) is described. Its development is based on the Self-Defining Text Archive and Retrieval (STAR) procedure [Hall (1991). J. Chem. Inf. Comput. Sci. 31, 326-333]. The CIF is a general, flexible and easily extensible free-format archive file; it is human and machine readable and can be edited by a simple text editor. The CIF is designed for the electronic transmission of crystallographic data between individual laboratories, journals and databases: it has been adopted by the International Union of Crystallography as the recommended medium for this purpose. The file consists of data names and data items, together with a loop facility for repeated items. The data names, constructed hierarchically so as to form data categories, are self-descriptive within a 32-character limit. The sorted list of data names, together with their precise definitions, constitutes the CIF Dictionary (Core Version 1991). The CIF Core Dictionary is presented in full and covers the fundamental and most commonly used data items relevant to crystal structure analysis. The Dictionary is also available as an electronic file suitable for CIF computer applications. Future extensions to the Dictionary will include data items used in more specialized areas of crystallography.", "authors": ["S.R. Hall", "F.H. Allen", "I.D. Brown"], "related_topics": ["117170267", "2778317086", "2781435461"], "citation_count": "500", "reference_count": "0", "references": ["1969360633", "2145538332", "2031158103", "2059205366", "2063334178", "2319902168", "2028056984", "2166689829", "2032842297", "2070227796"], "date": "1991"}, {"id": "1530753374", "title": "Graphs and hypergraphs", "abstract": "", "authors": ["C. Berge"], "related_topics": ["41008148", "114614502"], "citation_count": "5022", "reference_count": "0", "references": ["2611515161", "2114507260", "3037946710", "2486715098", "2120970098", "2064650227", "1988245022", "2107990165", "2078174680", "3035258118"], "date": "1972"}, {"id": "1973828215", "title": "XRANK: ranked keyword search over XML documents", "abstract": "We consider the problem of efficiently producing ranked results for keyword search queries over hyperlinked XML documents. Evaluating keyword search queries over hierarchical XML documents, as opposed to (conceptually) flat HTML documents, introduces many new challenges. First, XML keyword search queries do not always return entire documents, but can return deeply nested XML elements that contain the desired keywords. Second, the nested structure of XML implies that the notion of ranking is no longer at the granularity of a document, but at the granularity of an XML element. Finally, the notion of keyword proximity is more complex in the hierarchical XML data model. In this paper, we present the XRANK system that is designed to handle these novel features of XML keyword search. Our experimental results show that XRANK offers both space and performance benefits when compared with existing approaches. An interesting feature of XRANK is that it naturally generalizes a hyperlink based HTML search engine such as Google. XRANK can thus be used to query a mix of HTML and XML documents.", "authors": ["Lin Guo", "Feng Shao", "Chavdar Botev", "Jayavel Shanmugasundaram"], "related_topics": ["55348073", "44883583", "68699486"], "citation_count": "1259", "reference_count": "33", "references": ["3013264884", "2138621811", "2109464129", "2666600683", "1833785989", "2169624745", "2121350579", "2098388305", "1671881141", "2084243240"], "date": "2003"}, {"id": "1575528222", "title": "Faithfulness and reduplicative identity", "abstract": "", "authors": ["John J. McCarthy", "Alan S. Prince"], "related_topics": ["2779511057", "196368558", "2776134746"], "citation_count": "3860", "reference_count": "64", "references": ["207108878", "2607317773", "1598851216", "2152134037", "1546485226", "1518451176", "2064318101", "1590251447", "2111523402", "1579937068"], "date": "1994"}, {"id": "1971167516", "title": "The nature of managerial work", "abstract": "1. Introduction. 2. Contemporary Views of the Manager's Job. 3. Some Distinguishing Characteristics of Managerial Work. 4. The Manager's Working Roles. 5. Variations in Managers' Work. 6. Science and the Manager's Job. 7. The Future of Managerial Work. Appendix A: Major Studies of the Manager's Job. Appendix B: Seven Research Methods Used to Study Managerial Work. Appendix C: A Study of the Work of Five Chief Executives.", "authors": ["Henry Mintzberg"], "related_topics": ["176500657", "187736073", "39549134"], "citation_count": "14698", "reference_count": "0", "references": ["2108183214", "2136407476", "2134049161", "2065231053", "2911311425", "2028179265", "2133527607", "2100493403", "2111023775", "2127709152"], "date": "1972"}, {"id": "2110096996", "title": "Projected Gradient Methods for Nonnegative Matrix Factorization", "abstract": "Nonnegative matrix factorization (NMF) can be formulated as a minimization problem with bound constraints. Although bound-constrained optimization has been studied extensively in both theory and practice, so far no study has formally applied its techniques to NMF. In this letter, we propose two projected gradient methods for NMF, both of which exhibit strong optimization properties. We discuss efficient implementations and demonstrate that one of the proposed methods converges faster than the popular multiplicative update approach. A simple Matlab code is also provided.", "authors": ["Chih-Jen Lin"], "related_topics": ["115680565", "152671427", "55660270"], "citation_count": "1979", "reference_count": "38", "references": ["1902027874", "2798766386", "3143596294", "2150102617", "2118718620", "2135029798", "2013029404", "2136787567", "2116216716", "2059745395"], "date": "2007"}, {"id": "1968211101", "title": "Interacting with paper on the DigitalDesk", "abstract": "", "authors": ["Pierre Wellner"], "related_topics": ["40458791", "107457646", "41008148"], "citation_count": "1724", "reference_count": "86", "references": ["1647826363", "3004157836", "2086928636", "2622928986", "1983808135", "2154741421", "137024741", "2023331673", "3100816363", "2141496966"], "date": "1993"}, {"id": "2143635578", "title": "Development of a Spelling List", "abstract": "The word list used by the UNIX spelling checker, SPELL, was developed from many sources over several years. As the spelling checker may be used on minicomputers, it is important to make the list as compact as possible. Stripping prefixes and suffixes reduces the list below one third of its original size, hashing discards 60 percent of the bits that remain, and data compression halves it once again. This paper tells how the spelling checker works, how the words were chosen, how the spelling checker was used to improve itself, and how the (reduced) list of 30000 English words was squeezed into 26000 16-bit machine words.", "authors": ["M. McIlroy"], "related_topics": ["2777801307", "141603448", "99138194"], "citation_count": "183", "reference_count": "13", "references": ["2752853835", "2099964107", "2123845384", "2007780422", "2111192396", "2073578568", "788498898", "2114700786", "2030442875", "2115613939"], "date": "1981"}, {"id": "2143516773", "title": "Fast approximate energy minimization via graph cuts", "abstract": "Many tasks in computer vision involve assigning a label (such as disparity) to every pixel. A common constraint is that the labels should vary smoothly almost everywhere while preserving sharp discontinuities that may exist, e.g., at object boundaries. These tasks are naturally stated in terms of energy minimization. The authors consider a wide class of energies with various smoothness constraints. Global minimization of these energy functions is NP-hard even in the simplest discontinuity-preserving case. Therefore, our focus is on efficient approximation algorithms. We present two algorithms based on graph cuts that efficiently find a local minimum with respect to two types of large moves, namely expansion moves and swap moves. These moves can simultaneously change the labels of arbitrarily large sets of pixels. In contrast, many standard algorithms (including simulated annealing) use small moves where only one pixel changes its label at a time. Our expansion algorithm finds a labeling within a known factor of the global minimum, while our swap algorithm handles more general energy functions. Both of these algorithms allow important cases of discontinuity preserving energies. We experimentally demonstrate the effectiveness of our approach for image restoration, stereo and motion. On real data with ground truth, we achieve 98 percent accuracy.", "authors": ["Y. Boykov", "O. Veksler", "R. Zabih"], "related_topics": ["12229352", "148764684", "185690422"], "citation_count": "10570", "reference_count": "47", "references": ["2121947440", "2104095591", "1997063559", "1977545325", "2113137767", "2620619910", "2121781154", "2913192828", "1554544485", "1649464328"], "date": "2001"}, {"id": "2135943618", "title": "Mind in Society: The Development of Higher Psychological Processes", "abstract": "Introduction Michael Cole and Sylvia Scribner Biographical Note on L. S. Vygotsky Basic Theory and Data 1. Tool and Symbol in Child Development 2. The Development of Perception and Attention 3. Mastery of Memory and Thinking 4. Internalization of Higher Psychological Functions 5. Problems of Method Educational Implications 6. Interaction between Learning and Development 7. The Role of Play in Development 8. The Prehistory of Written Language Afterword Vera John-Steiner and Ellen Souberman Notes Vygotsky's Works Index", "authors": ["Lev Vygotsky"], "related_topics": ["12338191", "2780971556", "92936396"], "citation_count": "126893", "reference_count": "0", "references": ["10833075", "2147454772", "2120832154", "2003970683", "2139894798", "2063077274", "1595732857", "2086235321", "635707828", "2104357911"], "date": "1977"}, {"id": "2154323564", "title": "Deadlock-Free Message Routing in Multiprocessor Interconnection Networks", "abstract": "A deadlock-free routing algorithm can be generated for arbitrary interconnection networks using the concept of virtual channels. A necessary and sufficient condition for deadlock-free routing is the absence of cycles in a channel dependency graph. Given an arbitrary network and a routing function, the cycles of the channel dependency graph can be removed by splitting physical channels into groups of virtual channels. This method is used to develop deadlock-free routing algorithms for k-ary n-cubes, for cube-connected cycles, and for shuffle-exchange networks.", "authors": ["Dally", "Seitz"], "related_topics": ["204948658", "89305328", "9659607"], "citation_count": "3318", "reference_count": "14", "references": ["1964602554", "1984520032", "2065742943", "1689272351", "2073491596", "1976284552", "1979418125", "2109053145", "1822842400", "2164687688"], "date": "1987"}, {"id": "2081681829", "title": "Recurrence plots for the analysis of complex systems", "abstract": "Abstract Recurrence is a fundamental property of dynamical systems, which can be exploited to characterise the system's behaviour in phase space. A powerful tool for their visualisation and analysis called recurrence plot was introduced in the late 1980's. This report is a comprehensive overview covering recurrence based methods and their applications with an emphasis on recent developments. After a brief outline of the theory of recurrences, the basic idea of the recurrence plot with its variations is presented. This includes the quantification of recurrence plots, like the recurrence quantification analysis, which is highly effective to detect, e. g., transitions in the dynamics of systems from time series. A main point is how to link recurrences to dynamical invariants and unstable periodic orbits. This and further evidence suggest that recurrences contain all relevant information about a system's behaviour. As the respective phase spaces of two systems change due to coupling, recurrence plots allow studying and quantifying their interaction. This fact also provides us with a sensitive tool for the study of synchronisation of complex systems. In the last part of the report several applications of recurrence plots in economy, physiology, neuroscience, earth sciences, astrophysics and engineering are shown. The aim of this work is to provide the readers with the know how for the application of recurrence plot based methods in their own field of research. We therefore detail the analysis of data and indicate possible difficulties and pitfalls.", "authors": ["Norbert Marwan", "M. Carmen Romano", "Marco Thiel", "J\u00fcrgen Kurths"], "related_topics": ["43456602", "173134143", "155773797"], "citation_count": "3079", "reference_count": "207", "references": ["1620414136", "1560013842", "1517729176", "1970442252", "2081817659", "111157985", "2030308994", "2041782669", "2022058405", "2969734899"], "date": "2006"}, {"id": "2064650227", "title": "On visual formalisms", "abstract": "The higraph, a general kind of diagramming object, forms a visual formalism of topological nature. Higraphs are suited for a wide array of applications to databases, knowledge representation, and, most notably, the behavioral specification of complex concurrent systems using the higraph-based language of statecharts.", "authors": ["David Harel"], "related_topics": ["2777630123", "161301231", "171018156"], "citation_count": "2002", "reference_count": "44", "references": ["3144368627", "2099529102", "2002089154", "2158046522", "2155843307", "2799004609", "2152475379", "2945526390", "2137865376", "2113355185"], "date": "1988"}, {"id": "1976460644", "title": "Habits of the Heart: Individualism and Commitment in American Life", "abstract": "Meanwhile, the authors' antidote to the American sicknessa quest for democratic community that draws on our diverse civic and religious traditionshas contributed to a vigorous scholarly and popular debate. Attention has been focused on forms of social organization, be it civil society, democratic communitarianism, or associative democracy, that can humanize the market and the administrative state. In their new Introduction the authors relate the argument of their book both to the current realities of American society and to the growing debate about the country's future. With this new edition one of the most influential books of recent times takes on a new immediacy.\"", "authors": ["Robert Neelly Bellah", "Richard Madsen", "William M. Sullivan", "Ann Swidler", "Steven M. Tipton"], "related_topics": ["2779281402", "513891491", "555826173"], "citation_count": "6604", "reference_count": "0", "references": ["2097780989", "1746951143", "2727415001", "2055684847", "1503247412", "414482142", "2006905596", "2086399807", "2113953571", "2088861238"], "date": "1984"}, {"id": "2068215597", "title": "Input apparatus and control method of input apparatus", "abstract": "An input apparatus has a touch sensor for receiving an input, a load detection unit for detecting a pressure load on a touch face of the touch sensor, a tactile sensation providing unit for vibrating the touch face, and a control unit, when the pressure load detected by the load detection unit satisfies a standard for providing a tactile sensation, for controlling drive of the tactile sensation providing unit to vibrate the touch face at a frequency such that a click sensation is provided to an object (means) pressing the touch face. Thereby, a realistic click sensation similar to that obtained when a push-button switch is operated is provided when an operator operates the touch sensor.", "authors": ["Tomotake Aono"], "related_topics": ["81988521", "130093455", "205068"], "citation_count": "171", "reference_count": "88", "references": ["2107118797", "1953780116", "1973922175", "2147807235", "2170150948", "1893741530", "1033150858", "2856567270", "2741719482", "2155329499"], "date": "2010"}, {"id": "2117812871", "title": "Pattern recognition and neural networks", "abstract": "From the Publisher: Pattern recognition has long been studied in relation to many different (and mainly unrelated) applications, such as remote sensing, computer vision, space research, and medical imaging. In this book Professor Ripley brings together two crucial ideas in pattern recognition; statistical methods and machine learning via neural networks. Unifying principles are brought to the fore, and the author gives an overview of the state of the subject. Many examples are included to illustrate real problems in pattern recognition and how to overcome them.This is a self-contained account, ideal both as an introduction for non-specialists readers, and also as a handbook for the more expert reader.", "authors": ["Brian D. Ripley", "N. L. Hjort"], "related_topics": ["40608802", "44868376", "153180895"], "citation_count": "9263", "reference_count": "102", "references": ["2156909104", "1554663460", "2119821739", "3124955340", "2912934387", "1679913846", "2112076978", "2046079134", "2147800946", "1536929369"], "date": "1995"}, {"id": "2132081716", "title": "The Relational View: Cooperative Strategy and Sources of Interorganizational Competitive Advantage", "abstract": "In this article we offer a view that suggests that a firm's critical resources may span firm boundaries and may be embedded in interfirm resources and routines. We argue that an increasingly important unit of analysis for understanding competitive advantage is the relationship between firms and identify four potential sources of interorganizational competitive advantage: (1) relation-specific assets, (2) knowledge-sharing routines, (3) complementary resources/capabilities, and (4) effective governance. We examine each of these potential sources of rent in detail, identifying key subprocesses, and also discuss the isolating mechanisms that serve to preserve relational rents. Finally, we discuss how the relational view may offer normative prescriptions for firm-level strategies that contradict the prescriptions offered by those with a resource-based view or industry structure view.", "authors": ["Jeffrey H. Dyer", "Harbir Singh"], "related_topics": ["2779136266", "58546491", "2779445257"], "citation_count": "16967", "reference_count": "91", "references": ["2061977616", "3121398446", "3121147769", "2108795964", "2118549945", "2986921706", "1999410909", "2566856888", "3121584743", "1580880025"], "date": "1998"}, {"id": "2070722739", "title": "Complex networks: Structure and dynamics", "abstract": "Coupled biological and chemical systems, neural networks, social interacting species, the Internet and the World Wide Web, are only a few examples of systems composed by a large number of highly interconnected dynamical units. The first approach to capture the global properties of such systems is to model them as graphs whose nodes represent the dynamical units, and whose links stand for the interactions between them. On the one hand, scientists have to cope with structural issues, such as characterizing the topology of a complex wiring architecture, revealing the unifying principles that are at the basis of real networks, and developing models to mimic the growth of a network and reproduce its structural properties. On the other hand, many relevant questions arise when studying complex networks\u2019 dynamics, such as learning how a large ensemble of dynamical systems that interact through a complex wiring topology can behave collectively. We review the major concepts and results recently achieved in the study of the structure and dynamics of complex networks, and summarize the relevant applications of these ideas in many different disciplines, ranging from nonlinear science to biology, from statistical mechanics to medicine and engineering. \u00a9 2005 Elsevier B.V. All rights reserved.", "authors": ["S. Boccaletti", "V. Latora", "", "Y. Moreno", "M. Chavez", "D.-U. Hwang"], "related_topics": ["123757187", "34947359", "151915977"], "citation_count": "11012", "reference_count": "500", "references": ["3145128584", "2112090702", "2008620264", "2148606196", "2124637492", "2095293504", "2798909945", "2581275558", "2065769502", "2011039300"], "date": "2006"}, {"id": "2167920923", "title": "Ant colonies for the travelling salesman problem", "abstract": "We describe an artificial ant colony capable of solving the travelling salesman problem (TSP). Ants of the artificial colony are able to generate successively shorter feasible tours by using information accumulated in the form of a pheromone trail deposited on the edges of the TSP graph. Computer simulations demonstrate that the artificial ant colony is capable of generating good solutions to both symmetric and asymmetric instances of the TSP. The method is an example, like simulated annealing, neural networks and evolutionary computation, of the successful use of a natural metaphor to design an optimization algorithm.", "authors": ["Marco Dorigo", "Luca Maria Gambardella"], "related_topics": ["40128228", "60891933", "175859090"], "citation_count": "3096", "reference_count": "22", "references": ["2107941094", "1557517019", "32403112", "1717440967", "2051719061", "2042986967", "1566652554", "2013561074", "1971700807", "1970193303"], "date": "1997"}, {"id": "2131842403", "title": "Motion history image: its variants and applications", "abstract": "The motion history image (MHI) approach is a view-based temporal template method which is simple but robust in representing movements and is widely employed by various research groups for action recognition, motion analysis and other related applications. In this paper, we provide an overview of MHI-based human motion recognition techniques and applications. Since the inception of the MHI template for motion representation, various approaches have been adopted to improve this basic MHI technique. We present all important variants of the MHI method. This paper points some areas for further research based on the MHI method and its variants.", "authors": ["Md. Atiqur Rahman Ahad", "J. K. Tan", "H. Kim", "S. Ishikawa"], "related_topics": ["2776683197", "2777036941", "153180895"], "citation_count": "350", "reference_count": "157", "references": ["2161969291", "2102625004", "2140235142", "2034328688", "2132549764", "2533739470", "2482402870", "2114701396", "1499877760", "2020163092"], "date": "2012"}, {"id": "2118828104", "title": "Monitoring streams: a new class of data management applications", "abstract": "This paper introduces monitoring applications, which we will show differ substantially from conventional business data processing. The fact that a software system must process and react to continual inputs from many sources (e.g., sensors) rather than from human operators requires one to rethink the fundamental architecture of a DBMS for this application area. In this paper, we present Aurora, a new DBMS that is currently under construction at Brandeis University, Brown University, and M.I.T. We describe the basic system architecture, a stream-oriented set of operators, optimization tactics, and support for real-time operation.", "authors": ["Don Carney", "U\u01e7ur \u00c7etintemel", "Mitch Cherniack", "Christian Convey", "Sangdon Lee", "Greg Seidman", "Michael Stonebraker", "Nesime Tatbul", "Stan Zdonik"], "related_topics": ["41065761", "94070970", "98025372"], "citation_count": "1327", "reference_count": "29", "references": ["2132461362", "2203361072", "2135499008", "2296677182", "1749554492", "2169593628", "2132520482", "2140393476", "1943411325", "2081189989"], "date": "2002"}, {"id": "1979819178", "title": "Computer Recognition of Handwritten Numerals by Polygonal Approximations", "abstract": "The outlines of handwritten numerals are approximated by polygons using a method previously developed by Pavlidis and Horowitz [10]. This enables a simple evaluation of many intuitively descriptive features for numerals, for example, relative position and type of concave arcs. The method was tested on the Munson data (IEEE Data Base 1.2.2), and an overall error rate of 9.4 percent was achieved without any statistical optimization. A characteristic property of this approach is the existence of two steps: the first step (primitive feature generation) is primarily numerical, and the second step (feature selection and classification) makes extensive use of semantics.", "authors": ["Theodosios Pavlidis", "Farhat Ali"], "related_topics": ["112640561", "148483581", "40969351"], "citation_count": "176", "reference_count": "16", "references": ["2122827492", "2043735243", "2020187819", "2170633497", "2104846262", "2122741244", "1566833591", "2097486270", "2030721489", "2157456528"], "date": "1975"}, {"id": "2114839088", "title": "SafeVchat: detecting obscene content and misbehaving users in online video chat services", "abstract": "Online video chat services such as Chatroulette, Omegle, and vChatter that randomly match pairs of users in video chat sessions are fast becoming very popular, with over a million users per month in the case of Chatroulette. A key problem encountered in such systems is the presence of flashers and obscene content. This problem is especially acute given the presence of underage minors in such systems. This paper presents SafeVchat, a novel solution to the problem of flasher detection that employs an array of image detection algorithms. A key contribution of the paper concerns how the results of the individual detectors are fused together into an overall decision classifying the user as misbehaving or not, based on Dempster-Shafer Theory. The paper introduces a novel, motion-based skin detection method that achieves significantly higher recall and better precision. The proposed methods have been evaluated over real-world data and image traces obtained from Chatroulette.com.", "authors": ["Xinyu Xing", "Yu-Li Liang", "Hanqiang Cheng", "Jianxun Dang", "Sui Huang", "Richard Han", "Xue Liu", "Qin Lv", "Shivakant Mishra"], "related_topics": ["200632571", "49774154", "41008148"], "citation_count": "19", "reference_count": "23", "references": ["3124955340", "1973948212", "2111993661", "2046589280", "2153746365", "2078088780", "2797148637", "1981673219", "2127744755", "2063965450"], "date": "2011"}, {"id": "2169706611", "title": "Cg: a system for programming graphics hardware in a C-like language", "abstract": "The latest real-time graphics architectures include programmable floating-point vertex and fragment processors, with support for data-dependent control flow in the vertex processor. We present a programming language and a supporting system that are designed for programming these stream processors. The language follows the philosophy of C, in that it is a hardware-oriented, general-purpose language, rather than an application-specific shading language. The language includes a variety of facilities designed to support the key architectural features of programmable graphics processors, and is designed to support multiple generations of graphics architectures with different levels of functionality. The system supports both of the major 3D graphics APIs: OpenGL and Direct3D. This paper identifies many of the choices that we faced as we designed the system, and explains why we made the decisions that we did.", "authors": ["William R. Mark", "R. Steven Glanville", "Kurt Akeley", "Mark J. Kilgard"], "related_topics": ["18670160", "570499", "124577441"], "citation_count": "924", "reference_count": "29", "references": ["2987803397", "1544623790", "1568192366", "1579198843", "2118688057", "1548638602", "2611598995", "2067166017", "2178948257", "2111394443"], "date": "2003"}, {"id": "2135346934", "title": "Introduction to Statistical Pattern Recognition", "abstract": "This completely revised second edition presents an introduction to statistical pattern recognition. Pattern recognition in general covers a wide range of problems: it is applied to engineering problems, such as character readers and wave form analysis as well as to brain modeling in biology and psychology. Statistical decision and estimation, which are the main subjects of this book, are regarded as fundamental to the study of pattern recognition. This book is appropriate as a text for introductory courses in pattern recognition and as a reference book for workers in the field. Each chapter contains computer projects as well as exercises.", "authors": ["Keinosuke Fukunaga"], "related_topics": ["40608802", "153180895", "34127721"], "citation_count": "16249", "reference_count": "0", "references": ["2067191022", "2117812871", "1992419399", "2132103241", "2132549764", "2121601095", "2041823554", "2159128898", "2161160262", "2136040699"], "date": "1971"}, {"id": "3140179256", "title": "Control method and electronic apparatus", "abstract": "This application discloses a control method of electronic apparatus and an electronic apparatus, wherein the electronic apparatus includes a touch control unit, on which there is at least one operating icon. The control method comprises determining a first touch region corresponding to the at least one operating icon, wherein, an area of the first touch region is less than the area of the touch control unit; determining a second touch region on the touch control unit according to the first touch region, wherein, the second touch region is a region other than the first touch region on the touch control unit; generating a control instruction for making touch function of the second touch region to be in a disable status; and executing the control instruction to make the touch function of the second touch region to be in the disable status.", "authors": ["Guang Yang", "Na Ju", "Lifeng Fan", "Ke Shang", "Qi Li"], "related_topics": ["2909973361", "81988521", "9390403"], "citation_count": "4", "reference_count": "17", "references": ["1894920649", "2120823019", "1536912442", "2860077295", "2841543865", "2812158401", "2398697870", "2829115057", "2819467645", "2859919252"], "date": "2013"}, {"id": "2005198142", "title": "SmartSkin: an infrastructure for freehand manipulation on interactive surfaces", "abstract": "This paper introduces a new sensor architecture for making interactive surfaces that are sensitive to human hand and finger gestures. This sensor recognizes multiple hand positions and shapes and calculates the distance between the hand and the surface by using capacitive sensing and a mesh-shaped antenna. In contrast to camera-based gesture recognition systems, all sensing elements can be integrated within the surface, and this method does not suffer from lighting and occlusion problems. This paper describes the sensor architecture, as well as two working prototype systems: a table-size system and a tablet-size system. It also describes several interaction techniques that would be difficult to perform without using this architecture", "authors": ["Jun Rekimoto"], "related_topics": ["159437735", "207347870", "21822782"], "citation_count": "1400", "reference_count": "22", "references": ["2149891956", "2130851966", "1968211101", "2150874632", "2094982166", "2167686873", "1997556709", "2118041291", "2063812706", "2166175381"], "date": "2002"}, {"id": "271526086", "title": "Service innovation: a service-dominant logic perspective", "abstract": "In this article, we offer a broadened view of service innovation--one grounded in service-dominant logic--that transcends the tangible--intangible and producer--consumer divides that have plagued extant research in this area. Such a broadened conceptualization of service innovation emphasizes (1) innovation as a collaborative process occurring in an actor-to-actor (A2A) network, (2) service as the application of specialized competences for the benefit of another actor or the self and as the basis of all exchange, (3) the generativity unleashed by increasing resource liquefaction and resource density, and (4) resource integration as the fundamental way to innovate. Building on these core themes, we offer a tripartite framework of service innovation: (1) service ecosystems, as emergent A2A structures actors create and recreate through their effectual actions and which offer an organizing logic for the actors to exchange service and cocreate value; (2) service platforms, which enhance the efficiency and effectiveness of service exchange by liquefying resources and increasing resource density (facilitating easy access to appropriate resource bundles) and thereby serve as the venue for innovation; and (3) value cocreation, which views value as cocreated by the service offer(er) and the service beneficiary (e.g., customer) through resource integration and indicate the need for mechanisms to support the underlying roles and processes. In discussing these components, we consider the role of information technology--both as an operand resource and as an operant resource--and then examine the implications for research and practice in digitally enabled service innovation.", "authors": ["Robert F. Lusch", "Satish Nambisan"], "related_topics": ["61063171", "68595000", "3307092"], "citation_count": "1360", "reference_count": "116", "references": ["1551905080", "2135526934", "2133109597", "2126840412", "201578715", "2164284962", "2144981092", "2101419153", "2075284967", "1489109817"], "date": "2015"}, {"id": "2096578021", "title": "Toward a second-person neuroscience.", "abstract": "In spite of the remarkable progress made in the burgeoning field of social neuroscience, the neural mechanisms that underlie social encounters are only beginning to be studied and could-paradoxically-be seen as representing the \"dark matter\" of social neuroscience. Recent conceptual and empirical developments consistently indicate the need for investigations that allow the study of real-time social encounters in a truly interactive manner. This suggestion is based on the premise that social cognition is fundamentally different when we are in interaction with others rather than merely observing them. In this article, we outline the theoretical conception of a second-person approach to other minds and review evidence from neuroimaging, psychophysiological studies, and related fields to argue for the development of a second-person neuroscience, which will help neuroscience to really \"go social\"; this may also be relevant for our understanding of psychiatric disorders construed as disorders of social cognition.", "authors": ["Leonhard Schilbach", "Bert Timmermans", "Vasudevi Reddy", "Alan Costall", "Gary Bente", "Tobias Schlicht", "Kai Vogeley"], "related_topics": ["170320452", "32562604", "39394508"], "citation_count": "1361", "reference_count": "500", "references": ["2147264455", "2157619495", "2162010696", "1542722502", "2148764920", "2153791616", "2135943618", "2106980598", "2010931158", "2116146623"], "date": "2013"}, {"id": "2118371392", "title": "Robust and fast similarity search for moving object trajectories", "abstract": "An important consideration in similarity-based retrieval of moving object trajectories is the definition of a distance function. The existing distance functions are usually sensitive to noise, shifts and scaling of data that commonly occur due to sensor failures, errors in detection techniques, disturbance signals, and different sampling rates. Cleaning data to eliminate these is not always possible. In this paper, we introduce a novel distance function, Edit Distance on Real sequence (EDR) which is robust against these data imperfections. Analysis and comparison of EDR with other popular distance functions, such as Euclidean distance, Dynamic Time Warping (DTW), Edit distance with Real Penalty (ERP), and Longest Common Subsequences (LCSS), indicate that EDR is more robust than Euclidean distance, DTW and ERP, and it is on average 50% more accurate than LCSS. We also develop three pruning techniques to improve the retrieval efficiency of EDR and show that these techniques can be combined effectively in a search, increasing the pruning power significantly. The experimental results confirm the superior efficiency of the combined methods.", "authors": ["Lei Chen", "M. Tamer \u00d6zsu", "Vincent Oria"], "related_topics": ["44359876", "191787049", "120174047"], "citation_count": "1314", "reference_count": "40", "references": ["1971784203", "2160754664", "1499049447", "2147880780", "1853995153", "1541459201", "2133184712", "2163336863", "2042591571", "2036557187"], "date": "2005"}, {"id": "2074876593", "title": "Experiments on the determination of the relationships between terms", "abstract": "The retrieval effectiveness of an automatic method that uses relevance judgments for the determination of positive as well as negative relationships between terms is evaluated. The term relationships are incorporated into the retrieval process by using a generalized similarity function that has a term match component, a positive term relationship component, and a negative term relationship component. Two strategies, query partitioning and query clustering, for the evaluation of the effectiveness of the term relationships are investigated. The latter appears to be more attractive from linguistic as well as economic points of view. The positive and the negative relationships are verified to be effective both when used individually, and in combination. The importance attached to the term relationship components relative to that of term match component is found to have a substantial effect on the retrieval performance. The usefulness of discriminant analysis as a technique for determining the relative importance of these components is investigated.", "authors": ["Vijay V. Raghavan", "C. T. Yu"], "related_topics": ["22639730", "61797465", "69738355"], "citation_count": "27", "reference_count": "18", "references": ["3133917342", "3142071826", "1557757161", "2058089741", "2107668593", "1572870503", "2014706780", "2004913349", "1992081792", "2087404238"], "date": "1979"}, {"id": "1530699444", "title": "Estimation of Dependences Based on Empirical Data", "abstract": "Realism and Instrumentalism: Classical Statistics and VC Theory (1960-1980).- Falsifiability and Parsimony: VC Dimension and the Number of Entities (1980-2000).- Noninductive Methods of Inference: Direct Inference Instead of Generalization (2000-...).- The Big Picture.", "authors": ["Vladimir Naumovich Vapnik"], "related_topics": ["2776214188", "119322782", "177148314"], "citation_count": "5091", "reference_count": "0", "references": ["2137775453", "2119821739", "2139212933", "3124955340", "2119479037", "1964357740", "607505555", "2132549764", "2087347434", "1975846642"], "date": "2010"}, {"id": "3142604055", "title": "Capacitive input device", "abstract": "A capacitive input device includes a translucent substrate; first translucent electrode lines, extending in a first direction; second translucent electrode lines, extending in a second direction intersecting with the first direction; interlayer insulating layers; and relay electrodes. The first translucent electrode lines intersect with the second translucent electrode lines at intersecting portions. Portions of one of each first translucent electrode line and each second translucent electrode line are connected to each other with the intersecting portions. Portions of the other are separated from each other with the intersecting portions. The translucent interlayer insulating layers overlie the first or second translucent electrode line portions connected to each other with the intersecting portions. The translucent relay electrodes overlie the interlayer insulating layers to electrically connect the first or second translucent electrode line portions, separated from each other with the intersecting portions, to each other.", "authors": ["Mutsumi Matsuo"], "related_topics": ["17525397", "26710478", "2780142051"], "citation_count": "452", "reference_count": "12", "references": ["3139845981", "2108439668", "1505735841", "1552824375", "1951554264", "1526825361", "2835396430", "2252959402", "2874244399", "2739078936"], "date": "2008"}, {"id": "2071106922", "title": "Developments in automatic text retrieval.", "abstract": "Recent developments in the storage, retrieval, and manipulation of large text files are described. The text analysis problem is examined, and modern approaches leading to the identification and retrieval of selected text items in response to search requests are discussed.", "authors": ["Gerard Salton"], "related_topics": ["20228898", "182861755", "161156560"], "citation_count": "1016", "reference_count": "48", "references": ["1978394996", "2000672666", "2004131797", "2048045485", "2165612380", "2043909051", "2068632118", "3090556797", "2019087979", "2075006521"], "date": "1991"}, {"id": "3010781325", "title": "Estimating the asymptomatic proportion of coronavirus disease 2019 (COVID-19) cases on board the Diamond Princess cruise ship, Yokohama, Japan, 2020.", "abstract": "On 5 February 2020, in Yokohama, Japan, a cruise ship hosting 3,711 people underwent a 2-week quarantine after a former passenger was found with COVID-19 post-disembarking. As at 20 February, 634 persons on board tested positive for the causative virus. We conducted statistical modelling to derive the delay-adjusted asymptomatic proportion of infections, along with the infections' timeline. The estimated asymptomatic proportion was 17.9% (95% credible interval (CrI): 15.5-20.2%). Most infections occurred before the quarantine start.", "authors": ["Kenji Mizumoto", "", "Katsushi Kagaya", "", "Alexander Zarebski", "Gerardo Chowell"], "related_topics": ["2777910003", "2781402358", "116675565"], "citation_count": "1962", "reference_count": "20", "references": ["3001118548", "3006961006", "3008818676", "3004912618", "3006065484", "3012188173", "3006750069", "3023775996", "3033518790", "3014654669"], "date": "2020"}, {"id": "1993694278", "title": "Multiscale PCA with application to multivariate statistical process monitoring", "abstract": "Multiscale principal-component analysis (MSPCA) combines the ability of PCA to decorrelate the variables by extracting a linear relationship with that of wavelet analysis to extract deterministic features and approximately decorrelate autocorrelated measurements. MSPCA computes the PCA of wavelet coefficients at each scale and then combines the results at relevant scales. Due to its multiscale nature, MSPCA is appropriate for the modeling of data containing contributions from events whose behavior changes over time and frequency. Process monitoring by MSPCA involves combining only those scales where significant events are detected, and is equivalent to adaptively filtering the scores and residuals, and adjusting the detection limits for easiest detection of deterministic changes in the measurements. Approximate decorrelation of wavelet coefficients also makes MSPCA effective for monitoring autocorrelated measurements without matrix augmentation or time-series modeling. In addition to improving the ability to detect deterministic changes, monitoring by MSPCA also simultaneously extracts those features that represent abnormal operation. The superior performance of MSPCA for process monitoring is illustrated by several examples.", "authors": ["Bhavik R. Bakshi"], "related_topics": ["47432892", "27438332", "177860922"], "citation_count": "998", "reference_count": "45", "references": ["2132984323", "2098914003", "1965324089", "191129667", "2152820192", "2122538988", "1604810369", "2000858991", "1530872699", "1653130573"], "date": "1998"}, {"id": "2065769502", "title": "Error and attack tolerance of complex networks", "abstract": "Many complex systems display a surprising degree of tolerance against errors. For example, relatively simple organisms grow, persist and reproduce despite drastic pharmaceutical or environmental interventions, an error tolerance attributed to the robustness of the underlying metabolic network1. Complex communication networks2 display a surprising degree of robustness: although key components regularly malfunction, local failures rarely lead to the loss of the global information-carrying ability of the network. The stability of these and other complex systems is often attributed to the redundant wiring of the functional web defined by the systems' components. Here we demonstrate that error tolerance is not shared by all redundant systems: it is displayed only by a class of inhomogeneously wired networks, called scale-free networks, which include the World-Wide Web3,4,5, the Internet6, social networks7 and cells8. We find that such networks display an unexpected degree of robustness, the ability of their nodes to communicate being unaffected even by unrealistically high failure rates. However, error tolerance comes at a high price in that these networks are extremely vulnerable to attacks (that is, to the selection and removal of a few nodes that play a vital role in maintaining the network's connectivity). Such error tolerance and attack vulnerability are generic properties of communication networks.", "authors": ["Reka Albert", "Hawoong Jeong", "Albert L\u00e1szl\u00f3 Barab\u00e1si"], "related_topics": ["101142422", "34947359", "63540848"], "citation_count": "9889", "reference_count": "27", "references": ["2112090702", "2008620264", "1976969221", "2769133055", "2905110430", "2107252390", "2144885342", "3125161049", "1971788485", "1643412971"], "date": "2000"}, {"id": "2055654205", "title": "An efficient routing protocol for wireless networks", "abstract": "We present the Wireless Routing Protocol (WRP). In WRP, routing nodes communicate the distance and second-to-last hop for each destination. WRP reduces the number of cases in which a temporary routing loop can occur, which accounts for its fast convergence properties. A detailed proof of correctness is presented and its performance is compared by simulation with the performance of the distributed Bellman-Ford Algorithm (DBF), DUAL (a loop-free distance-vector algorithm) and an Ideal Link-state Algorithm (ILS), which represent the state of the art of internet routing. The simulation results indicate that WRP is the most efficient of the alternatives analyzed.", "authors": ["Shree Murthy", "J. J. Garcia-Luna-Aceves"], "related_topics": ["47318570", "189884158", "9659607"], "citation_count": "2220", "reference_count": "13", "references": ["2124651399", "1977439837", "2613173048", "2248064281", "2145721479", "2138760535", "1969057198", "2417828598", "1564531230", "1966441918"], "date": "1996"}, {"id": "2082102453", "title": "analysis of binary data", "abstract": "Binary response variables special logistical analyses some complications some related approaches more complex responses. Appendices: Theoretical background Choice of explanatory variables in multiple regression Review of computational aspects Further results and exercises.", "authors": ["D. R. Cox", "E. J. Snell"], "related_topics": ["2779190172", "48921125", "105795698"], "citation_count": "8872", "reference_count": "0", "references": ["1528905581", "2150865892", "2037139573", "3145077989", "2102201073", "2106578604", "2111578514", "2319962899", "2112621029", "2131987814"], "date": "1969"}, {"id": "109793532", "title": "Ethernet: distributed packet switching for local computer networks", "abstract": "Ethernet is a branching broadcast communication system for carrying digital data packets among locally distributed computing stations. The packet transport mechanism provided by Ethernet has been used to build systems which can be viewed as either local computer networks or loosely coupled multiprocessors. An Ethernet's shared communication facility, its Ether, is a passive broadcast medium with no central control. Coordination of access to the Ether for packet broadcasts is distributed among the contending transmitting stations using controlled statistical arbitration. Switching of packets to their destinations on the Ether is distributed among the receiving stations using packet address recognition. Design principles and implementation are described, based on experience with an operating Ethernet of 100 nodes along a kilometer of coaxial cable. A model for estimating performance under heavy loads and a packet protocol for error controlled communication are included for completeness.", "authors": ["R. M. Metcalfe", "D. R. Boggs"], "related_topics": ["205215620", "151898751", "151643298"], "citation_count": "2899", "reference_count": "0", "references": ["2163173102", "2121422684", "2165944385", "2090827962", "2254069673", "2155454189", "2120468807", "2158442834", "1975508847", "1578796610"], "date": "1988"}, {"id": "1755563775", "title": "Handbook of Blind Source Separation: Independent Component Analysis and Applications", "abstract": "Edited by the people who were forerunners in creating the field, together with contributions from 34 leading international experts, this handbook provides the definitive reference on Blind Source Separation, giving a broad and comprehensive description of all the core principles and methods, numerical algorithms and major applications in the fields of telecommunications, biomedical engineering and audio, acoustic and speech processing. Going beyond a machine learning perspective, the book reflects recent results in signal processing and numerical analysis, and includes topics such as optimization criteria, mathematical tools, the design of numerical algorithms, convolutive mixtures, and time frequency approaches. This Handbook is an ideal reference for university researchers, RD algebraic identification of under-determined mixtures, time-frequency methods, Bayesian approaches, blind identification under non negativity approaches, semi-blind methods for communicationsShows the applications of the methods to key application areas such as telecommunications, biomedical engineering, speech, acoustic, audio and music processing, while also giving a general method for developing applications", "authors": ["Pierre Comon", "Christian Jutten"], "related_topics": ["120317606", "61328038", "104267543"], "citation_count": "2014", "reference_count": "96", "references": ["2115755118", "2160547390", "2063978378", "2078204800", "2798909945", "2017761965", "2116148865", "2099641086", "2151693816", "2153233077"], "date": "2010"}, {"id": "2109970232", "title": "The transcriptional program in the response of human fibroblasts to serum.", "abstract": "The temporal program of gene expression during a model physiological response of human cells, the response of fibroblasts to serum, was explored with a complementary DNA microarray representing about 8600 different human genes. Genes could be clustered into groups on the basis of their temporal patterns of expression in this program. Many features of the transcriptional program appeared to be related to the physiology of wound repair, suggesting that fibroblasts play a larger and richer role in this complex multicellular response than had previously been appreciated.", "authors": ["Vishwanath R. Iyer", "Michael B. Eisen", "Douglas T. Ross", "Greg Schuler", "Troy Moore", "Jeffrey C. F. Lee", "Jeffrey M. Trent", "Louis M. Staudt", "James Hudson", "Mark S. Boguski", "Deval Lashkari", "Dari Shalon", "David Botstein", "Patrick O. Brown"], "related_topics": ["95371953", "104317684", "150194340"], "citation_count": "2587", "reference_count": "13", "references": ["2150926065", "1970156673", "238668910", "1994091239", "2068719237", "1964504843", "1986891966", "1968164578", "1971228457", "1607626977"], "date": "1998"}, {"id": "2137346077", "title": "Support Vector Machines: Training and Applications", "abstract": "The Support Vector Machine (SVM) is a new and very promising classification technique developed by Vapnik and his group at AT\\&T Bell Labs. This new learning algorithm can be seen as an alternative training technique for Polynomial, Radial Basis Function and Multi-Layer Perceptron classifiers. An interesting property of this approach is that it is an approximate implementation of the Structural Risk Minimization (SRM) induction principle. The derivation of Support Vector Machines, its relationship with SRM, and its geometrical insight, are discussed in this paper. Training a SVM is equivalent to solve a quadratic programming problem with linear and box constraints in a number of variables equal to the number of data points. When the number of data points exceeds few thousands the problem is very challenging, because the quadratic form is completely dense, so the memory needed to store the problem grows with the square of the number of data points. Therefore, training problems arising in some real applications with large data sets are impossible to load into memory, and cannot be solved using standard non-linear constrained optimization algorithms. We present a decomposition algorithm that can be used to train SVM''s over large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of, and also establish the stopping criteria for the algorithm. We present previous approaches, as well as results and important details of our implementation of the algorithm using a second-order variant of the Reduced Gradient Method as the solver of the sub-problems. As an application of SVM''s, we present preliminary results we obtained applying SVM to the problem of detecting frontal human faces in real images.", "authors": ["Edgar Osuna", "Robert Freund", "Federico Girosi"], "related_topics": ["10719679", "145828037", "124975894"], "citation_count": "1034", "reference_count": "0", "references": ["2153635508", "2115763357", "2124351082", "2108995755", "1608462934", "2005422315", "2080048739", "2133864802", "1761010383", "2147898188"], "date": "1997"}, {"id": "3000332379", "title": "Smoothing Noisy Data with Spline Functions Estimating the Correct Degree of Smoothing by the Method of Generalized Cross-Validation*", "abstract": "Smoothing splines are well known to provide nice curves which smooth discrete, noisy data. We obtain a practical, effective method for estimating the optimum amount of smoothing from the data. Deri...", "authors": ["Peter Craven", "Grace Wahba"], "related_topics": ["107457265", "3770464", "55259147"], "citation_count": "4376", "reference_count": "18", "references": ["1506069954", "2801179766", "1990381576", "2078841894", "2121203842", "2140170995", "1979519992", "2897129259", "2094438648", "2137645797"], "date": "1978"}, {"id": "2020584928", "title": "Join synopses for approximate query answering", "abstract": "In large data warehousing environments, it is often advantageous to provide fast, approximate answers to complex aggregate queries based on statistical summaries of the full data. In this paper, we demonstrate the difficulty of providing good approximate answers for join-queries using only statistics (in particular, samples) from the base relations. We propose join synopses as an effective solution for this problem and show how precomputing just one join synopsis for each relation suffices to significantly improve the quality of approximate answers for arbitrary queries with foreign key joins. We present optimal strategies for allocating the available space among the various join synopses when the query work load is known and identify heuristics for the common case when the work load is not known. We also present efficient algorithms for incrementally maintaining join synopses in the presence of updates to the base relations. Our extensive set of experiments on the TPC-D benchmark database show the effectiveness of join synopses and various other techniques proposed in this paper.", "authors": ["Swarup Acharya", "Phillip B. Gibbons", "Viswanath Poosala", "Sridhar Ramaswamy"], "related_topics": ["203570394", "188805328", "196713837"], "citation_count": "464", "reference_count": "28", "references": ["2080745194", "2296677182", "1993482412", "2171903035", "1601435884", "2153329411", "2147232895", "1992023276", "2162621793", "2133900260"], "date": "1999"}, {"id": "60275550", "title": "Studies in the Robustness of Multidimensional Scaling: Procrustes Statistics", "abstract": "", "authors": ["Robin Sibson"], "related_topics": ["2778585274", "97970142", "91682802"], "citation_count": "247", "reference_count": "13", "references": ["2035996732", "2032618685", "2057069782", "138719591", "2079255216", "1969060127", "2327780883", "2048168236", "1986051505", "2143386488"], "date": "1977"}, {"id": "2099641086", "title": "Uncertainty principles and ideal atomic decomposition", "abstract": "Suppose a discrete-time signal S(t), 0/spl les/t<N, is a superposition of atoms taken from a combined time-frequency dictionary made of spike sequences 1/sub {t=/spl tau/}/ and sinusoids exp{2/spl pi/iwt/N}//spl radic/N. Can one recover, from knowledge of S alone, the precise collection of atoms going to make up S? Because every discrete-time signal can be represented as a superposition of spikes alone, or as a superposition of sinusoids alone, there is no unique way of writing S as a sum of spikes and sinusoids in general. We prove that if S is representable as a highly sparse superposition of atoms from this time-frequency dictionary, then there is only one such highly sparse representation of S, and it can be obtained by solving the convex optimization problem of minimizing the l/sup 1/ norm of the coefficients among all decompositions. Here \"highly sparse\" means that N/sub t/+N/sub w/</spl radic/N/2 where N/sub t/ is the number of time atoms, N/sub w/ is the number of frequency atoms, and N is the length of the discrete-time signal. Underlying this result is a general l/sup 1/ uncertainty principle which says that if two bases are mutually incoherent, no nonzero signal can have a sparse representation in both bases simultaneously. For the above setting, the bases are sinusoids and spikes, and mutual incoherence is measured in terms of the largest inner product between different basis elements. The uncertainty principle holds for a variety of interesting basis pairs, not just sinusoids and spikes. The results have idealized applications to band-limited approximation with gross errors, to error-correcting encryption, and to separation of uncoordinated sources. Related phenomena hold for functions of a real variable, with basis pairs such as sinusoids and wavelets, and for functions of two variables, with basis pairs such as wavelets and ridgelets. In these settings, if a function f is representable by a sufficiently sparse superposition of terms taken from both bases, then there is only one such sparse representation; it may be obtained by minimum l/sup 1/ norm atomic decomposition. The condition \"sufficiently sparse\" becomes a multiscale condition; for example, that the number of wavelets at level j plus the number of sinusoids in the jth dyadic frequency band are together less than a constant times 2/sup j/2/.", "authors": ["D.L. Donoho", "X. Huo"], "related_topics": ["124066611", "27753989", "59372978"], "citation_count": "2365", "reference_count": "30", "references": ["2115755118", "2062024414", "2078204800", "2151693816", "1916685473", "1604810369", "2066462711", "2125455772", "1997149618", "2033367330"], "date": "2001"}, {"id": "2124776405", "title": "Neural Networks: A Comprehensive Foundation", "abstract": "From the Publisher: This book represents the most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all the important aspects of this emerging technology, including the learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular networks, temporal processing and neurodynamics, and VLSI implementation of neural networks. Written in a concise and fluid manner, by a foremost engineering textbook author, to make the material more accessible, this book is ideal for professional engineers and graduate students entering this exciting field. Computer experiments, problems, worked examples, a bibliography, photographs, and illustrations reinforce key concepts.", "authors": ["Simon Haykin"], "related_topics": ["2781121602", "76950829", "4279774"], "citation_count": "40861", "reference_count": "0", "references": ["2071707134", "2111072639", "1964357740", "2026131661", "2097308346", "2118978333", "2108384452", "3145506661", "2153233077", "2132549764"], "date": "1998"}, {"id": "2041145756", "title": "Responsible research and innovation: From science in society to science for society, with society", "abstract": "The term responsible (research and) innovation has gained increasing EU policy relevance in the last two years, in particular within the European Commission\u2019s Science in Society programme, in the context of the Horizon 2020 Strategy. We provide a brief historical overview of the concept, and identify three distinct features that are emerging from associated discourses. The first is an emphasis on the democratic governance of the purposes of research and innovation and their orientation towards the \u2018right impacts\u2019. The second is responsiveness, emphasising the integration and institutionalisation of established approaches of anticipation, reflection and deliberation in and around research and innovation, influencing the direction of these and associated policy. The third concerns the framing of responsibility itself in the context of research and innovation as collective activities with uncertain and unpredictable consequences. Finally, we reflect on possible motivations for responsible innovation itself.", "authors": ["Richard Owen", "Phil Macnaghten", "Jack Stilgoe"], "related_topics": ["2777720028", "164429055", "2776946740"], "citation_count": "1258", "reference_count": "49", "references": ["1551905080", "2100967449", "1605878143", "1818092435", "1516338434", "2044039018", "16795656", "31722454", "2099152065", "2075442155"], "date": "2012"}, {"id": "2160337655", "title": "A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking", "abstract": "Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system. Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or \"particle\") representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods. Several variants of the particle filter such as SIR, ASIR, and RPF are introduced within a generic framework of the sequential importance sampling (SIS) algorithm. These are discussed and compared with the standard EKF through an illustrative example.", "authors": ["M.S. Arulampalam", "S. Maskell", "N. Gordon", "T. Clapp"], "related_topics": ["52421305", "52483021", "106480740"], "citation_count": "14303", "reference_count": "39", "references": ["2125838338", "2126736494", "2098613108", "1749494163", "2131598171", "2124156864", "2129078811", "2077611006", "2064480843", "2105594594"], "date": "2002"}, {"id": "2079672501", "title": "Improved algorithms for topic distillation in a hyperlinked environment", "abstract": "This paper addresses the problem of topic distillation on the World Wide Web, namely, given a typical user query to find quality documents related to the query topic. Connectivity analysis has been shown to be useful in identifying high quality pages within a topic specific graph of hyperlinked documents. The essence of our approach is to augment a previous connectivity analysis based algorithm with content analysis. We identify three problems with the existing approach and devise algorithms to tackle them. The results of a user evaluation are reported that show an improvement of precision at 10 documents by at least 45% over pure connectivity analysis.", "authors": ["Krishna Bharat", "Monika R. Henzinger"], "related_topics": ["195409031", "192028432", "105606406"], "citation_count": "1296", "reference_count": "23", "references": ["2138621811", "2798909945", "2098162425", "1978394996", "2006119904", "1996764654", "2037498077", "2105276905", "1976232673", "2082751088"], "date": "1998"}, {"id": "2142960568", "title": "The CONSORT statement: revised recommendations for improving the quality of reports of parallel-group randomised trials", "abstract": "Summary To comprehend the results of a randomised controlled trial (RCT), readers must understand its design, conduct, analysis, and interpretation. That goal can be achieved only through total transparency from authors. Despite several decades of educational efforts, the reporting of RCTs needs improvement. Investigators and editors developed the original CONSORT (Consolidated Standards of Reporting Trials) statement to help authors improve reporting by use of a checklist and flow diagram. The revised CONSORT statement presented here incorporates new evidence and addresses some criticisms of the original statement. The checklist items pertain to the content of the Title, Abstract, Introduction, Methods, Results, and Discussion. The revised checklist includes 22 items selected because empirical evidence indicates that not reporting this information is associated with biased estimates of treatment effect, or because the information is essential to judge the reliability or relevance of the findings. We intended the flow diagram to depict the passage of participants through an RCT. The revised flow diagram depicts information from four stages of a trial (enrolment, intervention allocation, followup, and analysis). The diagram explicitly shows the number of participants, for each intervention group, included in the primary data analysis. Inclusion of these numbers allows the reader to judge whether the authors have done an intentionto- treat analysis. In sum, the CONSORT statement is intended to improve the reporting of an RCT, enabling readers to understand a trial's conduct and to assess the validity of its results.", "authors": ["David Moher", "Kenneth F Schulz", "Douglas G Altman"], "related_topics": ["49290038", "168563851", "2779356329"], "citation_count": "4660", "reference_count": "28", "references": ["1979423827", "2005775721", "2147581820", "2011932878", "1973281683", "2134338262", "2049321668", "1984052453", "2033156884", "2030958316"], "date": "2001"}, {"id": "2066789935", "title": "Classifying learnable geometric concepts with the Vapnik-Chervonenkis dimension", "abstract": "", "authors": ["A Blumer", "A Ehrenfeucht", "D Haussler", "M Warmuth"], "related_topics": ["119322782", "138552256", "118615104"], "citation_count": "271", "reference_count": "14", "references": ["2011039300", "2611147814", "2019363670", "2117362057", "2070902649", "2029538739", "2040924621", "1993058867", "1981233261", "2063961549"], "date": "1986"}, {"id": "2019976352", "title": "Inference Networks for Document Retrieval", "abstract": "The use of inference networks to support document retrieval is introduced. A network-basead retrieval model is described and compared to conventional probabilistic and Boolean models.", "authors": ["Howard Turtle", "W. Bruce Croft"], "related_topics": ["149189445", "68481662", "89686163"], "citation_count": "829", "reference_count": "30", "references": ["2159080219", "1956559956", "1593793857", "2797148637", "2048045485", "1984565341", "2478175895", "1978304080", "2914728526", "1973309770"], "date": "1989"}, {"id": "2164599981", "title": "Situated Cognition and the Culture of Learning", "abstract": "Many teaching practices implicitly assume that conceptual knowledge can be abstracted from the situations in which it is learned and used. This article argues that this assumption inevitably limits the effectiveness of such practices. Drawing on recent research into cognition as it is manifest in everyday activity, the authors argue that knowledge is situated, being in part a product of the activity, context, and culture in which it is developed and used. They discuss how this view of knowledge affects our understanding of learning, and they note that conventional schooling too often ignores the influence of school culture on what is learned in school. As an alternative to conventional practices, they propose cognitive apprenticeship (Collins, Brown, & Newman, in press), which honors the situated nature of knowledge. They examine two examples of mathematics instruction that exhibit certain key features of this approach to teaching.", "authors": ["John Seely Brown", "Allan Collins", "Paul Duguid"], "related_topics": ["80944243", "200380349", "2778573382"], "citation_count": "24521", "reference_count": "35", "references": ["2116199508", "2615899314", "2001564915", "2147583867", "2001722583", "2017103958", "1598089656", "3021970622", "1752512628", "1483147224"], "date": "1988"}, {"id": "2131399112", "title": "Orthogonal frequency division multiplexing for high-speed optical transmission", "abstract": "Optical Orthogonal frequency division multiplexing (OOFDM) is shown to outperform RZ-OOK transmission in high-speed optical communications systems in terms of transmission distance and spectral efficiency. The OOFDM in combination with the subcarrier multiplexing offers a significant improvement in spectral efficiency of at least 2.9 bits/s/Hz.", "authors": ["Ivan B. Djordjevic", "Bane Vasic"], "related_topics": ["2779103187", "26840048", "50661577"], "citation_count": "405", "reference_count": "18", "references": ["2110774823", "2149587304", "2121051729", "2010162055", "2122231345", "2150817728", "2068314916", "2866735992", "2129681561", "2170439548"], "date": "2006"}, {"id": "3001118548", "title": "Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China", "abstract": "A recent cluster of pneumonia cases in Wuhan, China, was caused by a novel betacoronavirus, the 2019 novel coronavirus (2019-nCoV). We report the epidemiological, clinical, laboratory, and radiological characteristics and treatment and clinical outcomes of these patients. All patients with suspected 2019-nCoV were admitted to a designated hospital in Wuhan. We prospectively collected and analysed data on patients with laboratory-confirmed 2019-nCoV infection by real-time RT-PCR and next-generation sequencing. Data were obtained with standardised data collection forms shared by the International Severe Acute Respiratory and Emerging Infection Consortium from electronic medical records. Researchers also directly communicated with patients or their families to ascertain epidemiological and symptom data. Outcomes were also compared between patients who had been admitted to the intensive care unit (ICU) and those who had not.", "authors": ["Chaolin Huang", "Yeming Wang", "Xingwang Li", "Lili Ren", "Jianping Zhao", "Yi Hu", "Li Zhang", "Guohui Fan", "Jiuyang Xu", "Xiaoying Gu", "Zhenshun Cheng", "Ting Yu", "Jiaan Xia", "Yuan Wei", "Wenjuan Wu", "Xuelei Xie", "Wen Yin", "Hui Li", "Min Liu", "Yan Xiao", "Hong Gao", "Li Guo", "Jungang Xie", "Guangfa Wang", "Rongmeng Jiang", "Zhancheng Gao", "Qi Jin", "Jianwei Wang", "Bin Cao"], "related_topics": ["2776525042", "2776376669", "2778158872"], "citation_count": "31613", "reference_count": "34", "references": ["2903899730", "2166867592", "3000413850", "2132260239", "2026274122", "2104548316", "2131262274", "2006434809", "3017468735", "2725497285"], "date": "2020"}, {"id": "2995160698", "title": "Are Sexual Minorities Hard-to-Survey? Insights from the 2020 Census Barriers, Attitudes, and Motivators Study (CBAMS) Survey", "abstract": "As a stigmatized and vulnerable population, sexual minorities are often assumed to also be a hard-to-survey population. Despite this implicit assumption, there is little empirical evidence on the topic. Using a nationally representative survey that included sexual orientation (the Census Barriers, Attitudes, and Motivators Survey), we examine level of effort, the Census Bureau\u2019s Low Response Score (LRS), and stated intent to respond to the 2020 Census as proxy measures to explore this assumption. We found no evidence that sexual minorities required higher levels of effort to secure participation in the survey. Additionally, we found that compared to straight respondents, lesbians, gays, and bisexuals had a higher intent to respond to the 2020 Census. We surmise the current social climate in the United States may be a contributing factor to these findings.", "authors": ["Nancy Bates", "Yazm\u00edn A. Garc\u00eda Trejo", "Monica Vines"], "related_topics": ["2908647359", "52130261", "2777997956"], "citation_count": "5", "reference_count": "26", "references": ["2099697766", "2517104773", "2494370076", "2144570985", "2148554754", "2096847671", "2727568558", "2758943428", "2123234696", "1516486747"], "date": "2019"}, {"id": "2914885528", "title": "Color indexing", "abstract": "Computer vision is moving into a new era in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, unconstrained environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the identity of an object with a known location, and determining the location of a known object. Color can be successfully used for both tasks. This dissertation demonstrates that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models. It shows that color histograms are stable object representations in the presence of occlusion and over change in view, and that they can differentiate among a large number of objects. For solving the identification problem, it introduces a technique called Histogram Intersection, which matches model and image histograms and a fast incremental version of Histogram Intersection which allows real-time indexing into a large database of stored models. It demonstrates techniques for dealing with crowded scenes and with models with similar color signatures. For solving the location problem it introduces an algorithm called Histogram Backprojection which performs this task efficiently in crowded scenes.", "authors": ["Michael James Swain", "Dana H. Ballard"], "related_topics": ["44404184", "2780052074", "53533937"], "citation_count": "8631", "reference_count": "23", "references": ["2115738369", "2913703059", "3021212382", "2415527960", "2125756925", "2119204143", "2172373809", "2489504689", "2069266228", "2136654525"], "date": "1991"}, {"id": "2151214689", "title": "The cache-and-forward network architecture for efficient mobile content delivery services in the future internet", "abstract": "This paper presents a novel \"cache-and-forward\" (CNF) protocol architecture for mobile content delivery services in the future Internet. The CNF architecture can be implemented as an overlay on top of the Internet Protocol (IP), or as a clean slate protocol for next-generation networks. CNF is based on the concept of store-and-forward routers with large storage, providing for opportunistic delivery to occasionally disconnected mobile users and for in-network caching of content. The proposed CNF protocol uses reliable hop-by-hop transfer of large data files between CNF routers in place of an end-to-end transport protocol like TCP. This approach makes it possible to serve mobile users with intermittent connectivity, while also mitigating self- interference problems which arise in multi-hop wireless scenarios. Hop-by-hop transport is similarly useful in wired networks where router storage can help to smooth out link congestion bottlenecks which arise in TCP/IP networks. A second key feature of the CNF protocol is the integration of address- based and content-based routing to support various content delivery modes that take advantage of in-network storage. An overview of the CNF architecture and major protocol components is given, and preliminary performance evaluation results are summarized to validate the main design principles.", "authors": ["S. Paul", "R. Yates", "D. Raychaudhuri", "J. Kurose"], "related_topics": ["65567647", "35341882", "178248399"], "citation_count": "392", "reference_count": "40", "references": ["2158049821", "2132932625", "2163059190", "2150825860", "2045028348", "2149959815", "2112316694", "2753542457", "2107520978", "2303054358"], "date": "2008"}, {"id": "2072035149", "title": "Better to be frustrated than bored: The incidence, persistence, and impact of learners' cognitive-affective states during interactions with three different computer-based learning environments", "abstract": "We study the incidence (rate of occurrence), persistence (rate of reoccurrence immediately after occurrence), and impact (effect on behavior) of students' cognitive-affective states during their use of three different computer-based learning environments. Students' cognitive-affective states are studied using different populations (Philippines, USA), different methods (quantitative field observation, self-report), and different types of learning environments (dialogue tutor, problem-solving game, and problem-solving-based Intelligent Tutoring System). By varying the studies along these multiple factors, we can have greater confidence that findings which generalize across studies are robust. The incidence, persistence, and impact of boredom, frustration, confusion, engaged concentration, delight, and surprise were compared. We found that boredom was very persistent across learning environments and was associated with poorer learning and problem behaviors, such as gaming the system. Despite prior hypothesis to the contrary, frustration was less persistent, less associated with poorer learning, and did not appear to be an antecedent to gaming the system. Confusion and engaged concentration were the most common states within all three learning environments. Experiences of delight and surprise were rare. These findings suggest that significant effort should be put into detecting and responding to boredom and confusion, with a particular emphasis on developing pedagogical interventions to disrupt the ''vicious cycles'' which occur when a student becomes bored and remains bored for long periods of time.", "authors": ["Ryan S. J. d. Baker", "Sidney K. D'Mello", "Ma.Mercedes T. Rodrigo", "Arthur C. Graesser"], "related_topics": ["2777589236", "2780343955", "6438553"], "citation_count": "826", "reference_count": "124", "references": ["2126925200", "1586442777", "2339343773", "2140205964", "1950299194", "1777119744", "2134031328", "1498025178", "2090242685", "2163640453"], "date": "2010"}, {"id": "1492367142", "title": "Co-compounds and natural coordination", "abstract": "1. Introduction 2. The Marking Patterns of Natural Coordination 3. Tight Coordination 4. Co-compounds as a Lexical Class Type 5. A Semantic Classification of Co-compounds 6. The Areal Distribution of Co-compounds in the Languages of Eurasia 7. Some Considerations about the Diachronic Evolution of Co-compounds 8. Conclusions Appendix References Index of Persons Index of Languages Index of Subjects", "authors": ["Bernhard W\u00e4lchli"], "related_topics": ["2781157624", "123406163", "204321447"], "citation_count": "371", "reference_count": "0", "references": ["2090626368", "2038542953", "2084082059", "2029958307", "1518700878", "378065404", "760094513", "601004259", "570794338", "1050192144"], "date": "2004"}, {"id": "2127114597", "title": "Definitional Interpreters for Higher-Order Programming Languages", "abstract": "Higher-order programming languages (i.e., languages in which procedures or labels can occur as values) are usually defined by interpreters that are themselves written in a programming language based on the lambda calculus (i.e., an applicative language such as pure LISP). Examples include McCarthy\u2018s definition of LISP, Landin\u2018s SECD machine, the Vienna definition of PL/I, Reynolds\u2018 definitions of GEDANKEN, and recent unpublished work by L. Morris and C. Wadsworth. Such definitions can be classified according to whether the interpreter contains higher-order functions, and whether the order of application (i.e., call by value versus call by name) in the defined language depends upon the order of application in the defining language. As an example, we consider the definition of a simple applicative programming language by means of an interpreter written in a similar language. Definitions in each of the above classifications are derived from one another by informal but constructive methods. The treatment of imperative features such as jumps and assignment is also discussed.", "authors": ["John C. Reynolds"], "related_topics": ["2777389541", "199305712", "20724563"], "citation_count": "1022", "reference_count": "25", "references": ["3146075203", "2069300761", "2124141583", "2987907651", "1512502927", "2045255985", "2152944474", "2012213337", "2134112335", "2109798037"], "date": "1998"}, {"id": "2248695218", "title": "On What Grounds What", "abstract": "", "authors": ["Jonathan Schaffer"], "related_topics": ["138885662"], "citation_count": "1345", "reference_count": "47", "references": ["3081949511", "2155535944", "2007273076", "2050691920", "2002265975", "2008657432", "2074231115", "1496312651", "2142359340", "2208883602"], "date": "2008"}, {"id": "2063698478", "title": "An Introduction to Multivariate Statistical Analysis", "abstract": "Preface to the Third Edition.Preface to the Second Edition.Preface to the First Edition.1. Introduction.2. The Multivariate Normal Distribution.3. Estimation of the Mean Vector and the Covariance Matrix.4. The Distributions and Uses of Sample Correlation Coefficients.5. The Generalized T2-Statistic.6. Classification of Observations.7. The Distribution of the Sample Covariance Matrix and the Sample Generalized Variance.8. Testing the General Linear Hypothesis: Multivariate Analysis of Variance9. Testing Independence of Sets of Variates.10. Testing Hypotheses of Equality of Covariance Matrices and Equality of Mean Vectors and Covariance Matrices.11. Principal Components.12. Cononical Correlations and Cononical Variables.13. The Distributions of Characteristic Roots and Vectors.14. Factor Analysis.15. Pattern of Dependence Graphical Models.Appendix A: Matrix Theory.Appendix B: Tables.References.Index.", "authors": ["T. W. Anderson"], "related_topics": ["180877172", "177384507", "178650346"], "citation_count": "16014", "reference_count": "0", "references": ["1587141723", "2159128662", "2121601095", "2153562738", "2124101779", "2096863518", "2159706540", "2117897510", "3101788651", "2148541040"], "date": "1984"}, {"id": "1586401530", "title": "Word-formation in English", "abstract": "This book is the second edition of a highly successful introduction to the study of word-formation, that is, the ways in which new words are built on the bases of other words (e.g. happy - happy-ness), focusing on English. The book's didactic aim is to enable students with little or no prior linguistic knowledge to do their own practical analyses of complex words. Readers are familiarized with the necessary methodological tools to obtain and analyze relevant data and are shown how to relate their findings to theoretical problems and debates. The second edition incorporates new developments in morphology at both the methodological and the theoretical level. It introduces the use of new corpora and data bases, acquaints the reader with state-of-the-art computational algorithms modeling morphology, and brings in current debates and theories.", "authors": ["Ingo Plag"], "related_topics": ["2777509023", "2778147775", "41895202"], "citation_count": "2031", "reference_count": "110", "references": ["2038721957", "2013833248", "2056573988", "1584710637", "2148274560", "1484602304", "1598851216", "1527142120", "160989634", "2058223424"], "date": "2002"}, {"id": "1671881141", "title": "Proximity Search in Databases", "abstract": "An information retrieval (IR) engine can rank documents based on textual proximity of keywords within each document. In this paper we apply this notion to search across an entire database for objects that are \"near\" other relevant objects. Proximity search enables simple \"focusing\" queries based on general relationships among objects, helpful for interactive query sessions. We view the database as a graph, with data in vertices (objects) and relationships indicated by edges. Proximity is defined based on shortest paths between objects. We have implemented a prototype search engine that uses this model to enable keyword searches over databases, and we have found it very effective for quickly finding relevant information. Computing the distance between objects in a graph stored on disk can be very expensive. Hence, we show how to build compact indexes that allow us to quickly find the distance between objects at search time. Experiments show that our algorithms are effcient and scale well.", "authors": ["Roy Goldman", "Narayanan Shivakumar", "Suresh Venkatasubramanian", "Hector Garcia-Molina"], "related_topics": ["170390413", "136134403", "97854310"], "citation_count": "340", "reference_count": "25", "references": ["1854214752", "1965014786", "1655990431", "1833785989", "2117849706", "2100674109", "2020919487", "1992810975", "2059372025", "2162621793"], "date": "1998"}, {"id": "2119717200", "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning", "abstract": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.", "authors": ["Ronald J. Williams"], "related_topics": ["199190896", "97541855", "155032097"], "citation_count": "9097", "reference_count": "27", "references": ["2154642048", "1652505363", "2100677568", "3011120880", "1569320505", "2286699414", "1583833196", "2152475379", "1547224907", "1538558539"], "date": "1992"}, {"id": "2056499831", "title": "Ecological momentary assessment (EMA) in studies of substance use.", "abstract": "Ecological momentary assessment (EMA) is particularly suitable for studying substance use, because use is episodic and thought to be related to mood and context. This article reviews EMA methods in substance use research, focusing on tobacco and alcohol use and relapse, where EMA has been most applied. Common EMA designs combine event-based reports of substance use with time-based assessments. Approaches to data organization and analysis have been very diverse, particularly regarding their treatment of time. Compliance with signaled assessments is often high. Compliance with recording of substance use appears good but is harder to validate. Treatment applications of EMA are emerging. EMA captures substance use patterns not measured by questionnaires or retrospective data and holds promise for substance use research.", "authors": ["Saul Shiffman"], "related_topics": ["2780049985", "2780931562", "2780733359"], "citation_count": "612", "reference_count": "74", "references": ["2155002669", "2031163840", "2135374245", "2144418705", "2776017876", "1997116342", "574900904", "1977741115", "1978691251", "2050791901"], "date": "2009"}, {"id": "2109200236", "title": "Feature Detection with Automatic Scale Selection", "abstract": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure. Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation. In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments.", "authors": ["Tony Lindeberg"], "related_topics": ["99102927", "27434737", "193536780"], "citation_count": "3617", "reference_count": "54", "references": ["2152328854", "2004217976", "2120062331", "2109863423", "2112328181", "2022735534", "1970269179", "1495971627", "2167034998", "2978983090"], "date": "1998"}, {"id": "1521785144", "title": "Principles of Robot Motion: Theory, Algorithms, and Implementations", "abstract": "A text that makes the mathematical underpinnings of robot motion accessible and relates low-level details of implementation to high-level algorithmic concepts. Robot motion planning has become a major focus of robotics. Research findings can be applied not only to robotics but to planning routes on circuit boards, directing digital actors in computer graphics, robot-assisted surgery and medicine, and in novel areas such as drug design and protein folding. This text reflects the great advances that have taken place in the last ten years, including sensor-based planning, probabalistic planning, localization and mapping, and motion planning for dynamic and nonholonomic systems. Its presentation makes the mathematical underpinnings of robot motion accessible to students of computer science and engineering, rleating low-level implementation details to high-level algorithmic concepts.", "authors": ["Howie M. Choset", "Jean-Claude Latombe"], "related_topics": ["81074085", "2778803389", "34413123"], "citation_count": "3606", "reference_count": "232", "references": ["3145128584", "3029645440", "2160337655", "2798766386", "1483307070", "2159080219", "2049981393", "2049633694", "2161406034", "2098613108"], "date": "2005"}, {"id": "2052842312", "title": "Concepts of the cover coefficient-based clustering methodology", "abstract": "Document clustering has several unresolved problems. Among them are high time and space complexity, difficulty of determining similarity thresholds, order dependence, nonuniform document distribution in clusters, and arbitrariness in determination of various cluster intiators. To overcome these problems to some degree, the cover coefficient based clustering methodology has been introduced. The concepts used in this methodology have created certain new concepts, relationships, and measures such as the effect of indexing on clustering, an optimal vocabulary generation for indexing, and a new matching function. These new concepts are discussed. The result of performance experiments that show the effectiveness of the clustering methodology and the matching function are also included. In these experiments, it has been also observed that the majority of the documents obtained in a search are concentrated in a few clusters containing a low percentage of documents of the database.", "authors": ["Fazli Can", "Esen A. Ozkarahan"], "related_topics": ["94641424", "73555534", "184509293"], "citation_count": "17", "reference_count": "13", "references": ["1956559956", "2118587067", "1557757161", "1525068132", "2054409659", "1985414707", "2133367958", "2107720767", "2102154751", "63452457"], "date": "1985"}, {"id": "1917531491", "title": "arXiv E-prints and the journal of record: An analysis of roles and relationships", "abstract": "Since its creation in 1991, arXiv has become central to the diffusion of research in a number of fields. Combining data from the entirety of arXiv and the Web of Science WoS, this article investigates a the proportion of papers across all disciplines that are on arXiv and the proportion of arXiv papers that are in the WoS, b the elapsed time between arXiv submission and journal publication, and c the aging characteristics and scientific impact of arXiv e-prints and their published version. It shows that the proportion of WoS papers found on arXiv varies across the specialties of physics and mathematics, and that only a few specialties make extensive use of the repository. Elapsed time between arXiv submission and journal publication has shortened but remains longer in mathematics than in physics. In physics, mathematics, as well as in astronomy and astrophysics, arXiv versions are cited more promptly and decay faster than WoS papers. The arXiv versions of papers-both published and unpublished-have lower citation rates than published papers, although there is almost no difference in the impact of the arXiv versions of published and unpublished papers.", "authors": ["Vincent Larivi\u00e8re", "", "Cassidy R. Sugimoto", "Benoit Macaluso", "", "Sta\u0161a Milojevi\u0107", "Blaise Cronin", "Mike Thelwall"], "related_topics": ["178315738", "2778805511", "23123220"], "citation_count": "85", "reference_count": "53", "references": ["2002034968", "2137725064", "2046303033", "2132615533", "2100117397", "2128349488", "2001450038", "1975257153", "2063332351", "2964139205"], "date": "2014"}, {"id": "2106887953", "title": "Notes on Data Base Operating Systems", "abstract": "This paper is a compendium of data base management operating systems folklore. It is an early paper and is still in draft form. It is intended as a set of course notes for a class on data base operating systems. After a brief overview of what a data management system is it focuses on particular issues unique to the transaction management component especially locking and recovery.", "authors": ["Jim Gray"], "related_topics": ["1668388", "91098038", "11354467"], "citation_count": "2944", "reference_count": "21", "references": ["2138709157", "2326587081", "1991199257", "2116436709", "2133384222", "2013012235", "2000018901", "1969898832", "2094162326", "2119285119"], "date": "1977"}, {"id": "2141012957", "title": "Cluster analysis for gene expression data: a survey", "abstract": "DNA microarray technology has now made it possible to simultaneously monitor the expression levels of thousands of genes during important biological processes and across collections of related samples. Elucidating the patterns hidden in gene expression data offers a tremendous opportunity for an enhanced understanding of functional genomics. However, the large number of genes and the complexity of biological networks greatly increases the challenges of comprehending and interpreting the resulting mass of data, which often consists of millions of measurements. A first step toward addressing this challenge is the use of clustering techniques, which is essential in the data mining process to reveal natural structures and identify interesting patterns in the underlying data. Cluster analysis seeks to partition a given data set into groups based on specified features so that the data points within a group are more similar to each other than the points in different groups. A very rich literature on cluster analysis has developed over the past three decades. Many conventional clustering algorithms have been adapted or directly applied to gene expression data, and also new algorithms have recently been proposed specifically aiming at gene expression data. These clustering algorithms have been proven useful for identifying biologically relevant groups of genes and samples. In this paper, we first briefly introduce the concepts of microarray technology and discuss the basic elements of clustering on gene expression data. In particular, we divide cluster analysis for gene expression data into three categories. Then, we present specific challenges pertinent to each clustering category and introduce several representative approaches. We also discuss the problem of cluster validation in three aspects and review various methods to assess the quality and reliability of clustering results. Finally, we conclude this paper and suggest the promising trends in this field.", "authors": ["Daxin Jiang", "Chun Tang", "Aidong Zhang"], "related_topics": ["73555534", "24361400", "28225019"], "citation_count": "1535", "reference_count": "135", "references": ["2140190241", "2150926065", "2109363337", "1992419399", "2157795344", "2147246240", "1970156673", "2148694408", "2165011536", "2103453943"], "date": "2004"}, {"id": "1513008779", "title": "Beyond the Kalman Filter: Particle Filters for Tracking Applications", "abstract": "Part I Theoretical concepts: introduction suboptimal nonlinear filters a tutorial on particle filters Cramer-Rao bounds for nonlinear filtering. Part II Tracking applications: tracking a ballistic object bearings-only tracking range-only tracking bistatic radar tracking tracking targets through blind Doppler terrain aided tracking detection and tracking of stealthy targets group and extended object tracking.", "authors": ["Branko Ristic", "Sanjeev Arulampalam", "Neil Gordon"], "related_topics": ["154586513", "41904074", "52421305"], "citation_count": "5129", "reference_count": "0", "references": ["2126302311", "2137585588", "1883186006", "2132240870", "2887114371", "2127342270", "2055936398", "1981373725", "2154353836", "2103632679"], "date": "2004"}, {"id": "2887242076", "title": "Self-organization of orientation sensitive cells in the striata cortex", "abstract": "A nerve net model for the visual cortex of higher vertebrates is presented. A simple learning procedure is shown to be sufficient for the organization of some essential functional properties of single units. The rather special assumptions usually made in the literature regarding preorganization of the visual cortex are thereby avoided. The model consists of 338 neurones forming a sheet analogous to the cortex. The neurones are connected randomly to a \u201cretina\u201d of 19 cells. Nine different stimuli in the form of light bars were applied. The afferent connections were modified according to a mechanism of synaptic training. After twenty presentations of all the stimuli individual cortical neurones became sensitive to only one orientation. Neurones with the same or similar orientation sensitivity tended to appear in clusters, which are analogous to cortical columns. The system was shown to be insensitive to a background of disturbing input excitations during learning. After learning it was able to repair small defects introduced into the wiring and was relatively insensitive to stimuli not used during training.", "authors": ["C. von der Malsburg"], "related_topics": ["2779345533", "2777348757", "2780196419"], "citation_count": "1983", "reference_count": "21", "references": ["2116360511", "2117731089", "85058473", "2119051448", "2008625057", "148261105", "2008353316", "1757333299", "1969469807", "2011203963"], "date": "1987"}, {"id": "2087964979", "title": "The Theory and Practice of Econometrics", "abstract": "SAMPLING THEORY AND BAYESIAN APPROACHES TO INFERENCE. The Classical Inference Approach for the General Linear Model. Statistical Decision Theory and Biased Estimation. The Bayesian Approach to Inference. INFERENCE IN GENERAL STATISTICAL MODELS AND TIME SERIES. Some Asymptotic Theory and Other General Results for the Linear Statistical Model. Nonlinear Statistical Models. Time Series. DYNAMIC SPECIFICATIONS. Autocorrelation. Finite Distributed Lags. Infinite Distributed Lags. SOME ALTERNATIVE COVARIANCE STRUCTURES. Heteroskedasticity. Disturbance--Related Sets of Regression Equations. Inference in Models that Combine Time Series and Cross--Sectional Data. INFERENCE IN SIMULTANEOUS EQUATION MODELS. Specification and Identification in Simultaneous Equation Models. Estimation and Inference in a System of Simultaneous Equations. Multiple Time Series and Systems of Dynamic Simultaneous Equations. FURTHER MODEL EXTENSIONS. Unobservable Variables. Qualitative and Limited Dependent Variable Models. Varying and Random Coefficient Models. Non--Normal Disturbances. On Selecting the Set of Aggressors. Multicollinearity. Appendices.", "authors": ["George G. Judge"], "related_topics": ["134261354", "95167961", "917703"], "citation_count": "7478", "reference_count": "0", "references": ["2140964565", "1990221500", "21994910", "3123129688", "2046519558", "2060704337", "2022220920", "2135385687", "2110630371", "1991642024"], "date": "1979"}, {"id": "2086976228", "title": "Multicluster, mobile, multimedia radio network", "abstract": "A multi-cluster, multi-hop packet radio network architecture for wireless adaptive mobile information systems is presented. The proposed network supports multimedia traffic and relies on both time division and code division access schemes. This radio network is not supported by a wired infrastructure as conventional cellular systems are. Thus, it can be instantly deployed in areas with no infrastructure at all. By using a distributed clustering algorithm, nodes are organized into clusters. The clusterheads act as local coordinators to resolve channel scheduling, perform power measurement/control, maintain time division frame synchronization, and enhance the spatial reuse of time slots and codes. Moreover, to guarantee bandwidth for real time traffic, the architecture supports virtual circuits and allocates bandwidth to circuits at call setup time. The network is scalable to large numbers of nodes, and can handle mobility. Simulation experiments evaluate the performance of the proposed scheme in static and mobile environments.", "authors": ["Mario Gerla", "Jack Tzu-Chieh Tsai"], "related_topics": ["153646914", "106365562", "7091991"], "citation_count": "2304", "reference_count": "12", "references": ["1969492090", "1977439837", "1994980566", "2124110518", "2047496769", "2127324499", "2101007051", "2142868546", "2142226047", "2115316391"], "date": "1995"}, {"id": "2787959293", "title": "Fractional differential equations", "abstract": "", "authors": ["Igor Podlubny"], "related_topics": ["2779760431", "154249771", "48089519"], "citation_count": "22925", "reference_count": "0", "references": ["2556784265", "2063067239", "2080931732", "1975670568", "19898668", "1509146820", "2058860728", "2011301580", "2006458314", "2619878922"], "date": "1998"}, {"id": "2074797641", "title": "Scattered data interpolation: tests of some methods", "abstract": "Absract. This paper is concerned with the evaluation of methods for scattered data interpolation and some of the results of the tests when applied to a number of methods. The process involves evaluation of the methods in terms of timing, storage, accuracy, visual pleasantness of the surface, and ease of implementation. To indicate the flavor of the type of results obtained, we give a summary table and representative perspective plots of several surfaces.", "authors": ["Richard Franke"], "related_topics": ["17378031", "203332170", "12713177"], "citation_count": "2627", "reference_count": "40", "references": ["1988744163", "2147169375", "2056894411", "2040513229", "2130859329", "1542085343", "2095769364", "2118623924", "1576724274", "2068179746"], "date": "1981"}, {"id": "2066859698", "title": "Checking system rules using system-specific, programmer-written compiler extensions", "abstract": "Systems software such as OS kernels, embedded systems, and libraries must obey many rules for both correctness and performance. Common examples include \"accesses to variable A must be guarded by lock B,\" \"system calls must check user pointers for validity before using them,\" and \"message handlers should free their buffers as quickly as possible to allow greater parallelism.\" Unfortunately, adherence to these rules is largely unchecked.This paper attacks this problem by showing how system implementors can use meta-level compilation (MC) to write simple, system-specific compiler extensions that automatically check their code for rule violations. By melding domain-specific knowledge with the automatic machinery of compilers, MC brings the benefits of language-level checking and optimizing to the higher, \"meta\" level of the systems implemented in these languages. This paper demonstrates the effectiveness of the MC approach by applying it to four complex, real systems: Linux, OpenBSD, the Xok exokernel, and the FLASH machine's embedded software. MC extensions found roughly 500 errors in these systems and led to numerous kernel patches. Most extensions were less than a hundred lines of code and written by implementors who had a limited understanding of the systems checked.", "authors": ["Dawson Engler", "Benjamin Chelf", "Andy Chou", "Seth Hallem"], "related_topics": ["169590947", "199519371", "172644921"], "citation_count": "803", "reference_count": "22", "references": ["2138363365", "1972544179", "2135274583", "2047226031", "2159890891", "1527793496", "2152056423", "2107995193", "2169476734", "2069300761"], "date": "2000"}, {"id": "2061741899", "title": "Computer corpora in English language research", "abstract": "", "authors": ["Stig Johansson"], "related_topics": ["129353971", "166007726", "83479923"], "citation_count": "53", "reference_count": "0", "references": ["1995991622", "2074952134", "1595454219", "1974094162", "2093099215", "2010236170", "1591623735", "2166935132", "2290591270", "2318841949"], "date": "1984"}, {"id": "1996021349", "title": "The wavelet transform, time-frequency localization and signal analysis", "abstract": "Two different procedures for effecting a frequency analysis of a time-dependent signal locally in time are studied. The first procedure is the short-time or windowed Fourier transform; the second is the wavelet transform, in which high-frequency components are studied with sharper time resolution than low-frequency components. The similarities and the differences between these two methods are discussed. For both schemes a detailed study is made of the reconstruction method and its stability as a function of the chosen time-frequency density. Finally, the notion of time-frequency localization is made precise, within this framework, by two localization theorems. >", "authors": ["I. Daubechies"], "related_topics": ["1109138", "76563020", "166386157"], "citation_count": "8349", "reference_count": "53", "references": ["2132984323", "2098914003", "2166982406", "2096684483", "2087377426", "2013987111", "1975474302", "1989491465", "2014757225", "2123487365"], "date": "1990"}, {"id": "2086921140", "title": "On active contour models and balloons", "abstract": "Abstract The use of energy-minimizing curves, known as \u201csnakes,\u201d to extract features of interest in images has been introduced by Kass, Witkin & Terzopoulos (Int. J. Comput. Vision 1, 1987, 321\u2013331). We present a model of deformation which solves some of the problems encountered with the original method. The external forces that push the curve to the edges are modified to give more stable results. The original snake, when it is not close enough to contours, is not attracted by them and straightens to a line. Our model makes the curve behave like a balloon which is inflated by an additional force. The initial curve need no longer be close to the solution to converge. The curve passes over weak edges and is stopped only if the edge is strong. We give examples of extracting a ventricle in medical images. We have also made a first step toward 3D object reconstruction, by tracking the extracted contour on a series of successive cross sections.", "authors": ["Laurent D. Cohen"], "related_topics": ["112353826", "198352243", "20749125"], "citation_count": "3578", "reference_count": "11", "references": ["2145023731", "2104095591", "2125848778", "2069562432", "2007153649", "2043647324", "2134781380", "2103580031", "1607751055", "52422579"], "date": "1991"}, {"id": "2053133047", "title": "Positive psychology: An introduction.", "abstract": "A science of positive subjective experience, positive individual traits, and positive institutions promises to improve quality of life and prevent the pathologies that arise when life is barren and meaningless, The exclusive focus on pathology that has dominated so much of our discipline results in a model of the human being lacking the positive features that make life worth living. Hope, wisdom, creativity, future mindedness, courage, spirituality, responsibility, and perseverance are ignored or explained as transformations of more authentic negative impulses. The 15 articles in this millennial issue of the American Psychologist discuss such issues as what enables happiness, the effects of autonomy and self-regulation, how optimism and hope affect health, what constitutes wisdom, and how talent and creativity come to fruition. The authors outline a framework for a science of positive psychology, point to gaps in our knowledge, and predict that the next century will see a science and profession that will come to understand and build the factors that allow individuals, communities, and societies to flourish.", "authors": ["Martin E. P. Seligman", "Mihaly Csikszentmihalyi"], "related_topics": ["2779077761", "2777991910", "12505134"], "citation_count": "13467", "reference_count": "32", "references": ["2141846678", "2888190061", "2070808447", "2088155659", "2071972904", "2010707353", "2063694620", "2062372985", "2135357145", "2072059287"], "date": "1999"}, {"id": "1498878034", "title": "Relational Frame Theory: A Post-Skinnerian Account Of Human Language And Cognition", "abstract": "Part I: The Basic Account. 1. Language and Cognition: Constructing an Alternative Approach Within the Behavioral Tradition S.C. Hayes, et al. 2. Derived Relational Responding as Learned Behavior S.C. Hayes, et al. 3. Multiple Stimulus Relations and the Transformation of Stimulus Functions D. Barnes-Holmes, et al. 4. Relations Among Relations: Analogies, Metaphors, and Stories I. Stewart, et al. 5. Thinking, Problem-Solving, and Pragmatic Verbal Analysis S.C. Hayes, et al. 6. Understanding and Verbal Regulation D. Barnes-Holmes, et al. 7. Self and Self-Directed Rules D. Barnes-Holmes, et al. 8. Relational Frame Theory: A Precis S.C. Hayes, et al. Part II: Extensions and Applications. 9. Psychological Development Y. Barnes-Holmes, et al. 10. Education Y. Barnes-Holmes, et al. 11. Social Processes B. Roche, et al. 12. Psychopathology and Psychotherapy K.G. Wilson, et al. 13. Religion, Spirituality, and Transcendence D. Barnes-Holmes, et al. Epilogue. References. Index.", "authors": ["Yvonne Barnes-Holmes", "Steven C. Hayes", "Dermot Barnes-Holmes", "Bryan Roche"], "related_topics": ["49815771", "2780289102", "2780302483"], "citation_count": "3791", "reference_count": "223", "references": ["2159061031", "1637267194", "1514273299", "2018415007", "2157985609", "2059975159", "2121773050", "1966905618", "2061230487", "1553508775"], "date": "2013"}, {"id": "2020764470", "title": "On the Complexity of Teaching", "abstract": "While most theoretical work in machine learning has focused on the complexity of learning, recently there has been increasing interest in formally studying the complexity of teaching. In this paper we study the complexity of teaching by considering a variant of the on-line learning model in which a helpful teacher selects the instances. We measure the complexity of teaching a concept from a given concept class by a combinatorial measure we call the teaching dimension, Informally, the teaching dimension of a concept class is the minimum number of instances a teacher must reveal to uniquely identify any target concept chosen from the class.", "authors": ["S.A. Goldman", "M.J. Kearns"], "related_topics": ["203313322", "21252375", "6435147"], "citation_count": "488", "reference_count": "20", "references": ["2011039300", "2019363670", "1970606468", "2154952480", "2428981601", "2157054705", "2029538739", "2094849970", "2064672629", "2154368141"], "date": "1995"}, {"id": "2122122381", "title": "A survey of augmented reality", "abstract": "This paper surveys the field of augmented reality AR, in which 3D virtual objects are integrated into a 3D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment, and military applications that have been explored. This paper describes the characteristics of augmented reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective augmented reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using augmented reality.", "authors": ["Ronald T. Azuma"], "related_topics": ["134202134", "153715457", "28896322"], "citation_count": "12571", "reference_count": "95", "references": ["1490482062", "2100115174", "1593163947", "2098362450", "1968211101", "1983808135", "2023331673", "2067779848", "2027654789", "2105655427"], "date": "1997"}, {"id": "1634005169", "title": "Vector Quantization and Signal Compression", "abstract": "1 Introduction.- 1.1 Signals, Coding, and Compression.- 1.2 Optimality.- 1.3 How to Use this Book.- 1.4 Related Reading.- I Basic Tools.- 2 Random Processes and Linear Systems.- 2.1 Introduction.- 2.2 Probability.- 2.3 Random Variables and Vectors.- 2.4 Random Processes.- 2.5 Expectation.- 2.6 Linear Systems.- 2.7 Stationary and Ergodic Properties.- 2.8 Useful Processes.- 2.9 Problems.- 3 Sampling.- 3.1 Introduction.- 3.2 Periodic Sampling.- 3.3 Noise in Sampling.- 3.4 Practical Sampling Schemes.- 3.5 Sampling Jitter.- 3.6 Multidimensional Sampling.- 3.7 Problems.- 4 Linear Prediction.- 4.1 Introduction.- 4.2 Elementary Estimation Theory.- 4.3 Finite-Memory Linear Prediction.- 4.4 Forward and Backward Prediction.- 4.5 The Levinson-Durbin Algorithm.- 4.6 Linear Predictor Design from Empirical Data.- 4.7 Minimum Delay Property.- 4.8 Predictability and Determinism.- 4.9 Infinite Memory Linear Prediction.- 4.10 Simulation of Random Processes.- 4.11 Problems.- II Scalar Coding.- 5 Scalar Quantization I.- 5.1 Introduction.- 5.2 Structure of a Quantizer.- 5.3 Measuring Quantizer Performance.- 5.4 The Uniform Quantizer.- 5.5 Nonuniform Quantization and Companding.- 5.6 High Resolution: General Case.- 5.7 Problems.- 6 Scalar Quantization II.- 6.1 Introduction.- 6.2 Conditions for Optimality.- 6.3 High Resolution Optimal Companding.- 6.4 Quantizer Design Algorithms.- 6.5 Implementation.- 6.6 Problems.- 7 Predictive Quantization.- 7.1 Introduction.- 7.2 Difference Quantization.- 7.3 Closed-Loop Predictive Quantization.- 7.4 Delta Modulation.- 7.5 Problems.- 8 Bit Allocation and Transform Coding.- 8.1 Introduction.- 8.2 The Problem of Bit Allocation.- 8.3 Optimal Bit Allocation Results.- 8.4 Integer Constrained Allocation Techniques.- 8.5 Transform Coding.- 8.6 Karhunen-Loeve Transform.- 8.7 Performance Gain of Transform Coding.- 8.8 Other Transforms.- 8.9 Sub-band Coding.- 8.10 Problems.- 9 Entropy Coding.- 9.1 Introduction.- 9.2 Variable-Length Scalar Noiseless Coding.- 9.3 Prefix Codes.- 9.4 Huffman Coding.- 9.5 Vector Entropy Coding.- 9.6 Arithmetic Coding.- 9.7 Universal and Adaptive Entropy Coding.- 9.8 Ziv-Lempel Coding.- 9.9 Quantization and Entropy Coding.- 9.10 Problems.- III Vector Coding.- 10 Vector Quantization I.- 10.1 Introduction.- 10.2 Structural Properties and Characterization.- 10.3 Measuring Vector Quantizer Performance.- 10.4 Nearest Neighbor Quantizers.- 10.5 Lattice Vector Quantizers.- 10.6 High Resolution Distortion Approximations.- 10.7 Problems.- 11 Vector Quantization II.- 11.1 Introduction.- 11.2 Optimality Conditions for VQ.- 11.3 Vector Quantizer Design.- 11.4 Design Examples.- 11.5 Problems.- 12 Constrained Vector Quantization.- 12.1 Introduction.- 12.2 Complexity and Storage Limitations.- 12.3 Structurally Constrained VQ.- 12.4 Tree-Structured VQ.- 12.5 Classified VQ.- 12.6 Transform VQ.- 12.7 Product Code Techniques.- 12.8 Partitioned VQ.- 12.9 Mean-Removed VQ.- 12.10 Shape-Gain VQ.- 12.11 Multistage VQ.- 12.12 Constrained Storage VQ.- 12.13 Hierarchical and Multiresolution VQ.- 12.14 Nonlinear Interpolative VQ.- 12.15 Lattice Codebook VQ.- 12.16 Fast Nearest Neighbor Encoding.- 12.17 Problems.- 13 Predictive Vector Quantization.- 13.1 Introduction.- 13.2 Predictive Vector Quantization.- 13.3 Vector Linear Prediction.- 13.4 Predictor Design from Empirical Data.- 13.5 Nonlinear Vector Prediction.- 13.6 Design Examples.- 13.7 Problems.- 14 Finite-State Vector Quantization.- 14.1 Recursive Vector Quantizers.- 14.2 Finite-State Vector Quantizers.- 14.3 Labeled-States and Labeled-Transitions.- 14.4 Encoder/Decoder Design.- 14.5 Next-State Function Design.- 14.6 Design Examples.- 14.7 Problems.- 15 Tree and Trellis Encoding.- 15.1 Delayed Decision Encoder.- 15.2 Tree and Trellis Coding.- 15.3 Decoder Design.- 15.4 Predictive Trellis Encoders.- 15.5 Other Design Techniques.- 15.6 Problems.- 16 Adaptive Vector Quantization.- 16.1 Introduction.- 16.2 Mean Adaptation.- 16.3 Gain-Adaptive Vector Quantization.- 16.4 Switched Codebook Adaptation.- 16.5 Adaptive Bit Allocation.- 16.6 Address VQ.- 16.7 Progressive Code Vector Updating.- 16.8 Adaptive Codebook Generation.- 16.9 Vector Excitation Coding.- 16.10 Problems.- 17 Variable Rate Vector Quantization.- 17.1 Variable Rate Coding.- 17.2 Variable Dimension VQ.- 17.3 Alternative Approaches to Variable Rate VQ.- 17.4 Pruned Tree-Structured VQ.- 17.5 The Generalized BFOS Algorithm.- 17.6 Pruned Tree-Structured VQ.- 17.7 Entropy Coded VQ.- 17.8 Greedy Tree Growing.- 17.9 Design Examples.- 17.10 Bit Allocation Revisited.- 17.11 Design Algorithms.- 17.12 Problems.", "authors": ["Allen Gersho", "Robert M. Gray"], "related_topics": ["199833920", "28855332", "93372532"], "citation_count": "9417", "reference_count": "0", "references": ["2140190241", "2160547390", "2116467012", "2141362318", "2111918405", "2147717514", "2161160262", "1976709621", "2186428165", "1501500081"], "date": "1990"}, {"id": "2964022491", "title": "CatBoost: unbiased boosting with categorical features", "abstract": "This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.", "authors": ["Liudmila Prokhorenkova", "Gleb Gusev", "Aleksandr Vorobev", "Anna Veronika Dorogush", "Andrey Gulin"], "related_topics": ["70153297", "46686674", "5274069"], "citation_count": "473", "reference_count": "23", "references": ["2295598076", "1678356000", "1594031697", "2024046085", "2070493638", "2129018774", "2162059449", "1985759455", "2616657226", "2106100548"], "date": "2018"}, {"id": "2158940042", "title": "Ideal spatial adaptation by wavelet shrinkage", "abstract": "SUMMARY With ideal spatial adaptation, an oracle furnishes information about how best to adapt a spatially variable estimator, whether piecewise constant, piecewise polynomial, variable knot spline, or variable bandwidth kernel, to the unknown function. Estimation with the aid of an oracle offers dramatic advantages over traditional linear estimation by nonadaptive kernels; however, it is a priori unclear whether such performance can be obtained by a procedure relying on the data alone. We describe a new principle for spatially-adaptive estimation: selective wavelet reconstruction. We show that variable-knot spline fits and piecewise-polynomial fits, when equipped with an oracle to select the knots, are not dramatically more powerful than selective wavelet reconstruction with an oracle. We develop a practical spatially adaptive method, RiskShrink, which works by shrinkage of empirical wavelet coefficients. RiskShrink mimics the performance of an oracle for selective wavelet reconstruction as well as it is possible to do so. A new inequality in multivariate normal decision theory which we call the oracle inequality shows that attained performance differs from ideal performance by at most a factor of approximately 2 log n, where n is the sample size. Moreover no estimator can give a better guarantee than this. Within the class of spatially adaptive procedures, RiskShrink is essentially optimal. Relying only on the data, it comes within a factor log 2 n of the performance of piecewise polynomial and variableknot spline methods equipped with an oracle. In contrast, it is unknown how or if piecewise polynomial methods could be made to function this well when denied access to an oracle and forced to rely on data alone.", "authors": ["David L Donoho", "Iain M Johnstone"], "related_topics": ["164660894", "55166926", "55259147"], "citation_count": "13625", "reference_count": "15", "references": ["2062024414", "2098914003", "1489213177", "2102201073", "1969423031", "3132971798", "654435104", "2797502950", "2024599390", "2140832824"], "date": "1994"}, {"id": "1423339008", "title": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks", "abstract": "Recursive structure is commonly found in the inputs of different modalities such as natural scene images or natural language sentences. Discovering this recursive structure helps us to not only identify the units that an image or sentence contains but also how they interact to form a whole. We introduce a max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences. The same algorithm can be used both to provide a competitive syntactic parser for natural language sentences from the Penn Treebank and to outperform alternative approaches for semantic scene segmentation, annotation and classification. For segmentation and annotation our algorithm obtains a new level of state-of-the-art performance on the Stanford background dataset (78.1%). The features from the image parse tree outperform Gist descriptors for scene classification by 4%.", "authors": ["Richard Socher", "Cliff C. Lin", "Chris Manning", "Andrew Y. Ng"], "related_topics": ["186644900", "2781466058", "206134035"], "citation_count": "1490", "reference_count": "25", "references": ["2100495367", "2162915993", "2067191022", "2117130368", "2132339004", "2130325614", "1574901103", "1566135517", "1528789833", "2536208356"], "date": "2011"}, {"id": "2128796442", "title": "On the self-similar nature of Ethernet traffic", "abstract": "We demonstrate that Ethernet local area network (LAN) traffic is statistically self-similar, that none of the commonly used traffic models is able to capture this fractal behavior, and that such behavior has serious implications for the design, control, and analysis of high-speed, cell-based networks. Intuitively, the critical characteristic of this self-similar traffic is that there is no natural length of a \"burst\": at every time scale ranging from a few milliseconds to minutes and hours, similar-looking traffic bursts are evident; we find that aggregating streams of such traffic typically intensifies the self-similarity (\"burstiness\") instead of smoothing it.Our conclusions are supported by a rigorous statistical analysis of hundreds of millions of high quality Ethernet traffic measurements collected between 1989 and 1992, coupled with a discussion of the underlying mathematical and statistical properties of self-similarity and their relationship with actual network behavior. We also consider some implications for congestion control in high-bandwidth networks and present traffic models based on self-similar stochastic processes that are simple, accurate, and realistic for aggregate traffic.", "authors": ["Will E. Leland", "Murad S. Taqqu", "Walter Willinger", "Daniel V. Wilson"], "related_topics": ["25492975", "13951911", "46451311"], "citation_count": "1665", "reference_count": "20", "references": ["2078206416", "2165551776", "2153964544", "2064371950", "2142872720", "2065175568", "2122401729", "2031753087", "1993444966", "1986372184"], "date": "1993"}, {"id": "89157676", "title": "Automatic Recognition of Complex Three-Dimensional Objects from Optical Images", "abstract": "The possibility of duplicating in a machine the ability of animals and man to interpret visual information has intrigued many investigators. While this problem has been treated with considerable success relative to automatic classification of two-dimensional objects, especially with regard to recognition of printed characters, comparatively little has been achieved in automatic identification of three-dimensional objects. Generally speaking, such successes as have been attained in the latter area can be grouped under two broad headings: 1) scene analysis in which various specialized procedures are used to determine spatial relationships between simple objects such as solid polyhedra, cylinders, cones, etc., and 2) statistical pattern recognition in which certain numerical features of an image of an unknown object are used to classify it and perhaps to estimate its position and orientation [1]. This paper is addressed entirely to the second approach and is concerned with recognition of complex man- made objects rather than natural objects or simple solids.", "authors": ["Robert B. McGhee"], "related_topics": ["9095184", "64729616", "78646695"], "citation_count": "9", "reference_count": "17", "references": ["3017143921", "2133246412", "2159498975", "2122827492", "2072405256", "2067958620", "2084280096", "2150642297", "2166036481", "2331651964"], "date": "1973"}, {"id": "2160697532", "title": "Bioconductor: open software development for computational biology and bioinformatics", "abstract": "The Bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. The goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. We describe details of our aims and methods, identify current challenges, compare Bioconductor to other open bioinformatics projects, and provide working examples.", "authors": ["Robert C Gentleman", "Vincent J Carey", "Douglas M. Bates", "B.M. Bolstad", "Marcel Dettling", "Sandrine Dudoit", "Byron Ellis", "Laurent Gautier", "Yongchao Ge", "Jeff Gentry", "Kurt Hornik", "Torsten Hothorn", "Wolfgang Huber", "Stefano M. Iacus", "Rafael Irizarry", "Friedrich Leisch", "Cheng Li", "Martin Maechler", "Anthony J Rossini", "Gunther Sawitzki", "Colin A Smith", "Gordon K. Smyth", "Luke Tierney", "Jean Yang", "Jianhua Zhang"], "related_topics": ["2779694297", "2777904410", "110875604"], "citation_count": "12676", "reference_count": "26", "references": ["1965014786", "2038437697", "3022734214", "2156877380", "2150934173", "2041114254", "1520411860", "2068517117", "2054251921", "1572663059"], "date": "2004"}, {"id": "2084606150", "title": "PYRROS: static task scheduling and code generation for message passing multiprocessors", "abstract": "We describe a parallel programming tool for scheduling static task graphs and generating the appropriate target code for message passing MIMD architectures. The computational complexity of the system is almost linear to the size of the task graph and preliminary experiments show performance comparable to the \"best\" hand-written programs.", "authors": ["Tao Yang", "Apostolos Gerasoulis"], "related_topics": ["854659", "133162039", "21032095"], "citation_count": "289", "reference_count": "24", "references": ["2002257715", "2125412556", "1493749856", "2019356799", "2092309910", "2110417760", "1549134103", "2167548825", "2118735733", "1969947998"], "date": "1992"}, {"id": "2155844971", "title": "Generalized contribution plots in multivariate statistical process monitoring", "abstract": "Abstract This paper discusses contribution plots for both the D -statistic and the Q -statistic in multivariate statistical process control of batch processes. Contributions of process variables to the D -statistic are generalized to any type of latent variable model with or without orthogonality constraints. The calculation of contributions to the Q -statistic is discussed. Control limits for both types of contributions are introduced to show the relative importance of a contribution compared to the contributions of the corresponding process variables in the batches obtained under normal operating conditions. The contributions are introduced for off-line monitoring of batch processes, but can easily be extended to on-line monitoring and to continuous processes, as is shown in this paper.", "authors": ["Johan A. Westerhuis", "Stephen P. Gurden", "Age K. Smilde"], "related_topics": ["166623804", "89128539", "65965080"], "citation_count": "526", "reference_count": "29", "references": ["2947369839", "1978994389", "2000858991", "2057283314", "1990283595", "2012914747", "2015436473", "195815859", "2079441011", "2107146446"], "date": "2000"}, {"id": "2097629904", "title": "640-Gbit/s Data Transmission and Clock Recovery Using an Ultrafast Periodically Poled Lithium Niobate Device", "abstract": "This paper presents the first demonstration of the use of a periodically poled lithium niobate device for signal processing at 640 Gbit/s. Clock recovery is performed successfully using the lithium niobate device, and the clock signal is used to control a nonlinear fiber-based demultiplexer. The full 640-Gbit/s system gives error-free performance with no pattern dependence and there is less than 1-dB power penalty after 50-km fiber transmission.", "authors": ["L.K. Oxenlwe", "F. Gomez-Agis", "C. Ware", "S. Kurimura", "H.C.H. Mulvad", "M. Galili", "H. Nakajima", "J. Ichikawa", "D. Erasme", "A.T. Clausen", "P. Jeppesen"], "related_topics": ["2779835379", "2777207636", "137059387"], "citation_count": "58", "reference_count": "18", "references": ["2035424713", "2075078459", "2065681666", "2101046417", "2270231497", "2036184364", "2017324275", "2131273630", "2145441225", "2151525382"], "date": "2009"}, {"id": "146175359", "title": "Automated theory formation in mathematics", "abstract": "A program called \"AM\" is described which cairies on simple mathematics research: defining, and studying new concepts under the guidance of a large body of heuiistic rules. The 250 heurKtus communicate via an agenda mechanism, a global priority queue of small bisk', for the program to perform and teasons why each task is plausible (e.g., \"Find PENCRAHZTION. of 'prnes', because turued out to be so useful a Concept\"). Each concept is an active, structured knowledge module. One bundled very incomplete modules are initially supplied, each one corresponding to an elementary set theoretic concept (e.g., union). This provides a definite but immense space which AM begins to explore. In one boor, AM rediscovers hundreds of common concepts (including singleton sets, natural numbers, arithmetic) and theorems (e.g., unique factorization).", "authors": ["Douglas B. Lenat"], "related_topics": ["184264201", "177264268", "2777423538"], "citation_count": "175", "reference_count": "10", "references": ["1488252886", "2022286645", "1823666162", "1988651604", "1983113859", "1996158986", "2085089824", "2797582242", "1985789487", "184719387"], "date": "1977"}, {"id": "1546485226", "title": "The emergence of the unmarked: Optimality in prosodic morphology", "abstract": "the University of Victoria, UMass, and Rutgers University, particularly to Nora Aion, Akin Akinlabi, Olga Babko-Malaya, Eric Bakovic, Jill Beckman, Jose Benki, Laura Benua, Barry Carlson, Megan Crowhurst, Merce Gonzalez, Sharon Inkelas, Zvi Gilbert, Amalia Gnanadesikan, Rene Kager, Ed Keer, John Kingston, Paul Kiparsky, Marc van Oostendorp, Jaye Padgett, Rossina Petrova, Ivan Sag, Vieri Samek-Lodovici, Lisa Selkirk, Yael Sharvit, Pat Shaw, Paul Smolensky, Rachel Thorburn, Suzanne Urbanczyk, Jennifer Yearley, Laura Walsh, and Arnold Zwicky, for their comments and questions. We owe a special debt to Junko Ito and Armin Mester, who reviewed a draft of the NELS handout and provided much useful feedback. T The Emergence of the Unmarked Optimality in Prosodic Morphology1", "authors": ["John J. McCarthy", "Alan S. Prince"], "related_topics": ["148934300", "52119013", "41895202"], "citation_count": "1407", "reference_count": "49", "references": ["1608707468", "1586944595", "1533473429", "207108878", "370001395", "1591993017", "2004334173", "1985229197", "1590251447", "2090266881"], "date": "1993"}, {"id": "2012587148", "title": "A Survey on Policy Search for Robotics", "abstract": "Policy search is a subfield in reinforcement learning which focuses on finding good parameters for a given policy parametrization. It is well suited for robotics as it can cope with high-dimensional state and action spaces, one of the main challenges in robot learning. We review recent successes of both model-free and model-based policy search in robot learning.Model-free policy search is a general approach to learn policies based on sampled trajectories. We classify model-free methods based on their policy evaluation strategy, policy update strategy, and exploration strategy and present a unified view on existing algorithms. Learning a policy is often easier than learning an accurate forward model, and, hence, model-free methods are more frequently used in practice. However, for each sampled trajectory, it is necessary to interact with the robot, which can be time consuming and challenging in practice. Model-based policy search addresses this problem by first learning a simulator of the robot's dynamics from data. Subsequently, the simulator generates trajectories that are used for policy learning. For both model-free and model-based policy search methods, we review their respective properties and their applicability to robotic systems.", "authors": ["Marc Peter Deisenroth", "Gerhard Neumann", "Jan Peters"], "related_topics": ["188888258", "97541855", "90509273"], "citation_count": "859", "reference_count": "96", "references": ["2296319761", "1663973292", "1746819321", "2122410182", "2336416123", "3140968660", "1506806321", "2123487311", "2098432798", "2138537392"], "date": "2013"}, {"id": "2132984323", "title": "A theory for multiresolution signal decomposition: the wavelet representation", "abstract": "Multiresolution representations are effective for analyzing the information content of images. The properties of the operator which approximates a signal at a given resolution were studied. It is shown that the difference of information between the approximation of a signal at the resolutions 2/sup j+1/ and 2/sup j/ (where j is an integer) can be extracted by decomposing this signal on a wavelet orthonormal basis of L/sup 2/(R/sup n/), the vector space of measurable, square-integrable n-dimensional functions. In L/sup 2/(R), a wavelet orthonormal basis is a family of functions which is built by dilating and translating a unique function psi (x). This decomposition defines an orthogonal multiresolution representation called a wavelet representation. It is computed with a pyramidal algorithm based on convolutions with quadrature mirror filters. Wavelet representation lies between the spatial and Fourier domains. For images, the wavelet representation differentiates several spatial orientations. The application of this representation to data compression in image coding, texture discrimination and fractal analysis is discussed. >", "authors": ["S.G. Mallat"], "related_topics": ["47432892", "196216189", "2777451244"], "citation_count": "29465", "reference_count": "43", "references": ["2078206416", "2098914003", "2103504761", "2109863423", "1980149518", "2096684483", "2022735534", "1995756857", "2139797453", "2978983090"], "date": "1989"}, {"id": "2133246412", "title": "Picture processing by computer", "abstract": "Abstract : The field of picture processing by computer is reviewed from a technique-oriented standpoint. Only the processing of given pictures (as opposed to computer-synthesized pictures) is considered. Specific areas covered include: (a) Pictures as information sources and their efficient encoding; (b) Approximation of pictures - sampling and quantization techniques; (c) Position-invariant operations on pictures and their implementation (digital, electro-optical, optical); applications to matched filtering (template matching), spatial frequency filtering and image restoration, measurement of image quality, and image enhancement ('smoothing' and 'sharpening'); (d) Picture properties (linear; local and 'textural'; random) useful for pictorial pattern recognition; (e) 'Figure extraction' from pictures; figure properties (topology, size, shape); (f) Picture description and 'picture languages.' (Author)", "authors": ["Azriel Rosenfeld"], "related_topics": ["158096908", "106430172", "199681165"], "citation_count": "877", "reference_count": "226", "references": ["1978818813", "2158240273", "2086789740", "1976678415", "1996342882", "2099168648", "2161376274", "118296737", "1969324628", "2170633497"], "date": "1968"}, {"id": "2025605741", "title": "Recommender systems survey", "abstract": "Recommender systems have developed in parallel with the web. They were initially based on demographic, content-based and collaborative filtering. Currently, these systems are incorporating social information. In the future, they will use implicit, local and personal information from the Internet of things. This article provides an overview of recommender systems as well as collaborative filtering methods and algorithms; it also explains their evolution, provides an original classification for these systems, identifies areas of future implementation and develops certain areas selected for past, present or future importance.", "authors": ["J. Bobadilla", "F. Ortega", "A. Hernando", "A. Guti\u00e9Rrez"], "related_topics": ["557471498", "21569690", "44263959"], "citation_count": "2786", "reference_count": "246", "references": ["2171960770", "2054141820", "1660390307", "2042281163", "1971040550", "2149684865", "2110325612", "2101409192", "2097726984", "2100235918"], "date": "2013"}, {"id": "2062526841", "title": "On methods in the analysis of profile data", "abstract": "This paper is concerned with methods for analyzing quantitative, non-categorical profile data, e.g., a battery of tests given to individuals in one or more groups. It is assumed that the variables have a multinormal distribution with an arbitrary variance-covariance matrix. Approximate procedures based on classical analysis of variance are presented, including an adjustment to the degrees of freedom resulting in conservativeF tests. These can be applied to the case where the variance-covariance matrices differ from group to group. In addition, exact generalized multivariate analysis methods are discussed. Examples are given illustrating both techniques.", "authors": ["Samuel W. Greenhouse", "Seymour Geisser"], "related_topics": ["43514536", "192424360", "180877172"], "citation_count": "6754", "reference_count": "17", "references": ["2063698478", "2324309783", "2140101900", "2020737422", "2095378814", "2076327797", "2087747394", "2127170893", "2314185483", "2314631972"], "date": "1959"}, {"id": "2148099880", "title": "MACA-a New Channel Access Method for Packet Radio", "abstract": "n a The existing Carrier Sense Multiple Access (CSMA) method widely used i mateur packet radio on shared simplex packet radio channels frequently suffers from l the well-known \"hidden terminal problem\" and the less well known but related prob em of the \"exposed terminal.\" This paper proposes a new scheme, Multiple Access c with Collision Avoidance (MACA), that could greatly relieve these problems. MACA an also be easily extended to provide automatic transmitter power control. This could increase the carrying capacity of a channel substantially.", "authors": ["P. Karn"], "related_topics": ["59229178", "167465779", "147621760"], "citation_count": "2140", "reference_count": "0", "references": ["2137775453", "2132932625", "2157457404", "2101963262", "2149472588", "2099057525", "1992876548", "2123825896", "2000548713", "2017333190"], "date": "1989"}, {"id": "1490514105", "title": "Experiments on the costs and benefits of windowing in ID3", "abstract": "Abstract Quinlan's machine learning system ID3 uses a method called windowing to deal economically with large training sets. This paper describes a series of experiments performed to investigate the merits of this technique. In nearly every experiment the use of windowing considerably increased the CPU requirements of ID3, but produced no significant benefits. We conclude that in noisy domains (where ID3 is now commonly used), windowing should be avoided.", "authors": ["Jarryl Wirth", "Jason Catlett"], "related_topics": ["119857082", "41008148", "124101348"], "citation_count": "65", "reference_count": "10", "references": ["2149706766", "2128420091", "2159047538", "167515793", "1985624473", "98436501", "76664001", "188803003", "2035255798", "2144728596"], "date": "1988"}, {"id": "2142228262", "title": "Asymptotically optimal block quantization", "abstract": "In 1948 W. R. Bennett used a companding model for nonuniform quantization and proposed the formula D \\: = \\: \\frac{1}{12N^{2}} \\: \\int \\: p(x) [ E(x) ]^{-2} \\dx for the mean-square quantizing error where N is the number of levels, p (x) is the probability density of the input, and E \\prime (x) is the slope of the compressor curve. The formula, an approximation based on the assumption that the number of levels is large and overload distortion is negligible, is a useful tool for analytical studies of quantization. This paper gives a heuristic argument generalizing Bennett's formula to block quantization where a vector of random variables is quantized. The approach is again based on the asymptotic situation where N , the number of quantized output vectors, is very large. Using the resulting heuristic formula, an optimization is performed leading to an expression for the minimum quantizing noise attainable for any block quantizer of a given block size k . The results are consistent with Zador's results and specialize to known results for the one- and two-dimensional cases and for the case of infinite block length (k \\rightarrow \\infty) . The same heuristic approach also gives an alternate derivation of a bound of Elias for multidimensional quantization. Our approach leads to a rigorous method for obtaining upper bounds on the minimum distortion for block quantizers. In particular, for k = 3 we give a tight upper bound that may in fact be exact. The idea of representing a block quantizer by a block \"compressor\" mapping followed with an optimal quantizer for uniformly distributed random vectors is also explored. It is not always possible to represent an optimal quantizer with this block companding model.", "authors": ["A. Gersho"], "related_topics": ["28855332", "77553402", "138465053"], "citation_count": "1347", "reference_count": "12", "references": ["1978382377", "2146519989", "2004003571", "2156908459", "2001968606", "2137263269", "1589055062", "2068071220", "1972736931", "2152316618"], "date": "1979"}, {"id": "2105055683", "title": "Software transactional memory for dynamic-sized data structures", "abstract": "We propose a new form of software transactional memory (STM) designed to support dynamic-sized data structures, and we describe a novel non-blocking implementation. The non-blocking property we consider is obstruction-freedom. Obstruction-freedom is weaker than lock-freedom; as a result, it admits substantially simpler and more efficient implementations. A novel feature of our obstruction-free STM implementation is its use of modular contention managers to ensure progress in practice. We illustrate the utility of our dynamic STM with a straightforward implementation of an obstruction-free red-black tree, thereby demonstrating a sophisticated non-blocking dynamic data structure that would be difficult to implement by other means. We also present the results of simple preliminary performance experiments that demonstrate that an \"early release\" feature of our STM is useful for reducing contention, and that our STM lends itself to the effective use of modular contention managers.", "authors": ["Maurice Herlihy", "Victor Luchangco", "Mark Moir", "William N. Scherer"], "related_topics": ["167149655", "134277064", "55647110"], "citation_count": "1350", "reference_count": "13", "references": ["2752885492", "2113751407", "2101939036", "2167282885", "2769656678", "1981393723", "1993301893", "1978280181", "1980806195", "2073256416"], "date": "2003"}, {"id": "1489671546", "title": "System and method for recognizing touch typing under limited tactile feedback conditions", "abstract": "A system is disclosed for recognizing typing from typing transducers that provide the typist with only limited tactile feedback of key position. The system includes a typing decoder sensitive to the geometric pattern of a keystroke sequence as well as the distance between individual finger touches and nearby keys. The typing decoder hypothesizes plausible key sequences and compares their geometric pattern to the geometric pattern of corresponding finger touches. It may also hypothesize home row key locations for touches caused by hands resting on or near home row. The resulting pattern match metrics may be combined with character sequence transition probabilities from a spelling model. The typing decoder then chooses the hypothesis sequence with the best cumulative match metric and sends it as key codes or commands to a host computing device.", "authors": ["Wayne Carl Westerman"], "related_topics": ["68859911", "161615301", "2781209916"], "citation_count": "1454", "reference_count": "192", "references": ["1930456798", "1584397650", "2113918921", "1893940590", "2005198142", "2107118797", "1886112015", "2150874632", "2103081962", "2760775914"], "date": "2006"}, {"id": "1530456100", "title": "Parallel Communication With Limited Buffers", "abstract": "Currently known parallel communication schemes allow n nodes interconnected by arcs (in such a way that each node meets only a fixed number of arcs) to transmit n packets according to an arbitrary permutation in such a way that (1) only one packet is sent over a given arc at any step, (2) at most 0(log n) packets reside at a given node at any time and (3) with high probability, each packet arrives at its destination within 0(log n) steps. We present and analyze a new parallel communication scheme that ensures that at most a fixed number of packets reside at a given node at any time.", "authors": ["N. Pippenger"], "related_topics": ["46135064", "158379750", "37829124"], "citation_count": "119", "reference_count": "11", "references": ["2107997203", "2076458424", "2069489095", "1988294273", "1977908721", "2058355999", "1989693809", "2112582868", "2117355618", "1991349080"], "date": "1984"}, {"id": "2807650837", "title": "Diachronic word embeddings and semantic shifts: a survey", "abstract": "Recent years have witnessed a surge of publications aimed at tracing temporal changes in lexical semantics using distributional methods, particularly prediction-based word embedding models. However, this vein of research lacks the cohesion, common terminology and shared practices of more established areas of natural language processing. In this paper, we survey the current state of academic research related to diachronic word embeddings and semantic shifts detection. We start with discussing the notion of semantic shifts, and then continue with an overview of the existing methods for tracing such time-related shifts with word embedding models. We propose several axes along which these methods can be compared, and outline the main challenges before this emerging subfield of NLP, as well as prospects and possible applications.", "authors": ["Andrey Kutuzov", "Lilja \u00d8vrelid", "Terrence Szymanski", "Erik Velldal"], "related_topics": ["2777462759", "98954769", "547195049"], "citation_count": "148", "reference_count": "61", "references": ["2153579005", "1614298861", "2250539671", "2147152072", "1662133657", "2019096529", "2125031621", "2323881768", "2072644219", "1854884267"], "date": "2018"}, {"id": "2110810394", "title": "Multivalued dependencies and a new normal form for relational databases", "abstract": "A new type of dependency, which includes the well-known functional dependencies as a special case, is defined for relational databases. By using this concept, a new (\u201cfourth\u201d) normal form for relation schemata is defined. This fourth normal form is strictly stronger than Codd's \u201cimproved third normal form\u201d (or \u201cBoyce-Codd normal form\u201d). It is shown that every relation schema can be decomposed into a family of relation schemata in fourth normal form without loss of information (that is, the original relation can be obtained from the new relations by taking joins).", "authors": ["Ronald Fagin"], "related_topics": ["60593393", "132805070", "44701536"], "citation_count": "908", "reference_count": "11", "references": ["2232207765", "2125223317", "1505165377", "2023663289", "2111869173", "1998512182", "1495302482", "2132490332", "2074023317", "2048841336"], "date": "1977"}, {"id": "2162800060", "title": "PhysioBank, PhysioToolkit, and PhysioNet Components of a New Research Resource for Complex Physiologic Signals", "abstract": "Abstract\u2014The newly inaugurated Research Resource for Complex Physiologic Signals, which was created under the auspices of the National Center for Research Resources of the National Institutes of He...", "authors": ["Ary L. Goldberger", "Luis A. N. Amaral", "Leon Glass", "Jeffrey M. Hausdorff", "Plamen Ch. Ivanov", "Roger G. Mark", "Joseph E. Mietus", "George B. Moody", "Chung-Kang Peng", "H. Eugene Stanley"], "related_topics": ["55472147", "2522767166", "71924100"], "citation_count": "10427", "reference_count": "26", "references": ["2127873098", "2020870533", "2079133700", "2006524496", "2169713586", "1844495464", "1489387013", "1563883302", "2034214746", "1984797082"], "date": "2000"}, {"id": "2000366549", "title": "An Introduction to Splines for Use in Computer Graphics and Geometric Modeling", "abstract": "1 Introduction 2 Preliminaries 3 Hermite and Cubic Spline Interpolation 4 A Simple Approximation Technique - Uniform Cubic B-splines 5 Splines in a More General Setting 6 The One-Sided Basis 7 Divided Differences 8 General B-splines 9 B-spline Properties 10 Bezier Curves 11. Knot Insertion 12 The Oslo Algorithm 13 Parametric vs. Geometric Continuity 14 Uniformly-Shaped Beta-spline Surfaces 15 Geometric Continuity, Reparametrization, and the Chain Rule 16 Continuously-Shaped Beta-splines 17 An Explicity Formulation for Cubic Beta-splines 18 Discretely-Shaped Beta-splines 19 B-spline Representations for Beta-splines 20 Rendering and Evaluation 21 Selected Applications", "authors": ["Richard H. Bartels", "John C. Beatty", "Brian A. Barsky"], "related_topics": ["64485984", "84607441", "31447003"], "citation_count": "2135", "reference_count": "0", "references": ["2161406034", "1481420047", "1968256263", "649866511", "2151050383", "1963565426", "2163324644", "2154332114", "2151857564", "2125281025"], "date": "1987"}, {"id": "2197062852", "title": "Supersymmetry and Kahler Manifolds", "abstract": "Abstract We give the supersymmetric extension of non-linear models with scalar fields taking values in a complex Kahler manifold. The supersymmetry is simple for four-dimensional Minkowski space, complex for two-dimensional space-time. The supersymmetric symmetric lagrangian is given by a simple and elegant formula in terms of the Kahler metric of the manifold. (Anti-) self- dual supersymmetric solutions are also given. The special cases of the CPn\u22121 models and of models with scalar fields valued in a Grassman manifold Gp,q=G(p+q)/G(p) \u2297 U(q) are discussed in some detail.", "authors": ["B. Zumino"], "related_topics": ["121089165", "157135747", "79464548"], "citation_count": "834", "reference_count": "14", "references": ["2003022923", "1560145191", "2030773516", "2048343255", "2055449790", "2143341543", "1978029160", "2009544046", "2033424029", "2065336602"], "date": "1979"}, {"id": "1881530487", "title": "Multi-touch system and method for emulating modifier keys via fingertip chords", "abstract": "A multi-touch system is disclosed that recognizes simultaneous touchdown of four fingers on, above, or below the home row of keys as a modifier chord and applies modifiers such as Shift, Ctrl, or Alt to subsequent touch activity until none of the chord fingertips remain touching. Touches by the thumb of the modifier chord hand that occur before any modifiable typing or clicking activity cause the modifier chord to be canceled and reinterpreted as hand resting. The Shift modifier may be released temporarily during thumb keypresses that are intermixed with typing of capitalized characters. Distributing the modifier chord touches across different zones or key rows selects multiple modifiers. In an alternative embodiment, different modifiers can be selected with different arrangements of the fingers relative to one another within the chord, irrespective of absolute hand alignment with the touch surface.", "authors": ["Wayne Carl Westerman", "John Greer Elias"], "related_topics": ["175497961", "135598885", "2776881184"], "citation_count": "1660", "reference_count": "171", "references": ["2113918921", "2005198142", "2107118797", "1886112015", "2150874632", "2103081962", "1489671546", "1933306657", "1897547913", "1905787154"], "date": "2001"}, {"id": "2158714612", "title": "A simple and general parameterization quantifying performance in fading channels", "abstract": "We quantify the performance of wireless transmissions over random fading channels at high signal-to-noise ratio (SNR). The performance criteria we consider are average probability of:error and outage probability. We show that as functions of the average SNR, they can both be characterized by two parameters: the diversity and coding gains. They both exhibit identical diversity orders, but their coding gains in decibels differ by a constant. The diversity and coding gains are found to depend on the behavior of-the random SNR's probability density function only at the origin, or equivalently, on the decaying order of the corresponding moment generating function (i.e., how fast the moment generating function goes to zero as its argument goes to infinity). Diversity and coding gains for diversity combining systems are expressed in terms of the diversity branches' individual diversity and coding gains, where the branches can come from any diversity technique such as space, time, frequency, or, multipath. The proposed analysis offers a simple and unifying approach to evaluating the performance of uncoded and (possibly space-time) coded transmissions over fading channels, and the method applies to almost all digital modulation schemes, including M-ary phaseshift keying, quadrature amplitude modulation, and frequency-shift keying with coherent or noncoherent detection.", "authors": ["Zhengdao Wang", "G.B. Giannakis"], "related_topics": ["198746922", "81978471", "136817519"], "citation_count": "1357", "reference_count": "15", "references": ["2118040894", "2110659753", "2798333393", "2168847332", "598996319", "2103036624", "2099798769", "2130098973", "3021727161", "2096647193"], "date": "2003"}, {"id": "2047278710", "title": "On the mathematical foundations of learning", "abstract": "(1) A main theme of this report is the relationship of approximation to learning and the primary role of sampling (inductive inference). We try to emphasize relations of the theory of learning to the mainstream of mathematics. In particular, there are large roles for probability theory, for algorithms such as least squares, and for tools and ideas from linear algebra and linear analysis. An advantage of doing this is that communication is facilitated and the power of core mathematics is more easily brought to bear. We illustrate what we mean by learning theory by giving some instances. (a) The understanding of language acquisition by children or the emergence of languages in early human cultures. (b) In Manufacturing Engineering, the design of a new wave of machines is anticipated which uses sensors to sample properties of objects before, during, and after treatment. The information gathered from these samples is to be analyzed by the machine to decide how to better deal with new input objects (see [43]). (c) Pattern recognition of objects ranging from handwritten letters of the alphabet to pictures of animals, to the human voice. Understanding the laws of learning plays a large role in disciplines such as (Cognitive) Psychology, Animal Behavior, Economic Decision Making, all branches of Engineering, Computer Science, and especially the study of human thought processes (how the brain works). Mathematics has already played a big role towards the goal of giving a universal foundation of studies in these disciplines. We mention as examples the theory of Neural Networks going back to McCulloch and Pitts [25] and Minsky and Papert [27], the PAC learning of Valiant [40], Statistical Learning Theory as developed by Vapnik [42], and the use of reproducing kernels as in [17] among many other mathematical developments. We are heavily indebted to these developments. Recent discussions with a number of mathematicians have also been helpful. In", "authors": ["Felipe Cucker", "Steve Smale", ""], "related_topics": ["92393732", "2779915298", "193826839"], "citation_count": "2018", "reference_count": "40", "references": ["2148603752", "1554663460", "560409768", "1554576613", "2146766088", "2010315317", "2019363670", "2110652811", "1550331971", "2010029425"], "date": "2001"}, {"id": "1660562555", "title": "Handbook of Applied Cryptography", "abstract": "From the Publisher: A valuable reference for the novice as well as for the expert who needs a wider scope of coverage within the area of cryptography, this book provides easy and rapid access of information and includes more than 200 algorithms and protocols; more than 200 tables and figures; more than 1,000 numbered definitions, facts, examples, notes, and remarks; and over 1,250 significant references, including brief comments on each paper.", "authors": ["Alfred J. Menezes", "Scott A. Vanstone", "Paul C. Van Oorschot"], "related_topics": ["126954023", "556948339", "186497982"], "citation_count": "19819", "reference_count": "500", "references": ["2752885492", "2011039300", "2168676717", "2052267638", "2913419753", "1606480398", "2131300413", "1496801598", "2106539366", "2010939995"], "date": "1995"}, {"id": "2996501936", "title": "ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring", "abstract": "We improve the recently-proposed ``MixMatch semi-supervised learning algorithm by introducing two new techniques: distribution alignment and augmentation anchoring. - Distribution alignment encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of ground-truth labels. - Augmentation anchoring} feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input. To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained. Our new algorithm, dubbed ReMixMatch, is significantly more data-efficient than prior work, requiring between 5 times and 16 times less data to reach the same accuracy. For example, on CIFAR-10 with 250 labeled examples we reach 93.73% accuracy (compared to MixMatch's accuracy of 93.58% with 4000 examples) and a median accuracy of 84.92% with just four labels per class.", "authors": ["David Berthelot", "Nicholas Carlini", "Ekin D. Cubuk", "Alex Kurakin", "Kihyuk Sohn", "Han Zhang", "Colin Raffel"], "related_topics": ["58973888", "165216359", "19453392"], "citation_count": "155", "reference_count": "26", "references": ["2964121744", "2964137095", "1479807131", "2963399829", "3136604105", "2964159205", "2107008379", "2978426779", "2530816535", "2963956526"], "date": "2020"}, {"id": "2963173190", "title": "Return of the Devil in the Details: Delving Deep into Convolutional Nets", "abstract": "The latest generation of Convolutional Neural Networks (CNN) have achieved impressive results in challenging benchmarks on image recognition and object detection, significantly raising the interest of the community in these methods. Nevertheless, it is still unclear how different CNN methods compare with each other and with previous state-of-the-art shallow representations such as the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts a rigorous evaluation of these new techniques, exploring different deep architectures and comparing them on a common ground, identifying and disclosing important implementation details. We identify several useful properties of CNN-based representations, including the fact that the dimensionality of the CNN output layer can be reduced significantly without having an adverse effect on performance. We also identify aspects of deep and shallow methods that can be successfully shared. In particular, we show that the data augmentation techniques commonly applied to CNN-based methods can also be applied to shallow methods, and result in an analogous performance boost. Source code and models to reproduce the experiments in the paper is made publicly available.", "authors": ["Ken Chatfield", "Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman"], "related_topics": ["81363708", "2776151529", "43126263"], "citation_count": "3184", "reference_count": "27", "references": ["2618530766", "2102605133", "2108598243", "1849277567", "2963542991", "2109255472", "2031489346", "2155541015", "2162915993", "2131846894"], "date": "2014"}, {"id": "1981885118", "title": "Computer solution of large sparse positive definite systems", "abstract": "", "authors": ["Joseph E. Pasciak", "Alan George", "Joseph W. Liu"], "related_topics": ["49712288", "2777128864", "46085209"], "citation_count": "2324", "reference_count": "0", "references": ["2035080386", "2070232376", "2124313187", "2103606462", "1837874438", "2009923109", "2089024363", "618254468", "2114030927", "1987902628"], "date": "1982"}, {"id": "2016589492", "title": "A learning algorithm for continually running fully recurrent neural networks", "abstract": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length.", "authors": ["Ronald J. Williams", "David Zipser"], "related_topics": ["108583219", "147168706", "2780005939"], "citation_count": "5334", "reference_count": "14", "references": ["2154642048", "2293063825", "2110485445", "2143503258", "1881179843", "1959983357", "1984205520", "1984375561", "2119796132", "1527772862"], "date": "1989"}, {"id": "2149008718", "title": "Some principles for designing a wide-area WDM optical network", "abstract": "We explore design principles for next-generation optical wide-area networks, employing wavelength-division multiplexing (WDM) and targeted to nationwide coverage. This optical network exploits wavelength multiplexers and optical switches in routing nodes, so that an arbitrary virtual topology may be embedded on a given physical fiber network. The virtual topology, which is used as a packet-switched network and which consists of a set of all-optical \"lightpaths\", is set up to exploit the relative strengths of both optics and electronics-viz. packets of information are carried by the virtual topology \"as far as possible\" in the optical domain, but packet forwarding from lightpath to lightpath is performed via electronic switching, whenever required. We formulate the virtual topology design problem as an optimization problem with one of two possible objective functions: (1) for a given traffic matrix, minimize the network-wide average packet delay (corresponding to a solution for present traffic demands), or (2) maximize the scale factor by which the traffic matrix can be scaled up (to provide the maximum capacity upgrade for future traffic demands). Since simpler versions of this problem have been shown to be NP-hard, we resort to heuristic approaches. Specifically, we employ an iterative approach which combines \"simulated annealing\" (to search for a good virtual topology) and \"flow deviation\" (to optimally route the traffic-and possibly bifurcate its components-on the virtual topology). We do not consider the number of available wavelengths to be a constraint, i.e., we ignore the routing of lightpaths and wavelength assignment for these lightpaths. We illustrate our approaches by employing experimental traffic statistics collected from NSFNET.", "authors": ["Biswanath Mukherjee", "Dhritiman Banerjee", "S. Ramamurthy", "Amarnath Mukherjee"], "related_topics": ["117729477", "199845137", "120317029"], "citation_count": "815", "reference_count": "39", "references": ["2128796442", "2147092597", "2136046802", "2109370530", "2049888220", "2161664123", "2126199809", "2014427146", "2130244809", "2027090677"], "date": "1996"}, {"id": "2132549764", "title": "Statistical pattern recognition: a review", "abstract": "The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.", "authors": ["A.K. Jain", "R.P.W. Duin", "Jianchang Mao"], "related_topics": ["40608802", "44868376", "52622490"], "citation_count": "8688", "reference_count": "178", "references": ["2156909104", "2148603752", "2124776405", "1554663460", "2139212933", "2912934387", "2117812871", "1548802052", "2125838338", "1679913846"], "date": "1999"}, {"id": "2159048618", "title": "Experimental queueing analysis with long-range dependent packet traffic", "abstract": "Traffic measurement studies from a wide range of working packet networks have convincingly established the presence of significant statistical features that are characteristic of fractal traffic processes, in the sense that these features span many time scales. Of particular interest in packet traffic modeling is a property called long-range dependence (LRD), which is marked by the presence of correlations that can extend over many time scales. We demonstrate empirically that, beyond its statistical significance in traffic measurements, long-range dependence has considerable impact on queueing performance, and is a dominant characteristic for a number of packet traffic engineering problems. In addition, we give conditions under which the use of compact and simple traffic models that incorporate long-range dependence in a parsimonious manner (e.g., fractional Brownian motion) is justified and can lead to new insights into the traffic management of high speed networks.", "authors": ["Ashok Erramilli", "Onuttom Narayan", "Walter Willinger"], "related_topics": ["113804518", "176715033", "16160715"], "citation_count": "1196", "reference_count": "32", "references": ["2105818147", "2148275477", "2171873915", "2128796442", "2115122866", "2158283087", "2158712333", "1978061253", "2563178574", "2129337887"], "date": "1996"}, {"id": "1985896407", "title": "Research toward the development of a lexical knowledge base for natural language processing", "abstract": "This paper documents research toward building a complete lexicon containing all the words found in general newspaper text. It is intended to provide the reader with an understanding of the inherent limitations of existing vocabulary collection methods and the need for greater attention to multi-word phrases as the building blocks of text. Additionally, while traditional reference books define many proper nouns, they appear to be very limited in their coverage of the new proper nouns appearing daily in newspapers. Proper nouns appear to require a grammar and lexicon of components much the way general parsing of text requires syntactic rules and a lexicon of common nouns.", "authors": ["R. A. Amsler"], "related_topics": ["41417386", "2778121359", "126706616"], "citation_count": "15", "reference_count": "20", "references": ["1493596129", "2032527312", "2152909313", "1731571041", "1485222543", "1566182035", "2027666258", "2011386395", "2058740097", "1606177486"], "date": "1989"}, {"id": "2129018774", "title": "An empirical comparison of supervised learning algorithms", "abstract": "A number of supervised learning methods have been introduced in the last decade. Unfortunately, the last comprehensive empirical evaluation of supervised learning was the Statlog Project in the early 90's. We present a large-scale empirical comparison between ten supervised learning methods: SVMs, neural nets, logistic regression, naive bayes, memory-based learning, random forests, decision trees, bagged trees, boosted trees, and boosted stumps. We also examine the effect that calibrating the models via Platt Scaling and Isotonic Regression has on their performance. An important aspect of our study is the use of a variety of performance criteria to evaluate the learning methods.", "authors": ["Rich Caruana", "Alexandru Niculescu-Mizil"], "related_topics": ["136389625", "58973888", "8038995"], "citation_count": "2630", "reference_count": "25", "references": ["2156909104", "2911964244", "2148603752", "2966207845", "1570448133", "2912934387", "2084812512", "1576520375", "2152761983", "1618905105"], "date": "2006"}, {"id": "2019635781", "title": "Probabilistic Solution of Ill-Posed Problems in Computational Vision", "abstract": "We formulate several problems in early vision as inverse problems. Among the solution methods we review standard regularization theory, discuss its limitations, and present new stochastic (in particular, Bayesian) techniques based on Markov Random Field models for their solution. We derive efficient algorithms and describe parallel implementations on digital parallel SIMD architectures, as well as a new class of parallel hybrid computers that mix digital with analog components.", "authors": ["Jose Marroquin", "S Mitter", "Tomaso Poggio"], "related_topics": ["18789546", "120373497", "2778045648"], "citation_count": "1184", "reference_count": "36", "references": ["2581275558", "1997063559", "2740373864", "2158365276", "2142901448", "1531060698", "2149846618", "1597739853", "2751862591", "2075379212"], "date": "1987"}, {"id": "2122825543", "title": "Regularization and variable selection via the elastic net", "abstract": "Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together.The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the", "authors": ["Hui Zou", "Trevor Hastie"], "related_topics": ["203868755", "2778060275", "148483581"], "citation_count": "14066", "reference_count": "32", "references": ["1554944419", "2135046866", "2109363337", "2063978378", "2157795344", "2798909945", "2143426320", "2074682976", "1975900269", "2138550913"], "date": "2005"}, {"id": "1584710637", "title": "What is morphology", "abstract": "Preface.Abbreviations.1. Thinking about Morphology and Morphological Analysis:.1.1 What is Morphology?.1.2 Morphemes.1.3 Morphology in Action.1.4 Foundational Beliefs.1.5 Introduction to Morphological Analysis.1.6 Summary.Introduction to Kujamaat Joola.Exercises.2. Words and Lexemes:.2.1 What is a Word?.2.2 Empirical Tests for Wordhood.2.3 Types of Words.2.4 Inflection vs. Derivation.2.5 Two Approaches to Morphology: Item-and-Arrangement, Item-and-Process.2.6 The Lexicon.2.7 Summary.Kujamaat Joola Noun Classes.Exercises.3. Morphology and Phonology:.3.1 Allomorphs.3.2 Prosodic Morphology.3.3 Primary and Secondary Affixes.3.4 Linguistic Exaptation, Leveling, and Analogy.3.5 Morphophonology and Secret Languages.3.6 Summary.Kujamaat Joola Morphophonology.Exercises.4. Derivation and the Lexicon:.4.1 The Saussurean Sign.4.2 Motivation and Compositionality.4.3 Derivation and Structure.4.4 Summary.Derivation in Kujamaat Joola.Exercises.5. Derivation and Semantics:.5.1 The Polysemy Problem.5.2 The Semantics of Derived Lexemes.5.3 Summary.Derivation and verbs in Kujamaat Joola.Exercises.6. Inflection:.6.1 What is Inflection?.6.2 Inflection vs. Derivation.6.3 Inventory of Inflectional Morphology Types.6.4 Syncretism.6.5 Typology.6.6 Summary.Agreement in Kujamaat Joola.Exercises.7. Morphology and Syntax:.7.1 Morphological vs. Syntactic Inflection.7.2 Structural constraints on morphological inflection.7.3 Inflection and Universal Grammar.7.4 Grammatical function changing.7.5 Summary.Kujamaat Joola verb morphology.A brief survey of Kujamaat Joola syntax.Exercises.8. Morphological Productivity:.8.1 What is morphological productivity?.8.2 Productivity and structure: Negative prefixes in English.8.3 Degrees of productivity.8.4 Salience and productivity.8.5 Testing productivity.8.6 Conclusion.Exercises.Glossary.References.Index", "authors": ["Mark Aronoff", "Kirsten Anne Fudeman"], "related_topics": ["159403335", "2778121359", "91713390"], "citation_count": "237", "reference_count": "0", "references": ["1586401530", "2038542953", "2070243191", "2310362279", "2470484508", "2251049886", "2010051322", "2302491277", "2889294614", "1987628253"], "date": "2004"}, {"id": "2117235019", "title": "Floodless in seattle: a scalable ethernet architecture for large enterprises", "abstract": "IP networks today require massive effort to configure and manage. Ethernet is vastly simpler to manage, but does not scale beyond small local area networks. This paper describes an alternative network architecture called SEATTLE that achieves the best of both worlds: The scalability of IP combined with the simplicity of Ethernet. SEATTLE provides plug-and-play functionality via flat addressing, while ensuring scalability and efficiency through shortest-path routing and hash-based resolution of host information. In contrast to previous work on identity-based routing, SEATTLE ensures path predictability and stability, and simplifies network management. We performed a simulation study driven by real-world traffic traces and network topologies, and used Emulab to evaluate a prototype of our design based on the Click and XORP open-source routing platforms. Our experiments show that SEATTLE efficiently handles network failures and host mobility, while reducing control overhead and state requirements by roughly two orders of magnitude compared with Ethernet bridging.", "authors": ["Changhoon Kim", "Matthew Caesar", "Jennifer Rexford"], "related_topics": ["151643298", "151898751", "68178114"], "citation_count": "507", "reference_count": "32", "references": ["2010365467", "2150676586", "2125855750", "2020765652", "2177058407", "2169196622", "2152226783", "2102907001", "2109224931", "2147499094"], "date": "2008"}, {"id": "2138756793", "title": "CCFinder: a multilinguistic token-based code clone detection system for large scale source code", "abstract": "A code clone is a code portion in source files that is identical or similar to another. Since code clones are believed to reduce the maintainability of software, several code clone detection techniques and tools have been proposed. This paper proposes a new clone detection technique, which consists of the transformation of input source text and a token-by-token comparison. For its implementation with several useful optimization techniques, we have developed a tool, named CCFinder (Code Clone Finder), which extracts code clones in C, C++, Java, COBOL and other source files. In addition, metrics for the code clones have been developed. In order to evaluate the usefulness of CCFinder and metrics, we conducted several case studies where we applied the new tool to the source code of JDK, FreeBSD, NetBSD, Linux, and many other systems. As a result, CCFinder has effectively found clones and the metrics have been able to effectively identify the characteristics of the systems. In addition, we have compared the proposed technique with other clone detection techniques.", "authors": ["T. Kamiya", "S. Kusumoto", "K. Inoue"], "related_topics": ["43126263", "11685472", "2778739878"], "citation_count": "2056", "reference_count": "15", "references": ["1990061958", "2610179052", "2157532207", "2109943392", "2128698639", "1698439592", "1964795700", "2115534035", "2118024368", "1512285202"], "date": "2002"}, {"id": "2158454296", "title": "Mining sequential patterns", "abstract": "We are given a large database of customer transactions, where each transaction consists of customer-id, transaction time, and the items bought in the transaction. We introduce the problem of mining sequential patterns over such databases. We present three algorithms to solve this problem, and empirically evaluate their performance using synthetic data. Two of the proposed algorithms, AprioriSome and AprioriAll, have comparable performance, albeit AprioriSome performs a little better when the minimum number of customers that must support a sequential pattern is low. Scale-up experiments show that both AprioriSome and AprioriAll scale linearly with the number of customer transactions. They also have excellent scale-up properties with respect to the number of transactions per customer and the number of items in a transaction. >", "authors": ["R. Agrawal", "R. Srikant"], "related_topics": ["25185021", "127722929", "191087605"], "citation_count": "8764", "reference_count": "11", "references": ["1484413656", "2166559705", "2045821558", "2784619191", "2154765457", "2175671778", "3004186389", "2162945593", "2002338745", "1964795578"], "date": "1995"}, {"id": "2026019770", "title": "Discrimination-aware data mining", "abstract": "In the context of civil rights law, discrimination refers to unfair or unequal treatment of people based on membership to a category or a minority, without regard to individual merit. Rules extracted from databases by data mining techniques, such as classification or association rules, when used for decision tasks such as benefit or credit approval, can be discriminatory in the above sense. In this paper, the notion of discriminatory classification rules is introduced and studied. Providing a guarantee of non-discrimination is shown to be a non trivial task. A naive approach, like taking away all discriminatory attributes, is shown to be not enough when other background knowledge is available. Our approach leads to a precise formulation of the redlining problem along with a formal result relating discriminatory rules with apparently safe ones by means of background knowledge. An empirical assessment of the results on the German credit dataset is also provided.", "authors": ["Dino Pedreshi", "Salvatore Ruggieri", "Franco Turini"], "related_topics": ["193524817", "2780049985", "2780451532"], "citation_count": "547", "reference_count": "14", "references": ["2084812512", "1506285740", "2128906841", "2154642793", "1623342295", "1580325466", "1973036367", "2146167636", "3126021231", "1648937643"], "date": "2008"}, {"id": "2159128662", "title": "Big Data: A Survey", "abstract": "In this paper, we review the background and state-of-the-art of big data. We first introduce the general background of big data and review related technologies, such as could computing, Internet of Things, data centers, and Hadoop. We then focus on the four phases of the value chain of big data, i.e., data generation, data acquisition, data storage, and data analysis. For each phase, we introduce the general background, discuss the technical challenges, and review the latest advances. We finally examine the several representative applications of big data, including enterprise management, Internet of Things, online social networks, medial applications, collective intelligence, and smart grid. These discussions aim to provide a comprehensive overview and big-picture to readers of this exciting area. This survey is concluded with a discussion of open problems and future directions.", "authors": ["Min Chen", "Shiwen Mao", "Yunhao Liu"], "related_topics": ["75684735", "89057211", "79974875"], "citation_count": "3358", "reference_count": "138", "references": ["2173213060", "3013264884", "1981420413", "1494137514", "2119565742", "2128438887", "2131975293", "2153704625", "2166445532", "1574901103"], "date": "2014"}, {"id": "2666600683", "title": "Optimal aggregation algorithms for middleware", "abstract": "Assume that each object in a database has m grades, or scores, one for each of m attributes. For example, an object can have a color grade, that tells how red it is, and a shape grade, that tells how round it is. For each attribute, there is a sorted list, which lists each object and its grade under that attribute, sorted by grade (highest grade first). Each object is assigned an overall grade, that is obtained by combining the attribute grades using a fixed monotone aggregation function, or combining rule, such as min or average. To determine the top k objects, that is, k objects with the highest overall grades, the naive algorithm must access every object in the database, to find its grade under each attribute. Fagin has given an algorithm (\"Fagin's Algorithm\", or FA) that is much more efficient. For some monotone aggregation functions, FA is optimal with high probability in the worst case. We analyze an elegant and remarkably simple algorithm (\"the threshold algorithm\", or TA) that is optimal in a much stronger sense than FA. We show that TA is essentially optimal, not just for some monotone aggregation functions, but for all of them, and not just in a high-probability worst-case sense, but over every database. Unlike FA, which requires large buffers (whose size may grow unboundedly as the database size grows), TA requires only a small, constant-size buffer. TA allows early stopping, which yields, in a precise sense, an approximate version of the top k answers. We distinguish two types of access: sorted access (where the middleware system obtains the grade of an object in some sorted list by proceeding through the list sequentially from the top), and random access (where the middleware system requests the grade of object in a list, and obtains it in one step). We consider the scenarios where random access is either impossible, or expensive relative to sorted access, and provide algorithms that are essentially optimal for these cases as well.", "authors": ["Ronald Fagin", "Amnon Lotem", "Moni Naor"], "related_topics": ["101722063", "64729616", "2834757"], "citation_count": "3955", "reference_count": "23", "references": ["2912565176", "2295428206", "1833785989", "2093191240", "1552828154", "1990313671", "2020919487", "2041645394", "2164520297", "2168605051"], "date": "2003"}, {"id": "2179295257", "title": "Simulation of wrinkled surfaces", "abstract": "Computer generated shaded images have reached an impressive degree of realism with the current state of the art. They are not so realistic, however, that they would fool many people into believing they are real. One problem is that the surfaces tend to look artificial due to their extreme smoothness. What is needed is a means of simulating the surface irregularities that are on real surfaces. In 1973 Ed Catmull introduced the idea of using the parameter values of parametrically defined surfaces to index into a texture definition function which scales the intensity of the reflected light. By tying the texture pattern to the parameter values, the texture is guaranteed to rotate and move with the object. This is good for showing patterns painted on the surface, but attempts to simulate rough surfaces in this way are unconvincing. This paper presents a method of using a texturing function to perform a small perturbation on the direction of the surface normal before using it in the intensity calculations. This process yields images with realistic looking surface wrinkles without the need to model each wrinkle as a separate surface element. Several samples of images made with this technique are included.", "authors": ["J. F. Blinn"], "related_topics": ["2775953907", "118732077", "2781195486"], "citation_count": "1144", "reference_count": "0", "references": ["2125833438", "2118588333", "2111920077", "2059753342", "2800944712", "2107487516", "1998785741", "2107258888", "2043012599", "2039838555"], "date": "1988"}, {"id": "2007179372", "title": "Culture, dialectics, and reasoning about contradiction.", "abstract": "Chinese ways of dealing with seeming contradictions result in a dialectical or compromise approach\u2014retaining basic elements of opposing perspectives by seeking a \"middle way.\" On the other hand, European-American ways, deriving from a lay version of Aristotelian logic, result in a differentiation model that polarizes contradictory perspectives in an effort to determine which fact or position is correct. Five empirical studies showed that dialectical thinking is a form of folk wisdom in Chinese culture: Chinese participants preferred dialectical proverbs containing seeming contradictions more than did American participants. Chinese participants also preferred dialectical resolutions to social conflicts and preferred dialectical arguments over classical Western logical arguments. Furthermore, when 2 apparently contradictory propositions were presented, American participants polarized their views, and Chinese participants were moderately accepting of both propositions. Origins of these cultural differences and their implications for human reasoning in general are discussed.", "authors": ["Kaiping Peng", "Richard E. Nisbett"], "related_topics": ["2776728590", "13184196", "2779398514"], "citation_count": "2212", "reference_count": "58", "references": ["1973294727", "1559468026", "2333584940", "3003370097", "2076207454", "2140225297", "2112072287", "2157904933", "2028211630", "2084812103"], "date": "1998"}, {"id": "2060366807", "title": "HYPOTHALAMIC UNIT ACTIVITY. I. VISCERAL AND SOMATIC INFLUENCES.", "abstract": "Abstract 1. 1. In sixteen acute experiments the firing rates of single units within hypothalamic and ventral thalamic structures were analyzed during individual and paired visceral and somatic stimulation. Visceral stimulation involved distention of the urinary bladder. Somatic stimulation consisted of electrical stimulation of the sciatic nerve, adjusted to minimize A-delta and C fiber volleys. Responses to auditory and visual stimuli were also noted. 2. 2. Thirty per cent of the units responded to bladder distention and 35 per cent to sciatic stimulation. During these stimuli, a reduction in firing rate was encountered nearly as frequently as an augmentation in rate. Ipsilateral sciatic stimulation exerted as strong an effect as contralateral stimulation on units within both ventral thalamic nuclei and the hypothalamus. 3. 3. Anterior and ventral posterior hypothalamic units were not as responsive to visceral and somatic stimuli as were dorsal posterior hypothalamic and ventral thalamic units. The pattern of response of the majority of ventral thalamic units was similar to that of the hypothalamic units. Few units, dispersed widely through the hypothalamus, were responsive to visual and auditory stimuli. 4. 4. Over 80 per cent of the units that responded to bladder distention also responded to sciatic stimulation or their firing rate during bladder distention was modified by simultaneous sciatic stimulation.", "authors": ["D.G. Stuart", "", "R.W. Porter", "", "W.R. Adey", "", "Y. Kamikawa", ""], "related_topics": ["24998067", "2779246727", "2781149210"], "citation_count": "72", "reference_count": "30", "references": ["632519486", "2082636923", "2948504911", "2602498755", "2030916992", "617440007", "2114696013", "2164809435", "2063781288", "2075261147"], "date": "1964"}, {"id": "2051781844", "title": "Theoretical analysis of the effects of noise on diffusion tensor imaging", "abstract": "A theoretical framework is presented for understanding the effects of noise on estimates of the eigenvalues and eigenvectors of the diffusion tensor at moderate to high signal-to-noise ratios. Image noise produces a random perturbation of the diffusion tensor. Power series solutions to the eigenvalue equation are used to evaluate the effects of the perturbation to second order. It is shown that in anisotropic systems the expectation value of the largest eigenvalue is overestimated and the lowest eigenvalue is underestimated. Hence, diffusion anisotropy is overestimated in general. This result is independent of eigenvalue sorting bias. Furthermore, averaging eigenvalues over a region of interest produces greater bias than averaging tensors prior to diagonalization. Finally, eigenvector noise is shown to depend on the eigenvalue contrast and imposes a theoretical limit on the accuracy of simple fiber tracking schemes. The theoretical results are shown to agree with Monte Carlo simulations.", "authors": ["Adam W. Anderson"], "related_topics": ["46865736", "2505209", "158693339"], "citation_count": "348", "reference_count": "27", "references": ["2142900310", "2022530159", "2110431535", "2170596158", "2157035009", "2147133578", "2137216139", "2048844243", "2046132588", "2057167208"], "date": "2001"}, {"id": "2089024363", "title": "Algorithm 887: CHOLMOD, Supernodal Sparse Cholesky Factorization and Update/Downdate", "abstract": "CHOLMOD is a set of routines for factorizing sparse symmetric positive definite matrices of the form A or AAT, updating/downdating a sparse Cholesky factorization, solving linear systems, updating/downdating the solution to the triangular system Lx\u2009=\u2009b, and many other sparse matrix functions for both symmetric and unsymmetric matrices. Its supernodal Cholesky factorization relies on LAPACK and the Level-3 BLAS, and obtains a substantial fraction of the peak performance of the BLAS. Both real and complex matrices are supported. CHOLMOD is written in ANSI/ISO C, with both C and MATLABTM interfaces. It appears in MATLAB 7.2 as x\u2009=\u2009A\\b when A is sparse symmetric positive definite, as well as in several other sparse matrix functions.", "authors": ["Yanqing Chen", "Timothy A. Davis", "William W. Hager", "Sivasankaran Rajamanickam"], "related_topics": ["44363057", "46085209", "34727166"], "citation_count": "750", "reference_count": "45", "references": ["2070232376", "1480928214", "1520511539", "2002257715", "2052602889", "2084379367", "2038469228", "2014730252", "2890534020", "1988425770"], "date": "2008"}, {"id": "2156580773", "title": "In search of an understandable consensus algorithm", "abstract": "Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems. In order to enhance understandability, Raft separates the key elements of consensus, such as leader election, log replication, and safety, and it enforces a stronger degree of coherency to reduce the number of states that must be considered. Results from a user study demonstrate that Raft is easier for students to learn than Paxos. Raft also includes a new mechanism for changing the cluster membership, which uses overlapping majorities to guarantee safety.", "authors": ["Diego Ongaro", "John Ousterhout"], "related_topics": ["55368355", "9132879", "49265948"], "citation_count": "1808", "reference_count": "33", "references": ["1981420413", "2119565742", "2119738171", "192446467", "3137759927", "3021428210", "1992479210", "2205436351", "1973501242", "2143149536"], "date": "2014"}, {"id": "2020459435", "title": "Human factors and behavioral science: Textons, the fundamental elements in preattentive vision and perception of textures", "abstract": "Recent research in texture discrimination has revealed the existence of a separate \u201cpreattentive visual system\u201d that cannot process complex forms, yet can, almost instantaneously, without effort or scrutiny, detect differences in a few local conspicuous features, regardless of where they occur. These features, called \u201ctextons\u201d, are elongated blobs (e.g., rectangles, ellipses, or line segments) with specific properties, including color, angular orientation, width, length, binocular and movement disparity, and flicker rate. The ends-of-lines (terminators) and crossings of line segments are also textons. Only differences in the textons or in their density (or number) can be preattentively detected while the positional relationship between neighboring textons passes unnoticed. This kind of positional information is the essence of form perception, and can be extracted only by a time-consuming and spatially restricted process that we call \u201cfocal attention\u201d. The aperture of focal attention can be very narrow, even restricted to a minute portion of the fovea, and shifting its locus requires about 50 ms. Thus preattentive vision serves as an \u201cearly warning system\u201d by pointing out those loci of texton differences that should be attended to. According to this theory, at any given instant the visual information intake is relatively modest.", "authors": ["B. Julesz", "J. R. Bergen"], "related_topics": ["139132820", "2779934759", "26760741"], "citation_count": "670", "reference_count": "26", "references": ["2149095485", "2032533296", "2130355536", "2117731089", "1997494543", "1510355813", "2064633044", "1980429329", "2066548055", "2006243321"], "date": "1983"}, {"id": "393180982", "title": "The Extended Mind", "abstract": "Where does the mind stop and the rest of the world begin? The question invites two standard replies. Some accept the intuitive demarcations of skin and skull, and say that what is outside the body is outside the mind. Others are impressed by arguments suggesting that the meaning of our words \"just ain't in the head\", and hold that this externalism about meaning carries over into an externalism about mind. We propose to pursue a third position. We will advocate an externalism about mind, but one that is in no way grounded in the debatable role of external reference in fixing the contents of our mental states. Rather, we advocate an *active externalism*, based on the active role of the environment in driving cognitive processes.", "authors": ["Andy Clark", "David J. Chalmers"], "related_topics": ["159977948", "2778171780", "2781142449"], "citation_count": "6661", "reference_count": "66", "references": ["2085529605", "1505563434", "1977308918", "2945424237", "2048701323", "1698657956", "2587573685", "2914331897", "1516748551", "2118373646"], "date": "1997"}, {"id": "2000041758", "title": "Ligra: a lightweight graph processing framework for shared memory", "abstract": "There has been significant recent interest in parallel frameworks for processing graphs due to their applicability in studying social networks, the Web graph, networks in biology, and unstructured meshes in scientific simulation. Due to the desire to process large graphs, these systems have emphasized the ability to run on distributed memory machines. Today, however, a single multicore server can support more than a terabyte of memory, which can fit graphs with tens or even hundreds of billions of edges. Furthermore, for graph algorithms, shared-memory multicores are generally significantly more efficient on a per core, per dollar, and per joule basis than distributed memory systems, and shared-memory algorithms tend to be simpler than their distributed counterparts.In this paper, we present a lightweight graph processing framework that is specific for shared-memory parallel/multicore machines, which makes graph traversal algorithms easy to write. The framework has two very simple routines, one for mapping over edges and one for mapping over vertices. Our routines can be applied to any subset of the vertices, which makes the framework useful for many graph traversal algorithms that operate on subsets of the vertices. Based on recent ideas used in a very fast algorithm for breadth-first search (BFS), our routines automatically adapt to the density of vertex sets. We implement several algorithms in this framework, including BFS, graph radii estimation, graph connectivity, betweenness centrality, PageRank and single-source shortest paths. Our algorithms expressed using this framework are very simple and concise, and perform almost as well as highly optimized code. Furthermore, they get good speedups on a 40-core machine and are significantly more efficient than previously reported results using graph frameworks on machines with many more cores.", "authors": ["Julian Shun", "Guy E. Blelloch"], "related_topics": ["136134403", "115625", "96333769"], "citation_count": "704", "reference_count": "292", "references": ["3145128584", "2112090702", "2148606196", "3013264884", "2101196063", "2170616854", "2035080386", "1507039213", "2096544401", "2755088640"], "date": "2013"}, {"id": "2030620341", "title": "Reproducible Research in Computational Harmonic Analysis", "abstract": "Scientific computation is emerging as absolutely central to the scientific method. Unfortunately, it's error-prone and currently immature-traditional scientific publication is incapable of finding and rooting out errors in scientific computation-which must be recognized as a crisis. An important recent development and a necessary response to the crisis is reproducible computational research in which researchers publish the article along with the full computational environment that produces the results. In this article, the authors review their approach and how it has evolved over time, discussing the arguments for and against working reproducibly.", "authors": ["D.L. Donoho", "A. Maleki", "I.U. Rahman", "M. Shahram", "V. Stodden"], "related_topics": ["2522767166", "41008148", "80444323"], "citation_count": "330", "reference_count": "10", "references": ["2296616510", "2243629635", "2099641086", "2050834445", "1977252496", "2129270900", "1595114968", "2096610373", "2064954714", "1974804467"], "date": "2008"}, {"id": "1993482412", "title": "New sampling-based summary statistics for improving approximate query answers", "abstract": "In large data recording and warehousing environments, it is often advantageous to provide fast, approximate answers to queries, whenever possible. Before DBMSs providing highly-accurate approximate answers can become a reality, many new techniques for summarizing data and for estimating answers from summarized data must be developed. This paper introduces two new sampling-based summary statistics, concise samples and counting samples, and presents new techniques for their fast incremental maintenance regardless of the data distribution. We quantify their advantages over standard sample views in terms of the number of additional sample points for the same view size, and hence in providing more accurate query answers. Finally, we consider their application to providing fast approximate answers to hot list queries. Our algorithms maintain their accuracy in the presence of ongoing insertions to the data warehouse.", "authors": ["Phillip B. Gibbons", "Yossi Matias"], "related_topics": ["44692378", "135572916", "29499845"], "citation_count": "605", "reference_count": "27", "references": ["1506285740", "2037965136", "2080745194", "2296677182", "2171903035", "1601435884", "2147232895", "1992023276", "2119885577", "2025051251"], "date": "1998"}, {"id": "1965972569", "title": "Data Streams: Algorithms and Applications", "abstract": "1 Introduction 2 Map 3 The Data Stream Phenomenon 4 Data Streaming: Formal Aspects 5 Foundations: Basic Mathematical Ideas 6 Foundations: Basic Algorithmic Techniques 7 Foundations: Summary 8 Streaming Systems 9 New Directions 10 Historic Notes 11 Concluding Remarks Acknowledgements References.", "authors": ["S. Muthukrishnan"], "related_topics": ["187166803", "89198739", "2778484313"], "citation_count": "2092", "reference_count": "176", "references": ["2296616510", "2127949150", "2116148865", "2011039300", "2295428206", "2123825896", "2001474264", "1993284846", "1521478692", "2149576945"], "date": "2004"}, {"id": "2014306526", "title": "Experimental Test of Bell's Inequalities Using Time- Varying Analyzers", "abstract": "Correlations of linear polarizations of pairs of photons have been measured with time-varying analyzers. The analyzer in each leg of the apparatus is an acousto-optical switch followed by two linear polarizers. The switches operate at incommensurate frequencies near 50 MHz. Each analyzer amounts to a polarizer which jumps between two orientations in a time short compared with the photon transit time. The results are in good agreement with quantum mechanical predictions but violate Bell's inequalities by 5 standard deviations.", "authors": ["Alain Aspect", "Jean Dalibard", "G\u00e9rard Roger"], "related_topics": ["36494176", "11511207", "158007255"], "citation_count": "5417", "reference_count": "0", "references": ["2266294403", "3037737784", "2120583949", "1709784975", "2142739935", "2762179548", "2174298480", "3037776276", "2015275764", "3038000163"], "date": "1982"}, {"id": "2059432853", "title": "Statistical and structural approaches to texture", "abstract": "In this survey we review the image processing literature on the various approaches and models investigators have used for texture. These include statistical approaches of autocorrelation function, optical transforms, digital transforms, textural edgeness, structural element, gray tone cooccurrence, run lengths, and autoregressive models. We discuss and generalize some structural approaches to texture based on more complex primitives than gray tone. We conclude with some structural-statistical generalizations which apply the statistical techniques to the structural primitives.", "authors": ["R.M. Haralick"], "related_topics": ["63099799", "8072696", "117479156"], "citation_count": "7765", "reference_count": "64", "references": ["2044465660", "1968245656", "2117395697", "2003304826", "2158240273", "2987654510", "1976678415", "1996342882", "2129739837", "1988563578"], "date": "1978"}, {"id": "2112844139", "title": "Epoch Extraction From Speech Signals", "abstract": "Epoch is the instant of significant excitation of the vocal-tract system during production of speech. For most voiced speech, the most significant excitation takes place around the instant of glottal closure. Extraction of epochs from speech is a challenging task due to time-varying characteristics of the source and the system. Most epoch extraction methods attempt to remove the characteristics of the vocal-tract system, in order to emphasize the excitation characteristics in the residual. The performance of such methods depends critically on our ability to model the system. In this paper, we propose a method for epoch extraction which does not depend critically on characteristics of the time-varying vocal-tract system. The method exploits the nature of impulse-like excitation. The proposed zero resonance frequency filter output brings out the epoch locations with high accuracy and reliability. The performance of the method is demonstrated using CMU-Arctic database using the epoch information from the electroglottograph as reference. The proposed method performs significantly better than the other methods currently available for epoch extraction. The interesting part of the results is that the epoch extraction by the proposed method seems to be robust against degradations like white noise, babble, high-frequency channel, and vehicle noise.", "authors": ["K.S.R. Murty", "B. Yegnanarayana"], "related_topics": ["61328038", "2777796867", "151405878"], "citation_count": "585", "reference_count": "29", "references": ["1766888123", "2132085292", "1557133539", "2155295839", "2022554507", "95152782", "2103075368", "1814775863", "2143166897", "2102072896"], "date": "2008"}, {"id": "2145142319", "title": "Harnessing the power of \"favorites\" lists for recommendation systems", "abstract": "We propose a novel collaborative recommendation approach to take advantage of the information available in user-created lists. Our approach assumes associations among any two items appearing in a list together. We calculate sum of Bayesian ratings (SBR) of all lists containing an item pair as the strength of item-item associations in that pair. SBR takes into consideration not only the number of lists the items have co-appeared in, but also the quality of the lists. We collected a data set of user ratings for books along with Listmania lists on Amazon.com using Amazon Web Services (AWS). Our method shows superior performance to existing user-based and item-based collaborative filtering approaches according to the resulted MAE, coverage and F-measure.", "authors": ["Maryam Khezrzadeh", "Alex Thomo", "William W. Wadge"], "related_topics": ["21569690", "557471498", "23123220"], "citation_count": "10", "reference_count": "31", "references": ["2171960770", "2042281163", "1971040550", "2110325612", "2147152072", "3121531027", "2124591829", "1966553486", "1999047234", "2142144955"], "date": "2009"}, {"id": "2145713659", "title": "A New Academic Word List", "abstract": "This article describes the development and evaluation of a new academic word list (Coxhead, 1998), which was compiled from a corpus of 3.5 million running words of written academic text by examining the range and frequency of words outside the first 2,000 most frequently occurring words of English, as described by West (1953). The AWL contains 570 word families that account for approximately 10.0% of the total words (tokens) in academic texts but only 1.4% of the total words in a fiction collection of the same size. This difference in coverage provides evidence that the list contains predominantly academic words. By highlighting the words that university students meet in a wide range of academic texts, the AWL shows learners with academic goals which words are most worth studying. The list also provides a useful basis for further research into the nature of academic vocabulary.", "authors": ["Averil Coxhead"], "related_topics": ["175293574", "2777601683", "2776046745"], "citation_count": "2681", "reference_count": "25", "references": ["2114282361", "1967461618", "17172702", "2148259819", "2315022969", "1972143595", "1601849497", "2010289719", "2074952134", "2132379210"], "date": "2000"}, {"id": "2090464118", "title": "An improving online accuracy updated ensemble method in learning from evolving data streams", "abstract": "Most stream classifiers need to detect and react to concept drifts, as traditional machine learning goes to big data machine learning. The most popular ways to adaptive to concept drifts are incrementally learning and classifier dynamic ensemble. Recent years, ensemble classifiers have become an established research line in this field, mainly due to their modularity which offers a natural way of adapting to changes. However, many ensembles which process instances in blocks do not react to sudden changes sufficiently quickly, and which process streams incrementally do not offer accurate reactions to gradual and incremental changes. Fortunately, an Online Accuracy Updated Ensemble (OAUE) algorithm was presented by Brzezinski and Stefanowski. OAUE algorithm has been proven to be an effective ensemble to deal with drifting data stream. But, it has a potentially weakness to adaptive to sudden changes as it uses a fixed window. Therefore, we put forward a Window-Adaptive Online Accuracy Updated Ensemble (WAOAUE) algorithm, which is based on OAUE, and a change detector is added to the ensemble for deciding the window size of each candidate classifier. The proposed algorithm was experimentally compared with four state-of-the-art online ensembles, include OAUE, and provided best practice for big data stream mining.", "authors": ["Xiao-Feng Gu", "Jia-Wen Xu", "Shi-Jing Huang", "Liao-Ming Wang"], "related_topics": ["45942800", "89198739", "2778484313"], "citation_count": "4", "reference_count": "17", "references": ["2140190241", "2124868070", "2487087946", "2135335717", "2068714596", "2002830978", "2009727399", "3124873412", "1990079212", "2000454347"], "date": "2014"}, {"id": "28988785", "title": "A computational model for face location based on cognitive principles", "abstract": "The human face is an object that is easily located in complex scenes by infants and adults alike. Yet the development of an automated system to perform this task is extremely challenging. This paper is concerned with the development of a computational model for locating human faces in newspaper photographs based on cognitive research in human perceptual development. In the process of learning to recognize objects in the visual world, one could assume that natural growth favors the development of the abilities to detect the more essential features first. Hence, a study of the progress of an infant's visual abilities can be used to categorize the potential features in terms of their importance. The face locator developed by the authors takes a hypothesis generate and test approach to the task of finding the locations of people's faces in digitized pictures. Information from the accompanying caption is used in the verification phase. The system successfully located all faces in 44 of the 60 (73%) test newspaper photographs.", "authors": ["Venu Govindaraju", "Sargur N. Srihari", "David Sher"], "related_topics": ["2780451532", "94124525", "205068"], "citation_count": "20", "reference_count": "12", "references": ["2045798786", "2782830414", "1970596291", "2020839919", "2067950060", "208011355", "2144723948", "1965376427", "2020244778", "193825441"], "date": "1992"}, {"id": "2123306636", "title": "Estimating Dependency Structure as a Hidden Variable", "abstract": "This paper introduces a probability model, the mixture of trees that can account for sparse, dynamically changing dependence relationships. We present a family of efficient algorithms that use EM and the Minimum Spanning Tree algorithm to find the ML and MAP mixture of trees for a variety of priors, including the Dirichlet and the MDL priors.", "authors": ["Marina Meila", "Michael I. Jordan"], "related_topics": ["13743678", "63645285", "177769412"], "citation_count": "76", "reference_count": "14", "references": ["2159080219", "2049633694", "2170112109", "2142334564", "2075201173", "2171582839", "2147409005", "2101782549", "2308181013", "2163166770"], "date": "1997"}, {"id": "2073257493", "title": "An interactive activation model of context effects in letter perception: I. An account of basic findings.", "abstract": "", "authors": ["James L. McClelland", "David E. Rumelhart"], "related_topics": ["76188268", "178253425", "26760741"], "citation_count": "6750", "reference_count": "45", "references": ["1509703770", "2007780422", "2045597501", "2068868410", "2053127376", "2147311265", "2098683904", "2040187703", "2006769754", "2154634575"], "date": "1981"}, {"id": "2018915326", "title": "How open is innovation", "abstract": "This paper is motivated by a desire to clarify the definition of \u2018openness\u2019 as currently used in the literature on open innovation, and to re-conceptualize the idea for future research on the topic. We combine bibliographic analysis of all papers on the topic published in Thomson\u2019s ISI Web of Knowledge (ISI) with a systematic content analysis of the field to develop a deeper understanding of earlier work. Our review indicates two inbound processes: sourcing and acquiring, and two outbound processes, revealing and selling. We analyze the advantages and disadvantages of these different forms of openness. The paper concludes with implications for theory and practice, charting several promising areas for future research.", "authors": ["Linus Dahlander", "David M. Gann"], "related_topics": ["148415826", "2779370449", "75434695"], "citation_count": "2578", "reference_count": "79", "references": ["1551905080", "2108795964", "2160449301", "2164284962", "2132081716", "1511351087", "2141647475", "2087712586", "1999216122", "2179492332"], "date": "2010"}, {"id": "2012186625", "title": "Emerging adulthood. A theory of development from the late teens through the twenties.", "abstract": "Emerging adulthood is proposed as a new conception of development for the period from the late teens through the twenties, with a focus on ages 18-25. A theoretical background is presented. Then evidence is provided to support the idea that emerging adulthood is a distinct period demographically, subjectively, and in terms of identity explorations. How emerging adulthood differs from adolescence and young adulthood is explained. Finally, a cultural context for the idea of emerging adulthood is outlined, and it is specified that emerging adulthood exists only in cultures that allow young people a prolonged period of independent role exploration during the late teens and twenties.", "authors": ["Jeffrey Jensen Arnett"], "related_topics": ["205545832", "117250062", "69897798"], "citation_count": "15435", "reference_count": "59", "references": ["1505203270", "2014198383", "2007286593", "2024435009", "2068524195", "1831475266", "98607287", "1528929238", "2027261724", "2014205162"], "date": "2000"}, {"id": "1579638493", "title": "Distributing information for collaborative filtering on Usenet Net News", "abstract": "As part of the Information Revolution,\" the amount of raw information available to computer users has increased as never before. Unfortunately , there has been a corresponding jump in the amount of unrelated information users must search through in order find information of interest. Harnessing the power of multiple users to form a collaborative fillter provides a robust wayy of helping direct users to the information that will be most useful to them. To test this idea, we have designed a large scale collaborative filltering system tuned to help users extract information from Usenet Net News. In this thesis we demonstrate a system for collaborative filltering that can scale up to encompass the large distributed information sources of which Usenet Net News is an example. Our system provides varying levels of anonymity to protect the interests of the users, as w ell as means of minimizing the load placed on the existing information source. We believe the system will be especially good at three tasks: supporting users as they explore new areas of interest; providing users a way of keeping up to date on areas they already have familiarity with; and at providing extra information to other fillters.", "authors": ["D. A. Maltz"], "related_topics": ["178674793", "21569690", "2777474334"], "citation_count": "69", "reference_count": "12", "references": ["3121531027", "1996360405", "1966553486", "2031618446", "2137719099", "2142094977", "2123922130", "2135329168", "2143471387", "1818099451"], "date": "1993"}, {"id": "1864634822", "title": "Emerging trends in peer review-a survey.", "abstract": "\u201cClassical peer review\u201d has been subject to intense criticism for slowing down the publication process, bias against specific categories of paper and author, unreliability, inability to detect errors and fraud, unethical practices, and the lack of recognition for unpaid reviewers. This paper surveys innovative forms of peer review that attempt to address these issues. Based on an initial literature review, we construct a sample of 81 channels of scientific communication covering all forms of review identified by the survey and analyze the review mechanisms used by each channel. We identify two major trends: the rapidly expanding role of pre-print servers (e.g. ArXiv) that dispense with traditional peer review altogether and the growth of \u201cnon-selective review\u201d, focusing on papers\u2019 scientific quality rather than their perceived importance and novelty. Other potentially important developments include forms of \u201copen review\u201d, which remove reviewer anonymity and interactive review, as well as new mechanisms for post-publication review and out-of-channel reader commentary, especially critical commentary targeting high profile papers. One of the strongest findings of the survey is the persistence of major differences between the peer review processes used by different disciplines. None of these differences is likely to disappear in the foreseeable future. The most likely scenario for the coming years is thus continued diversification, in which different review mechanisms serve different author and reader needs. Relatively little is known about the impact of these innovations on the problems they address. These are important questions for future quantitative research.", "authors": ["Richard Walker", "Pascal Rocha da Silva"], "related_topics": ["138368954", "140608501", "170879859"], "citation_count": "114", "reference_count": "73", "references": ["2243629635", "2067833766", "2100267603", "2047629610", "2115339903", "2012950673", "2005950835", "2017899036", "2005295476", "2041212401"], "date": "2015"}, {"id": "1550302919", "title": "Improving Acoustic Models by Watching Television", "abstract": "Abstract : Obtaining sufficient labelled training data is a persistent difficulty for speech recognition research. Although well transcribed data is expensive to produce, there is a constant stream of challenging speech data and poor transcription broadcast as closed-captioned television. We describe a reliable unsupervised method for identifying accurately transcribed sections of these broadcasts, and show how these segments can be used to train a recognition system. Starting from acoustic models trained on the Wall Street Journal database, a single iteration of our training method reduced the word error rate on an independent broadcast television news test set from 62.2% to 59.5%.", "authors": ["Michael J. Witbrock", "Alexander G. Hauptmann"], "related_topics": ["81959379", "40969351", "169903167"], "citation_count": "18", "reference_count": "10", "references": ["2103555337", "1501187080", "2155368638", "2113094193", "2148798929", "2120358855", "1546181631", "2302164184", "2145264505", "1718064325"], "date": "1998"}, {"id": "2168847332", "title": "Principles of mobile communication", "abstract": "Principles of Mobile Communication, Third Edition, is an authoritative treatment of the fundamentals of mobile communications. This book stresses the \"fundamentals\" of physical-layer wireless and mobile communications engineering that are important for the design of \"any\" wireless system. This book differs from others in the field by stressing mathematical modeling and analysis. It includes many detailed derivations from first principles, extensive literature references, and provides a level of depth that is necessary for graduate students wishing to pursue research on this topic. The book's focus will benefit students taking formal instruction and practicing engineers who are likely to already have familiarity with the standards and are seeking to increase their knowledge of this important subject. Major changes from the second edition: 1. Updated discussion of wireless standards (Chapter 1). 2. Updated treatment of land mobile radio propagation to include space-time correlation functions, mobile-to-mobile (or vehicle-to-vehicle) channels, multiple-input multiple-output (MIMO) channels, improved simulation models for land mobile radio channels, and 3G cellular simulation models. 3. Updated treatment of modulation techniques and power spectrum to include Nyquist pulse shaping and linearized Gaussian minimum shift keying (LGMSK). 4. Updated treatment of antenna diversity techniques to include optimum combining, non-coherent square-law combining, and classical beamforming. 5. Updated treatment of error control coding to include space-time block codes, the BCJR algorithm, bit interleaved coded modulation, and space-time trellis codes. 6. Updated treatment of spread spectrum to include code division multiple access (CDMA) multi-user detection techniques. 7. A completely new chapter on multi-carrier techniques to include the performance of orthogonal frequency division multiplexing (OFDM) on intersymbol interference (ISI) channels, OFDM residual ISI cancellation, single-carrier frequency domain equalization (SC-FDE), orthogonal frequency division multiple access (OFDMA) and single-carrier frequency division multiple access (SC-FDMA). 8. Updated discussion of frequency planning to include OFDMA frequency planning. 9. Updated treatment of CDMA cellular systems to include hierarchical CDMA cellular architectures and capacity analysis. 10. Updated treatment of radio resource management to include CDMA soft handoff analysis. Includes numerous homework problems throughout.", "authors": ["Gordon L. Stuber"], "related_topics": ["153646914", "2775907427", "2776208322"], "citation_count": "5632", "reference_count": "0", "references": ["2031211320", "2098257210", "1988456768", "2109815475", "2151222548", "2158714612", "2155782306", "2075295072", "2136812100", "2100958239"], "date": "1995"}, {"id": "2157590573", "title": "Acoustical and environmental robustness in automatic speech recognition", "abstract": "This dissertation describes a number of algorithms developed to increase the robustness of automatic speech recognition systems with respect to changes in the environment. These algorithms attempt to improve the recognition accuracy of speech recognition systems when they are trained and tested in different acoustical environments, and when a desk-top microphone (rather than a close-talking microphone) is used for speech input. Without such processing, mismatches between training and testing conditions produce an unacceptable degradation in recognition accuracy. Two kinds of environmental variability are introduced by the use of desk-top microphones and different training and testing conditions: additive noise and spectral tilt introduced by linear filtering. An important attribute of the novel compensation algorithms described in this thesis is that they provide joint rather than independent compensation for these two types of degradation. Acoustical compensation is applied in our algorithms as an additive correction in the cepstral domain. This allows a higher degree of integration within SPHINX, the Carnegie Mellon speech recognition system, that uses the cepstrum as its feature vector. Therefore, these algorithms can be implemented very efficiently. Processing in many of these algorithms is based on instantaneous signal-to-noise ratio (SNR), as the appropriate compensation represents a form of noise suppression at low SNRs and spectral equalization at high SNRs. The compensation vectors for additive noise and spectral transformations are estimated by minimizing the differences between speech feature vectors obtained from a \"standard\" training corpus of speech and feature vectors that represent the current acoustical environment. In our work this is accomplished by minimizing the distortion of vector-quantized cepstra that are produced by the feature extraction module in SPHINX. In this dissertation we describe several algorithms including the SNR-Dependent Cepstral Normalization, (SDCN) and the Codeword-Dependent Cepstral Normalization (CDCN). With CDCN, the accuracy of SPHINX when trained on speech recorded with a close-talking microphone and tested on speech recorded with a desk-top microphone is essentially the same obtained when the system is trained and tested on speech from the desk-top microphone. An algorithm for frequency normalization has also been proposed in which the parameter of the bilinear transformation that is used by the signal-processing stage to produce frequency warping is adjusted for each new speaker and acoustical environment. The optimum value of this parameter is again chosen to minimize the vector-quantization distortion between the standard environment and the current one. In preliminary studies, use of this frequency normalization produced a moderate additional decrease in the observed error rate.", "authors": ["Alejandro Acero"], "related_topics": ["61328038", "204201278", "2778263558"], "citation_count": "1333", "reference_count": "78", "references": ["2049633694", "2134383396", "2105594594", "2186435531", "2913399920", "2121973264", "2128653836", "1667165204", "2069501481", "2148154194"], "date": "1991"}, {"id": "2161461831", "title": "Web browser with dynamic display of information objects during linking", "abstract": "A method of browsing the World Wide Web of the Internet using a client machine supporting a graphical user interface and an Internet browser. The method locally stores, retrieves and outputs information objects to reduce the waiting time normally associated with the download of hypertext documents having high resolution graphics. In one embodiment, the method begins as a web page is being displayed on the graphical user interface (70), the web page having a link to a hypertext document preferably located at a remote server. In response to the user clicking on the link, the link is activated by the browser (74) to request downloading the hypertext document from the remote server to the graphical user interface of the client (76). While the client waits for a reply and/or as the hypertext document is being downloaded, the browser displays a previously-cached information object (82).", "authors": ["David H. Judson"], "related_topics": ["61096286", "21959979", "127613066"], "citation_count": "2595", "reference_count": "24", "references": ["2120827127", "2831078930", "2839912453", "1924000956", "2099312314", "1754794633", "2112319734", "2876332835", "2822022295", "1607673112"], "date": "1996"}, {"id": "2170381724", "title": "Some advances in transformation-based part of speech tagging", "abstract": "Most recent research in trainable part of speech taggers has explored stochastic tagging. While these taggers obtain high accuracy, linguistic information is captured indirectly, typically in tens of thousands of lexical and contextual probabilities. In (Brill 1992), a trainable rule-based tagger was described that obtained performance comparable to that of stochastic taggers, but captured relevant linguistic information in a small number of simple non-stochastic rules. In this paper, we describe a number of extensions to this rule-based tagger. First, we describe a method for expressing lexical relations in tagging that stochastic taggers are currently unable to express. Next, we show a rule-based approach to tagging unknown words. Finally, we show how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty.", "authors": ["Eric Brill"], "related_topics": ["53893814", "123406163", "204321447"], "citation_count": "505", "reference_count": "14", "references": ["1632114991", "2099247782", "2081687495", "2046224275", "1718065290", "1554031433", "2100796029", "1571096757", "2102924265", "2166394306"], "date": "1994"}, {"id": "1975508847", "title": "Energy-Efficient Leader Election Protocols for Single-Hop Radio Networks", "abstract": "In this paper we investigate leader election protocols for single-hop radio networks from the perspective of energetic complexity. We discuss different models of energy consumption and their impact on time complexity. We also present some results about energy consumption in classic protocols optimal with respect to time complexity - we show that some very basic, intuitive algorithms for simpler model (with known number of stations) do not have to be optimal when energy of stations is restricted. We show that they can be significantly improved by introducing very simple modifications. Our main technical result is however a protocol for solving leader election problem in case of unknown number of stations n, with expected time O(log epsilon n), such that each station transmits O(1) number of times and no station is awake for more than O(log log log n) rounds.", "authors": ["Marcin Kardas", "Marek Klonowski", "Dominik Pajak"], "related_topics": ["53480672", "311688", "2780165032"], "citation_count": "11", "reference_count": "19", "references": ["109793532", "2087596759", "1984375161", "1984355228", "2154343170", "2033487809", "1983700804", "2180072861", "1480670011", "2108820146"], "date": "2013"}, {"id": "2903158431", "title": "Active Learning Literature Survey", "abstract": "", "authors": ["Burr Settles"], "related_topics": ["26258499", "3017831414", "182449105"], "citation_count": "5630", "reference_count": "166", "references": ["2099111195", "2147880316", "2119821739", "3124955340", "2912934387", "2121863487", "2107598941", "1970381522", "2048679005", "2136504847"], "date": "2008"}, {"id": "2163922914", "title": "Representation Learning: A Review and New Perspectives", "abstract": "The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.", "authors": ["Y. Bengio", "A. Courville", "P. Vincent"], "related_topics": ["58973888", "8038995", "77967617"], "citation_count": "9127", "reference_count": "237", "references": ["2618530766", "2136922672", "3118608800", "2310919327", "2100495367", "2158899491", "2187089797", "1665214252", "2162915993", "2160815625"], "date": "2013"}, {"id": "1508207006", "title": "The Meme Machine", "abstract": "Humans are extraordinary creatures, with the unique ability among animals to imitate and so copy from one another ideas, habits, skills, behaviours, inventions, songs, and stories. These are all memes, a term first coined by Richard Dawkins in 1976 in his book The Selfish Gene. Memes, like genes, are replicators, and this enthralling book is an investigation of whether this link between genes and memes can lead to important discoveries about the nature of the inner self. Confronting the deepest questions about our inner selves, with all our emotions, memories, beliefs, and decisions, Susan Blackmore makes a compelling case for the theory that the inner self is merely an illusion created by the memes for the sake of replication.", "authors": ["Susan J. Blackmore"], "related_topics": ["76838447", "51620047", "129759858"], "citation_count": "5791", "reference_count": "175", "references": ["1581387623", "2140205964", "1495038747", "1490421035", "3122042041", "1993750641", "2978315572", "1659631989", "2148300948", "2035791902"], "date": "1999"}, {"id": "2028891984", "title": "Wherefore art thou R3579X?: anonymized social networks, hidden patterns, and structural steganography", "abstract": "In a social network, nodes correspond topeople or other social entities, and edges correspond to social links between them. In an effort to preserve privacy, the practice of anonymization replaces names with meaningless unique identifiers. We describe a family of attacks such that even from a single anonymized copy of a social network, it is possible for an adversary to learn whether edges exist or not between specific targeted pairs of nodes.", "authors": ["Lars Backstrom", "Cynthia Dwork", "Jon Kleinberg"], "related_topics": ["86256295", "119839945", "108801101"], "citation_count": "1290", "reference_count": "26", "references": ["2517104773", "2159024459", "2911978475", "2905110430", "2128906841", "2010523825", "2110868467", "2135930857", "2159675343", "2119067110"], "date": "2011"}, {"id": "2004003571", "title": "Instantaneous companding of quantized signals", "abstract": "Instantaneous companding may be used to improve the quantized approximation of a signal by producing effectively nonuniform quantization. A revision, extension, and reinterpretation of the analysis of Panter and Dite permits the calculation of the quantizing error power as a function of the degree of companding, the number of quantizing steps, the signal volume, the size of the \u201cequivalent dc component\u201d' in the signal input to the compressor, and the statistical distribution of amplitudes in the signal. It appears, from Bennett's spectral analysis, that the total quantizing error power so calculated may properly be studied without attention to the detailed composition of the error spectrum, provided the signal is complex (such as speech or noise) and is sampled at the minimum information-theoretic rate. These calculations lead to the formulation of an effective process for choosing the proper combination of the number of digits per code group and companding characteristic for quantized speech communication systems. An illustrative application is made to the planning of a hypothetical PCM system, employing a common channel compandor on a time division multiplex basis. This reveals that the calculated companding improvement, for the weakest signals to be encountered in such a system, is equivalent to the addition of about 4 to 6 digits per code group, i.e., to an increase in the number of uniform quantizing steps by a factor between 24 = 16 and 26 = 64 Comparison with the results of related theoretical and experimental studies is also provided", "authors": ["Bernard Smith"], "related_topics": ["104250799", "107139520", "28855332"], "citation_count": "268", "reference_count": "18", "references": ["2001968606", "1995871078", "2068071220", "2022330547", "2134994416", "2105232697", "2084795850", "2165067301", "1989395836", "2010541627"], "date": "1957"}, {"id": "2050660892", "title": "How to use expert advice", "abstract": "We analyze algorithms that predict a binary value by combining the predictions of several prediction strategies, called `experts''. Our analysis is for worst-case situations, i.e., we make no assumptions about the way the sequence of bits to be predicted is generated. We measure the performance of the algorithm by the difference between the expected number of mistakes it makes on the bit sequence and the expected number of mistakes made by the best expert on this sequence, where the expectation is taken with respect to the randomization in the predictions. We show that the minimum achievable difference is on the order of the square root of the number of mistakes of the best expert, and we give efficient algorithms that achieve this. Our upper and lower bounds have matching leading constants in most cases. We then show how this leads to certain kinds of pattern recognition/learning algorithms with performance bounds that improve on the best results currently known in this context. We also extend our analysis to the case in which log loss is used instead of the expected number of mistakes.", "authors": ["Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "David P. Helmbold", "David Haussler", "Robert E. Schapire", "Manfred K. Warmuth"], "related_topics": ["77553402", "37724570", "2780049985"], "citation_count": "204", "reference_count": "41", "references": ["2124776405", "1530699444", "2019363670", "3124873412", "2154952480", "2054658115", "2611627047", "2972424502", "1968908999", "2042024619"], "date": "1993"}, {"id": "2140562769", "title": "Light speed reduction to 17 metres per second in an ultracold atomic gas", "abstract": "Techniques that use quantum interference effects are being actively investigated to manipulate the optical properties of quantum systems1. One such example is electromagnetically induced transparency, a quantum effect that permits the propagation of light pulses through an otherwise opaque medium2,3,4,5. Here we report an experimental demonstration of electromagnetically induced transparency in an ultracold gas of sodium atoms, in which the optical pulses propagate at twenty million times slower than the speed of light in a vacuum. The gas is cooled to nanokelvin temperatures by laser and evaporative cooling6,7,8,9,10. The quantum interference controlling the optical properties of the medium is set up by a \u2018coupling\u2019 laser beam propagating at a right angle to the pulsed \u2018probe\u2019 beam. At nanokelvin temperatures, the variation of refractive index with probe frequency can be made very steep. In conjunction with the high atomic density, this results in the exceptionally low light speeds observed. By cooling the cloud below the transition temperature for Bose\u2013Einstein condensation11,12,13 (causing a macroscopic population of alkali atoms in the quantum ground state of the confining potential), we observe even lower pulse propagation velocities (17?m?s\u22121) owing to the increased atom density. We report an inferred nonlinear refractive index of 0.18?cm2?W\u22121 and find that the system shows exceptionally large optical nonlinearities, which are of potential fundamental and technological interest for quantum optics.", "authors": ["Lene Vestergaard Hau", "", "S. E. Harris", "Zachary Dutton", "", "Cyrus H. Behroozi", ""], "related_topics": ["131935069", "68717125", "151662813"], "citation_count": "4916", "reference_count": "25", "references": ["2211778065", "1991602497", "2080769419", "2150262561", "2016608283", "1973406635", "2090717958", "2136171089", "2025493266", "2035927728"], "date": "1999"}, {"id": "1521255875", "title": "Frequency and the emergence of linguistic structure", "abstract": "1. Introduction to frequency and the emergence of linguistic structure (by Bybee, Joan L.) 2. Part I: Patterns of Use 3. Transitivity, clause structure, and argument structure: Evidence from conversation (by Thompson, Sandra A.) 4. Local patterns of subjectivity in person and verb type in American English coversation (by Scheibman, Joanne) 5. Paths to prepositions? A corpus-based study of the acquisition of a lexico-grammatical category (by Hallan, Naomi) 6. Part II: Word-level frequency effects 7. Lexical diffusion, lexical frequency, and lexical analysis (by Phillips, Betty S.) 8. Exemplar dynamics: Word frequency, lenition and contrast (by Pierrehumbert, Janet B.) 9. Emergent phonotactic generalizations in English and Arabic (by Frisch, Stefan A.) 10. Ambiguity and frequency effects in regular verb inflection (by Hare, Mary L.) 11. Frequency, regularity and the paradigm: A perspective from Russian on a complex relation (by Corbett, Greville G.) 12. Part III: Phrases and constructions 13. Probabilistic relations between words: Evidence from reduction in lexical production (by Jurafsky, Daniel) 14. Frequency effects and word-boundary palatization in English (by Bush, Nathan) 15. The role of frequency in the realization of English that (by Berkenfield, Catie) 16. Frequency, iconicity, categorization: Evidence from emerging modals (by Krug, Manfred G.) 17. Frequency effects on French liaison (by Bybee, Joan L.) 18. The role of frequency in the specialization of the English anterior (by Smith, K. Aaron) 19. Hypercorrect pronoun case in English? Cognitive processes that account for pronoun usage (by Boyland, Joyce Tang) 20. Variability, frequency, and productivity in the irrealis domain of French (by Poplack, Shana) 21. Part IV: General 22. Familiarity, information flow, and linguistic form (by Fenk-Oczlon, Gertraud) 23. Emergentist approaches to language (by MacWhinney, Brian) 24. Inflationary effects in language and elsewhere (by Dahl, Osten) 25. Subject index 26. Name index", "authors": ["Joan L. Bybee", "Paul J. Hopper"], "related_topics": ["2779052005", "2777939226", "2776397901"], "citation_count": "1741", "reference_count": "0", "references": ["2109151141", "2078906720", "382421368", "354650940", "2120409145", "2580252561", "2066646430", "1577142816", "2129955048", "2064304610"], "date": "2001"}, {"id": "2160547390", "title": "$rm K$ -SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation", "abstract": "In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data", "authors": ["M. Aharon", "M. Elad", "A. Bruckstein"], "related_topics": ["154771677", "124066611", "156872377"], "citation_count": "10199", "reference_count": "44", "references": ["2078204800", "2116148865", "2099641086", "2108384452", "2151693816", "2097323375", "2049633694", "2050834445", "1634005169", "2154332973"], "date": "2006"}, {"id": "1980792219", "title": "Dynamic Generalized Linear Models and Bayesian Forecasting", "abstract": "Abstract Dynamic Bayesian models are developed for application in nonlinear, non-normal time series and regression problems, providing dynamic extensions of standard generalized linear models. A key feature of the analysis is the use of conjugate prior and posterior distributions for the exponential family parameters. This leads to the calculation of closed, standard-form predictive distributions for forecasting and model criticism. The structure of the models depends on the time evolution of underlying state variables, and the feedback of observational information to these variables is achieved using linear Bayesian prediction methods. Data analytic aspects of the models concerning scale parameters and outliers are discussed, and some applications are provided. Dynamic Bayesian models are developed for application in nonlinear, non-normal time series and regression problems, providing dynamic extensions of standard generalized linear models. A key feature of the analysis is the use of conjugate prior and...", "authors": ["Mike West", "P. Jeff Harrison", "Helio S. Migon"], "related_topics": ["37903108", "71983512", "26004113"], "citation_count": "763", "reference_count": "11", "references": ["1528905581", "2801490189", "2020214980", "2083333988", "191167826", "2304999498", "2795391743", "2904579105", "2904464170", "2106069426"], "date": "1985"}, {"id": "2043909051", "title": "Relevance weighting of search terms", "abstract": "This paper examines statistical techniques for exploiting relevance information to weight search terms. These techniques are presented as a natural extension of weighting methods using information about the distribution of index terms in documents in general. A series of relevance weighting functions is derived and is justified by theoretical considerations. In particular, it is shown that specific weighted search methods are implied by a general probabilistic theory of retrieval. Different applications of relevance weighting are illustrated by experimental results for test collections.", "authors": ["Stephen Robertson", "K. Sparck Jones"], "related_topics": ["183115368", "87546605", "187231660"], "citation_count": "2979", "reference_count": "14", "references": ["2082102453", "3090556797", "1966365186", "1908696901", "2119529697", "2022516005", "2049870103", "2002852304", "2170946109", "2049174056"], "date": "1976"}, {"id": "1577111082", "title": "Chapter 8 - Local Operator Theory, Random Matrices and Banach Spaces", "abstract": "", "authors": ["Kenneth R. Davidson", "Stanislaw J. Szarek"], "related_topics": ["99392333", "79013869", "19496378"], "citation_count": "650", "reference_count": "143", "references": ["2798707604", "1971565000", "2130401121", "2021467799", "2499952289", "1546851689", "1546322230", "2045535845", "2002912011", "1973286131"], "date": "2000"}, {"id": "1981025738", "title": "Parallel visual computation", "abstract": "The functional abilities and parallel architecture of the human visual system are a rich source of ideas about visual processing. Any visual task that we can perform quickly and effortlessly is likely to have a computational solution using a parallel algorithm. Recently, several such parallel algorithms have been found that exploit information implicit in an image to compute intrinsic properties of surfaces, such as surface orientation, reflectance and depth. These algorithms require a computational architecture that has similarities to that of visual cortex in primates.", "authors": ["Dana H. Ballard", "Geoffrey E. Hinton", "Terrence J. Sejnowski"], "related_topics": ["160086991", "2778251979", "120373497"], "citation_count": "487", "reference_count": "39", "references": ["2581275558", "2620619910", "2740373864", "1995756857", "1979622972", "2048330959", "1509703770", "2116360511", "2133246412", "2002882922"], "date": "1983"}, {"id": "2133584444", "title": "A survey of medical image registration.", "abstract": "The purpose of this paper is to present a survey of recent (published in 1993 or later) publications concerning medical image registration techniques. These publications will be classified according to a model based on nine salient criteria, the main dichotomy of which is extrinsic versus intrinsic methods. The statistics of the classification show definite trends in the evolving registration techniques, which will be discussed. At this moment, the bulk of interesting intrinsic methods is based on either segmented points or surfaces, or on techniques endeavouring to use the full information content of the images involved.", "authors": ["J.B.Antoine Maintz", "Max A. Viergever"], "related_topics": ["166704113", "2780719617", "31601959"], "citation_count": "4879", "reference_count": "257", "references": ["2170120409", "2049981393", "2408227189", "1874027545", "2141796362", "2028555274", "2004537679", "2051809205", "1988874269", "2044719420"], "date": "1998"}, {"id": "2048701870", "title": "Methods and apparatus for data input", "abstract": "Methods and apparatus for data input. Devices (90) are provided in accordance with this invention which utilize capacitive coupling of an object (60) to the device (90) to sense the object's position. The devices (90) are comprised of a plurality of electrode strips (130) which form virtual electrodes (160, 170). The virtual electrodes are selectively connected to form virtual dipole electrodes (180, 190) which are responsive to the object's (60) position.", "authors": ["George E. Gerpheide"], "related_topics": ["68278764", "64729616", "200925200"], "citation_count": "784", "reference_count": "42", "references": ["2875516510", "1904843846", "2626627692", "2143669205", "1898285880", "2129681395", "2562533828", "2836457976", "2142710305", "2155878993"], "date": "1990"}, {"id": "1983587324", "title": "MULTILISP: a language for concurrent symbolic computation", "abstract": "Multilisp is a version of the Lisp dialect Scheme extended with constructs for parallel execution. Like Scheme, Multilisp is oriented toward symbolic computation. Unlike some parallel programming languages, Multilisp incorporates constructs for causing side effects and for explicitly introducing parallelism. The potential complexity of dealing with side effects in a parallel context is mitigated by the nature of the parallelism constructs and by support for abstract data types: a recommended Multilisp programming style is presented which, if followed, should lead to highly parallel, easily understandable programs.Multilisp is being implemented on the 32-processor Concert multiprocessor; however, it is ultimately intended for use on larger multiprocessors. The current implementation, called Concert Multilisp, is complete enough to run the Multilisp compiler itself and has been run on Concert prototypes including up to eight processors. Concert Multilisp uses novel techniques for task scheduling and garbage collection. The task scheduler helps control excessive resource utilization by means of an unfair scheduling policy; the garbage collector uses a multiprocessor algorithm based on the incremental garbage collector of Baker.", "authors": ["Robert H. Halstead"], "related_topics": ["2778588189", "105122174", "190883126"], "citation_count": "1484", "reference_count": "46", "references": ["3144368627", "1770006921", "2983995785", "2089674328", "1964602554", "2123586642", "2172307690", "1555673550", "2225811560", "2157598146"], "date": "1985"}, {"id": "2133338501", "title": "Cluster I/O with River: making the fast case common", "abstract": "We introduce River, a data-flow programming environment and I/O substrate for clusters of computers. River is designed to provide maximum performance in the common case \u2014 even in the face of nonuniformities in hardware, software, and workload. River is based on two simple design features: a high-performance distributed queue, and a storage redundancy mechanism called graduated declustering. We have implemented a number of data-intensive applications on River, which validate our design with near-ideal performance in a variety of non-uniform performance scenarios.", "authors": ["Remzi H. Arpaci-Dusseau", "Eric Anderson", "Noah Treuhaft", "David E. Culler", "Joseph M. Hellerstein", "David Patterson", "Kathy Yelick"], "related_topics": ["152124472", "2777904410", "160403385"], "citation_count": "274", "reference_count": "45", "references": ["2114728910", "2155066383", "2032401773", "2082693041", "1997020216", "2154207621", "83026775", "1967800745", "2098815550", "1978513924"], "date": "1999"}, {"id": "2142827986", "title": "Top 10 algorithms in data mining", "abstract": "This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development.", "authors": ["Xindong Wu", "Vipin Kumar", "J. Ross Quinlan", "Joydeep Ghosh", "Qiang Yang", "Hiroshi Motoda", "Geoffrey J. McLachlan", "Angus Ng", "Bing Liu", "Philip S. Yu", "Zhi-Hua Zhou", "Michael Steinbach", "David J. Hand", "Dan Steinberg"], "related_topics": ["112515388", "73555534", "207968372"], "citation_count": "5772", "reference_count": "96", "references": ["2156909104", "2164598857", "1565377632", "3013264884", "1484413656", "3124955340", "2138621811", "1854214752", "2125055259", "3023786531"], "date": "2007"}, {"id": "1528941926", "title": "Supertagging: an approach to almost parsing", "abstract": "In this paper, we have proposed novel methods for robust parsing that integrate the flexibility of linguistically motivated lexical descriptions with the robustness of statistical techniques. Our thesis is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (supertags) that impose complex constraints in a local context. The supertags are designed such that only those elements on which the lexical item imposes constraints appear within a given supertag. Further, each lexical item is associated with as many supertags as the number of different syntactic contexts in which the lexical item can appear. This makes the number of different descriptions for each lexical item much larger than when the descriptions are less complex, thus increasing the local ambiguity for a parser. But this local ambiguity can be resolved by using statistical distributions of supertag co-occurrences collected from a corpus of parses. We have explored these ideas in the context of the Lexicalized Tree-Adjoining Grammar (LTAG) framework. The supertags in LTAG combine both phrase structure information and dependency information in a single representation. Supertag disambiguation results in a representation that is effectively a parse (an almost parse), and the parser need \"only\" combine the individual supertags. This method of parsing can also be used to parse sentence fragments such as in spoken utterances where the disambiguated supertag sequence may not combine into a single structure.", "authors": ["Srinivas Bangalore", "Aravind K. Joshi"], "related_topics": ["186644900", "126706616", "80877019"], "citation_count": "427", "reference_count": "59", "references": ["1632114991", "2099247782", "2110882317", "1567570606", "2134237567", "2153439141", "3089319657", "1972573551", "1718065290", "1479758177"], "date": "1999"}, {"id": "2131987814", "title": "Minimum redundancy feature selection from microarray gene expression data.", "abstract": "How to selecting a small subset out of the thousands of genes in microarray data is important for accurate classification of phenotypes. Widely used methods typically rank genes according to their ...", "authors": ["Chris H. Q. Ding", "Hanchuan Peng"], "related_topics": ["16811321", "8415881", "104317684"], "citation_count": "2705", "reference_count": "21", "references": ["2109363337", "2147246240", "2172000360", "2017337590", "2087684630", "1989076816", "2108728387", "2138218344", "1988078905", "2018843280"], "date": "2005"}, {"id": "1979408141", "title": "Interference Alignment and Degrees of Freedom of the $K$ -User Interference Channel", "abstract": "For the fully connected K user wireless interference channel where the channel coefficients are time-varying and are drawn from a continuous distribution, the sum capacity is characterized as C(SNR)=K/2log(SNR)+o(log(SNR)) . Thus, the K user time-varying interference channel almost surely has K/2 degrees of freedom. Achievability is based on the idea of interference alignment. Examples are also provided of fully connected K user interference channels with constant (not time-varying) coefficients where the capacity is exactly achieved by interference alignment at all SNR values.", "authors": ["V.R. Cadambe", "S.A. Jafar"], "related_topics": ["155437304", "32022120", "97744766"], "citation_count": "3807", "reference_count": "27", "references": ["2157989362", "2106549261", "2167357515", "2162370583", "2130781639", "2089318831", "2141243408", "2151027523", "2062610219", "2153946652"], "date": "2008"}, {"id": "1840435438", "title": "A large annotated corpus for learning natural language inference", "abstract": "Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time.", "authors": ["Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning"], "related_topics": ["95318506", "2776214188", "195324797"], "citation_count": "1988", "reference_count": "32", "references": ["2095705004", "2250539671", "2064675550", "2251939518", "6908809", "2081580037", "2097606805", "2185175083", "2584341106", "2154359981"], "date": "2015"}, {"id": "2002016471", "title": "Artificial neural networks: a tutorial", "abstract": "Artificial neural nets (ANNs) are massively parallel systems with large numbers of interconnected simple processors. The article discusses the motivations behind the development of ANNs and describes the basic biological neuron and the artificial computational model. It outlines network architectures and learning processes, and presents some of the most commonly used ANN models. It concludes with character recognition, a successful ANN application.", "authors": ["A.K. Jain", "Jianchang Mao", "K.M. Mohiuddin"], "related_topics": ["50644808", "193415008", "154945302"], "citation_count": "3454", "reference_count": "20", "references": ["1652505363", "2042264548", "2133671888", "2293063825", "2147800946", "1554576613", "22297218", "23758216", "3121926921", "26450609"], "date": "1996"}, {"id": "1973406635", "title": "Bose-Einstein Condensation of Lithium: Observation of Limited Condensate Number", "abstract": "Bose-Einstein condensation of ${}^{7}\\mathrm{Li}$ has been studied in a magnetically trapped gas. Because of the effectively attractive interactions between ${}^{7}\\mathrm{Li}$ atoms, many-body quantum theory predicts that the occupation number of the condensate is limited to about 1400 atoms. We observe the condensate number to be limited to a maximum value between 650 and 1300 atoms. The measurements were made using a versatile phase-contrast imaging technique.", "authors": ["C. C. Bradley", "C. A. Sackett", "R. G. Hulet"], "related_topics": ["37589322", "178205975", "2779472767"], "citation_count": "1877", "reference_count": "0", "references": ["2140562769", "1989563849", "2034012235", "1563040068", "2176364383", "2103752582", "2078791968", "1642234848", "2211454332", "2746957752"], "date": "1997"}, {"id": "2615953416", "title": "Stochastic Simulation", "abstract": "", "authors": ["Brian D. Ripley"], "related_topics": ["127491075", "194387892", "25915931"], "citation_count": "2975", "reference_count": "0", "references": ["2160337655", "2126736494", "2161406034", "2148534890", "1517555081", "2083875149", "2136796925", "2131598171", "2119539043", "2163738067"], "date": "1986"}, {"id": "2037055884", "title": "Citation linking: improving access to online journals", "abstract": "The most innovative online journals are maturing rapidly and distinctive new features are emerging. Foremost among these features is the hypertext link, popularised by the World Wide Web and which will form the basis of a new, highly integrated scholarly literature. Journal integration in this instance seeks to recognise, extend and exploit relationships at the level of journal content-the papers-while maintaining some of the familiar contexts, in some cases journal identities, that define the content hierarchy and inform decision-making by readers. Links are a powerful tool for journal integration, most immediately in the form of citation linking. The paper reviews examples of citation linking in practice, and describes a new system, a link service, which is being developed to support novel and flexible linking mechanisms on the Web. One application of this link service is the Open Journal project, which is working with journal publishers to investigate the most effective ways of applying these powerful link types to enhance online journals.", "authors": ["S. Hitchcock", "L. Carr", "S. Harris", "J. M. N. Hey", "W. Hall"], "related_topics": ["162215914", "2778805511", "2780126544"], "citation_count": "80", "reference_count": "19", "references": ["1560210504", "1965177842", "1517663366", "2126353541", "2137836165", "1868376572", "1580610219", "1985544876", "2123520200", "1607322158"], "date": "1997"}, {"id": "2070808447", "title": "Subjective well-being. The science of happiness and a proposal for a national index.", "abstract": "One area of positive psychology analyzes subjective well-being (SWB), people's cognitive and affective evaluations of their lives. Progress has been made in understanding the components of SWB, the importance of adaptation and goals to feelings of well-being, the temperament underpinnings of SWB, and the cultural influences on well-being. Representative selection of respondents, naturalistic experience sampling measures, and other methodological refinements are now used to study SWB and could be used to produce national indicators of happiness.", "authors": ["Ed Diener"], "related_topics": ["112570445", "2778999518", "12505134"], "citation_count": "9660", "reference_count": "57", "references": ["2148905283", "3126140319", "2081155210", "2088155659", "3124068636", "2084528250", "3124281538", "2010707353", "2152073788", "2131663864"], "date": "1999"}, {"id": "1980202081", "title": "Trust in recommender systems", "abstract": "Recommender systems have proven to be an important response to the information overload problem, by providing users with more proactive and personalized information services. And collaborative filtering techniques have proven to be an vital component of many such recommender systems as they facilitate the generation of high-quality recom-mendations by leveraging the preferences of communities of similar users. In this paper we suggest that the traditional emphasis on user similarity may be overstated. We argue that additional factors have an important role to play in guiding recommendation. Specifically we propose that the trustworthiness of users must be an important consideration. We present two computational models of trust and show how they can be readily incorporated into standard collaborative filtering frameworks in a variety of ways. We also show how these trust models can lead to improved predictive accuracy during recommendation.", "authors": ["John O'Donovan", "Barry Smyth"], "related_topics": ["557471498", "21569690", "178674793"], "citation_count": "1160", "reference_count": "20", "references": ["2110325612", "3121531027", "45952787", "2100107987", "2072651985", "2000855935", "1725202765", "2161644106", "1652319903", "2089566520"], "date": "2005"}, {"id": "2118558147", "title": "Designing efficient sorting algorithms for manycore GPUs", "abstract": "We describe the design of high-performance parallel radix sort and merge sort routines for manycore GPUs, taking advantage of the full programmability offered by CUDA. Our radix sort is the fastest GPU sort and our merge sort is the fastest comparison-based sort reported in the literature. Our radix sort is up to 4 times faster than the graphics-based GPUSort and greater than 2 times faster than other CUDA-based radix sorts. It is also 23% faster, on average, than even a very carefully optimized multicore CPU sorting routine. To achieve this performance, we carefully design our algorithms to expose substantial fine-grained parallelism and decompose the computation into independent tasks that perform minimal global communication. We exploit the high-speed onchip shared memory provided by NVIDIA's GPU architecture and efficient data-parallel primitives, particularly parallel scan. While targeted at GPUs, these algorithms should also be well-suited for other manycore processors.", "authors": ["Nadathur Satish", "Mark Harris", "Michael Garland"], "related_topics": ["108094655", "32041758", "35555965"], "citation_count": "852", "reference_count": "36", "references": ["2173213060", "3145128584", "2028499920", "301824129", "2155503253", "2119547137", "3138798301", "2752853835", "2129817042", "2161061943"], "date": "2009"}, {"id": "2166667242", "title": "The magical number 4 in short-term memory: a reconsideration of mental storage capacity.", "abstract": "Miller (1956) summarized evidence that people can remember about seven chunks in short-term memory (STM) tasks. How- ever, that number was meant more as a rough estimate and a rhetorical device than as a real capacity limit. Others have since suggested that there is a more precise capacity limit, but that it is only three to five chunks. The present target article brings together a wide vari- ety of data on capacity limits suggesting that the smaller capacity limit is real. Capacity limits will be useful in analyses of information processing only if the boundary conditions for observing them can be carefully described. Four basic conditions in which chunks can be identified and capacity limits can accordingly be observed are: (1) when information overload limits chunks to individual stimulus items, (2) when other steps are taken specifically to block the recoding of stimulus items into larger chunks, (3) in performance discontinuities caused by the capacity limit, and (4) in various indirect effects of the capacity limit. Under these conditions, rehearsal and long-term memory cannot be used to combine stimulus items into chunks of an unknown size; nor can storage mechanisms that are not capacity- limited, such as sensory memory, allow the capacity-limited storage mechanism to be refilled during recall. A single, central capacity limit averaging about four chunks is implicated along with other, noncapacity-limited sources. The pure STM capacity limit expressed in chunks is distinguished from compound STM limits obtained when the number of separately held chunks is unclear. Reasons why pure capacity estimates fall within a narrow range are discussed and a capacity limit for the focus of attention is proposed.", "authors": ["Nelson Cowan"], "related_topics": ["179226034", "58632812", "165520287"], "citation_count": "7443", "reference_count": "424", "references": ["1542722502", "1708874574", "22297218", "2118615399", "1898014694", "1679907412", "1994851566", "1993750641", "2149095485", "2142796031"], "date": "2001"}, {"id": "2152073788", "title": "Happiness and economic performance", "abstract": "If a nation's economic performance improves, how much extra happiness does that buy its citizens? Most public debate assumes -- without real evidence -- that the answer is a lot. This paper examines the question by using information on well-being in Western countries. The data are of four kinds: on reported happiness, on reported life satisfaction, on reported job satisfaction, and on the number of suicides. These reveal patterns that are not visible to the anecdotal eye. In industrialized countries, well-being appears to rise as real national income grows. But the rise is so small as to be sometimes almost undetectable. Unemployment, however, seems to be a large source of unhappiness. This suggests that governments ought to be trying to reduce the amount of joblessness in the economy. In a country that is already rich, policy aimed instead at raising economic growth may be of comparatively little value.", "authors": ["Andrew J. Oswald"], "related_topics": ["2778046797", "2778999518", "2780017527"], "citation_count": "3928", "reference_count": "66", "references": ["3124068636", "3134690818", "2084528250", "2112484287", "2078205970", "2571495779", "2092027953", "2170921686", "2911752419", "2057978731"], "date": "1996"}, {"id": "131663217", "title": "Computer keyboard with switchable typing/cursor control modes", "abstract": "The keyboard portion of a computer has a small toggle switch structure positioned among its keys and reachable by a user while his hands are in the home row typing position. The switch structure is used to selectively switch the computer between typing and cursor control modes. When the computer is switched to its cursor control mode by depressing a stick-like activation portion of the switch structure, a small video camera mounted above the keyboard monitors an observation zone above the keyboard. A cursor control system in which the camera is incorporated detects the presence of the user's hand in a first predetermined configuration within the observation zone, tracks the hand's cursor control movement through the zone, and correspondingly moves the cursor on the computer's display screen. To carry out a cursor \"pick\" function in conjunction with the repositioned cursor, the user reshapes his hand to a second predetermined configuration. The system detects the second hand configuration and responsively generates an appropriate cursor pick signal. When the user desires to return the computer to its typing mode he either depresses the activation portion of the toggle switch structure or moves his control hand out of the observation zone, moves the hand back into the zone, and presses any of the keys. The video controlled cursor positioning system is representatively illustrated in both a portable and desktop computer embodiment.", "authors": ["Charles A. Sellers"], "related_topics": ["153232905", "2778852477", "17500928"], "citation_count": "96", "reference_count": "15", "references": ["2515464329", "274003869", "1759885662", "2562409180", "1523128755", "324491766", "992600001", "1959903632", "2148855229", "996823392"], "date": "1997"}, {"id": "2029136760", "title": "Pattern recognition and associative memory as dynamical processes in a synergetic system", "abstract": "We first present numerical results for the decomposition procedure for complex scenes described in Part I of these papers. Part II then mainly deals with a formalism that allows a formulation of our approach to pattern recognition and associative memory that is simultaneously invariant against translation, rotation, and scaling, Part II thus contains an explicit elaboration of ideas of Part I.", "authors": ["A. Fuchs", "H. Haken"], "related_topics": ["53442348", "153180895", "49209780"], "citation_count": "117", "reference_count": "17", "references": ["2293063825", "1554576613", "2392040", "2011937936", "1998024692", "2013697551", "2036791170", "2091797867", "1981167547", "2050145015"], "date": "1988"}, {"id": "2301027021", "title": "Voice trigger for a digital assistant", "abstract": "A method for operating a voice trigger is provided. In some implementations, the method is performed at an electronic device including one or more processors and memory storing instructions for execution by the one or more processors. The method includes receiving a sound input. The sound input may correspond to a spoken word or phrase, or a portion thereof. The method includes determining whether at least a portion of the sound input corresponds to a predetermined type of sound, such as a human voice. The method includes, upon a determination that at least a portion of the sound input corresponds to the predetermined type, determining whether the sound input includes predetermined content, such as a predetermined trigger word or phrase. The method also includes, upon a determination that the sound input includes the predetermined content, initiating a speech-based service, such as a voice-based digital assistant.", "authors": ["Justin G. Binder", "Onur Tackin", "Samuel D. Post", "Thomas Robert Gruber"], "related_topics": ["20766975", "2776224158", "61249035"], "citation_count": "506", "reference_count": "500", "references": ["2250539671", "2147880316", "2141599568", "2122410182", "1523105128", "2137079713", "2147152072", "1930456798", "2097356832", "2133109597"], "date": "2014"}, {"id": "2034163998", "title": "Automatic spelling correction in scientific and scholarly text", "abstract": "", "authors": ["Joseph J. Pollock", "Antonio Zamora"], "related_topics": ["2777801307", "204321447", "41008148"], "citation_count": "278", "reference_count": "14", "references": ["1647671624", "2111192396", "2010392031", "2066792529", "2016768890", "2023358833", "2161123931", "2013413947", "2019363722", "2073317977"], "date": "1984"}, {"id": "2116908653", "title": "The Composition of Complex Cardinals", "abstract": "This paper proposes an analysis of the syntax and semantics of complex cardinal numerals, which involve multiplication (two hundred) and/or addition (twentythree). It is proposed that simplex cardinals have the semantic type of modifiers (AEAEe, tae, AEe, taeae). Complex cardinals are composed linguistically, using standard syntax (complementation, coordination) and standard principles of semantic composition. This analysis is supported by syntactic evidence (such as Case assignment) and semantic evidence (such as internal composition of complex cardinals). We present several alternative syntactic analyses of cardinals, and suggest that different languages may use different means to construct complex cardinals even though their lexical semantics remains the same. Further issues in the syntax of numerals (modified numerals and counting) are discussed and shown to be compatible with the proposed analysis of complex cardinals. Extra-linguistic constraints on the composition of complex cardinals are discussed and compared to similar restrictions in other domains.", "authors": ["Tania Ionin", "Ora Matushansky"], "related_topics": ["60048249", "98954769", "124246873"], "citation_count": "314", "reference_count": "85", "references": ["2264742718", "1711163617", "1482796826", "2097028840", "2100513762", "2130103043", "1491525124", "2048953720", "1499341405", "2018848073"], "date": "2006"}, {"id": "1746951143", "title": "Handbook of positive psychology", "abstract": "Psychology has long been enamored of the dark side of human existence, rarely exploring a more positive view of the mind. What has psychology contributed, for example, to our understanding of the various human virtues? Regrettably, not much. The last decade, however, has witnessed a growing movement to abandon the exclusive focus on the negative. Psychologists from several subdisciplines are now asking an intriguing question: \"What strengths does a person employ to deal effectively with life?\" The Handbook of Positive Psychology provides a forum for a more positive view of the human condition. In its pages, readers are treated to an analysis of what the foremost experts believe to be the fundamental strengths of humankind. Both seasoned professionals and students just entering the field are eager to grasp the power and vitality of the human spirit as it faces a multitude of life challenges. The Handbook is the first systematic attempt to bring together leading scholars to give voice to the emerging field of positive psychology.", "authors": ["C. R. Snyder", "Shane J. Lopez"], "related_topics": ["24668966", "2777991910", "2776409293"], "citation_count": "4250", "reference_count": "312", "references": ["1562208008", "2159061031", "2053133047", "1581387623", "2082107925", "2007445014", "1542722502", "3126140319", "1928999099", "3019273456"], "date": "2001"}, {"id": "2166559705", "title": "Mining association rules between sets of items in large databases", "abstract": "We are given a large database of customer transactions. Each transaction consists of items purchased by a customer in a visit. We present an efficient algorithm that generates all significant association rules between items in the database. The algorithm incorporates buffer management and novel estimation and pruning techniques. We also present results of applying this algorithm to sales data obtained from a large retailing company, which shows the effectiveness of the algorithm.", "authors": ["Rakesh Agrawal", "Tomasz Imieli\u0144ski", "Arun Swami"], "related_topics": ["87146676", "81440476", "112515388"], "citation_count": "24473", "reference_count": "12", "references": ["1594031697", "2149706766", "2100406636", "1601529450", "2019363670", "1556507321", "1487801850", "2323746689", "1988757393", "68135340"], "date": "1993"}, {"id": "2166935132", "title": "GETTING ON WITH CORPUS COMPILATION: FROM THEORY TO PRACTICE.", "abstract": "The aim of this paper is first to present some theoretical guidelines on the design and compilation of a specialized corpus in compliance with Corpus Linguistics standards; second, to provide a comprehensive description of the stages followed in the creation of the Telecommunication Engineering Corpus and its characteristics; and finally, to report the immediate results obtained from the basic analysis of the corpus: statistical information and frequency list. This paper is particularly addressed to those ESP practitioners who have to deal with the compilation of a specialized corpus for the first time, without a working knowledge of the specific subject domain they are involved in 1 .", "authors": ["Camino Rea Rizzo"], "related_topics": ["532629269", "2474386", "175293574"], "citation_count": "16", "reference_count": "18", "references": ["1967461618", "2074350771", "1502139047", "17172702", "603910251", "2104630935", "2074952134", "1948620562", "623622508", "2061741899"], "date": "2009"}, {"id": "2005639687", "title": "The future of interactive systems and the emergence of direct manipulation", "abstract": "Abstract This paper suggests three motivations for the strong interest in human factors' aspects of user interfaces and reviews five design issues: command language versus menu selection, response time and display rates, wording of system messages, on-line tutorials, explanations and help messages and hardware devices. Five methods and tools for system development are considered: participatory design, specification methods, software implementation tools, pilot studies and acceptance tests and evolutionary refinement based on user feedback. The final portion of the paper presents direct manipulation, an approach which promises to become widely used in interactive systems. Direct manipulation involves representation of the object of interest, rapid incremental reversible actions and physical action instead of complex syntax.", "authors": ["Ben Shneiderman"], "related_topics": ["2780968085", "89505385", "2776778970"], "citation_count": "729", "reference_count": "21", "references": ["2062168151", "2155741178", "2469714746", "1966629784", "1500303984", "2014243053", "1972320112", "3121583963", "3123368171", "1484005358"], "date": "1982"}, {"id": "2097045245", "title": "Epidemiology of Seasonal Influenza: Use of Surveillance Data and Statistical Models to Estimate the Burden of Disease", "abstract": "The US Centers for Disease Control and Prevention (CDC) uses a 7-component national surveillance system for influenza that includes virologic, influenza-like illness, hospitalization, and mortality data. In addition, some states and health organizations collect additional influenza surveillance data that complement the CDC's surveillance system. Current surveillance data from these programs, together with national hospitalization and mortality data, have been used in statistical models to estimate the annual burden of disease associated with influenza in the United States for many years. National influenza surveillance data also have been used in suitable models to estimate the possible impact of future pandemics. As part of the public health response to the 2003-2004 influenza season, which was noteworthy for its severe effect among children, new US surveillance activities were undertaken. Further improvements in national influenza surveillance systems will be needed to collect and analyze data in a timely manner during the next pandemic.", "authors": ["William W. Thompson", "Lorraine Comanor", "David K. Shay"], "related_topics": ["2777546802", "89623803", "138816342"], "citation_count": "314", "reference_count": "20", "references": ["1886211768", "2139841187", "2058144955", "2065420324", "2116090359", "2031180239", "2016383224", "2081797984", "2904578924", "1968795443"], "date": "2006"}, {"id": "2063694620", "title": "The future of optimism.", "abstract": "Recent theoretical discussions of optimism as an inherent aspect of human nature converge with empirical investigations of optimism as an individual difference to show that optimism can be a highly beneficial psychological characteristic linked to good mood, perseverance, achievement, and physical health. Questions remain about optimism as a research topic and more generally as a societal value. Is the meaning of optimism richer than its current conceptualization in cognitive terms? Are optimism and pessimism mutually exclusive? What is the relationship between optimism and reality, and what are the costs of optimistic beliefs that prove to be wrong? How can optimism be cultivated? How does optimism play itself out across different cultures? Optimism promises to be one of the important topics of interest to positive social science, as long as it is approached in an even-handed way.", "authors": ["Christopher Peterson"], "related_topics": ["204017024", "9992130", "2780945536"], "citation_count": "2663", "reference_count": "100", "references": ["2140205964", "2134419850", "2171975196", "2124103550", "1969233283", "2100826189", "2060200544", "2018697112", "2029487046", "2170246810"], "date": "1999"}, {"id": "2160269795", "title": "The psychology of curiosity: A review and reinterpretation.", "abstract": "Research on curiosity has undergone 2 waves of intense activity. The 1st, in the 1960s, focused mainly on curiosity's psychological underpinnings. The 2nd, in the 1970s and 1980s, was characterized by attempts to measure curiosity and assess its dimensionality. This article reviews these contributions with a concentration on the 1st wave. It is argued that theoretical accounts of curiosity proposed during the 1st period fell short in 2 areas: They did not offer an adequate explanation for why people voluntarily seek out curiosity, and they failed to delineate situational determinants of curiosity. Furthermore, these accounts did not draw attention to, and thus did not explain, certain salient characteristics of curiosity: its intensity, transience, association with impulsivity, and tendency to disappoint when satisfied. A new account of curiosity is offered that attempts to address these shortcomings. The new account interprets curiosity as a form of cognitively induced deprivation that arises from the perception of a gap in knowledge or understanding. Curiosity is the most superficial of all the affections; it changes its object perpetually; it has an appetite which is very sharp, but very easily satisfied; and it has always an appearance of giddiness, rest", "authors": ["George Loewenstein"], "related_topics": ["33435437", "146198305", "9114305"], "citation_count": "2299", "reference_count": "153", "references": ["2133469585", "22297218", "2129261459", "1763311249", "158727920", "2149095485", "2025494137", "123366752", "3108441448", "2094136133"], "date": "1994"}, {"id": "3021727161", "title": "Analysis of equal gain diversity on Nakagami fading channels", "abstract": "An infinite series for the complementary probability distribution function (cdf) of the signal-to-noise ratio (SNR) at the output of L-branch equal gain (EG) diversity combiners in Nakagami fading channels is derived. The bit error rate for a matched filter receiver is analyzed for the L-branch EG combiner and different fading parameters. Both coherent phase shift keying (CPSK) and differential coherent phase shift keying (DCPSK) are considered", "authors": ["N. C. Beaulieu", "A. A. Abu-Dayya"], "related_topics": ["81978471", "56296756", "50151734"], "citation_count": "259", "reference_count": "0", "references": ["2135176758", "2137073979", "2152350475", "2147002559", "2159593936", "2167969644", "2068480774", "2120272819", "2154971292", "2153580705"], "date": "1990"}, {"id": "1965909177", "title": "Shifting Sands: An Interest-Relative Theory of Vagueness", "abstract": "", "authors": ["Delia Graff"], "related_topics": ["2776825360", "24726157", "135646171"], "citation_count": "400", "reference_count": "27", "references": ["1711163617", "2026725080", "2087099129", "2075322664", "46517763", "1965185410", "2026043881", "2039497362", "2331827577", "2313853868"], "date": "2000"}, {"id": "2081028405", "title": "Time-series data mining", "abstract": "In almost every scientific field, measurements are performed over time. These observations lead to a collection of organized data called time series. The purpose of time-series data mining is to try to extract all meaningful knowledge from the shape of data. Even if humans have a natural capacity to perform these tasks, it remains a complex problem for computers. In this article we intend to provide a survey of the techniques applied for time-series data mining. The first part is devoted to an overview of the tasks that have captured most of the interest of researchers. Considering that in most cases, time-series task relies on the same components for implementation, we divide the literature depending on these common aspects, namely representation techniques, distance measures, and indexing methods. The study of the relevant literature has been categorized for each individual aspects. Four types of robustness could then be formalized and any kind of distance could then be classified. Finally, the study submits various research trends and avenues that can be explored in the near future. We hope that this article can provide a broad and deep understanding of the time-series data mining research field.", "authors": ["Philippe Esling", "Carlos Agon"], "related_topics": ["89198739", "2639959", "75165309"], "citation_count": "902", "reference_count": "205", "references": ["2140190241", "2122646361", "2140971281", "1501500081", "1990061958", "2075647286", "2798056406", "2151135734", "2098759488", "2134752891"], "date": "2012"}, {"id": "3124068636", "title": "Subjective Well-being", "abstract": "The literature on subjective well-being (SWB), including happiness, life satisfaction, and positive affect, is reviewed in three areas: measurement, causal factors, and theory. Psychometric data on single-item and multi-item subjective well-being scales are presented, and the measures are compared. Measuring various components of subjective well-being is discussed. In terms of causal influences, research findings on the demographic correlates of SWB are evaluated, as well as the findings on other influences such as health, social contact, activity, and personality. A number of theoretical approaches to happiness are presented and discussed: telic theories, associationistic models, activity theories, judgment approaches, and top-down versus bottom-up conceptions.", "authors": ["Ed Diener"], "related_topics": ["112570445", "2778999518", "2776420229"], "citation_count": "24779", "reference_count": "188", "references": ["3124410800", "2042276900", "2102573486", "2076763018", "37476018", "2040541818", "1539609515", "2001980658", "2052156595", "615989429"], "date": "1984"}, {"id": "2108995755", "title": "An introduction to kernel-based learning algorithms", "abstract": "This paper provides an introduction to support vector machines, kernel Fisher discriminant analysis, and kernel principal component analysis, as examples for successful kernel-based learning methods. We first give a short background about Vapnik-Chervonenkis theory and kernel feature spaces and then proceed to kernel based learning in supervised and unsupervised scenarios including practical and algorithmic considerations. We illustrate the usefulness of kernel algorithms by discussing applications such as optical character recognition and DNA analysis.", "authors": ["K.-R. Muller", "S. Mika", "G. Ratsch", "K. Tsuda", "B. Scholkopf"], "related_topics": ["182335926", "75866337", "140417398"], "citation_count": "4583", "reference_count": "141", "references": ["2156909104", "2148603752", "2124776405", "1995945562", "1554663460", "2119821739", "2139212933", "3124955340", "3023786531", "2798766386"], "date": "2001"}, {"id": "2049694710", "title": "Unsupervised texture segmentation using Gabor filters", "abstract": "Abstract This paper presents a texture segmentation algorithm inspired by the multi-channel filtering theory for visual information processing in the early stages of human visual system. The channels are characterized by a bank of Gabor filters that nearly uniformly covers the spatial-frequency domain, and a systematic filter selection scheme is proposed, which is based on reconstruction of the input image from the filtered images. Texture features are obtained by subjecting each (selected) filtered image to a nonlinear transformation and computing a measure of \u201cenergy\u201d in a window around each pixel. A square-error clustering algorithm is then used to integrate the feature images and produce a segmentation. A simple procedure to incorporate spatial information in the clustering process is proposed. A relative index is used to estimate the \u201ctrue\u201d number of texture categories.", "authors": ["Anil K. Jain", "Farshid Farrokhnia"], "related_topics": ["63099799", "144743038", "124504099"], "citation_count": "3271", "reference_count": "37", "references": ["2132984323", "1971784203", "2006500012", "2059432853", "2171181782", "2115738369", "1499486838", "2038836824", "2136127238", "2029683515"], "date": "1991"}, {"id": "1973108021", "title": "Thermodynamic theory of structure, stability and fluctuations", "abstract": "", "authors": ["Paul Glansdorff", "Ilya Prigogine"], "related_topics": ["14380042", "113174994", "105236789"], "citation_count": "3348", "reference_count": "0", "references": ["2177721432", "2130518506", "654350894", "2063186269", "2080601147", "2067870911", "2006960725", "2501046150", "2964153669", "2016320357"], "date": "1970"}, {"id": "2058653372", "title": "Psychology: A Study of A Science", "abstract": "", "authors": ["Koch Sigmund Ed", "Ellis Albert"], "related_topics": ["35858820", "17567262", "9246003"], "citation_count": "3156", "reference_count": "0", "references": ["2099697766", "2081155210", "2759494838", "2144109530", "1965514675", "2153480757", "2117504085", "2072098593", "2088507508", "2127184359"], "date": "1962"}, {"id": "3101788651", "title": "Regularized estimation of large covariance matrices", "abstract": "This paper considers estimating a covariance matrix of p variables from n observations by either banding the sample covariance matrix or estimating a banded version of the inverse of the covariance. We show that these estimates are consistent in the operator norm as long as (logp) 2 =n ! 0, and obtain explicit rates. The results are uniform over some fairly natural well-conditioned families of covariance matrices. We also introduce an analogue of the Gaussian white noise model and show that if the population covariance is embeddable in that model and well-conditioned then the banded approximations produce consistent estimates of the eigenvalues and associated eigenvectors of the covariance matrix. The results can be extended to smooth versions of banding and to non-Gaussian distributions with su\u2010ciently short tails. A resampling approach is proposed for choosing the banding parameter in practice. This approach is illustrated numerically on both simulated and real data.", "authors": ["Peter J. Bickel", "Elizaveta Levina"], "related_topics": ["178650346", "185142706", "112633086"], "citation_count": "1293", "reference_count": "29", "references": ["2798909945", "2010824638", "2047028564", "1975900269", "2062125287", "1520752838", "2046649434", "1575147392", "2118250684", "2073681337"], "date": "2008"}, {"id": "2126169247", "title": "High-speed switch scheduling for local-area networks", "abstract": "Current technology trends make it possible to build communication networks that can support high-performance distributed computing. This paper describes issues in the design of a prototype switch for an arbitrary topology point-to-point network with link speeds of up to 1 Gbit/s. The switch deals in fixed-length ATM-style cells, which it can process at a rate of 37 million cells per second. It provides high bandwidth and low latency for datagram traffic. In addition, it supports real-time traffic by providing bandwidth reservations with guaranteed latency bounds. The key to the switch's operation is a technique called parallel iterative matching, which can quickly identify a set of conflict-free cells for transmission in a time slot. Bandwidth reservations are accommodated in the switch by building a fixed schedule for transporting cells from reserved flows across the switch; parallel iterative matching can fill unused slots with datagram traffic. Finally, we note that parallel iterative matching may not allocate bandwidth fairly among flows of datagram traffic. We describe a technique called statistical matching, which can be used to ensure fairness at the switch and to support applications with rapidly changing needs for guaranteed bandwidth.", "authors": ["Thomas E. Anderson", "Susan S. Owicki", "James B. Saxe", "Charles P. Thacker"], "related_topics": ["2780768318", "152298349", "113200698"], "citation_count": "1436", "reference_count": "29", "references": ["3163287424", "2116142303", "2073440460", "2121523570", "109793532", "2096597645", "2099440788", "2102396830", "2178664229", "2124906592"], "date": "1993"}, {"id": "2613634265", "title": "Scaling learning algorithms towards AI", "abstract": "One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), reasoning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, with minimal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally limited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very inefficient in terms of required number of computational elements and examples. Second, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learning) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more abstract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence.", "authors": ["Yoshua Bengio", "", "", "Yann Lecun"], "related_topics": ["122280245", "98234853", "151876577"], "citation_count": "1419", "reference_count": "47", "references": ["2136922672", "2148603752", "2310919327", "2119821739", "2053186076", "2116064496", "2001141328", "2110798204", "2057175746", "2140095548"], "date": "2006"}, {"id": "1595303882", "title": "What Is the Nearest Neighbor in High Dimensional Spaces", "abstract": "Nearest neighbor search in high dimensional spaces is an interesting and important problem which is relevant for a wide variety of novel database applications. As recent results show, however, the problem is a very di cult one, not only with regards to the performance issue but also to the quality issue. In this paper, we discuss the quality issue and identify a new generalized notion of nearest neighbor search as the relevant problem in high dimensional space. In contrast to previous approaches, our new notion of nearest neighbor search does not treat all dimensions equally but uses a quality criterion to select relevant dimensions (projections) with respect to the given query. As an example for a useful quality criterion, we rate how well the data is clustered around the query point within the selected projection. We then propose an e cient and e ective algorithm to solve the generalized nearest neighbor problem. Our experiments based on a number of real and synthetic data sets show that our new approach provides new insights into the nature of nearest neighbor search on high", "authors": ["Alexander Hinneburg", "Charu C. Aggarwal", "Daniel A. Keim"], "related_topics": ["116738811", "161986146", "113238511"], "citation_count": "751", "reference_count": "18", "references": ["2055043387", "1833785989", "2118269922", "2238624099", "1541459201", "1975830550", "2065811242", "2106642566", "2010595692", "2112210867"], "date": "2000"}, {"id": "3107669106", "title": "Inclusive GAN: Improving Data and Minority Coverage in Generative Models", "abstract": "Generative Adversarial Networks (GANs) have brought about rapid progress towards generating photorealistic images. Yet the equitable allocation of their modeling capacity among subgroups has received less attention, which could lead to potential biases against underrepresented minorities if left uncontrolled. In this work, we first formalize the problem of minority inclusion as one of data coverage, and then propose to improve data coverage by harmonizing adversarial training with reconstructive generation. The experiments show that our method outperforms the existing state-of-the-art methods in terms of data coverage on both seen and unseen data. We develop an extension that allows explicit control over the minority subgroups that the model should ensure to include, and validate its effectiveness at little compromise from the overall performance on the entire dataset. Code, models, and supplemental videos are available at https://github.com/ningyu1991/InclusiveGAN.git.", "authors": ["Ning Yu", "Ke Li", "Peng Zhou", "Jitendra Malik", "Larry S. Davis", "Mario Fritz"], "related_topics": ["2910734998", "119857082", "41008148"], "citation_count": "10", "reference_count": "51", "references": ["2099471712", "2108598243", "1959608418", "2310919327", "2963373786", "2962879692", "2962897886", "1834627138", "2963226019", "2963981733"], "date": "2020"}, {"id": "2031454541", "title": "Pedestrian Detection: An Evaluation of the State of the Art", "abstract": "Pedestrian detection is a key problem in computer vision, with several applications that have the potential to positively impact quality of life. In recent years, the number of approaches to detecting pedestrians in monocular images has grown steadily. However, multiple data sets and widely varying evaluation protocols are used, making direct comparisons difficult. To address these shortcomings, we perform an extensive evaluation of the state of the art in a unified framework. We make three primary contributions: 1) We put together a large, well-annotated, and realistic monocular pedestrian detection data set and study the statistics of the size, position, and occlusion patterns of pedestrians in urban scenes, 2) we propose a refined per-frame evaluation methodology that allows us to carry out probing and informative comparisons, including measuring performance in relation to scale and occlusion, and 3) we evaluate the performance of sixteen pretrained state-of-the-art detectors across six data sets. Our study allows us to assess the state of the art and provides a framework for gauging future efforts. Our experiments show that despite significant progress, performance still has much room for improvement. In particular, detection is disappointing at low resolutions and for partially occluded pedestrians.", "authors": ["P. Dollar", "C. Wojek", "B. Schiele", "P. Perona"], "related_topics": ["2776151529", "2780156472", "153180895"], "citation_count": "3195", "reference_count": "87", "references": ["2151103935", "2161969291", "2168356304", "2031489346", "3097096317", "2163352848", "2110764733", "2104974755", "2154422044", "1565746575"], "date": "2012"}, {"id": "2052267638", "title": "Random oracles are practical: a paradigm for designing efficient protocols", "abstract": "We argue that the random oracle model\u2014where all parties have access to a public random oracle\u2014provides a bridge between cryptographic theory and cryptographic practice. In the paradigm we suggest, a practical protocol P is produced by first devising and proving correct a protocol PR for the random oracle model, and then replacing oracle accesses by the computation of an \u201cappropriately chosen\u201d function h. This paradigm yields protocols much more efficient than standard ones while retaining many of the advantages of provable security. We illustrate these gains for problems including encryption, signatures, and zero-knowledge proofs.", "authors": ["Mihir Bellare", "Phillip Rogaway"], "related_topics": ["94284585", "178774983", "13929819"], "citation_count": "5717", "reference_count": "39", "references": ["1996360405", "3145042860", "2156186849", "1589034595", "1970606468", "2151413173", "2117362057", "2090903439", "1979215153", "2077300005"], "date": "1993"}, {"id": "2108992228", "title": "Spatiotemporal energy models for the perception of motion", "abstract": "A motion sequence may be represented as a single pattern in x\u2013y\u2013t space; a velocity of motion corresponds to a three-dimensional orientation in this space. Motion sinformation can be extracted by a system that responds to the oriented spatiotemporal energy. We discuss a class of models for human motion mechanisms in which the first stage consists of linear filters that are oriented in space-time and tuned in spatial frequency. The outputs of quadrature pairs of such filters are squared and summed to give a measure of motion energy. These responses are then fed into an opponent stage. Energy models can be built from elements that are consistent with known physiology and psychophysics, and they permit a qualitative understanding of a variety of motion phenomena.", "authors": ["Edward H. Adelson", "James R. Bergen"], "related_topics": ["2780624872", "124774092", "146159030"], "citation_count": "4231", "reference_count": "43", "references": ["2164934677", "2035108601", "1999908130", "1964415410", "2074798463", "2129181505", "2022491393", "1988849438", "2157392891", "2053895730"], "date": "1985"}, {"id": "2170798091", "title": "Approaching the Non-Linear Shannon Limit", "abstract": "We review the recent progress of information theory in optical communications, and describe the current experimental results and associated advances in various individual technologies which increase the information capacity. We confirm the widely held belief that the reported capacities are approaching the fundamental limits imposed by signal-to-noise ratio and the distributed non-linearity of conventional optical fibres, resulting in the reduction in the growth rate of communication capacity. We also discuss the techniques which are promising to increase and/or approach the information capacity limit.", "authors": ["A.D. Ellis", "Jian Zhao", "D. Cotter"], "related_topics": ["97744766", "52622258", "103073706"], "citation_count": "490", "reference_count": "87", "references": ["2798333393", "2092754166", "2126259959", "2137705579", "2019019730", "2049824694", "2153372660", "2791457971", "2126533086", "1639951707"], "date": "2010"}, {"id": "1767470961", "title": "Promoting an open research culture", "abstract": "Transparency, openness, and reproducibility are readily recognized as vital features of science (1, 2). When asked, most scientists embrace these features as disciplinary norms and values (3). Therefore, one might expect that these valued features would be routine in daily practice. Yet, a growing body of evidence suggests that this is not the case (4\u20136).", "authors": ["B. A. Nosek", "G. Alter", "G. C. Banks", "D. Borsboom", "S. D. Bowman", "S. J. Breckler", "S. Buck", "C. D. Chambers", "G. Chin", "G. Christensen", "M. Contestabile", "A. Dafoe", "E. Eich", "J. Freese", "R. Glennerster", "D. Goroff", "D. P. Green", "B. Hesse", "M. Humphreys", "J. Ishiyama", "D. Karlan", "A. Kraut", "A. Lupia", "P. Mabry", "T. A. Madon", "N. Malhotra", "E. Mayo-Wilson", "M. McNutt", "E. Miguel", "E. Levy Paluck", "U. Simonsohn", "C. Soderberg", "B. A. Spellman", "J. Turitto", "G. VandenBos", "S. Vazire", "E. J. Wagenmakers", "R. Wilson", "T. Yarkoni"], "related_topics": ["2780233690", "2778464652", "84976871"], "citation_count": "1683", "reference_count": "13", "references": ["2161498332", "2100267603", "3124333825", "1997809363", "2126539575", "2123263696", "2002030061", "2128246772", "2113788769", "2143083982"], "date": "2015"}, {"id": "1495302482", "title": "Analysis and design of relational schemata for database systems.", "abstract": "", "authors": ["Carlo Antonio Zaniolo"], "related_topics": ["5655090", "148840519", "40207289"], "citation_count": "202", "reference_count": "0", "references": ["2060849841", "2122789628", "2148417962", "2110810394", "1975714036", "2125223317", "2032386524", "1992732065", "2028222220", "1985581502"], "date": "1975"}, {"id": "1992479210", "title": "The Chubby lock service for loosely-coupled distributed systems", "abstract": "We describe our experiences with the Chubby lock service, which is intended to provide coarse-grained locking as well as reliable (though low-volume) storage for a loosely-coupled distributed system. Chubby provides an interface much like a distributed file system with advisory locks, but the design emphasis is on availability and reliability, as opposed to high performance. Many instances of the service have been used for over a year, with several of them each handling a few tens of thousands of clients concurrently. The paper describes the initial design and expected use, compares it with actual use, and explains how the design had to be modified to accommodate the differences.", "authors": ["Mike Burrows"], "related_topics": ["84172371", "12096594", "152043487"], "citation_count": "1335", "reference_count": "24", "references": ["2173213060", "1981420413", "2119565742", "3021428210", "2005373714", "2182688186", "2035362408", "194677851", "2296636214", "1497150730"], "date": "2006"}, {"id": "640156484", "title": "Applied Multivariate Analysis", "abstract": "Introduction.- Vector and Matrix Algebra.- The Multivariate Normal Distribution, Multivariate Normality, and Covariance Structure.- One- and Two-Sample Tests.- Multivariate Analysis of Variance.- Discriminant Analysis.- Canonical Correlation.- Principal Component Analysis.- Factor Analysis.- Structural Equations.", "authors": ["Neil H. Timm"], "related_topics": ["43514536", "161584116", "73791607"], "citation_count": "787", "reference_count": "407", "references": ["3133236490", "2324392187", "2049633694", "1512719169", "1528905581", "2059334100", "2129905273", "2018201949", "1550443206", "2047028564"], "date": "2002"}, {"id": "2086253379", "title": "Searching distributed collections with inference networks", "abstract": "The use of information retrieval systems in networked environments raises a new set of issues that have received little attention. These issues include ranking document collections for relevance to a query, selecting the best set of collections from a ranked list, and merging the document rankings that are returned from a set of collections. This paper describes methods of addressing each issue in the inference network model, discusses their implementation in the INQUERY system, and presents experimental results demonstrating their effectiveness.", "authors": ["James P. Callan", "Zhihong Lu", "W. Bruce Croft"], "related_topics": ["87546605", "197927960", "177264268"], "citation_count": "991", "reference_count": "13", "references": ["1482214997", "2073788020", "2078875869", "1605873790", "2914866334", "1572257961", "1980515494", "1540841176", "36244633", "2092433256"], "date": "1995"}, {"id": "2758943428", "title": "Social Attitudes Regarding Same-Sex Marriage and LGBT Health Disparities: Results from a National Probability Sample", "abstract": "This study examined the health consequences for lesbian, gay, bisexual, and transgender (LGBT) populations of exposure to communities with relatively high versus low levels of support for same-sex marriage. We used data from the Gallup Daily tracking survey, the largest probability-based sample of LGBT-identified adults in the United States (N = 11,949 LGBT respondents; N = 352,343 non-LGBT respondents), which was linked to attitudinal responses on same-sex marriage obtained from the 2012 Cooperative Congressional Election Survey (N = 54,535). Controlling for potential confounders, higher levels of local approval of same-sex marriage lowered the probability that LGBT (and non-LGBT) individuals reported smoking and fair/poor self-rated health; further, LGBT disparities in smoking were lower in communities where residents were most likely to support same-sex marriage. Findings suggest that local attitudes may be related to the health of LGBT individuals and contribute to sexual orientation health disparities, providing further evidence for the role of structural stigma in shaping LGBT health.", "authors": ["Mark L. Hatzenbuehler", "Andrew R. Flores", "Gary J. Gates"], "related_topics": ["2250968", "2777997956", "2779671885"], "citation_count": "55", "reference_count": "32", "references": ["2049633694", "1996823741", "2117784915", "2160513825", "2131981140", "2157216651", "1992657881", "2003948162", "2149702901", "2007068017"], "date": "2017"}, {"id": "2065336344", "title": "InfoSleuth: agent-based semantic integration of information in open and dynamic environments", "abstract": "The goal of the InfoSleuth project at MCC is to exploit and synthesize new technologies into a unified system that retrieves and processes information in an ever-changing network of information sources. InfoSleuth has its roots in the Carnot project at MCC, which specialized in integrating heterogeneous information bases. However, recent emerging technologies such as internetworking and the World Wide Web have significantly expanded the types, availability, and volume of data available to an information management system. Furthermore, in these new environments, there is no formal control over the registration of new information sources, and applications tend to be developed without complete knowledge of the resources that will be available when they are run. Federated database projects such as Carnot that do static data integration do not scale up and do not cope well with this ever-changing environment. On the other hand, recent Web technologies, based on keyword search engines, are scalable but, unlike federated databases, are incapable of accessing information based on concepts. In this experience paper, we describe the architecture, design, and implementation of a working version of InfoSleuth. We show how InfoSleuth integrates new technological developments such as agent technology, domain ontologies, brokerage, and internet computing, in support of mediated interoperation of data and services in a dynamic and open environment. We demonstrate the use of information brokering and domain ontologies as key elements for scalability.", "authors": ["R. J. Bayardo", "W. Bohrer", "R. Brice", "A. Cichocki", "J. Fowler", "A. Helal", "V. Kashyap", "T. Ksiezyk", "G. Martin", "M. Nodine", "M. Rashid", "M. Rusinkiewicz", "R. Shea", "C. Unnikrishnan", "A. Unruh", "D. Woelk"], "related_topics": ["110903229", "29848774", "139458680"], "citation_count": "773", "reference_count": "32", "references": ["2166559705", "2137079713", "1523293200", "1804031886", "2160851181", "2336741951", "1879587332", "2161256997", "1638026557", "2147846431"], "date": "1997"}, {"id": "2083333988", "title": "Monitoring Renal Transplants: An Application of the Multiprocess Kalman Filter", "abstract": "SUMMARY The multiprocess Kalman filter offers a powerful general framework for the modelling and analysis of noisy time series which are subject to abrupt changes in pattern. It has considerable potential application to many forms of biological series used in clinical monitoring. In particular, the approach can be used to provide on-line probabilities of whether changes have occurred, as well as to identify the type of change that is involved. In this paper, we extend and illustrate the methodology within the context of a particular case study. The general features of the problem, and the approach adopted, will be seen to have wide application.", "authors": ["A. F. M. Smith", "M. West"], "related_topics": ["157286648", "2780049985", "2911091166"], "citation_count": "207", "reference_count": "10", "references": ["128740895", "1987037087", "2797328151", "2304999498", "85832130", "2727025559", "2337532458", "2798174714", "2796771297", "2034018107"], "date": "1983"}, {"id": "2987657883", "title": "Near Shannon limit error-correcting coding and decoding : Turbo-codes", "abstract": "", "authors": ["C. Berrou"], "related_topics": ["33529081", "64948573", "103073706"], "citation_count": "7545", "reference_count": "0", "references": ["2135764410", "2112772743", "2000006997", "2101394529", "2102251435", "2156938362", "2169415915", "1964402820", "2114869758", "2126259959"], "date": "1992"}, {"id": "10183563", "title": "Comments on Moravcsik\u2019s Paper", "abstract": "The basic problem is to determine what concrete mass nouns denote and how one is to give truth conditions for sentences containing them. I ignore for the most part \u2018abstract mass nouns\u2019 and \u2018mass adjectives\u2019, but see below.", "authors": ["Richard Montague"], "related_topics": ["39308869", "121934690", "41895202"], "citation_count": "11", "reference_count": "0", "references": ["2126363317", "2087366550", "2016518182", "2069907248", "2122025167", "23814011", "939131515", "1991950671", "2054037106", "197950511"], "date": "1972"}, {"id": "1605878143", "title": "A Vision of Responsible Research and Innovation", "abstract": "This paper outlines a vision of responsible research and innovation and develops an implementation strategy for it.", "authors": ["Ren\u00e9 von Schomberg"], "related_topics": ["2777720028", "2780328347", "2777362162"], "citation_count": "924", "reference_count": "24", "references": ["2302031502", "2044039018", "31722454", "2099152065", "2147233604", "2160792700", "1948761388", "2054413447", "1820085034", "2101205979"], "date": "2013"}, {"id": "2078841894", "title": "Singular value decomposition and least squares solutions", "abstract": "Let A be a real m\u00d7n matrix with m\u2267n. It is well known (cf. [4]) that $$A = U\\sum {V^T}$$ (1) where $${U^T}U = {V^T}V = V{V^T} = {I_n}{\\text{ and }}\\sum {\\text{ = diag(}}{\\sigma _{\\text{1}}}{\\text{,}} \\ldots {\\text{,}}{\\sigma _n}{\\text{)}}{\\text{.}}$$ The matrix U consists of n orthonormalized eigenvectors associated with the n largest eigenvalues of AA T , and the matrix V consists of the orthonormalized eigenvectors of A T A. The diagonal elements of \u2211 are the non-negative square roots of the eigenvalues of A T A; they are called singular values. We shall assume that $${\\sigma _1} \\geqq {\\sigma _2} \\geqq \\cdots \\geqq {\\sigma _n} \\geqq 0.$$ Thus if rank(A)=r, \u03c3 r+1 = \u03c3 r+2=\u22ef=\u03c3 n = 0. The decomposition (1) is called the singular value decomposition (SVD).", "authors": ["G. H. Golub", "C. Reinsch"], "related_topics": ["109282560", "73864959", "137127113"], "citation_count": "4022", "reference_count": "13", "references": ["2081720252", "2005423095", "2156722294", "1995854415", "2037324677", "2743834670", "2013333913", "1997643177", "1976167430", "2087788281"], "date": "1970"}, {"id": "217710249", "title": "SOLVING SYSTEMS OF POLYNOMIAL EQUATIONS", "abstract": "Polynomials in one variable Grobner bases of zero-dimensional ideals Bernstein's theorem and fewnomials Resultants Primary decomposition Polynomial systems in economics Sums of squares Polynomial systems in statistics Tropical algebraic geometry Linear partial differential equations with constant coefficients Bibliography Index.", "authors": ["Bernd Sturmfels"], "related_topics": ["101044782", "90119067", "34179328"], "citation_count": "964", "reference_count": "63", "references": ["1495410784", "1521877949", "2133404041", "1483218536", "2081659888", "2066181227", "1518341038", "2088986191", "1973128036", "2160135758"], "date": "2002"}, {"id": "2016559894", "title": "Scheduling multithreaded computations by work stealing", "abstract": "This paper studies the problem of efficiently schedulling fully strict (i.e., well-structured) multithreaded computations on parallel computers. A popular and practical method of scheduling this kind of dynamic MIMD-style computation is \u201cwork stealing,\u201d in which processors needing work steal computational threads from other processors. In this paper, we give the first provably good work-stealing scheduler for multithreaded computations with dependencies.Specifically, our analysis shows that the expected time to execute a fully strict computation on P processors using our work-stealing scheduler is T1/P + O(T \u221e , where T1 is the minimum serial execution time of the multithreaded computation and (T \u221e is the minimum execution time with an infinite number of processors. Moreover, the space required by the execution is at most S1P, where S1 is the minimum serial space requirement. We also show that the expected total communication of the algorithm is at most O(PT \u221e( 1 + nd)Smax), where Smax is the size of the largest activation record of any thread and nd is the maximum number of times that any thread synchronizes with its parent. This communication bound justifies the folk wisdom that work-stealing schedulers are more communication efficient than their work-sharing counterparts. All three of these bounds are existentially optimal to within a constant factor.", "authors": ["Robert D. Blumofe", "Charles E. Leiserson"], "related_topics": ["2778076476", "113200698", "138101251"], "citation_count": "2649", "reference_count": "43", "references": ["2032401773", "2072725684", "2098147619", "1773176621", "1969008575", "2149663533", "1986804682", "2175675949", "2104680817", "1995085071"], "date": "1999"}, {"id": "2160835070", "title": "Color constant color indexing", "abstract": "Objects can be recognized on the basis of their color alone by color indexing, a technique developed by Swain-Ballard (1991) which involves matching color-space histograms. Color indexing fails, however, when the incident illumination varies either spatially or spectrally. Although this limitation might be overcome by preprocessing with a color constancy algorithm, we instead propose histogramming color ratios. Since the ratios of color RGB triples from neighboring locations are relatively insensitive to changes in the incident illumination, this circumvents the need for color constancy preprocessing. Results of tests with the new color-constant-color-indexing algorithm on synthetic and real images show that it works very well even when the illumination varies spatially in its intensity and color. >", "authors": ["B.V. Funt", "G.D. Finlayson"], "related_topics": ["187888035", "82990744", "2961294"], "citation_count": "963", "reference_count": "13", "references": ["2914885528", "3021212382", "1989811281", "2051826135", "2164847484", "1997604630", "1994794884", "1994500434", "2109242101", "123950313"], "date": "1995"}, {"id": "2146474141", "title": "Face recognition by independent component analysis", "abstract": "A number of current face recognition algorithms use face representations found by unsupervised statistical methods. Typically these methods find a set of basis images and represent faces as a linear combination of those images. Principal component analysis (PCA) is a popular example of such methods. The basis images found by PCA depend only on pairwise relationships between pixels in the image database. In a task such as face recognition, in which important information may be contained in the high-order relationships among pixels, it seems reasonable to expect that better basis images may be found by methods sensitive to these high-order statistics. Independent component analysis (ICA), a generalization of PCA, is one such method. We used a version of ICA derived from the principle of optimal information transfer through sigmoidal neurons. ICA was performed on face images in the FERET database under two different architectures, one which treated the images as random variables and the pixels as outcomes, and a second which treated the pixels as random variables and the images as outcomes. The first architecture found spatially local basis images for the faces. The second architecture produced a factorial face code. Both ICA representations were superior to representations based on PCA for recognizing faces across days and changes in expression. A classifier that combined the two ICA representations gave the best performance.", "authors": ["M.S. Bartlett", "J.R. Movellan", "T.J. Sejnowski"], "related_topics": ["137087632", "31510193", "51432778"], "citation_count": "2826", "reference_count": "56", "references": ["2138451337", "1902027874", "2099741732", "2108384452", "2145889472", "2124101779", "2098947662", "1997011019", "1996355918", "2133069808"], "date": "2002"}, {"id": "1607673112", "title": "Video on demand", "abstract": "A video-on-demand system in which catalog data is periodically transferred to the user sites, where it is stored. This catalog data includes listings of the video products available at the central station, so-called trailers or previews for certain of the video products, and lead-ins for the initial portions of certain products to provide a seamless lead in to program material ordered from the central station. In a preferred embodiment of the invention, menu driven software allows a user to control the display of catalog data and to order video products from the central station interactively with displayed catalog material.", "authors": ["Norton Garfinkle"], "related_topics": ["2777904410", "49774154", "2775995803"], "citation_count": "378", "reference_count": "12", "references": ["2154431853", "1585637477", "1036915893", "1841771049", "980784249", "1484161782", "1891537869", "1891159246", "2150582796", "1924200221"], "date": "1994"}, {"id": "1693345094", "title": "Image segmentation in video sequences: a probabilistic approach", "abstract": "\"Background subtraction\" is an old technique for finding moving objects in a video sequence--for example, cars driving on a freeway. The idea is that subtracting the current image from a time-averaged background image will leave only nonstationary objects. It is, however, a crude approximation to the task of classifying each pixel of the current image; it fails with slow-moving objects and does not distinguish shadows from moving objects. The basic idea of this paper is that we can classify each pixel using a model of how that pixel looks when it is part of different classes. We learn a mixture-of-Gaussians classification model for each pixel using an unsupervised technique--an efficient, incremental version of EM. Unlike the standard image-averaging approach, this automatically updates the mixture component for each class according to likelihood of membership; hence slow-moving objects are handled perfectly. Our approach also identifies and eliminates shadows much more effectively than other techniques such as thresholding. Application of this method as part of the Roadwatch traffic surveillance project is expected to result in significant improvements in vehicle identification and tracking.", "authors": ["Nir Friedman", "Stuart Russell"], "related_topics": ["32653426", "124504099", "191178318"], "citation_count": "1242", "reference_count": "12", "references": ["2049633694", "2117853077", "2132576733", "2119444142", "2099330788", "2116453776", "2063089147", "1580495158", "2128768415", "2163330161"], "date": "1997"}, {"id": "2061265788", "title": "Normalization of speech by adaptive labelling", "abstract": "In a speech processor system in which prototype vectors of speech are generated by an acoustic processor under reference noise and known ambient conditions and in which feature vectors of speech are generated during varying noise and other ambient and recording conditions, normalized vectors are generated to reflect the form the feature vectors would have if generated under the reference conditions. The normalized vectors are generated by: (a) applying an operator function A i to a set of feature vectors x occurring at or before time interval i to yield a normalized vector y i =A i (x); (b) determining a distance error vector E i by which the normalized vector is projectively moved toward the closest prototype vector to the normalized vector y i ; (c) up-dating the operator function for next time interval to correspond to the most recently determined distance error vector; and (d) incrementing i to the next time interval and repeating steps (a) through (d) wherein the feature vector corresponding to the incremented i value has the most recent up-dated operator function applied thereto. With successive time intervals, successive normalized vectors are generated based on a successively up-dated operator function. For each normalized vector, the closest prototype thereto is associated therewith. The string of normalized vectors or the string of associated prototypes (or respective label identifiers thereof) or both provide output from the acoustic processor.", "authors": ["Arthur Joseph Nadas", "David Nahamoo"], "related_topics": ["83665646", "84316537", "123832482"], "citation_count": "68", "reference_count": "21", "references": ["3143345320", "2110007337", "2015123809", "3098408845", "1972105585", "2032371686", "2007695687", "2519644083", "1973092082", "1894490566"], "date": "1987"}, {"id": "2110416104", "title": "Only connections: A critique of semantic networks.", "abstract": "This article examines theories that assume that semantic networks account for the mental representation of meaning. It assesses their similarities and divergencies, and argues that as a class of theories they remain too powerful to be refuted by empirical evidence. The theories are also confronted by a number of problematical semantic phenomena that arise because networks deal with the connections between concepts rather than with their connections to the world. The solution to these problems could be embodied in a new network system, but such a system would differ in both structure and function from current network theories.", "authors": ["Philip N. Johnson-Laird", "Douglas J. Herrmann", "Roger Chaffin"], "related_topics": ["511149849", "85407183", "124246873"], "citation_count": "246", "reference_count": "71", "references": ["3009986018", "2039107287", "2135255848", "2117832390", "2170716495", "2530006810", "2109334311", "74704794", "2032152873", "2064332540"], "date": "1984"}, {"id": "1749253503", "title": "Vibration sensing touch input device", "abstract": "The present invention provides a touch sensitive input device that uses vibrations due to touch impacts and/or frictional movement of a touch implement across a surface to determine information related to the touch, such as touch position. The present invention also provides for detecting lift-off events in such vibration sensing input devices. Lift-off detection can be accomplished by monitoring for a signal that indicates a sustained touch on the touch plate, and correlating a change in such a signal with a lift-off event. Signals indicating a sustained touch can include low frequency rumbles coupled into the touch plate via the touch implement, touch plate bending under the force of a sustained touch, and touch plate displacement under the force of a sustained touch.", "authors": ["Nicholas P. R. Cygnet House Hill", "Darius M. Cygnet House Sullivan"], "related_topics": ["121449826", "113841659", "108489624"], "citation_count": "231", "reference_count": "40", "references": ["2098221549", "2150628651", "1948319504", "2160576303", "2815704152", "1530111492", "1839505766", "1495207559", "1857127336", "1960241050"], "date": "2004"}, {"id": "2135496634", "title": "Stress inoculation training", "abstract": "Stress inoculation training originally referred to a relatively specific set of operations (Meichenbaum & Cameron, 1972). In order to evaluate the efficacy of a skills training approach to anxiety management, a study was conducted using phobia as a target problem. Treatment involved three phases. It began with an educational phase that clarified the cognitive, affective, and physiological concomitants of the client\u2019s avoidant behavior. The Schachter (1966) model of emotion was presented to the client, who was encouraged to view anxiety as a reaction involving negative self-statements and images and physiological arousal. It was suggested that acquisition of two skills, namely, coping self-statements and self-directed relaxation, would help ameliorate the problem. This initial phase was followed by a skills training phase: specific types of coping self-statements and relaxation skills were learned and rehearsed. Finally, during an application phase, the client actually tested out the skills in a stressful laboratory situation (unpredictable electric shock was administered). This treatment was found to be more effective than imaginal systematic desensitization, then the standard treatment for phobia.", "authors": ["Donald Meichenbaum"], "related_topics": ["2777879506", "558461103", "54039966"], "citation_count": "1349", "reference_count": "59", "references": ["2179683524", "2102573486", "1998493215", "2498214524", "2081031067", "2064698198", "119946076", "2071936644", "655326068", "1512664624"], "date": "1984"}, {"id": "2061977616", "title": "Firm Resources and Sustained Competitive Advantage", "abstract": "Understanding sources of sustained competitive advantage has become a major area of research in strategic management. Building on the assumptions that strategic resources are heterogeneously distributed across firms and that these differences are stable over time, this article examines the link between firm resources and sustained competitive advantage. Four empirical indicators of the potential of firm resources to generate sustained competitive advantage-value, rareness, imitability, and substitutability are discussed. The model is applied by analyzing the potential of several firm resources for generating sustained competitive advantages. The article concludes by examining implications of this firm resource model of sustained competitive advantage for other business disciplines.", "authors": ["Jay B. Barney"], "related_topics": ["2779669084", "58546491", "176632266"], "citation_count": "96480", "reference_count": "71", "references": ["2140956556", "2101946146", "151157839", "3044348100", "1495886451", "2108767715", "2041670752", "2043593255", "2066557547", "3016265253"], "date": "1991"}, {"id": "2053631808", "title": "Quasi-random set systems", "abstract": "There are many properties of mathematical objects that satisfy what is sometimes called a 0-1 law, in the following sense. Under some natural probability measure on the set of objects, the measure of the subset of objects having the given property is either 0 or 1. In the latter case we can say that almost all the objects have the property. Familiar examples of this phenomenon are the following: almost all real numbers are transcendental (or normal to every base), almost all integers are composite, almost all continuous real functions are nondifferentiable, etc. It is often the case that the objects under consideration can be partitioned into a countable number of finite classes Cn, with the probability assigned to an object in Cn being just 1/ICn I. In this case, we say that a property Pn satisfies a 0-1 law if the fraction of the number of objects in Cn that satisfy Pn either tends to 0 or tends to 1 as n -x 0o. For example, almost all graphs on n vertices have maximum cliques and maximum independent sets of size at most 2 log n, almost all Boolean functions with n variables have circuit complexity (1 + o( 1 ))2n and almost all binary codes of length n with at most 2nR codewords (with R less than the binary symmetric channel capacity C) have arbitrarily small error probability (a special case of Shannon's coding theorem; see [S48]). One of the first general results of this type was the theorem of Fagin [F76] and Glebskii et al. [GKLT69], which asserts that every property of graphs that can be expressed in first-order logic satisfies a 0-1 law (see [SS88] for recent striking developments in this topic). One obvious method for finding explicit objects having some property Pn shared by almost all objects in Cn is simply to select one at random. With overwhelming probability (tending to 1 as n -x oc), the selected object will have property Pn. Unfortunately, it may be (and often is) extremely difficult to prove that any particular object does indeed satisfy Pn . It is our purpose in this paper to describe a method that can to a certain extent circumvent this difficulty. We will show that, for a variety of families, it is possible to identify a natural hierarchy of equivalence classes of properties, all of which are shared by almost all objects in the family. Any object satisfying", "authors": ["F. R. K. Chung", "R. L. Graham"], "related_topics": ["21031990", "52386014", "110729354"], "citation_count": "126", "reference_count": "34", "references": ["2905110430", "2799004609", "2797646349", "2901284226", "1484040084", "2983896310", "1995875735", "1552744309", "2088164510", "2151436648"], "date": "1990"}, {"id": "2099741732", "title": "Independent component analysis, a new concept?", "abstract": "Abstract The independent component analysis (ICA) of a random vector consists of searching for a linear transformation that minimizes the statistical dependence between its components. In order to define suitable search criteria, the expansion of mutual information is utilized as a function of cumulants of increasing orders. An efficient algorithm is proposed, which allows the computation of the ICA of a data matrix within a polynomial time. The concept of ICA may actually be seen as an extension of the principal component analysis (PCA), which can only impose independence up to the second order and, consequently, defines directions that are orthogonal. Potential applications of ICA include data analysis and compression, Bayesian detection, localization of sources, and blind identification and deconvolution.", "authors": ["Pierre Comon"], "related_topics": ["51432778", "157709420", "27438332"], "citation_count": "11030", "reference_count": "49", "references": ["1996355918", "2171074980", "2018388266", "2098301339", "2114018052", "1560089794", "2796930440", "2225937484", "1995963238", "2140352766"], "date": "1994"}, {"id": "2109363337", "title": "Molecular classification of cancer: class discovery and class prediction by gene expression monitoring.", "abstract": "Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.", "authors": ["T. R. Golub", "", "D. K. Slonim", "P. Tamayo", "C. Huard", "M. Gaasenbeek", "J. P. Mesirov", "H. Coller", "M. L. Loh", "J. R. Downing", "M. A. Caligiuri", "C. D. Bloomfield", "E. S. Lander"], "related_topics": ["121608353", "77360908", "548314002"], "citation_count": "14730", "reference_count": "45", "references": ["2103453943", "2130494035", "2109970232", "2135187880", "2087810003", "238668910", "2030958510", "2069271664", "2079501979", "2100555004"], "date": "1999"}, {"id": "2090196588", "title": "Deformable templates for face recognition", "abstract": "We describe an approach for extracting facial features from images and for determining the spatial organization between these features using the concept of a deformable template. This is a parameterized geometric model of the object to be recognized together with a measure of how well it fits the image data. Variations in the parameters correspond to allowable deformations of the object and can be specified by a probabilistic model. After the extraction stage the parameters of the deformable template can be used for object description and recognition.", "authors": ["Alan L. Yuille"], "related_topics": ["31510193", "153180895", "104065381"], "citation_count": "556", "reference_count": "18", "references": ["2104095591", "2164741953", "2129249398", "2103504761", "2051719061", "1574225613", "2045798786", "1504499192", "1977699267", "1758984152"], "date": "1990"}, {"id": "2035996732", "title": "The Procrustes Program: Producing direct rotation to test a hypothesized factor structure.", "abstract": "", "authors": ["John R. Hurley", "Raymond B. Cattell"], "related_topics": ["74050887", "2910331095", "33923547"], "citation_count": "421", "reference_count": "13", "references": ["1997320786", "2007622430", "1969502977", "1606947449", "1512018163", "2124667783", "2084777239", "2012912068", "2051176770", "2050657606"], "date": "2007"}, {"id": "192446467", "title": "ZooKeeper: wait-free coordination for internet-scale systems", "abstract": "In this paper, we describe ZooKeeper, a service for coordinating processes of distributed applications. Since ZooKeeper is part of critical infrastructure, ZooKeeper aims to provide a simple and high performance kernel for building more complex coordination primitives at the client. It incorporates elements from group messaging, shared registers, and distributed lock services in a replicated, centralized service. The interface exposed by Zoo-Keeper has the wait-free aspects of shared registers with an event-driven mechanism similar to cache invalidations of distributed file systems to provide a simple, yet powerful coordination service. The ZooKeeper interface enables a high-performance service implementation. In addition to the wait-free property, ZooKeeper provides a per client guarantee of FIFO execution of requests and linearizability for all requests that change the ZooKeeper state. These design decisions enable the implementation of a high performance processing pipeline with read requests being satisfied by local servers. We show for the target workloads, 2:1 to 100:1 read to write ratio, that ZooKeeper can handle tens to hundreds of thousands of transactions per second. This performance allows ZooKeeper to be used extensively by client applications.", "authors": ["Patrick Hunt", "Mahadev Konar", "Flavio P. Junqueira", "Benjamin Reed"], "related_topics": ["84172371", "93996380", "115537543"], "citation_count": "2013", "reference_count": "29", "references": ["2153704625", "3021428210", "2114579022", "1992479210", "2005373714", "2038345682", "2143149536", "2111586962", "2101939036", "2152465173"], "date": "2010"}, {"id": "1574789166", "title": "Statistics and Chemometrics for Analytical Chemistry", "abstract": "1. Introduction 1.1 Analytical problems 1.2 Errors in qunatitative analysis 1.3 Types of error 1.4 Random and systematic errors in titrimetric analysis 1.5 Handling systematic errors 1.6 Planning and design of experiments 1.7 Calculators and computers in statistical calculations 2. Statistics of Repeated Measurements 2.1 Mean and standard deviation 2.2 The distribution of repeated measurements 2.3 Log-normal distribution 2.4 Definition of a 'sample' 2.5 The sampling distribution of the mean 2.6 Confidence limits of the mean for large samples 2.7 Confidence limits of the mean for small samples 2.8 Presentation of results 2.9 Other uses of confidence limits 2.10 Confidence limits of the geometric mean for a log-normal distribution 2.11 Propagation of random errors 2.12 Propagation of systematic errors 3. Significance Tests 3.1 Introduction 3.2 Comparison of an experimental mean with a known value 3.3 Comparison of two experimental means 3.4 Paired t-test 3.5 One-sided and two-sided tests 3.6 F-test for the comparison of standard deviations 3.7 Outliers 3.8 Analysis of variance 3.9 Comparison of several means 3.10 The arithmetic of ANOVA calculations 3.11 The chi-squared test 3.12 Testing for normality of distribution 3.13 Conclusions from significance tests 3.14 Bayesian Statistics 4. The Quality of Analytical Measurements 4.1 Introduction 4.2 Sampling 4.3 Separation and estimation of variances using ANOVA 4.4 Sampling strategy 4.5 Quality control methods - Introduction 4.6 Stewhart charts for mean values 4.7 Stewhart charts for ranges 4.8 Establishing the process capability 4.9 Average run length: cusum charts 4.10 Zone control charts (J-charts) 4.11 Proficiency testing schemes 4.12 Method performance studies (collaborative trials) 4.13 Uncertainty 4.14 Acceptable sampling 4.15 Method validation 5. Calibration Methods in Instumental Analysis 5.1 Introduction: instrumentational analysis 5.2 Calibration graphs in instrumental analysis 5.3 The product-moment correlation coefficient 5.4 The line of regression of y on x 5.5 Errors in the slope and intercept of the regression line 5.6 Calculation of a concentration and its random error 5.7 Limits of detection 5.8 The method of standard additions 5.9 Use of regression lines for comparing analytical methods 5.10 Weighted regression lines 5.11 Intersection of two straight lines 5.12 ANOVA and regression calculations 5.13 Curvilinear regression methods - Introduction 5.14 Curve fitting 5.15 Outliers in regression 6. Non-parametric and Robust Methods 6.1 Introduction 6.2 The median: initial data analysis 6.3 The sign test 6.4 The Wald-Wolfowitz runs test 6.5 The Wilcoxon signed rank test 6.6 Simple tests for two independent samples 6.7 Non-parametric tests for more than two samples 6.8 Rank correlation 6.9 Non-parametric regression methods 6.10 Robust methods: introduction 6.11 Simple robust methods: trimming and winsorization 6.12 Further robust estimates of location and spread 6.13 Robust ANOVA 6.14 Robust regression methods 6.15 Re-sampling statistics 6.16 Conclusions 7. Experiimental Design and Optimization 7.1 Introduction 7.2 Randomization and blocking 7.3 Two-way ANOVA 7.4 Latin squares and other designs 7.5 Interactions 7.6 Identifying the important factors: factorial designs 7.7 Fractional factorial designs 7.8 Optimization: basic principles and univariate methods 7.9 Optimization using the alternating variable search method 7.10 The method of steepest ascent 7.11 Simplex optimization 7.12 Simulated annealing 8. Multivariate Analysis 8.1 Introduction 8.2 Initial analysis 8.3 Prinicipal component analysis 8.4 Cluster analysis 8.5 Discriminant analysis 8.6 K-nearest neighbour method 8.7 Disjoint class modelling 8.8 Regression methods 8.9 Multiple linear regression 8.10 Principal component regression 8.11 Partial least squares regression 8.12 Natural computation methods artificial neural networks 8.13 Conclusions Solutions to Exercises Appendix 1 Commonly used statistical significance tests Appendix 2 Statistical tables Index", "authors": ["James N. Miller", "Jane C. Miller"], "related_topics": ["70259352", "35519122", "5292614"], "citation_count": "6217", "reference_count": "0", "references": ["644895208", "2162116192", "1495773224", "2580319474", "1997527498", "2279992745", "1874953331", "2026779107", "1563946068", "2036703300"], "date": "2001"}, {"id": "2108795964", "title": "ABSORPTIVE CAPACITY: A NEW PERSPECTIVE ON LEARNING AND INNOVATION", "abstract": "In this paper, we argue that the ability of a firm to recognize the value of new, external information, assimilate it, and apply it to commercial ends is critical to its innovative capabilities. We label this capability a firm's absorptive capacity and suggest that it is largely a function of the firm's level of prior related knowledge. The discussion focuses first on the cognitive basis for an individual's absorptive capacity including, in particular, prior related knowledge and diversity of background. We then characterize the factors that influence absorptive capacity at the organizational level, how an organization's absorptive capacity differs from that of its individual members, and the role of diversity of expertise within an organization. We argue that the development of absorptive capacity, and, in turn, innovative performance are history- or path-dependent and argue how lack of investment in an area of expertise early on may foreclose the future development of a technical capability in that area. We formulate a model of firm investment in research and development (R&D), in which R&D contributes to a firm's absorptive capacity, and test predictions relating a firm's investment in R&D to the knowledge underlying technical change within an industry. Discussion focuses on the implications of absorptive capacity for the analysis of other related innovative activities, including basic research, the adoption and diffusion of innovations, and decisions to participate in cooperative R&D ventures. **", "authors": ["Wesley M. Cohen", "Daniel A. Levinthal"], "related_topics": ["2777724570", "2780888560", "2777455136"], "citation_count": "52718", "reference_count": "42", "references": ["2137358449", "2005144066", "3124140110", "2099670044", "3016265253", "3122012035", "3124909988", "1598208848", "2008374349", "2132723011"], "date": "1990"}, {"id": "2101769805", "title": "Deformations of Coxeter Hyperplane Arrangements", "abstract": "We investigate several hyperplane arrangements that can be viewed as deformations of Coxeter arrangements. In particular, we prove a conjecture of Linial and Stanley that the number of regions of the arrangement xi?xj=1, 1?i", "authors": ["Alexander Postnikov", "Richard P. Stanley"], "related_topics": ["37486056", "140860697", "143669375"], "citation_count": "209", "reference_count": "25", "references": ["2914659449", "377884864", "2276336683", "1607402086", "2138241477", "2091715579", "2058285899", "1556866066", "1591020685", "2048453639"], "date": "2000"}, {"id": "2126590220", "title": "Minimum-redundancy coding for the discrete noiseless channel", "abstract": "This paper gives a method for constructing minimum-redundancy prefix codes for the general discrete noiseless channel without constraints. The costs of code letters need not be equal, and the symbols encoded are not assumed to be equally probable. A solution had previously been given by Huffman [10] in 1952 for the special case in which all code letters are of equal cost. The present development is algebraic. First, structure functions are defined, in terms of which necessary and sufficient conditions for the existence of prefix codes may be stated. From these conditions, linear inequalities are derived which may be used to characterize prefix codes. Gomory's integer programming algorithm is then used to construct optimum codes subject to these inequalities; computational experience is presented to demonstrate the practicability of the method. Finally, some additional coding problems are discussed and a problem of classification is treated.", "authors": ["R. Karp"], "related_topics": ["20079647", "205612216", "2400350"], "citation_count": "185", "reference_count": "11", "references": ["1995875735", "1992371956", "2009683816", "1992649154", "2126711987", "1509016759", "648844600", "2169476932", "2027875058", "1480469437"], "date": "1960"}, {"id": "1506619236", "title": "Visual information seeking: tight coupling of dynamic query filters with starfield displays", "abstract": "ABSTRACT This paper offers new principles for visual information seeking (VIS). A key concept is to support browsing, which is distinguished from familiar query composition and information retrieval because of its emphasis on rapid filtering to reduce result sets, progressive refinement of search parameters, continuous reformulation of goals, and visual scanning to identify results. VIS principles developed include: dynamic query filters (query parameters are rapidly adjusted with sliders, buttons, maps, etc.), starfield displays (two-dimensional scatterplots to structure result sets and zooming to reduce clutter), and tight coupling (interrelating query components to preserve display invariants and support progressive refinement combined with an emphasis on using search output to foster search input). A FilmFinder prototype using a movie database demonstrates these principles in a VIS environment.", "authors": ["Christopher Ahlberg", "Ben Shneiderman"], "related_topics": ["99016210", "157692150", "118689300"], "citation_count": "1516", "reference_count": "0", "references": ["2093931563", "2098231756", "1981560284", "3041294746", "284763255", "2134732931", "2037222196", "2050885482", "1560990812", "2112038367"], "date": "1995"}, {"id": "2556784265", "title": "A new Definition of Fractional Derivative without Singular Kernel", "abstract": "In the paper, we present a new definition of fractional deriva tive with a smooth kernel which takes on two different representations for the temporal and spatial variable. The first works on the time variables; thus it is suitable to use th e Laplace transform. The second definition is related to the spatial va riables, by a non-local fractional derivative, for which it is more convenient to work with the Fourier transform. The interest for this new approach with a regular kernel was born from the prospect that there is a class of non-local systems, which have the ability to descri be the material heterogeneities and the fluctuations of diff erent scales, which cannot be well described by classical local theories or by fractional models with singular kernel.", "authors": ["Michele Caputo", "Mauro Fabrizio"], "related_topics": ["154249771", "98234853", "102519508"], "citation_count": "1779", "reference_count": "33", "references": ["2787959293", "1584611818", "1975670568", "433794350", "101914685", "617317968", "617206983", "2506586217", "1973352373", "260145074"], "date": "2014"}, {"id": "2238624099", "title": "The X-tree: an index structure for high-dimensional data", "abstract": "In this paper, we propose a new method for indexing large amounts of point and spatial data in high-dimensional space. An analysis shows that index structures such as the R*-tree are not adequate for indexing high-dimensional data sets. The major problem of R-tree-based index structures is the overlap of the bounding boxes in the directory, which increases with growing dimension. To avoid this problem, we introduce a new organization of the directory which uses a split algorithm minimizing overlap and additionally utilizes the concept of supernodes. The basic idea of overlap-minimizing split and supernodes is to keep the directory as hierarchical as possible, and at the same time to avoid splits in the directory that would result in high overlap. Our experiments show that for high-dimensional data, the X-tree outperforms the well-known R*-tree and the TV-tree by up to two orders of magnitude.", "authors": ["Stefan Berchtold", "Daniel A. Keim", "Hans-Peter Kriegel"], "related_topics": ["111904168", "2777717936", "2777683733"], "citation_count": "2297", "reference_count": "26", "references": ["2055043387", "2151135734", "2118269922", "1499049447", "1975830550", "2046144220", "2167081989", "2010595692", "2149173084", "2155776210"], "date": "2001"}, {"id": "179875071", "title": "Recurrent neural network based language model", "abstract": "A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity. Index Terms: language modeling, recurrent neural networks, speech recognition", "authors": ["Tomas Mikolov", "Martin Karafi\u00e1t", "Luk\u00e1s Burget", "Jan Cernock\u00fd", "Sanjeev Khudanpur"], "related_topics": ["175202392", "137293760", "147168706"], "citation_count": "5581", "reference_count": "14", "references": ["2132339004", "2110485445", "2107878631", "36903255", "2096072088", "2468573742", "2152808281", "2292896937", "2027499299", "2437096199"], "date": "2009"}, {"id": "1505203270", "title": "How college affects students : findings and insights from twenty years of research", "abstract": "Foreword 1. Studying College Outcomes: Overview and Organization of the Research 2. Theories and Models of Student Change in College 3. Development of Verbal, Quantitative, and Subject Matter Competence 4. Cognitive Skills and Intellectual Growth 5. Psychosocial Changes: Identity, Selt--Concept, and Self--Esteem 6. Psycholsocial Changes: Relating to Others and the External World 7. Attitudes and Values 8. Moral Development 9. Educational Attainment 10. Career Choice and Development 11. Economic Benefits of College 12. Quality of Life After College 13. How College Makes a Difference: A Summary 14. Implications of the Research for Policy and Practice AppAndix: Methodological and Analytical Issues in Assessing the Influence of College", "authors": ["Ernest T. Pascarella", "Patrick T. Terenzini"], "related_topics": ["76247681", "140441792", "100521375"], "citation_count": "4213", "reference_count": "0", "references": ["2012186625", "2091227467", "2113671972", "2132790577", "2021089563", "2114994015", "2160355410", "2048628297", "2123775477", "2111292692"], "date": "1992"}, {"id": "2177040213", "title": "A massively parallel architecture for a self-organizing neural pattern recognition machine", "abstract": "A neural network architecture for the learning of recognition categories is derived. Real-time network dynamics are completely characterized through mathematical analysis and computer simulations. The architecture self-organizes and self-stabilizes its recognition codes in response to arbitrary orderings of arbitrarily many and arbitrarily complex binary input patterns. Top-down attentional and matching mechanisms are critical in self-stabilizing the code learning process. The architecture embodies a parallel search scheme which updates itself adaptively as the learning process unfolds. After learning self-stabilizes, the search process is automatically disengaged. Thereafter input patterns directly access their recognition codes without any search. Thus recognition time does not grow as a function of code complexity. A novel input pattern can directly access a category if it shares invariant properties with the set of familiar exemplars of that category. These invariant properties emerge in the form of learned critical feature patterns, or prototypes. The architecture possesses a context-sensitive self-scaling property which enables its emergent critical feature patterns to form. They detect and remember statistically predictive configurations of featural elements which are derived from the set of all input patterns that are ever experienced. Four types of attentional process\u2014priming, gain control, vigilance, and intermodal competition\u2014are mechanistically characterized. Top\u2014down priming and gain control are needed for code matching and self-stabilization. Attentional vigilance determines how fine the learned categories will be. If vigilance increases due to an environmental disconfirmation, then the system automatically searches for and learns finer recognition categories. A new nonlinear matching law (the \u2154 Rule) and new nonlinear associative laws (the Weber Law Rule, the Associative Decay Rule, and the Template Learning Rule) are needed to achieve these properties. All the rules describe emergent properties of parallel network interactions. The architecture circumvents the noise, saturation, capacity, orthogonality, and linear predictability constraints that limit the codes which can be stably learned by alternative recognition models.", "authors": ["G. A. Carpenter", "S. Grossberg"], "related_topics": ["2779127903", "40608802", "153180895"], "citation_count": "4070", "reference_count": "0", "references": ["2116424792", "2166280719", "2012611887", "2015857587", "2145747704", "2065134213", "1977867644", "2154102142", "2119141384", "2153858306"], "date": "1988"}, {"id": "2035446426", "title": "Introduction to Stochastic Dynamic Programming", "abstract": "", "authors": ["Sheldon M. Ross"], "related_topics": ["137631369", "37404715", "41008148"], "citation_count": "1948", "reference_count": "0", "references": ["2121863487", "2119567691", "1557517019", "1592847719", "2009533501", "2126940339", "355207094", "2130762526", "2943528199", "2099153975"], "date": "2014"}, {"id": "2052645364", "title": "On the efficiency of algorithms of analysis", "abstract": "", "authors": ["Steve Smale"], "related_topics": ["11644782", "33923547", "126255220"], "citation_count": "376", "reference_count": "36", "references": ["1655990431", "2013737143", "2010069926", "2127470768", "2023413246", "2062985118", "1966287322", "1490692428", "2144493917", "2314942319"], "date": "1985"}, {"id": "2610179052", "title": "Algorithms on strings, trees, and sequences", "abstract": "Linear-Time Construction of Suffix Trees We will present two methods for constructing suffix trees in detail, Ukkonen\u2019s method and Weiner\u2019s method. Weiner was the first to show that suffix trees can be built in linear time, and his method is presented both for its historical importance and for some different technical ideas that it contains. However, lJkkonen\u2019s method is equally fast and uses far less space (i.e., memory) in practice than Weiner\u2019s method Hence Ukkonen is the method of choice for most problems requiring the construction of a suffix tree. We also believe that Ukkonen\u2019s method is easier to understand. Therefore, it will be presented first A reader who wishes to study only one method is advised to concentrate on it. However, our development of Weiner\u2019s method does not depend on understanding Ukkonen\u2019s algorithm, and the two algorithms can be read independently (with one small shared section noted in the description of Weiner\u2019s method).", "authors": ["Dan Gusfield"], "related_topics": ["143168145", "2781166958", "118146561"], "citation_count": "2971", "reference_count": "0", "references": ["2036897871", "2107282968", "2001496424", "2138756793", "2106595237", "2144544802", "2099256741", "2137786570", "2072193858", "1894414046"], "date": "1996"}, {"id": "2127347346", "title": "Ear-phone: an end-to-end participatory urban noise mapping system", "abstract": "A noise map facilitates monitoring of environmental noise pollution in urban areas. It can raise citizen awareness of noise pollution levels, and aid in the development of mitigation strategies to cope with the adverse effects. However, state-of-the-art techniques for rendering noise maps in urban areas are expensive and rarely updated (months or even years), as they rely on population and traffic models rather than on real data. Participatory urban sensing can be leveraged to create an open and inexpensive platform for rendering up-to-date noise maps.In this paper, we present the design, implementation and performance evaluation of an end-to-end participatory urban noise mapping system called Ear-Phone. Ear-Phone, for the first time, leverages Compressive Sensing to address the fundamental problem of recovering the noise map from incomplete and random samples obtained by crowdsourcing data collection. Ear-Phone, implemented on Nokia N95 and HP iPAQ mobile devices, also addresses the challenge of collecting accurate noise pollution readings at a mobile device. Extensive simulations and outdoor experiments demonstrate that Ear-Phone is a feasible platform to assess noise pollution, incurring reasonable system resource consumption at mobile devices and providing high reconstruction accuracy of the noise map.", "authors": ["Rajib Kumar Rana", "Chun Tung Chou", "Salil S. Kanhere", "Nirupama Bulusu", "Wen Hu"], "related_topics": ["130858481", "86781634", "2779208394"], "citation_count": "849", "reference_count": "11", "references": ["2143319963", "2129319777", "1583075929", "2157747589", "2044035162", "2139151158", "2162277470", "2128513955", "2132792959", "1484342212"], "date": "2010"}, {"id": "1980911747", "title": "A Comparison of Affine Region Detectors", "abstract": "The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector of `maximally stable extremal regions', proposed by Matas et al. (2002); an edge-based region detector (Tuytelaars and Van Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van Gool, 2000), and a detector of `salient regions', proposed by Kadir, Zisserman and Brady (2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression. The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework.", "authors": ["K. Mikolajczyk", "T. Tuytelaars", "C. Schmid", "A. Zisserman", "J. Matas", "F. Schaffalitzky", "T. Kadir", "L. Van Gool"], "related_topics": ["153077589", "6408098", "202227193"], "citation_count": "4250", "reference_count": "49", "references": ["2151103935", "2033819227", "2124386111", "2177274842", "2131846894", "2154422044", "2145023731", "1625255723", "2172188317", "2124404372"], "date": "2005"}, {"id": "201578715", "title": "Sensemaking in organizations", "abstract": "The Nature of Sensemaking Seven Properties of Sensemaking Sensemaking in Organizations Occasions for Sensemaking The Substance of Sensemaking Belief-Driven Processes of Sensemaking Action-Driven Processes of Sensemaking The Future of Sensemaking", "authors": ["Karl E. Weick"], "related_topics": ["2780554381", "2776321126", "56739046"], "citation_count": "30697", "reference_count": "0", "references": ["2108183214", "2112665591", "2343951702", "2012370212", "1985721027", "2018514036", "1996293917", "2025691702", "271526086", "2097549324"], "date": "1994"}, {"id": "2105364438", "title": "Adaptive smoothing: a general tool for early vision", "abstract": "A method to smooth a signal while preserving discontinuities is presented. This is achieved by repeatedly convolving the signal with a very small averaging mask weighted by a measure of the signal continuity at each point. Edge detection can be performed after a few iterations, and features extracted from the smoothed signal are correctly localized (hence, no tracking is needed). This last property allows the derivation of a scale-space representation of a signal using the adaptive smoothing parameter k as the scale dimension. The relation of this process to anisotropic diffusion is shown. A scheme to preserve higher-order discontinuities and results on range images is proposed. Different implementations of adaptive smoothing are presented, first on a serial machine, for which a multigrid algorithm is proposed to speed up the smoothing effect, then on a single instruction multiple data (SIMD) parallel machine such as the Connection Machine. Various applications of adaptive smoothing such as edge detection, range image feature extraction, corner detection, and stereo matching are discussed. >", "authors": ["P. Saint-Marc", "J.-S. Chen", "G. Medioni"], "related_topics": ["3770464", "193536780", "102248274"], "citation_count": "1101", "reference_count": "37", "references": ["2145023731", "1997063559", "2150134853", "2109863423", "2003370853", "2913192828", "2158365276", "1995756857", "1597739853", "2133155955"], "date": "1991"}, {"id": "2072644219", "title": "Dynamic topic models", "abstract": "A family of probabilistic time series models is developed to analyze the time evolution of topics in large document collections. The approach is to use state space models on the natural parameters of the multinomial distributions that represent the topics. Variational approximations based on Kalman filters and nonparametric wavelet regression are developed to carry out approximate posterior inference over the latent topics. In addition to giving quantitative, predictive models of a sequential corpus, dynamic topic models provide a qualitative window into the contents of a large document collection. The models are demonstrated by analyzing the OCR'ed archives of the journal Science from 1880 through 2000.", "authors": ["David M. Blei", "John D. Lafferty"], "related_topics": ["181389423", "131205210", "102366305"], "citation_count": "2897", "reference_count": "16", "references": ["1880262756", "2098126593", "2107034620", "2001082470", "2140124448", "2103658758", "2099768828", "2112050062", "1571975558", "2151926297"], "date": "2006"}, {"id": "2087747577", "title": "A structural view of the Cedar programming environment", "abstract": "This paper presents an overview of the Cedar programming environment, focusing on its overall structure\u2014that is, the major components of Cedar and the way they are organized. Cedar supports the development of programs written in a single programming language, also called Cedar. Its primary purpose is to increase the productivity of programmers whose activities include experimental programming and the development of prototype software systems for a high-performance personal computer. The paper emphasizes the extent to which the Cedar language, with run-time support, has influenced the organization, flexibility, usefulness, and stability of the Cedar environment. It highlights the novel system features of Cedar, including automatic storage management of dynamically allocated typed values, a run-time type system that provides run-time access to Cedar data type definitions and allows interpretive manipulation of typed values, and a powerful device-independent imaging model that supports the user interface facilities. Using these discussions to set the context, the paper addresses the language and system features and the methodologies used to facilitate the integration of Cedar applications. A comparison of Cedar with other programming environments further identifies areas where Cedar excels and areas where work remains to be done.", "authors": ["Daniel C. Swinehart", "Polle T. Zellweger", "Richard J. Beach", "Robert B. Hagmann"], "related_topics": ["2988821698", "138958017", "2780049985"], "citation_count": "283", "reference_count": "47", "references": ["1770006921", "87357050", "2199322517", "2043671329", "1975470983", "2172651430", "2174305619", "2148238464", "2124212956", "2105896399"], "date": "1986"}, {"id": "1976709621", "title": "From Sparse Solutions of Systems of Equations to Sparse Modeling of Signals and Images", "abstract": "A full-rank matrix ${\\bf A}\\in \\mathbb{R}^{n\\times m}$ with $n<m$ generates an underdetermined system of linear equations ${\\bf Ax} = {\\bf b}$ having infinitely many solutions. Suppose we seek the sparsest solution, i.e., the one with the fewest nonzero entries. Can it ever be unique? If so, when? As optimization of sparsity is combinatorial in nature, are there efficient methods for finding the sparsest solution? These questions have been answered positively and constructively in recent years, exposing a wide variety of surprising phenomena, in particular the existence of easily verifiable conditions under which optimally sparse solutions can be found by concrete, effective computational methods. Such theoretical results inspire a bold perspective on some important practical problems in signal and image processing. Several well-known signal and image processing problems can be cast as demanding solutions of undetermined systems of equations. Such problems have previously seemed, to many, intractable, but there is considerable evidence that these problems often have sparse solutions. Hence, advances in finding sparse solutions to underdetermined systems have energized research on such signal and image processing problems\u2014to striking effect. In this paper we review the theoretical results on sparse solutions of linear systems, empirical results on sparse modeling of signals and images, and recent applications in inverse problems and compression in image processing. This work lies at the intersection of signal processing and applied mathematics, and arose initially from the wavelets and harmonic analysis research communities. The aim of this paper is to introduce a few key notions and applications connected to sparsity, targeting newcomers interested in either the mathematical aspects of this area or its applications.", "authors": ["Alfred M. Bruckstein", "David L. Donoho", "Michael Elad"], "related_topics": ["124066611", "156872377", "179690561"], "citation_count": "2447", "reference_count": "163", "references": ["2296616510", "2145096794", "2115755118", "2129131372", "2127271355", "1548802052", "2160547390", "2063978378", "2164452299", "2078204800"], "date": "2009"}, {"id": "2057978731", "title": "Job satisfaction and gender: Why are women so happy at work?", "abstract": "Abstract By most objective standards, women's jobs are worse than men's, yet women report higher levels of job satisfaction than do men. This paper uses a recent large-scale British survey to document the extent of this gender differential for eight measures of job satisfaction and to evaluate the proposition that identical men and women in identical jobs should be equally satisfied. Neither the different jobs that men and women do, their different work values, nor sample selection account for the gender satisfaction differential. The paper's proposed explanation appeals to the notion of relative well-being, especially relative to workers' expectations. An identical man and woman with the same jobs and expectations would indeed report identical job satisfaction, but women's expectations are argued to be lower than men's. This hypothesis is supported by the finding that the gender satisfaction differential disappears for the young, the higher-educated, professionals and those in male-dominated workplaces, for all of whom there is less likely to be a gender difference in job expectations.", "authors": ["Andrew E. Clark"], "related_topics": ["2718322", "150706916", "15744967"], "citation_count": "2559", "reference_count": "57", "references": ["2133469585", "2078205970", "2571495779", "3121813221", "3149337475", "2140674153", "2040689732", "2022003982", "2145964516", "2126269244"], "date": "1997"}, {"id": "2143075689", "title": "Fusion, propagation, and structuring in belief networks", "abstract": "Belief networks are directed acyclic graphs in which the nodes represent propositions (or variables), the arcs signify direct dependencies between the linked propositions, and the strengths of these dependencies are quantified by conditional probabilities. A network of this sort can be used to represent the generic knowledge of a domain expert, and it turns into a computational architecture if the links are used not merely for storing factual knowledge but also for directing and activating the data flow in the computations which manipulate this knowledge. The first part of the paper deals with the task of fusing and propagating the impacts of new information through the networks in such a way that, when equilibrium is reached, each proposition will be assigned a measure of belief consistent with the axioms of probability theory. It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network. The second part of the paper deals with the problem of finding a tree-structured representation for a collection of probabilistically coupled propositions using auxiliary (dummy) variables, colloquially called \"hidden causes.\" It is shown that if such a tree-structured representation exists, then it is possible to uniquely uncover the topology of the tree by observing pairwise dependencies among the available propositions (i.e., the leaves of the tree). The entire tree structure, including the strengths of all internal relationships, can be reconstructed in time proportional to n log n, where n is the number of leaves.", "authors": ["J Pearl"], "related_topics": ["163797641", "1465435", "101056560"], "citation_count": "3061", "reference_count": "27", "references": ["1997063559", "1708874574", "2478175895", "1979622972", "2002478775", "2068868410", "1580038098", "2156094048", "2163166770", "2173593652"], "date": "1986"}, {"id": "2009803313", "title": "The Traveling-Salesman Problem and Minimum Spanning Trees", "abstract": "This paper explores new approaches to the symmetric traveling-salesman problem in which 1-trees, which are a slight variant of spanning trees, play an essential role. A 1-tree is a tree together with an additional vertex connected to the tree by two edges. We observe that i a tour is precisely a 1-tree in which each vertex has degree 2, ii a minimum 1-tree is easy to compute, and iii the transformation on \"intercity distances\" cij \u00e2\u0086\u0092 Cij + \u03c0i + \u03c0j leaves the traveling-salesman problem invariant but changes the minimum 1-tree. Using these observations, we define an infinite family of lower bounds w\u03c0 on C*, the cost of an optimum tour. We show that max\u03c0w\u03c0 = C* precisely when a certain well-known linear program has an optimal solution in integers. We give a column-generation method and an ascent method for computing max\u03c0w\u03c0, and construct a branch-and-bound method in which the lower bounds w\u03c0 control the search for an optimum tour.", "authors": ["Michael Held", "Richard M. Karp"], "related_topics": ["13743678", "64331007", "175859090"], "citation_count": "1918", "reference_count": "14", "references": ["2169528473", "1965680834", "1969186119", "1991528957", "2037455079", "2144946856", "2058937865", "2085478109", "2086863198", "2136499036"], "date": "1970"}, {"id": "2057283314", "title": "Statistical Process Control of Multivariate Processes", "abstract": "Abstract With process computers routinely collecting measurements on large numbers of process variables, multivariate statistical methods for the analysis, monitoring and diagnosis of process operating performance have received increasing attention. Extensions of traditional univariate Shewhart, CUSUM and EWMA control charts to multivariate quality control situations are based on Hotelling's T 2 statistic. Recent approaches to multivariate statistical process control which utilize not only product quality data (Y), but also all of the available process variable data (X) are based on multivariate statistical projection methods (Principal Component Analysis (PCA) and Partial Least Squares (PLS)). This paper gives an overview of these methods, and their use for the statistical process control of both continuous and batch multivariate processes. Examples are provided of their use for analysing the operations of a mineral processing plant, for on-line monitoring and fault diagnosis of a continuous polymerization process and for the on-line monitoring of an industrial batch polymerization reactor.", "authors": ["J.F. MacGregor", "T. Kourti"], "related_topics": ["113644684", "199163554", "196985124"], "citation_count": "1532", "reference_count": "46", "references": ["2148694408", "2152820192", "2158863190", "1978994389", "2044036264", "2000858991", "1966089218", "1990283595", "2141734529", "2015436473"], "date": "1994"}, {"id": "2084684966", "title": "Some theorems about the sentential calculi of Lewis and Heyting", "abstract": "In this paper we shall prove theorems about some systems of sentential calculus, by making use of results we have established elsewhere regarding closure algebras and Brouwerian albegras. We shall be concerned mostly with the Lewis system and the Heyting system. Some of the results here are new (in particular, Theorems 2.4, 3.1, 3.9, 3.10, 4.5, and 4.6); others have been stated without proof in the literature (in particular, Theorems 2.1, 2.2, 4.4, 5.2, and 5.3).The proofs to be given here will be found to be mostly very simple; generally speaking, they amount to drawing conclusions from the theorems established in McKinsey and Tarski [10] and [11]. We have thought it might be worth while, however, to publish these rather elementary consequences of our previous work\u2014so as to make them readily available to those whose main interest lies in sentential calculus rather than in topology or algebra.", "authors": ["J. C. C. McKinsey", "Alfred Tarski"], "related_topics": ["69562738", "108710211", "18734090"], "citation_count": "482", "reference_count": "10", "references": ["2050527500", "2007096790", "2080823411", "957426456", "1982459732", "2121820351", "578063101", "2093157821", "3152800724", "1972649844"], "date": "1948"}, {"id": "2094228499", "title": "Unidraw: a framework for building domain-specific graphical editors", "abstract": "Unidraw is a framework for creating graphical editors in domains such as technical and artistic drawing, music composition, and circuit design. The Unidraw architecture simplifies the construction of these editors by proving programming abstractions that are common across domains. Unidraw defines four basic abstractions: components define operations on components, and external representations define the mapping between components and the file format generated by the editor. Unidraw also supports multiple views, graphical connectivity, and dataflow between components. This paper describes the Unidraw design, implementation issues, and three experimental domain specific editors we have developed with Unidraw: a drawing editor, a user interface builder, and a schematic capture system. Our results indicate a substantial reduction in implementation time and effort compared with existing tools.", "authors": ["John M. Vlissides", "Mark A. Linton"], "related_topics": ["89505385", "138413398", "16963264"], "citation_count": "220", "reference_count": "16", "references": ["2161825580", "1996974848", "2033337919", "67830776", "2105183873", "2339354324", "2112779958", "1966808888", "1974795494", "1497441482"], "date": "1990"}, {"id": "2121016876", "title": "Base-calling of automated sequencer traces using Phred. I. accuracy assessment", "abstract": "The availability of massive amounts of DNA sequence information has begun to revolutionize the practice of biology. As a result, current large-scale sequencing output, while impressive, is not adequate to keep pace with growing demand and, in particular, is far short of what will be required to obtain the 3-billion-base human genome sequence by the target date of 2005. To reach this goal, improved automation will be essential, and it is particularly important that human involvement in sequence data processing be significantly reduced or eliminated. Progress in this respect will require both improved accuracy of the data processing software and reliable accuracy measures to reduce the need for human involvement in error correction and make human review more efficient. Here, we describe one step toward that goal: a base-calling program for automated sequencer traces, phred, with improved accuracy. phred appears to be the first base-calling program to achieve a lower error rate than the ABI software, averaging 40%-50% fewer errors in the data sets examined independent of position in read, machine running conditions, or sequencing chemistry.", "authors": ["Brent Ewing", "LaDeana Hillier", "Michael C. Wendl", "Phil Green"], "related_topics": ["91239632", "93664055", "118573713"], "citation_count": "7131", "reference_count": "19", "references": ["2170120409", "2138270253", "2432517183", "2119923823", "2087064593", "2796837256", "2132380334", "1969757078", "1992194142", "2092784580"], "date": "1998"}, {"id": "2108384452", "title": "An information-maximization approach to blind separation and blind deconvolution", "abstract": "We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in \"blind\" signal processing.", "authors": ["Anthony J. Bell", "Terrence J. Sejnowski"], "related_topics": ["120317606", "30044814", "51432778"], "citation_count": "11140", "reference_count": "50", "references": ["2124776405", "2099741732", "2019502123", "1996355918", "2038085771", "2180838288", "1667165204", "2096789154", "2006544565", "2056211671"], "date": "1995"}, {"id": "1975791222", "title": "A novel navigation paradigm for XML repositories", "abstract": "The advances in storage and communications enable users to store massive amounts of data, and to share it seamlessly with their peers. With the advent of XML, we expect a significant portion of this data to be in XML format. We describe here the architecture and implementation of an XML repository that promotes a novel navigation paradigm for XML documents based on content and context. Support for these capabilities is achieved by bringing to bear the organizational power of information retrieval to the domain of semistructured documents. File systems remain the preferred storage infrastructure for the home and business desktop environments. We have built a system, XMLFS, based on the ideas stated above. XMLFS presents a storage abstraction that manifests itself to the client as a familiar file system. However, it breaks the tight coupling between the directory hierarchical structure and the file system. XMLFS creates automatically a directory organization of any XML document collection based on content and context. Each user can navigate through the file system according to her/his domain of interest at that point in time. Our result is a first step towards a solution to the discovery and navigation problems presented by the collective repositories of XML documents in peer-to-peer environments.", "authors": ["Alain Azagury", "Michael E. Factor", "Yoelle S. Maarek", "Benny Mandler"], "related_topics": ["55348073", "11508877", "173242113"], "citation_count": "17", "reference_count": "18", "references": ["2160484851", "2621280964", "33041674", "2084243240", "2889395214", "22830412", "2139921445", "2023695725", "2139533939", "2001832505"], "date": "2002"}, {"id": "2133184712", "title": "Exact indexing of dynamic time warping", "abstract": "The problem of indexing time series has attracted much research interest in the database community. Most algorithms used to index time series utilize the Euclidean distance or some variation thereof. However is has been forcefully shown that the Euclidean distance is a very brittle distance measure. Dynamic Time Warping (DTW) is a much more robust distance measure for time series, allowing similar shapes to match even if they are out of phase in the time axis. Because of this flexibility, DTW is widely used in science, medicine, industry and finance. Unfortunately however, DTW does not obey the triangular inequality, and thus has resisted attempts at exact indexing. Instead, many researchers have introduced approximate indexing techniques, or abandoned the idea of indexing and concentrated on speeding up sequential search. In this work we introduce a novel technique for the exact indexing of DTW. We prove that our method guarantees no false dismissals and we demonstrate its vast superiority over all competing approaches in the largest and most comprehensive set of time series indexing experiments ever undertaken.", "authors": ["Eamonn Keogh"], "related_topics": ["88516994", "120174047", "75165309"], "citation_count": "1772", "reference_count": "29", "references": ["1560013842", "2118269922", "2128061541", "2147880780", "2066796814", "2046144220", "2163336863", "116902681", "1587157435", "2167081989"], "date": "2002"}, {"id": "2073788020", "title": "The effectiveness of GIOSS for the text database discovery problem", "abstract": "The popularity of on-line document databases has led to a new problem: finding which text databases (out of many candidate choices) are the most relevant to a user. Identifying the relevant databases for a given query is the text database discovery problem. The first part of this paper presents a practical solution based on estimating the result size of a query and a database. The method is termed GlOSS\u2014Glossary of Servers Server. The second part of this paper evaluates the effectiveness of GlOSS based on a trace of real user queries. In addition, we analyze the storage cost of our approach.", "authors": ["Luis Gravano", "H\u00e9ctor Garc\u00eda-Molina", "Anthony Tomasic"], "related_topics": ["54239708", "12439846", "78161392"], "citation_count": "318", "reference_count": "15", "references": ["1956559956", "2117085788", "21247300", "2123922130", "2152645051", "2092433256", "2133966932", "1978597180", "2111170717", "2030350774"], "date": "1994"}, {"id": "2110247921", "title": "Does Rejection Hurt? An fMRI Study of Social Exclusion", "abstract": "A neuroimaging study examined the neural correlates of social exclusion and tested the hypothesis that the brain bases of social pain are similar to those of physical pain. Participants were scanned while playing a virtual ball-tossing game in which they were ultimately excluded. Paralleling results from physical pain studies, the anterior cingulate cortex (ACC) was more active during exclusion than during inclusion and correlated positively with self-reported distress. Right ventral prefrontal cortex (RVPFC) was active during exclusion and correlated negatively with self-reported distress. ACC changes mediated the RVPFC-distress correlation, suggesting that RVPFC regulates the distress of social exclusion by disrupting ACC activity.", "authors": ["Naomi I. Eisenberger", "Matthew D. Lieberman", "Kipling D. Williams"], "related_topics": ["544768975", "2778402161", "2781210436"], "citation_count": "4884", "reference_count": "17", "references": ["2125823313", "2044634376", "2085955270", "2094347820", "2087608601", "2037715202", "1967996189", "2243948722", "2144463055", "2104135024"], "date": "2003"}, {"id": "2292896937", "title": "A guide to recurrent neural networks and backpropagation", "abstract": "This paper provides guidance to some of the concepts surrounding recurrent neural networks. Contrary to feedforward networks, recurrent networks can be sensitive, and be adapted to past inputs. Backpropagation learning is described for feedforward networks, adapted to suit our (probabilistic) modeling needs, and extended to cover recurrent networks. The aim of this brief paper is to set the scene for applying and understanding recurrent neural networks.", "authors": ["Mikael Boden"], "related_topics": ["108583219", "47702885", "177973122"], "citation_count": "297", "reference_count": "20", "references": ["2110485445", "2107878631", "2339378878", "2016589492", "1979684610", "3036751298", "2151834591", "1959983357", "2121553911", "2468203291"], "date": "2000"}, {"id": "2080558111", "title": "Towards answering opinion questions: separating facts from opinions and identifying the polarity of opinion sentences", "abstract": "Opinion question answering is a challenging task for natural language processing. In this paper, we discuss a necessary component for an opinion question answering system: separating opinions from fact, at both the document and sentence level. We present a Bayesian classifier for discriminating between documents with a preponderance of opinions such as editorials from regular news stories, and describe three unsupervised, statistical techniques for the significantly harder task of detecting opinions at the sentence level. We also present a first model for classifying opinion sentences as positive or negative in terms of the main perspective being expressed in the opinion. Results from a large collection of news stories and a human evaluation of 400 sentences are reported, indicating that we achieve very high performance in document classification (upwards of 97% precision and recall), and respectable performance in detecting opinions and classifying them at the sentence level as positive, negative, or neutral (up to 91% accuracy).", "authors": ["Hong Yu", "Vasileios Hatzivassiloglou"], "related_topics": ["2777530160", "44291984", "2780479914"], "citation_count": "1538", "reference_count": "13", "references": ["2166706824", "3146306708", "1535015163", "2155328222", "2199803028", "2117400858", "2133341045", "1998442272", "1565863475", "2150098611"], "date": "2003"}, {"id": "1528929238", "title": "Health Risks and Developmental Transitions during Adolescence", "abstract": "1. Negotiating developmental transitions during adolescence and young adulthood: health risks and opportunities John Schulenberg, Jennifer L. Maggs, Klaus Hurrelmann Part I. Sociocultural, Physical and Cognitive Foundations of Adolescent Transitions: 2. Cultural, historical and subcultural contexts of adolescence: implications for health and development Lisa J. Crockett 3. Social change and adolescent well-being: healthy country, healthy teens Peter Noack and Barbel Kracke 4. Self-reported maturational timing and adaptation in adolescence Rainer K. Silbereisen and Barbel Kracke 5. Adolescents' decisions about risks: a cognitive perspective Ruth Beyth-Marom and Baruch Fischhoff Part II. Affiliation Transitions and Health: 6. The family as health risk and opportunity: a focus on divorce and working families Nancy L. Galambos and Marion F. Ehrenberg 7. Transformations in peer relationships at adolescence: implications for health-related behavior B. Bradford Brown, M. Margaret Dolcini and Amy Leventhal 8. Sexuality and developmental transitions during adolescence Jeanne Brooks-Gunn and Roberta Paikoff 9. Child bearing during adolescence: mental health risks and opportunities Cleopatra Howard Caldwell and Toni C. Antonucci 10. Marriage, divorce, and parenthood during the transition to young adulthood: impacts on drug use and abuse Jerald G. Bachman, Katherine N. Wadsworth, Patrick M. O'Malley, John Schulenberg and Lloyd D. Johnston Part III. Achievement Transitions and Health: 11. The association of school transitions in early adolescence with developmental trajectories through High School Jacquelynne S. Eccles, Sarah E. Lord, Robert W. Roeser, Bonnie L. Barber and Debra M. Hernandez Jozefowicz 12. Transitions into part-time work: health risks and opportunities Michael D. Finch, Jeylan T. Mortimer and Seongryeol Ryu 13. Alcohol and binge drinking as goal-directed action during the transition to post-secondary education Jennifer L. Maggs 14. Health risks and deviance in the transition from school to work Eduard Matt, Lydia Seus and Karl F. Schumann Part IV. Identity Transitions and Health: 15. Self definition and mental health during adolescence and young adulthood Jarik-Erik Nurmi 16. Ethnic and racial identity development and mental health Jean S. Phinney and Eric L. Kohatsu 17. Religion and adolescent health compromising behavior John M. Wallace Jr. and David R. Williams Part V. Intervention: Altering Transition-Health Risk Connections: 18. Promoting mental health during the transition into adolescence Anne C. Petersen, Nancy Leffert, Barbara Graham, Jan Alwin and Shuai Ding 19. Preventing health compromising behaviors among youth and promoting their positive development: a developmental-contextual perspective Richard M. Lerner, Charles W. Ostrum and Melissa A. Freel 20. Developmental transitions during adolescence: health promotion implications Jennifer L. Maggs, John Schulenberg and Klaus Hurrelmann.", "authors": ["John E. Schulenberg", "Jennifer Maggs", "Klaus Hurrelmann"], "related_topics": ["2778063736", "185618831", "134362201"], "citation_count": "607", "reference_count": "0", "references": ["2012186625", "1985645068", "2109046676", "2156426418", "2139433778", "2043872160", "2120793910", "2037171332", "2166538722", "2102643648"], "date": "1999"}, {"id": "2786672974", "title": "UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction", "abstract": "UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.", "authors": ["Leland McInnes", "John Healy"], "related_topics": ["151876577", "178207025", "70518039"], "citation_count": "2823", "reference_count": "43", "references": ["2153579005", "3120740533", "2187089797", "2001141328", "2097308346", "2156718197", "2750384547", "1875842236", "2902652978", "2245493112"], "date": "2018"}, {"id": "1492411220", "title": "The obligatory contour principle and phonological rules: a loss of identity", "abstract": "", "authors": ["Moira Yip"], "related_topics": ["2779511057", "2779447941", "151670969"], "citation_count": "326", "reference_count": "10", "references": ["1504955803", "2152134037", "1490528202", "1508460870", "1521566952", "8426857", "1978506025", "1686196694", "1486285723", "1528266487"], "date": "1987"}, {"id": "2139841919", "title": "Approximation algorithms for metric facility location and k-Median problems using the primal-dual schema and Lagrangian relaxation", "abstract": "We present approximation algorithms for the metric uncapacitated facility location problem and the metric k-median problem achieving guarantees of 3 and 6 respectively. The distinguishing feature of our algorithms is their low running time: O(m logm) and O(m logm(L + log (n))) respectively, where n and m are the total number of vertices and edges in the underlying complete bipartite graph on cities and facilities. The main algorithmic ideas are a new extension of the primal-dual schema and the use of Lagrangian relaxation to derive approximation algorithms.", "authors": ["Kamal Jain", "Vijay V. Vazirani"], "related_topics": ["17387949", "148764684", "50524431"], "citation_count": "1102", "reference_count": "40", "references": ["1968143987", "2085751730", "3148765228", "1854155592", "2065060195", "2114493937", "2001139415", "2101622070", "2608158342", "2003719999"], "date": "2001"}, {"id": "2140170995", "title": "Smoothing noisy data with spline functions", "abstract": "Smoothing splines are well known to provide nice curves which smooth discrete, noisy data. We obtain a practical, effective method for estimating the optimum amount of smoothing from the data. Derivatives can be estimated from the data by differentiating the resulting (nearly) optimally smoothed spline. We consider the modely i (t i )+? i ,i=1, 2, ...,n,t i?[0, 1], whereg?W 2 (m) ={f:f,f?, ...,f (m?1) abs. cont.,f (m)??2[0,1]}, and the {? i } are random errors withE? i =0,E? i ? j =?2? ij . The error variance ?2 may be unknown. As an estimate ofg we take the solutiong n, ? to the problem: Findf?W 2 (m) to minimize $$\\frac{1}{n}\\sum\\limits_{j = 1}^n {(f(t_j ) - y_j )^2 + \\lambda \\int\\limits_0^1 {(f^{(m)} (u))^2 du} }$$ . The functiong n, ? is a smoothing polynomial spline of degree 2m?1. The parameter ? controls the tradeoff between the \"roughness\" of the solution, as measured by $$\\int\\limits_0^1 {[f^{(m)} (u)]^2 du}$$ , and the infidelity to the data as measured by $$\\frac{1}{n}\\sum\\limits_{j = 1}^n {(f(t_j ) - y_j )^2 }$$ , and so governs the average square errorR(?; g)=R(?) defined by $$R(\\lambda ) = \\frac{1}{n}\\sum\\limits_{j = 1}^n {(g_{n,\\lambda } (t_j ) - g(t_j ))^2 }$$ . We provide an estimate $$\\hat \\lambda$$ , called the generalized cross-validation estimate, for the minimizer ofR(?). The estimate $$\\hat \\lambda$$ is the minimizer ofV(?) defined by $$V(\\lambda ) = \\frac{1}{n}\\parallel (I - A(\\lambda ))y\\parallel ^2 /\\left[ {\\frac{1}{n}{\\text{Trace(}}I - A(\\lambda ))} \\right]^2$$ , wherey=(y 1, ...,y n)t andA(?) is then\u00d7n matrix satisfying(g n, ? (t 1), ...,g n, ? (t n))t=A (?) y. We prove that there exist a sequence of minimizers $$\\tilde \\lambda = \\tilde \\lambda (n)$$ ofEV(?), such that as the (regular) mesh{t i} i=1 n becomes finer, $$\\mathop {\\lim }\\limits_{n \\to \\infty } ER(\\tilde \\lambda )/\\mathop {\\min }\\limits_\\lambda ER(\\lambda ) \\downarrow 1$$ . A Monte Carlo experiment with several smoothg's was tried withm=2,n=50 and several values of ?2, and typical values of $$R(\\hat \\lambda )/\\mathop {\\min }\\limits_\\lambda R(\\lambda )$$ were found to be in the range 1.01---1.4. The derivativeg? ofg can be estimated by $$g'_{n,\\hat \\lambda } (t)$$ . In the Monte Carlo examples tried, the minimizer of $$R_D (\\lambda ) = \\frac{1}{n}\\sum\\limits_{j = 1}^n {(g'_{n,\\lambda } (t_j ) - } g'(t_j ))$$ tended to be close to the minimizer ofR(?), so that $$\\hat \\lambda$$ was also a good value of the smoothing parameter for estimating the derivative.", "authors": ["Grace Wahba"], "related_topics": ["2778113609", "114614502", "55259147"], "citation_count": "4569", "reference_count": "25", "references": ["2801179766", "2078841894", "2121203842", "1979519992", "2897129259", "2094438648", "2137645797", "1976601779", "2015904350", "2002355073"], "date": "1975"}, {"id": "2901284226", "title": "Quasi-random graphs", "abstract": "We introduce a large equivalence class of graph properties, all of which are shared by so-called random graphs. Unlike random graphs, however, it is often relatively easy to verify that a particular family of graphs possesses some property in this class.", "authors": ["Fan R. K. Chung", "Ronald L. Graham", "Richard M. Wilson"], "related_topics": ["47458327", "2777044963", "64339825"], "citation_count": "539", "reference_count": "17", "references": ["2905110430", "1998400388", "1552744309", "2088164510", "2064197162", "184868352", "23397926", "2079810243", "1984080039", "164275096"], "date": "1989"}, {"id": "2123263696", "title": "An agenda for purely confirmatory research", "abstract": "The veracity of substantive research claims hinges on the way experimental data are collected and analyzed. In this article, we discuss an uncomfortable fact that threatens the core of psychology\u2019s academic enterprise: almost without exception, psychologists do not commit themselves to a method of data analysis before they see the actual data. It then becomes tempting to fine tune the analysis to the data in order to obtain a desired result\u2014a procedure that invalidates the interpretation of the common statistical tests. The extent of the fine tuning varies widely across experiments and experimenters but is almost impossible for reviewers and readers to gauge. To remedy the situation, we propose that researchers preregister their studies and indicate in advance the analyses they intend to conduct. Only these analyses deserve the label \u201cconfirmatory,\u201d and only for these analyses are the common statistical tests valid. Other analyses can be carried out but these should be labeled \u201cexploratory.\u201d We illustrate our proposal with a confirmatory replication attempt of a study on extrasensory perception.", "authors": ["Eric-Jan Wagenmakers", "Ruud Wetzels", "Denny Borsboom", "Han L. J. van der Maas", "Rogier A. Kievit"], "related_topics": ["78875605", "153180980", "55037315"], "citation_count": "794", "reference_count": "40", "references": ["2243629635", "2161498332", "1987777080", "2067833766", "2100267603", "1978662219", "3124333825", "2015866962", "2118699776", "2160453617"], "date": "2012"}, {"id": "1962622193", "title": "Universal Stanford dependencies: A cross-linguistic typology", "abstract": "Revisiting the now de facto standard Stanford dependency representation, we propose an improved taxonomy to capture grammatical relations across languages, including morphologically rich ones. We suggest a two-layered taxonomy: a set of broadly attested universal grammatical relations, to which language-specific relations can be added. We emphasize the lexicalist stance of the Stanford Dependencies, which leads to a particular, partially new treatment of compounding, prepositions, and morphology. We show how existing dependency schemes for several languages map onto the universal taxonomy proposed here and close with consideration of practical implications of dependency representation choices for NLP applications, in particular parsing.", "authors": ["Marie-Catherine de Marneffe", "Timothy Dozat", "Natalia Silveira", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D. Manning"], "related_topics": ["94413719", "186644900", "524601802"], "citation_count": "513", "reference_count": "29", "references": ["2097606805", "1508977358", "2158847908", "2092654472", "2139621418", "2143995218", "1568793342", "2094061585", "1586060904", "331019419"], "date": "2014"}, {"id": "2072405256", "title": "A Survey of Preprocessing and Feature Extraction Techniques for Radiographic Images", "abstract": "Feature extraction is one of the more difficult steps in image pattern recognition. Some sources of difficulty are the presence of irrelevant information and the relativity of a feature set to a particular application. Several preprocessing techniques for enhancing selected features and removing irrelevant data are described and compared. The techniques include gray level distribution linearization, digital spatial filtering, contrast enhancement, and image subtraction. Also, several feature extraction techniques are illustrated. The techniques are divided into spatial and Fourier domain operations. The spatial domain operations of directional signatures and contour tracing are first described. Then, the Fourier domain techniques of frequency signatures and template matching are illustrated. Finally, a practical image pattern recognition problem is solved using some of the described techniques.", "authors": ["E.L. Hall", "R.P. Kruger", "S.J. Dwyer", "D.L. Hall", "R.W. Mclaren", "G.S. Lodwick"], "related_topics": ["52622490", "7374053", "40608802"], "citation_count": "273", "reference_count": "11", "references": ["2133246412", "2099168648", "2067958620", "2102052485", "2150642297", "2116966585", "1844855551", "2077375822", "2412361578", "2417617546"], "date": "1971"}, {"id": "41801118", "title": "Remote procedure call", "abstract": "Remote procedure call is the synchronous language-level transfer of control between programs in disjoint address spaces whose primary communication medium is a narrow channel. The thesis of this dissertation is that remote procedure call (RPC) is a satisfactory and efficient programming language primitive for constructing distributed systems. A survey of existing remote procedure mechanisms shows that past RPC efforts are weak in addressing the five crucial issues: uniform call semantics, binding and configuration, strong typechecking, parameter functionality, and concurrency and exception control. The body of the dissertation elaborates these issues and defines a set of corresponding essential properties for RPC mechanisms. These properties must be satisfied by any RPC mechanism that is fully and uniformly integrated into a programming language for a homogeneous distributed system. Uniform integration is necessary to meet the dissertation's fundamental goal of syntactic and semantic transparency for local and remote procedures. Transparency is important so that programmers need not concern themselves with the physical distribution of their programs. In addition to these essential language properties, a number of pleasant properties are introduced that ease the work of distributed programming. These pleasant properties are good performance, sound remote interface design, atomic transactions, respect for autonomy, type translation, and remote debugging. With the essential and pleasant properties broadly explored, the detailed design of an RPC mechanism that satisfies all of the essential properties and the performance property is presented. Two design approaches are used: The first assumes full programming language support and involves changes to the language's compiler and binder. The second involves no language changes, but uses a separate translator--a source-to-source RPC compiler--to implement the same functionality. Design decisions crucial to the efficiency of the mechanism are made using a set of RPC performance lessons. These lessons are based on the empirical performance evaluation of a sequence of five working RPC mechanisms, each one faster than its predecessor. Some expected results about the costs of parameter copying, process switching, and runtime type manipulation are confirmed; a surprising result about the price of protocol layering is presented as well. These performance lessons, applied in concert, reduce the roundtrip time for a remote procedure call by a remarkable factor of 35. For moderate speed personal computers communicating over an Ethernet, for example, a simple remote call takes 800 microseconds; on a higher speed personal computer, the same remote call takes 149 microseconds. In both cases the remote call takes about 20 times longer than the same local call. This represents a substantial performance improvement over other operational RPC mechanisms.", "authors": ["Bruce Jay Nelson"], "related_topics": ["172086080", "134122824", "91062100"], "citation_count": "601", "reference_count": "0", "references": ["2155066383", "87357050", "2039179345", "1977560620", "1971069895", "2001438822", "2078775767", "2137622193", "2599536137", "1993503482"], "date": "1980"}, {"id": "2165497495", "title": "Reliable feature matching across widely separated views", "abstract": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches.", "authors": ["A. Baumberg"], "related_topics": ["52622490", "92757383", "153077589"], "citation_count": "915", "reference_count": "20", "references": ["2124386111", "2130103520", "2124087378", "2111308925", "2085261163", "2112328181", "3022352042", "1970269179", "2143753158", "1549739843"], "date": "2000"}, {"id": "2002779084", "title": "Structural Holes and Good Ideas.", "abstract": "This article outlines the mechanism by which brokerage provides social capital. Opinion and behavior are more homogeneous within than between groups, so people connected across groups are more familiar with alternative ways of thinking and behaving. Brokerage across the structural holes between groups provides a vision of options otherwise unseen, which is the mechanism by which brokerage becomes social capital. I review evidence consistent with the hypothesis, then look at the networks around managers in a large American electronics company. The organization is rife with structural holes, and brokerage has its expected correlates. Compensation, positive performance evaluations, promotions, and good ideas are disproportionately in the hands of people whose networks span structural holes. The between-group brokers are more likely to express ideas, less likely to have ideas dismissed, and more likely to have ideas evaluated as valuable. I close with implications for creativity and structural change.", "authors": ["Ronald S. Burt"], "related_topics": ["2778727218", "68062652", "11012388"], "citation_count": "6435", "reference_count": "94", "references": ["2112090702", "2108795964", "2108183214", "2115059495", "2153943092", "2007180942", "2164284962", "2179492332", "1973459906", "2109469951"], "date": "2004"}, {"id": "238668910", "title": "Use of a cDNA microarray to analyse gene expression patterns in human cancer.", "abstract": "The development and progression of cancer and the experimental reversal of tumorigenicity are accompanied by complex changes in patterns of gene expression. Microarrays of cDNA provide a powerful tool for studying these complex phenomena. The tumorigenic properties of a human melanoma cell line, UACC-903, can be suppressed by introduction of a normal human chromosome 6, resulting in a reduction of growth rate, restoration of contact inhibition, and suppression of both soft agar clonogenicity and tumorigenicity in nude mice. We used a high density microarray of 1,161 DNA elements to search for differences in gene expression associated with tumour suppression in this system. Fluorescent probes for hybridization were derived from two sources of cellular mRNA [UACC-903 and UACC-903(+6)] which were labelled with different fluors to provide a direct and internally controlled comparison of the mRNA levels corresponding to each arrayed gene. The fluorescence signals representing hybridization to each arrayed gene were analysed to determine the relative abundance in the two samples of mRNAs corresponding to each gene. Previously unrecognized alterations in the expression of specific genes provide leads for further investigation of the genetic basis of the tumorigenic phenotype of these cells.", "authors": ["Joseph L. DeRisi", "Lolita Penland", "Patrick O. Brown", "M. L. Bittner", "P. S. Meltzer", "M. Ray", "Yidong Chen", "Y. A. Su", "J. M. Trent"], "related_topics": ["95371953", "150194340", "104317684"], "citation_count": "3347", "reference_count": "22", "references": ["1970156673", "2015519364", "2030958510", "2161893150", "2088536629", "2068719237", "1968164578", "1998947396", "2074242397", "2120483508"], "date": "1995"}, {"id": "2152808281", "title": "Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model", "abstract": "Previous work on statistical language modeling has shown that it is possible to train a feedforward neural network to approximate probabilities over sequences of words, resulting in significant error reduction when compared to standard baseline models based on n-grams. However, training the neural network model with the maximum-likelihood criterion requires computations proportional to the number of words in the vocabulary. In this paper, we introduce adaptive importance sampling as a way to accelerate training of the model. The idea is to use an adaptive n-gram model to track the conditional distributions produced by the neural network. We show that a very significant speedup can be obtained on standard problems.", "authors": ["Y. Bengio", "J.-S. Senecal"], "related_topics": ["175202392", "134342201", "47702885"], "citation_count": "235", "reference_count": "32", "references": ["2116064496", "2132339004", "1574901103", "1985093013", "2096175520", "2069739265", "1802356529", "2134237567", "1934041838", "2140679639"], "date": "2008"}, {"id": "2142094977", "title": "Edit wear and read wear", "abstract": "We describe two applications that illustrate the idea of computational wear in the domain of document processing. By graphically depicting the history of author and reader interactions with documents, these applications offer otherwise unavailable information to guide work. We discuss how their design accords with a theory of professional work and an informational physics perspective on interface design.", "authors": ["William C. Hill", "James D. Hollan", "Dave Wroblewski", "Tim McCandless"], "related_topics": ["149229913", "125367622", "67905146"], "citation_count": "575", "reference_count": "11", "references": ["2568476927", "2106470680", "2022335546", "2173023656", "2165604170", "1584117460", "2163360974", "2139791793", "2066299564", "160219894"], "date": "1992"}, {"id": "2147771055", "title": "Human performance using computer input devices in the preferred and non-preferred hands", "abstract": "Subjects' performance was compared in pointing and dragging tasks using the preferred and non-preferred hands. Tasks were tested using three different input devices: a mouse, a trackball, and a tablet-with-stylus. The trackball had the least degradation across hands in performing the tasks, however it remained inferior to both the mouse and stylus. For small distances and small targets, the preferred hand was superior. However, for larger targets and larger distances, both hands performed about the same. The experiment shows that the non-preferred hand is more than a poor approximation of the preferred hand. The hands are complementary, each having its own strength and weakness. One design implication is that the non-preferred hand is well suited for tasks that do not require precise action, such as scrolling.", "authors": ["Paul Kabbash", "I. Scott MacKenzie", "William Buxton"], "related_topics": ["159842133", "59046462", "164086593"], "citation_count": "171", "reference_count": "20", "references": ["2179427518", "2168443748", "2136022845", "2095956339", "2147160183", "2990320994", "1996884089", "2915048722", "84091793", "1502356487"], "date": "1993"}, {"id": "2115059495", "title": "Social Capital: Its Origins and Applications in Modern Sociology", "abstract": "This paper reviews the origins and definitions of social capital in the writings of Bourdieu, Loury, and Coleman, among other authors. It distinguishes four sources of social capital and examines their dynamics. Applications of the concept in the sociological literature emphasize its role in social control, in family support, and in benefits mediated by extrafamilial networks. I provide examples of each of these positive functions. Negative consequences of the same processes also deserve attention for a balanced picture of the forces at play. I review four such consequences and illustrate them with relevant examples. Recent writings on social capital have extended the concept from an individual asset to a feature of communities and even nations. The final sections describe this conceptual stretch and examine its limitations. I argue that, as shorthand for the positive consequences of sociability, social capital has a definite place in sociological theory. However, excessive extensions of the concept may j...", "authors": ["Alejandro Portes"], "related_topics": ["186314094", "63545947", "68062652"], "citation_count": "19618", "reference_count": "60", "references": ["2108991971", "2157619495", "2085491458", "2153943092", "1533558196", "2004877893", "1490948437", "1601897243", "2479621352", "2119538357"], "date": "1998"}, {"id": "2004217976", "title": "Characterization of signals from multiscale edges", "abstract": "A multiscale Canny edge detection is equivalent to finding the local maxima of a wavelet transform. The authors study the properties of multiscale edges through the wavelet theory. For pattern recognition, one often needs to discriminate different types of edges. They show that the evolution of wavelet local maxima across scales characterize the local shape of irregular structures. Numerical descriptors of edge types are derived. The completeness of a multiscale edge representation is also studied. The authors describe an algorithm that reconstructs a close approximation of 1-D and 2-D signals from their multiscale edges. For images, the reconstruction errors are below visual sensitivity. As an application, a compact image coding algorithm that selects important edges and compresses the image data by factors over 30 has been implemented. >", "authors": ["S. Mallat", "S. Zhong"], "related_topics": ["14705441", "193536780", "196216189"], "citation_count": "5801", "reference_count": "26", "references": ["2062024414", "2145023731", "2152328854", "1970352604", "2109863423", "2003370853", "2166982406", "2096684483", "2022735534", "3132971798"], "date": "2011"}, {"id": "2103632679", "title": "Survey of maneuvering target tracking. Part V. Multiple-model methods", "abstract": "This is the fifth part of a series of papers that provide a comprehensive survey of techniques for tracking maneuvering targets without addressing the so-called measurement-origin uncertainty. Part I and Part II deal with target motion models. Part III covers measurement models and associated techniques. Part IV is concerned with tracking techniques that are based on decisions regarding target maneuvers. This part surveys the multiple-model methods $the use of multiple models (and filters) simultaneously - which is the prevailing approach to maneuvering target tracking in recent years. The survey is presented in a structured way, centered around three generations of algorithms: autonomous, cooperating, and variable structure. It emphasizes the underpinning of each algorithm and covers various issues in algorithm design, application, and performance.", "authors": ["X. Rong Li", "V.P. Jilkov"], "related_topics": ["106516650", "124101348", "41904074"], "citation_count": "1230", "reference_count": "348", "references": ["1639032689", "1497256448", "2125838338", "2798766386", "2049633694", "1634005169", "1513008779", "2942228371", "1568122762", "2117853077"], "date": "2005"}, {"id": "2561377267", "title": "A multiple-baseline stereo", "abstract": "A stereo matching method that uses multiple stereo pairs with various baselines generated by a lateral displacement of a camera to obtain precise distance estimates without suffering from ambiguity is presented. Matching is performed simply by computing the sum of squared-difference (SSD) values. The SSD functions for individual stereo pairs are represented with respect to the inverse distance and are then added to produce the sum of SSDs. This resulting function is called the SSSD-in-inverse-distance. It is shown that the SSSD-in-inverse-distance function exhibits a unique and clear minimum at the correct matching position, even when the underlying intensity patterns of the scene include ambiguities or repetitive patterns. The authors first define a stereo algorithm based on the SSSD-in-inverse-distance and present a mathematical analysis to show how the algorithm can remove ambiguity and increase precision. Experimental results with real stereo images are presented to demonstrate the effectiveness of the algorithm. >", "authors": ["M. Okutomi", "T. Kanade"], "related_topics": ["31451488", "19453392", "9417928"], "citation_count": "1622", "reference_count": "15", "references": ["1995756857", "2102071159", "2168564612", "2064586097", "2069035105", "1604766291", "1533832053", "1992331046", "2460923303", "2033536284"], "date": "1993"}, {"id": "2047028564", "title": "Ridge regression: biased estimation for nonorthogonal problems", "abstract": "In multiple regression it is shown that parameter estimates based on minimum residual sum of squares have a high probability of being unsatisfactory, if not incorrect, if the prediction vectors are not orthogonal. Proposed is an estimation procedure based on adding small positive quantities to the diagonal of X\u2032X. Introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality. It is then shown how to augment X\u2032X to obtain biased estimates with smaller mean square error.", "authors": ["Arthur E. Hoerl", "Robert W. Kennard"], "related_topics": ["49847556", "49392186", "189285262"], "citation_count": "9516", "reference_count": "18", "references": ["1584444527", "2021142183", "2795495912", "2014725748", "2092369573", "184430818", "2042442229", "2126163471", "1981525111", "3156302520"], "date": "2000"}, {"id": "2529660825", "title": "A context for user interface management", "abstract": "The design of the user interface management system (UIMS) is discussed within the context of the problems that it is intended to solve. The aim is not to review the various forms and strategies that have been proposed and used for UIMS development but rather to clarify the environment of a UIMS. The issues, which relate the services of a UIMS to the applications that it is intended to support, range along a continuum from the keystroke/transaction level, or micro level, to the macro level of integration across an entire application environment. Three examples are presented to illustrate the range of this continuum and the issues that arise at each level.", "authors": ["Dan R. Olsen", "William Buxton", "Roger Ehrich", "David J. Kasik", "James R. Rhyne", "John Sibert"], "related_topics": ["149229913", "89505385", "130858515"], "citation_count": "73", "reference_count": "0", "references": ["2013227389", "1992138757", "186391655", "1543914446", "2933363829", "1526543055", "89982408", "1991916171", "2062669432", "116034705"], "date": "1990"}, {"id": "2019413183", "title": "An Introduction to Functional Grammar", "abstract": "Part 1 The clause: constituency towards a functional grammar clause as message clause as exchange clause as representation. Part 2 Above, below and beyond the clause: below the clause - groups and phrases above the clause - the clause complex additional - group and phrase complexes beside the clause - intonation and rhythm around the clause - cohesion and discourse beyond the clause - metaphorical modes of expression.", "authors": ["Michael Halliday"], "related_topics": ["134510687", "191070533", "2776224158"], "citation_count": "41192", "reference_count": "0", "references": ["2084046180", "1528113760", "2014902591", "2126631960", "2915177913", "1735617816", "191344148", "2133518763", "1747959040", "2604799547"], "date": "1984"}, {"id": "1979519992", "title": "A completely automatic french curve: fitting spline functions by cross validation", "abstract": "The cross validation mean square error technique is used to determine the correct degree of smoothing, in fitting smoothing solines to discrete, noisy observations from some unknown smooth function. Monte Cario results snow amazing success in estimating the true smooth function as well as its derivative.", "authors": ["G. Wahba", "S. Wold"], "related_topics": ["107457265", "3770464", "184389593"], "citation_count": "611", "reference_count": "13", "references": ["2121203842", "1976601779", "2015904350", "1995544102", "2088946168", "2088429582", "2139865434", "2020073125", "2076333420", "2017278777"], "date": "1974"}, {"id": "2060200544", "title": "Lifetime Prevalence of Specific Psychiatric Disorders in Three Sites", "abstract": "\u2022 Lifetime rates are presented for 15 DSM-III psychiatric diagnoses evaluated in three large household samples on the basis of lay interviewers' use of the Diagnostic Interview Schedule. The most common diagnoses were alcohol abuse and dependence, phobia, major depressive episode, and drug abuse and dependence. Disorders that most clearly predominated in men were antisocial personality and alcohol abuse and dependence. Disorders that most clearly predominated in women were depressive episodes and phobias. The age group with highest rates for most disorders was found to be young adults (aged 25 to 44 years). Correlates with race, education, and urbanization are presented.", "authors": ["Lee N. Robins", "John E. Helzer", "Myrna M. Weissman", "Helen Orvaschel", "Ernest Gruenberg", "Jack D. Burke", "Darrel A. Regier"], "related_topics": ["40010229", "2780931562", "2781210005"], "citation_count": "3739", "reference_count": "18", "references": ["2050768782", "2119089847", "2118532778", "2063473805", "2021061525", "1966236911", "2090378580", "2002140368", "2128622916", "2100091617"], "date": "1984"}, {"id": "2141559645", "title": "Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching", "abstract": "To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus two-fold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning. This paper compares eight reinforcement learning frameworks: adaptive heuristic critic (AHC) learning due to Sutton, Q-learning due to Watkins, and three extensions to both basic methods for speeding up learning. The three extensions are experience replay, learning action models for planning, and teaching. The frameworks were investigated using connectionism as an approach to generalization. To evaluate the performance of different frameworks, a dynamic environment was used as a testbed. The environment is moderately complex and nondeterministic. This paper describes these frameworks and algorithms in detail and presents empirical evaluation of the frameworks.", "authors": ["Long-Ji Lin"], "related_topics": ["199190896", "97541855", "188888258"], "citation_count": "1791", "reference_count": "31", "references": ["2154642048", "1652505363", "2100677568", "2016589492", "3011120880", "1491843047", "1569296262", "2009207944", "1931792391", "2167224731"], "date": "1992"}, {"id": "3102641634", "title": "Community detection in graphs", "abstract": "The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks.", "authors": ["Santo Fortunato"], "related_topics": ["128243737", "2779982251", "73555534"], "citation_count": "10145", "reference_count": "432", "references": ["1995945562", "2112090702", "2008620264", "1497256448", "2148606196", "2124637492", "2009435671", "3013264884", "1480376833", "2103017472"], "date": "2010"}, {"id": "2132271720", "title": "Dual learning processes in interactive skill acquisition.", "abstract": "Acquisition of interactive skills involves the use of internal and external cues. Experiment 1 showed that when actions were interdependent, learning was effective with and without external cues in the single-task condition but was effective only with the presence of external cues in the dual-task condition. In the dual-task condition, actions closer to the feedback were learned faster than actions farther away but this difference was reversed in the single-task condition. Experiment 2 tested how knowledge acquired in single and dual-task conditions would transfer to a new reward structure. Results confirmed the two forms of learning mediated by the secondary task: A declarative memory encoding process that simultaneously assigned credits to actions and a reinforcement-learning process that slowly propagated credits backward from the feedback. The results showed that both forms of learning were engaged during training, but only at the response selection stage, one form of knowledge may dominate over the other depending on the availability of attentional resources.", "authors": ["Wai Tat Fu", "John R. Anderson"], "related_topics": ["97541855", "132758656", "169900460"], "citation_count": "20", "reference_count": "60", "references": ["2121863487", "2136518234", "2117726420", "1528027857", "1984214648", "2130736456", "2167362547", "1991691398", "1990100773", "2911335841"], "date": "2008"}, {"id": "2163738067", "title": "Explaining the Gibbs Sampler", "abstract": "Abstract Computer-intensive algorithms, such as the Gibbs sampler, have become increasingly popular statistical tools, both in applied and theoretical work. The properties of such algorithms, however, may sometimes not be obvious. Here we give a simple explanation of how and why the Gibbs sampler works. We analytically establish its properties in a simple case and provide insight for more complicated cases. There are also a number of examples.", "authors": ["George Casella", "Edward I. George"], "related_topics": ["158424031", "2780586882", "121864883"], "citation_count": "3786", "reference_count": "30", "references": ["1997063559", "2049633694", "2083875149", "2124181495", "2108306139", "2007069447", "2152828142", "2615953416", "2152977846", "2204383650"], "date": "1992"}, {"id": "2063077274", "title": "The benefits of playing video games", "abstract": "Video games are a ubiquitous part of almost all children's and adolescents' lives, with 97% playing for at least one hour per day in the United States. The vast majority of research by psychologists on the effects of \"gaming\" has been on its negative impact: the potential harm related to violence, addiction, and depression. We recognize the value of that research; however, we argue that a more balanced perspective is needed, one that considers not only the possible negative effects but also the benefits of playing these games. Considering these potential benefits is important, in part, because the nature of these games has changed dramatically in the last decade, becoming increasingly complex, diverse, realistic, and social in nature. A small but significant body of research has begun to emerge, mostly in the last five years, documenting these benefits. In this article, we summarize the research on the positive effects of playing video games, focusing on four main domains: cognitive, motivational, emotional, and social. By integrating insights from developmental, positive, and social psychology, as well as media psychology, we propose some candidate mechanisms by which playing video games may foster real-world psychosocial benefits. Our aim is to provide strong enough evidence and a theoretical rationale to inspire new programs of research on the largely unexplored mental health benefits of gaming. Finally, we end with a call to intervention researchers and practitioners to test the positive uses of video games, and we suggest several promising directions for doing so.", "authors": ["Isabela Granic", "Adam Lobel", "Rutger C. M. E. Engels"], "related_topics": ["3017944768", "2776631333", "134362201"], "citation_count": "2144", "reference_count": "71", "references": ["1527994979", "2007445014", "2074503869", "2152264416", "2135943618", "2108682032", "2073338313", "2113101808", "1746951143", "2151922135"], "date": "2013"}, {"id": "2168231600", "title": "Large Scale Distributed Deep Networks", "abstract": "Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k categories. We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm.", "authors": ["Jeffrey Dean", "Greg Corrado", "Rajat Monga", "Kai Chen", "Matthieu Devin", "Mark Mao", "Marc'aurelio Ranzato", "Andrew Senior", "Paul Tucker", "Ke Yang", "Quoc V. Le", "Andrew Y. Ng"], "related_topics": ["108583219", "50644808", "59404180"], "citation_count": "3338", "reference_count": "33", "references": ["2108598243", "2173213060", "3118608800", "2146502635", "2117130368", "2147768505", "2132339004", "2141125852", "2184045248", "2118858186"], "date": "2012"}, {"id": "2010236170", "title": "Adverbial stance types in English", "abstract": "The present paper identifies various speech styles of English as marked by stance adver\u2010bials. By stance we mean the overt expression of an author's or speaker's attitudes, feelings, judgments, or commitment concerning the message. Adverbials are one of the primary lexical markers of stance in English, and we limit ourselves in this paper to adverbial marking of stance (the attitudinal and style disjuncts presented in Quirk, Green\u2010baum, Leech, & Svartvik, 1985). All occurrences of stance adverbials are identified in the LOB and London\u2010Lund corpora (410 texts of written and spoken British English), and each is analyzed in its sentential context to distinguish true markers of stance from adverbials that serve other functions (e.g., as manner adverbs). The adverbials marking stance are divided into six semantic categories, and the frequency of occurrence for each category in each text is computed. The six categories are labeled (1) honestly adverbials, (2) generally adverbials, (3) surely adverbials, (4) act...", "authors": ["Douglas Biber", "Edward Finegan"], "related_topics": ["2779357210", "2779855358", "2780049985"], "citation_count": "596", "reference_count": "17", "references": ["2796493717", "2062837929", "1984218255", "1659701168", "2152397575", "2029315691", "2094270587", "2017302109", "87722466", "2009475852"], "date": "1987"}, {"id": "2121739212", "title": "Foundations of the PARAFAC procedure: Models and conditions for an \"explanatory\" multi-model factor analysis", "abstract": "Simple structure and other common principles of factor rotation do not in general provide strong grounds for attributing explanatory significance to the factors which they select. In contrast, it is shown that an extension of Cattell's principle of rotation to Proportional Profiles (PP) offers a basis for determining explanatory factors for three-way or higher order multi-mode data. Conceptual models are developed for two basic patterns of multi-mode data variation, systemand object-variation, and PP analysis is found to apply in the system-variation case. Although PP was originally formulated as a principle of rotation to be used with classic two-way factor analysis, it is shown to embody a latent three-mode factor model, which is here made explicit and generalized frown two to N \"parallel occasions\". As originally formulated, PP rotation was restricted to orthogonal factors. The generalized PP model is demonstrated to give unique \"correct\" solutions with oblique, non-simple structure, and even non-linear factor structures. A series of tests, conducted with synthetic data of known factor composition, demonstrate the capabilities of linear and non-linear versions of the model, provide data on the minimal necessary conditions of uniqueness, and reveal the properties of the analysis procedures when these minimal conditions are not fulfilled. In addition, a mathematical proof is presented for the uniqueness of the solution given certain conditions on the data. Three-mode PP factor analysis is applied to a three-way set of real data consisting of the fundamental and first three formant frequencies of 11 persons saying 8 vowels. A unique solution is extracted, consisting of three factors which are highly meaningful and consistent with prior knowledge and theory concerning vowel quality. The relationships between the three-mode PP model and Tucker's multi-modal model, McDonald's non-linear model and Carroll and Chang's multi-dimensional scaling model are explored.", "authors": ["Richard A. Harshman"], "related_topics": ["42704193", "2777021972", "160920958"], "citation_count": "3708", "reference_count": "29", "references": ["2000215628", "1966382716", "2335487254", "1997320786", "1963826206", "181056519", "2042122853", "1995372796", "2067713126", "2166475545"], "date": "1969"}, {"id": "2933363829", "title": "Concepts and design space for a better understanding of multi-device user interfaces", "abstract": "This paper discusses the motivations behind and the characterising concepts of multi-device user interfaces by looking at the main design issues that have been addressed and the various solutions proposed. The discussion of relevant systems and frameworks highlights their main features, which are then used as the basis for comparative discussion. It compares different approaches and perspectives adopted in this area (e.g. responsive design, cross-device, distributed, migratory user interfaces). The features constitute a design space that can be used to facilitate analysis and comparison of tools and frameworks for multi-device user interfaces. Such aspects can be exploited by user interface designers and developers to analyse and compare various options when addressing existing and new applications. The analysis provided may inspire the design and development of new tools and frameworks as well.", "authors": ["Fabio Patern\u00f2"], "related_topics": ["89505385", "107457646", "41008148"], "citation_count": "1", "reference_count": "77", "references": ["1967661515", "2913293464", "2118366990", "1997556709", "2108715885", "2134816385", "2077274398", "1948677622", "2147149886", "2136224256"], "date": "2020"}, {"id": "1817561967", "title": "Bayesian Network Classifiers", "abstract": "Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state-of-the-art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we evaluate approaches for inducing classifiers from data, based on the theory of learning Bayesian networks. These networks are factored representations of probability distributions that generalize the naive Bayesian classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness that characterize naive Bayes. We experimentally tested these approaches, using problems from the University of California at Irvine repository, and compared them to C4.5, naive Bayes, and wrapper methods for feature selection.", "authors": ["Nir Friedman", "Dan Geiger", "Moises Goldszmidt"], "related_topics": ["2780312044", "52001869", "127043819"], "citation_count": "6134", "reference_count": "49", "references": ["2099111195", "2117812871", "2125055259", "2752885492", "2159080219", "2017337590", "1680392829", "3017143921", "2170112109", "2008906462"], "date": "1997"}, {"id": "2164741953", "title": "Image Analysis and Mathematical Morphology", "abstract": "", "authors": ["Jean Serra"], "related_topics": ["148171850", "74032544", "185568154"], "citation_count": "14279", "reference_count": "0", "references": ["2124260943", "2073252511", "2131697388", "2001298023", "2125848778", "2096579040", "2045227075", "1480546554", "2130761473", "2008043556"], "date": "1984"}, {"id": "2159398820", "title": "Toward a mechanistic psychology of dialogue", "abstract": "Traditional mechanistic accounts of language processing derive almost entirely from the study of monologue. Yet, the most natural and basic form of language use is dialogue. As a result, these accounts may only offer limited theories of the mechanisms that un- derlie language processing in general. We propose a mechanistic account of dialogue, the interactive alignment account, and use it to de- rive a number of predictions about basic language processes. The account assumes that, in dialogue, the linguistic representations em- ployed by the interlocutors become aligned at many levels, as a result of a largely automatic process. This process greatly simplifies production and comprehension in dialogue. After considering the evidence for the interactive alignment model, we concentrate on three aspects of processing that follow from it. It makes use of a simple interactive inference mechanism, enables the development of local di- alogue routines that greatly simplify language processing, and explains the origins of self-monitoring in production. We consider the need for a grammatical framework that is designed to deal with language in dialogue rather than monologue, and discuss a range of implica- tions of the account.", "authors": ["Martin J. Pickering", "Simon Garrod"], "related_topics": ["2776264592", "89267518", "2776481267"], "citation_count": "3108", "reference_count": "268", "references": ["1996672843", "1841352775", "2168488947", "2038248725", "2974832207", "2130142026", "1994851566", "3140196993", "2098676269", "1492502800"], "date": "2004"}, {"id": "2132513611", "title": "A theory and methodology of inductive learning", "abstract": "The presented theory views inductive learning as a heuristic search through a space of symbolic descriptions, generated by an application of various inference rules to the initial observational statements. The inference rules include generalization rules, which perform generalizing transformations on descriptions, and conventional truth-preserving deductive rules. The application of the inference rules to descriptions is constrained by problem background knowledge, and guided by criteria evaluating the \u201cquality\u201d of generated inductive assertions.", "authors": ["Ryszard S. Michalski"], "related_topics": ["6489637", "21563000", "28006648"], "citation_count": "2747", "reference_count": "67", "references": ["2121773050", "2009207944", "2110293626", "2020149918", "2067642555", "1488252886", "2023299380", "1651030661", "1530765221", "3027109149"], "date": "1993"}, {"id": "3098915991", "title": "A Survey on Device-to-Device Communication in Cellular Networks", "abstract": "Device-to-device (D2D) communications was initially proposed in cellular networks as a new paradigm for enhancing network performance. The emergence of new applications such as content distribution and location-aware advertisement introduced new user cases for D2D communications in cellular networks. The initial studies showed that D2D communications has advantages such as increased spectral efficiency and reduced communication delay. However, this communication mode introduces complications in terms of interference control overhead and protocols that are still open research problems. The feasibility of D2D communications in Long-Term Evolution Advanced is being studied by academia, industry, and standardization bodies. To date, there are more than 100 papers available on D2D communications in cellular networks, but there is no survey on this field. In this paper, we provide a taxonomy based on the D2D communicating spectrum and review the available literature extensively under the proposed taxonomy. Moreover, we provide new insights into the over-explored and under-explored areas that lead us to identify open research problems of D2D communications in cellular networks.", "authors": ["Arash Asadi", "Qing Wang", "Vincenzo Mancuso"], "related_topics": ["138660444", "153646914", "95491727"], "citation_count": "2079", "reference_count": "99", "references": ["2613176274", "2106248279", "2148963518", "2157457404", "2101840010", "2140656373", "2137152139", "2011039300", "2117537207", "2130347036"], "date": "2014"}, {"id": "2094982166", "title": "i-LAND: an interactive landscape for creativity and innovation", "abstract": "We describe the i-LAND environment which constitutes an example of our vision of the workspaces of the future, in this case supporting cooperative work of dynamic teams with changing needs. i-LAND requires and provides new forms of human-computer interaction and new forms of computer-supported cooperative work. Its design is based on an integration of information and architectural spaces, implications of new work practices and an empirical requirements study informing our design. i-LAND consists of several roomware components, i.e. computer-aug- mented objects integrating room elements with information technology. We present the current realization of i-LAND in terms of an interactive electronic wall, an interactive table, two computer-enhanced chairs, and two bridges for the Passage-mechanism. This is complemented by the description of the creativity support application and the technological infrastructure. The paper is accompanied by a video figure in the CHI99 video program.", "authors": ["Norbert A. Streitz", "J\u00f6rg Gei\u00dfler", "Torsten Holmer", "Shin'ichi Konomi", "Christian M\u00fcller-Tomfelde", "Wolfgang Reischl", "Petra Rexroth", "Peter Seitz", "Ralf Steinmetz"], "related_topics": ["198439703", "172195944", "153715457"], "citation_count": "913", "reference_count": "26", "references": ["1647826363", "2149891956", "2086928636", "1968211101", "2167686873", "2023331673", "2108715885", "1822534520", "2067779848", "101595803"], "date": "1999"}, {"id": "2087099129", "title": "The English Noun Phrase in its Sentential Aspect", "abstract": "Thesis (Ph. D.)--Massachusetts Institute of Technology, Dept. of Linguistics and Philosophy, 1987.", "authors": ["Steven Paul Abney"], "related_topics": ["153962237", "2779028527", "41895202"], "citation_count": "6790", "reference_count": "0", "references": ["2028189805", "2153568660", "640626888", "2097125878", "1595210733", "1582911418", "2124669395", "2114644712", "2120950064", "2142270908"], "date": "1986"}, {"id": "2140785063", "title": "On the Optimality of the Simple Bayesian Classifier under Zero-One Loss", "abstract": "The simple Bayesian classifier is known to be optimal when attributes are independent given the class, but the question of whether other sufficient conditions for its optimality exist has so far not been explored. Empirical results showing that it performs surprisingly well in many domains containing clear attribute dependences suggest that the answer to this question may be positive. This article shows that, although the Bayesian classifier\u2018s probability estimates are only optimal under quadratic loss if the independence assumption holds, the classifier itself can be optimal under zero-one loss (misclassification rate) even when this assumption is violated by a wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian classifier has a much greater range of applicability than previously thought. For example, in this article it is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption. Further, studies in artificial domains show that it will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain. This article\u2018s results also imply that detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier, and this is also verified empirically.", "authors": ["Pedro Domingos", "Michael Pazzani"], "related_topics": ["173102733", "149569020", "52620605"], "citation_count": "4007", "reference_count": "34", "references": ["2125055259", "1817561967", "2982720039", "3017143921", "1678889691", "1912123407", "2136000097", "1840338487", "1625504505", "1587718046"], "date": "1997"}, {"id": "1536929369", "title": "The Handbook of Brain Theory and Neural Networks", "abstract": "From the Publisher: Dramatically updating and extending the first edition, published in 1995, the second edition of The Handbook of Brain Theory and Neural Networks presents the enormous progress made in recent years in the many subfields related to the two great questions: How does the brain work? and, How can we build intelligent machines? Once again, the heart of the book is a set of almost 300 articles covering the whole spectrum of topics in brain theory and neural networks. The first two parts of the book, prepared by Michael Arbib, are designed to help readers orient themselves in this wealth of material. Part I provides general background on brain modeling and on both biological and artificial neural networks. Part II consists of \"Road Maps\" to help readers steer through articles in part III on specific topics of interest. The articles in part III are written so as to be accessible to readers of diverse backgrounds. They are cross-referenced and provide lists of pointers to Road Maps, background material, and related reading. The second edition greatly increases the coverage of models of fundamental neurobiology, cognitive neuroscience, and neural network approaches to language. It contains 287 articles, compared to the 266 in the first edition. Articles on topics from the first edition have been updated by the original authors or written anew by new authors, and there are 106 articles on new topics.", "authors": ["Michael A. Arbib"], "related_topics": ["554936623", "17289045", "188147891"], "citation_count": "5323", "reference_count": "0", "references": ["2076063813", "2117812871", "2070722739", "2164727176", "2964265128", "2130306094", "2165599843", "2105464873", "2963090522", "2096691069"], "date": "2006"}, {"id": "2003333103", "title": "Hidden Markov models for speech recognition", "abstract": "The use of hidden Markov models for speech recognition has become predominant in the last several years, as evidenced by the number of published papers and talks at major speech conferences. The reasons this method has become so popular are the inherent statistical (mathematically precise) framework; the ease and availability of training algorithms for cstimating the parameters of the models from finite training sets of speech data; the flexibility of the resulting recognition system in which one can easily change the size, type, or architecture of the models to suit particular words, sounds, and so forth; and the ease of implementation of the overall recognition system. In this expository article, we address the role of statistical methods in this powerful technology as applied to speech recognition and discuss a range of theoretical and practical issues that are as yet unsolved in terms of their importance and their effect on performance for different system implementations.", "authors": ["B. H. Juang", "L. R. Rabiner"], "related_topics": ["61328038", "133892786", "54953205"], "citation_count": "1311", "reference_count": "80", "references": ["2125838338", "1594031697", "2049633694", "3017143921", "2134383396", "2105594594", "2186435531", "1966812932", "2142384583", "2022554507"], "date": "1991"}, {"id": "2177745862", "title": "Compositing digital images", "abstract": "Most computer graphics pictures have been computed all at once, so that the rendering program takes care of all computations relating to the overlap of objects. There are several applications, however, where elements must be rendered separately, relying on compositing techniques for the anti-aliased accumulation of the full image. This paper presents the case for four-channel pictures, demonstrating that a matte component can be computed similarly to the color channels. The paper discusses guidelines for the generation of elements and the arithmetic for their arbitrary compositing.", "authors": ["T. Porter", "T. Duff"], "related_topics": ["129315195", "94406722", "205711294"], "citation_count": "2010", "reference_count": "0", "references": ["2156343066", "2118588333", "2112074221", "2139610316", "2101766358", "2115921274", "2101766509", "2123144575", "2125975474", "2116678088"], "date": "1988"}, {"id": "2026552514", "title": "Measures of concurrency in networks and the spread of infectious disease", "abstract": "An investigation is made into the impact of concurrent partnerships on epidemic spread. Starting from a definition of concurrency on the level of individuals, the authors define ways to quantify concurrency on the population level. An index of concurrency based on graph theoretical considerations is introduced, and the way in which it is related to the degree distribution of the contact graph is demonstrated. Then the spread of an infectious disease on a dynamic partnership network is investigated. The model is based on a stochastic process of pair formation and separation and a process of disease transmission within partnerships of susceptible and infected individuals. Using Monte Carlo simulation, the spread of the epidemic is compared for contact patterns ranging from serial monogamy to situations where individuals can have many partners simultaneously. It is found that for a fixed mean number of partners per individual the distribution of these partnerships over the population has a major influence on the speed of the epidemic in its initial phase and consequently in the number of individuals who are infected after a certain time period.", "authors": ["Mirjam Kretzschmar", "Martina Morris"], "related_topics": ["2910813776", "2908647359", "2909760446"], "citation_count": "491", "reference_count": "35", "references": ["1591736593", "1982306896", "1575154287", "2034743991", "1988236284", "2037513907", "1566493102", "2087735159", "1977382351", "2054889970"], "date": "1996"}, {"id": "2124313187", "title": "Bundle Adjustment - A Modern Synthesis", "abstract": "This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.", "authors": ["Bill Triggs", "Philip F. McLauchlan", "Richard I. Hartley", "Andrew W. Fitzgibbon"], "related_topics": ["179458375", "97970142", "45923927"], "citation_count": "5005", "reference_count": "83", "references": ["2033819227", "2117812871", "2798909945", "2077658674", "2070232376", "2010315317", "1480928214", "2954064014", "2004951603", "1649464328"], "date": "1999"}, {"id": "1968331067", "title": "Parst: A system of fortran routines for calculating molecular structure parameters from results of crystal structure analyses", "abstract": "Abstract Given a set of atomic positional and thermal parameters in a crystal defined by the unit cell constants and the space group symmetry operations, the ti The estimated standard deviations of the derived quantities are calculated from the e.s.d.'s of the atomic parameters and unit cell constants, neglecti", "authors": ["M. Nardelli"], "related_topics": ["115624301", "57401468", "2778241615"], "citation_count": "2272", "reference_count": "10", "references": ["1982414593", "2020541484", "1989160710", "2024398070", "2028547173", "2009828525", "2060530331", "1999411521", "2085121129", "2051217510"], "date": "1982"}, {"id": "1511160855", "title": "Diffusion Kernels on Graphs and Other Discrete Input Spaces", "abstract": "The application of kernel-based learning algorithms has, so far, largely been confined to realvalued data and a few special data types, such as strings. In this paper we propose a general method of constructing natural families of kernels over discrete structures, based on the matrix exponentiation idea. In particular, we focus on generating kernels on graphs, for which we propose a special class of exponential kernels called diffusion kernels, which are based on the heat equation and can be regarded as the discretization of the familiar Gaussian kernel of Euclidean space.", "authors": ["Risi Imre Kondor", "John D. Lafferty"], "related_topics": ["2780420008", "73000952", "183212220"], "citation_count": "1077", "reference_count": "19", "references": ["2124637492", "2139212933", "3023786531", "2149684865", "2097308346", "1578099820", "2009570821", "2122837498", "1576213419", "1979711143"], "date": "2002"}, {"id": "2080581973", "title": "Data mining with decision trees and decision rules", "abstract": "Abstract This paper describes the use of decision tree and rule induction in data-mining applications. Of methods for classification and regression that have been developed in the fields of pattern recognition, statistics, and machine learning, these are of particular interest for data mining since they utilize symbolic and interpretable representations. Symbolic solutions can provide a high degree of insight into the decision boundaries that exist in the data, and the logic underlying them. This aspect makes these predictive-mining techniques particularly attractive in commercial and industrial data-mining applications. We present here a synopsis of some major state-of-the-art tree and rule mining methodologies, as well as some recent advances.", "authors": ["Chidanand Apt\u00e9", "Sholom Weiss"], "related_topics": ["5481197", "10229987", "84839998"], "citation_count": "337", "reference_count": "24", "references": ["2912934387", "2117812871", "2125055259", "2112076978", "1670263352", "2142334564", "28412257", "2136000097", "1533169541", "1576962511"], "date": "1997"}, {"id": "1527994979", "title": "Reality Is Broken: Why Games Make Us Better and How They Can Change the World", "abstract": "Practical Advice for Gamers by Jane McGonigal Reality is Broken explains the science behind why games are good for us--why they make us happier, more creative, more resilient, and better able to lead others in world-changing efforts. But some games are better for us than others, and there is too much of a good thing. Here are a few secrets that arent in the book to help you (or the gamer in your life) get the most positive impact from playing games. This practical advice--5 key quidelines, plus 2 quick rules--is scientifically backed, and it can be summed up in a single sentence: Play games you enjoy no more than 21 hours a week; face-to-face with friends and family as often as you can; and in co-operative or creator modes whenever possible. 1. Dont play more than 21 hours a week. Studies show that games benefit us mentally and emotionally when we play up to 3 hours a day, or 21 hours a week. (In extremely stressful circumstances--such as serving in the military during war-time--research shows that gamers can benefit from as many as 28 hours a week.) But for virtually everyone else, whenever you play more than 21 hours a week, the benefits of gaming start to decline sharply. By the time youre spending 40 hours or more a week playing games, the psychological benefits of playing games have disappeared entirely--and are replaced with negative impacts on your physical health, relationships, and real-life goals. So always strive to keep your gaming in the sweet spot: 721 hours a week. 2. Playing with real-life friends and family is better than playing alone all the time, or with strangers. Gaming strengthens your social bonds and builds trust, two key factors in any positive relationship. And the more positive relationships you have in real life, the happier, healthier and more successful you are. You can get mental and emotional benefits from single-player games, or by playing with strangers online--but to really unlock the power of games, its important to play them with people you really know and like as often as possible. A handy rule-of-thumb: try to make half of your gaming social. If you play 10 hours a week, try to play face-to-face with real-life friends or family for at least 5 of those hours. (And if youre not a gamer yourself--but you have a family member who plays games all the time, it would do you both good to play together--even if you think you dont like games!) 3. Playing face-to-face with friends and family beats playing with them online. If youre in the same physical space, youll supercharge both the positive emotional impacts and the social bonding. Many of the benefits of games are derived from the way they make us feel--and all positive emotions are heightened by face-to-face interaction. Plus, research shows that social ties are strengthened much more when we play games in the same room than when we play games together online. Multi-player games are great for this. But single-player works too! You can get all the same benefits by taking turns at a single-player game, helping and cheering each other on. 4. Cooperative gameplay, overall, has more benefits than competitive gameplay. Studies show that cooperative gameplay lifts our mood longer, and strengthens our friendships more, than competing against each other. Cooperative gameplay also makes us more likely to help someone in real life, and better collaborators at work--boosting our real-world likeability and chances for success. Competition has its place, too, of course--we learn to trust others more when we compete against them. But if we spend all our time competing with others, we miss out on the special benefits of co-op play. So when youre gaming with others, be sure to check to see if there are co-op missions or a co-op mode available. An hour of co-op a week goes a long way. (Find great co-op games for every platform, and a family-friendly list too, at Co-Optimus, the best online resource for co-op gaming.) 5. Creative games have special positive impacts. Many games encourage or even require players to design and create as part of the gameplay process--for example: Spore, Little Big Planet, and Minecraft; the Halo level designer and the Guitar Hero song creator. These games have been shown to build up players sense of creative agency--and they make us more likely to create something outside of the game. If you want to really build up your own creative powers, creative games are a great place to start. Of course, you can always take the next creative step--and start making your own games. If youve never made a game, its easier than you think--and there are some great books to help you get started. 2 Other Important Rules: * You can get all of the benefits of a good game without realistic violence--you (or your kids) dont have to play games with guns or gore. If you feel strongly about violence, look to games in other genres--theres no shortage of amazing sports, music, racing, puzzle, role-playing, casual, strategy and adventure games. *Any game that makes you feel bad is no longer a good game for you to play. This should be obvious, but sometimes we get so caught up in our games that we forget theyre supposed to be fun. If you find yourself feeling really upset when you lose a game, or if youre fighting with friends or strangers when you play--youre too invested. Switch to a different game for a while, a game that has lower stakes for you personally. Or, especially if you play with strangers online, you might find yourself surrounded by other players who say things that make you uncomfortable--or who just generally act like jerks. Their behavior will actually make it harder for you to get the positive benefits of games--so dont waste your time playing with a community that gets you down. Meanwhile, if you start to wonder if youre spending too much time on a particular game maybe youre starting to feel just a tiny bit addicted--keep track of your gaming hours for one week. Make sure they add up to less than 21 hours! And you may want to limit yourself to even fewer for a little while if youre feeling too much gamer regret.", "authors": ["Jane McGonigal"], "related_topics": ["170828538", "42133412", "2780573756"], "citation_count": "5392", "reference_count": "0", "references": ["2023718959", "2049080106", "2063077274", "2081655353", "2479485957", "162947531", "2196633743", "2037621702", "2024262300", "2057148748"], "date": "2011"}, {"id": "2045186954", "title": "A review on machinery diagnostics and prognostics implementing condition-based maintenance", "abstract": "Condition-based maintenance (CBM) is a maintenance program that recommends maintenance decisions based on the information collected through condition monitoring. It consists of three main steps: data acquisition, data processing and maintenance decision-making. Diagnostics and prognostics are two important aspects of a CBM program. Research in the CBM area grows rapidly. Hundreds of papers in this area, including theory and practical applications, appear every year in academic journals, conference proceedings and technical reports. This paper attempts to summarise and review the recent research and developments in diagnostics and prognostics of mechanical systems implementing CBM with emphasis on models, algorithms and technologies for data processing and maintenance decision-making. Realising the increasing trend of using multiple sensors in condition monitoring, the authors also discuss different techniques for multiple sensor data fusion. The paper concludes with a brief discussion on current practices and possible future trends of CBM.", "authors": ["Andrew K.S. Jardine", "Daming Lin", "Dragan Banjevic"], "related_topics": ["2776907094", "129364497", "2775846686"], "citation_count": "4410", "reference_count": "243", "references": ["2125838338", "2963623381", "2165878107", "3146003712", "1592847587", "1575210522", "2029027380", "2031423206", "2139896607", "2140417752"], "date": "2006"}, {"id": "2121350579", "title": "DBXplorer: a system for keyword-based search over relational databases", "abstract": "Internet search engines have popularized the keyword-based search paradigm. While traditional database management systems offer powerful query languages, they do not allow keyword-based search. In this paper, we discuss DBXplorer, a system that enables keyword-based searches in relational databases. DBXplorer has been implemented using a commercial relational database and Web server and allows users to interact via a browser front-end. We outline the challenges and discuss the implementation of our system, including results of extensive experimental evaluation.", "authors": ["S. Agrawal", "S. Chaudhuri", "G. Das"], "related_topics": ["157154645", "5655090", "192028432"], "citation_count": "1129", "reference_count": "15", "references": ["2138621811", "1660390307", "1535992660", "1671881141", "2074863013", "2118382442", "2162621793", "2163652601", "2135494327", "1972978715"], "date": "2002"}, {"id": "2137701085", "title": "Fractals and Solid Modeling", "abstract": "Trying to combine fractal geometry and solid modeling seems to be a contradiction in itself, In this paper a new type of 3D objects is presented that accomplishes this combination in a specific way. Objects with a fractal macro structure and a 3D solid micro structure can be specified and rendered efficiently by using context free, attribute, geometric grammars. This new object type can be incorporated into the CSG-modeling technique (Constructive Solid Geometry) in two ways: a) using CSG for the specification of the micro structure of the new object type, b) using these fractal like objects as a new type of primitive in the CSG model. Ray tracing is used for generating high quality images of these geometrically complex objects.", "authors": ["M. Eduard Gr\u00f6ller"], "related_topics": ["188032258", "108882727", "69270405"], "citation_count": "4", "reference_count": "10", "references": ["2078206416", "2339378878", "2000690667", "2522324076", "1482997031", "2173925477", "2111963422", "2172446179", "2097896816", "1866655461"], "date": "1992"}, {"id": "2072725684", "title": "The implementation of the Cilk-5 multithreaded language", "abstract": "The fifth release of the multithreaded language Cilk uses a provably good \"work-stealing\" scheduling algorithm similar to the first system, but the language has been completely redesigned and the runtime system completely reengineered. The efficiency of the new implementation was aided by a clear strategy that arose from a theoretical analysis of the scheduling algorithm: concentrate on minimizing overheads that contribute to the work, even at the expense of overheads that contribute to the critical path. Although it may seem counterintuitive to move overheads onto the critical path, this \"work-first\" principle has led to a portable Cilk-5 implementation in which the typical cost of spawning a parallel thread is only between 2 and 6 times the cost of a C function call on a variety of contemporary machines. Many Cilk programs run on one processor with virtually no degradation compared to equivalent C programs. This paper describes how the work-first principle was exploited in the design of Cilk-5's compiler and its runtime system. In particular, we present Cilk-5's novel \"two-clone\" compilation strategy and its Dijkstra-like mutual-exclusion protocol for implementing the ready deque in the work-stealing scheduler.", "authors": ["Matteo Frigo", "Charles E. Leiserson", "Keith H. Randall"], "related_topics": ["2778076476", "2778522416", "2780870223"], "citation_count": "1734", "reference_count": "27", "references": ["2752885492", "2045271686", "2032401773", "2016559894", "2098147619", "1983587324", "2054739713", "2112590555", "1773176621", "2149663533"], "date": "1998"}, {"id": "2127385318", "title": "Fast Learning in Multi-Resolution Hierarchies", "abstract": "A class of fast, supervised learning algorithms is presented. They use local representations, hashing, and multiple scales of resolution to approximate functions which are piece-wise continuous. Inspired by Albus's CMAC model, the algorithms learn orders of magnitude more rapidly than typical implementations of back propagation, while often achieving comparable qualities of generalization. Furthermore, unlike most traditional function approximation methods, the algorithms are well suited for use in real time adaptive signal processing. Unlike simpler adaptive systems, such as linear predictive coding, the adaptive linear combiner, and the Kalman filter, the new algorithms are capable of efficiently capturing the structure of complicated non-linear systems. As an illustration, the algorithm is applied to the prediction of a chaotic timeseries.", "authors": ["John Moody"], "related_topics": ["102248274", "91873725", "157286648"], "citation_count": "193", "reference_count": "18", "references": ["1594031697", "2171277043", "2103504761", "3036751298", "2066366061", "2034099719", "2052207834", "2153709524", "2094631910", "1993740947"], "date": "1987"}, {"id": "1770825568", "title": "Introduction to statistical pattern recognition (2nd ed.)", "abstract": "", "authors": ["Keinosuke Fukunaga"], "related_topics": ["41008148", "178980831", "154945302"], "citation_count": "7085", "reference_count": "0", "references": ["2067191022", "1992419399", "1989702938", "2132103241", "2132549764", "2121601095", "2161160262", "2108995755", "2136040699", "2136251662"], "date": "1990"}, {"id": "2074064356", "title": "Active control of slow light on a chip with photonic crystal waveguides", "abstract": "Photonic crystals could become the silicon chips of optoelectronics, engineered to control the properties of photons in much the same way that the atomic lattice of a semiconductor controls electrons. Yurii Vlasov and co-workers at IBM's T. J. Watson Research Center have applied photonic crystal technology to \u2018slow light\u2019. In this still-new field, pulses of light are drastically slowed and even brought to a halt in various atomic and solid-state systems where material absorption is countered by optical pumping. This has potential in applications ranging from all-optical storage to optical switching. Vlasev et al. demonstrate an over 300-fold reduction of the group velocity of a light pulse on a silicon chip via an ultra-compact photonic integrated circuit utilizing low-loss silicon photonic crystal waveguides. The cover shows a scanning electron micrograph of the experimental setup. It is known that light can be slowed down in dispersive materials near resonances1. Dramatic reduction of the light group velocity\u2014and even bringing light pulses to a complete halt\u2014has been demonstrated recently in various atomic2,3,4,5 and solid state systems6,7,8, where the material absorption is cancelled via quantum optical coherent effects3,4,5,7. Exploitation of slow light phenomena has potential for applications ranging from all-optical storage to all-optical switching9,10. Existing schemes, however, are restricted to the narrow frequency range of the material resonance, which limits the operation frequency, maximum data rate and storage capacity10. Moreover, the implementation of external lasers, low pressures and/or low temperatures prevents miniaturization and hinders practical applications. Here we experimentally demonstrate an over 300-fold reduction of the group velocity on a silicon chip via an ultra-compact photonic integrated circuit using low-loss silicon photonic crystal waveguides11,12 that can support an optical mode with a submicrometre cross-section13,14. In addition, we show fast (\u223c100\u2009ns) and efficient (2\u2009mW electric power) active control of the group velocity by localized heating of the photonic crystal waveguide with an integrated micro-heater.", "authors": ["Yurii A. Vlasov", "Martin O'Boyle", "Hendrik F. Hamann", "Sharee J. McNab"], "related_topics": ["22799297", "75302062", "151662813"], "citation_count": "1517", "reference_count": "27", "references": ["2011964761", "2140562769", "2036210074", "2157420334", "2139653117", "2052616886", "1968895711", "2088470320", "2002105262", "2125702087"], "date": "2005"}, {"id": "2162310432", "title": "Method of delivery, targeting, and measuring advertising over networks", "abstract": "Methods and apparatuses for targeting the delivery of advertisements over a network such as the Internet are disclosed. Statistics are compiled on individual users and networks and the use of the advertisements is tracked to permit targeting of the advertisements of individual users. In response to requests from affiliated sites, an advertising server transmits to people accessing the page of a site an appropriate one of the advertisement based upon profiling of users and networks.", "authors": ["Dwight Allen Merriman", "Kevin Joseph O'Connor"], "related_topics": ["70133500", "110875604", "15116735"], "citation_count": "3444", "reference_count": "182", "references": ["2152592781", "2161461831", "2150169316", "2128499373", "2870688700", "1648470663", "2126825876", "2101304210", "2139020969", "1921020360"], "date": "2004"}, {"id": "2045830397", "title": "Cognitive Representations of Semantic Categories.", "abstract": "", "authors": ["Eleanor Rosch"], "related_topics": ["86658582", "169900460", "96526673"], "citation_count": "5225", "reference_count": "52", "references": ["1989314580", "2135255848", "1990451873", "2059799772", "2007780422", "2000255081", "2025668003", "2000667669", "2032946087", "2021625970"], "date": "1975"}, {"id": "1578352865", "title": "Handbook of Face Recognition", "abstract": "This highly anticipated new edition provides a comprehensive account of face recognition research and technology, spanning the full range of topics needed for designing operational face recognition systems. After a thorough introductory chapter, each of the following chapters focus on a specific topic, reviewing background information, up-to-date techniques, and recent results, as well as offering challenges and future directions. Features: fully updated, revised and expanded, covering the entire spectrum of concepts, methods, and algorithms for automated face detection and recognition systems; provides comprehensive coverage of face detection, tracking, alignment, feature extraction, and recognition technologies, and issues in evaluation, systems, security, and applications; contains numerous step-by-step algorithms; describes a broad range of applications; presents contributions from an international selection of experts; integrates numerous supporting graphs, tables, charts, and performance data.", "authors": ["Stan Z. Li", "Anil K. Jain"], "related_topics": ["191070858", "4641261", "31510193"], "citation_count": "2744", "reference_count": "156", "references": ["2161969291", "2164598857", "2033819227", "2099111195", "2124386111", "2053186076", "2001141328", "2138451337", "1989702938", "2121647436"], "date": "2011"}, {"id": "1485665416", "title": "WebDSL: A Case Study in Domain-Specific Language Engineering", "abstract": "The goal of domain-specific languages (DSLs) is to increase the productivity of software engineers by abstracting from low-level boilerplate code. Introduction of DSLs in the software development process requires a smooth workflow for the production of DSLs themselves. This requires technology for designing and implementing DSLs, but also a methodology for using that technology. That is, a collection of guidelines, design patterns, and reusable DSL components that show developers how to tackle common language design and implementation issues. This paper presents a case study in domain-specific language engineering. It reports on a project in which the author designed and built WebDSL, a DSL for web applications with a rich data model, using several DSLs for DSL engineering: SDF for syntax definition and Stratego/XT for code generation. The paper follows the stages in the development of the DSL. The contributions of the paper are three-fold. (1) A tutorial in the application of the specific SDF and Stratego/XT technology for building DSLs. (2) A description of an incremental DSL development process. (3) A domain-specific language for web-applications with rich data models. The paper concludes with a survey of related approaches.", "authors": ["Eelco Visser"], "related_topics": ["135257023", "180152950", "146054899"], "citation_count": "256", "reference_count": "98", "references": ["1649645444", "1493688518", "146458024", "1500250067", "1491178396", "2139872812", "1487672899", "2061659496", "2014596857", "2577584179"], "date": "2007"}, {"id": "2113242816", "title": "The random subspace method for constructing decision forests", "abstract": "Much of previous attention on decision trees focuses on the splitting criteria and optimization of tree sizes. The dilemma between overfitting and achieving maximum accuracy is seldom resolved. A method to construct a decision tree based classifier is proposed that maintains highest accuracy on training data and improves on generalization accuracy as it grows in complexity. The classifier consists of multiple trees constructed systematically by pseudorandomly selecting subsets of components of the feature vector, that is, trees constructed in randomly chosen subspaces. The subspace method is compared to single-tree classifiers and other forest construction methods by experiments on publicly available datasets, where the method's superiority is demonstrated. We also discuss independence between trees in a forest and relate that to the combined classification accuracy.", "authors": ["Tin Kam Ho"], "related_topics": ["169258074", "106135958", "84525736"], "citation_count": "6236", "reference_count": "30", "references": ["2156909104", "2912934387", "2125055259", "2112076978", "1594031697", "2149706766", "2101522199", "1966280301", "2102734279", "1930624869"], "date": "1998"}, {"id": "2199322517", "title": "Data encryption standard", "abstract": "Presentation de la norme americaine de codage des donnees informatisees (DES: Data Encryption Standard). Adaptee par l'Agence nationale de securite en janvier 1988, elle permet de proteger les donnees selon des criteres qui sont developpes dans ce texte", "authors": ["Ralph Howard"], "related_topics": ["148730421", "15708023", "2549261"], "citation_count": "1567", "reference_count": "0", "references": ["1613874182", "2043508455", "2108255910", "2613364042", "2123510989", "1565369953", "2153268908", "2171027248", "2062086221", "2020918964"], "date": "1987"}, {"id": "2034108404", "title": "Maintained activity in the cat's retina in light and darkness.", "abstract": "Nervous activity has been recorded from the unopened eye of decerebrate cats. Recordings were made with metal electrodes or with small micropipettes from ganglion cells or nerve fibers. Continuous maintained discharges were seen in all ganglion cells during steady illumination of their receptive fields, as well as in complete darkness. Possible artefacts, such as electrode pressure, abnormal circulation, anesthetic, and several other factors have been excluded as the source of the maintained discharge. Visual stimuli are therefore transmitted by modulating the ever present background activity. Discharge frequencies were measured following changes of retinal illumination. No consistent patterns of frequency change were found. The maintained discharge frequency may be permanently increased or decreased, or may remain practically unchanged by altering the steady level of illumination. In addition, there were often transient frequency changes during the first 5 to 10 minutes after changing illumination, before a final steady rate was established. A statistical analysis of the impulse intervals of the maintained discharge showed: (a) the intervals were distributed according to the gamma distribution (Pearson's type III), (b) the first serial correlation coefficient of the intervals was between -0.10 and -0.24, with a mean value of -0.17, which is significantly different from zero, (c) the higher order serial correlation coefficients were not significantly different from zero. Thus the firing probability at any time depends on the times of occurrence of the two preceding impulses only, and in such a way as to indicate that each impulse is followed by a transient depression of excitability that outlasts the following impulse. The possible sites at which spontaneous or maintained activity may originate in the retina are discussed.", "authors": ["S. W. Kuffler", "R. Fitzhugh", "H. B. Barlow"], "related_topics": ["19071747", "2777093970", "2779027399"], "citation_count": "382", "reference_count": "21", "references": ["2212384750", "2314833535", "2110185620", "40428800", "1963829377", "1985424395", "1965332348", "2121181436", "2050821488", "2007305847"], "date": "1957"}, {"id": "2012766363", "title": "An extension of Bochner's problem: Exceptional invariant subspaces", "abstract": "We prove an extension of Bochner's classical result that characterizes the classical polynomial families as eigenfunctions of a second-order differential operator with polynomial coefficients. The extended result involves considering differential operators with rational coefficients and the requirement is that they have a numerable sequence of polynomial eigenfunctions p\"1,p\"2,... of all degrees except for degree zero. The main theorem of the paper provides a characterization of all such differential operators. The existence of such differential operators and polynomial sequences is based on the concept of exceptional polynomial subspaces, and the converse part of the main theorem rests on the classification of codimension one exceptional subspaces under projective transformations, which is performed in this paper.", "authors": ["David G\u00f3mez-Ullate", "Niky Kamran", "Robert Milson"], "related_topics": ["101044782", "45025165", "97395012"], "citation_count": "255", "reference_count": "22", "references": ["2980671223", "1974525177", "290527292", "2023180912", "2078454384", "1971903211", "2049750483", "2041178476", "3100908196", "2073764973"], "date": "2010"}, {"id": "2079948225", "title": "Oscillatory responses in cat visual cortex exhibit inter-columnar synchronization which reflects global stimulus properties", "abstract": "A FUNDAMENTAL step in visual pattern recognition is the establishment of relations between spatially separate features. Recently, we have shown that neurons in the cat visual cortex have oscillatory responses in the range 40\u201360 Hz (refs 1,2) which occur in synchrony for cells in a functional column and are tightly correlated with a local oscillatory field potential. This led us to hypothesize that the synchronization of oscillatory responses of spatially distributed, feature selective cells might be a way to establish relations between features in different parts of the visual field2,3. In support of this hypothesis, we demonstrate here that neurons in spatially separate columns can synchronize their oscillatory responses. The synchronization has, on average, no phase difference, depends on the spatial separation and the orientation preference of the cells and is influenced by global stimulus properties.", "authors": ["Charles M. Gray", "Peter K\u00f6nig", "Andreas K. Engel", "Wolf Singer"], "related_topics": ["2779345533", "19071747", "147004232"], "citation_count": "5089", "reference_count": "22", "references": ["2032533296", "2048330959", "2024390075", "1491926324", "1981025738", "1864836097", "2056934252", "2046384002", "2326003143", "2017558200"], "date": "1989"}, {"id": "2033156884", "title": "Recommendations for Reporting Cost-effectiveness Analyses", "abstract": "Objective. \u2014This article, the third in a 3-part series, describes recommendations for the reporting of cost-effective analyses (CEAs) intended to improve the quality and accessibility of CEA reports. Participants. \u2014The Panel on Cost-Effectiveness in Health and Medicine, a nonfederal panel with expertise in CEA, clinical medicine, ethics, and health outcomes measurement, convened by the US Public Health Service. Evidence. \u2014The panel reviewed the theoretical foundations of CEA, current practices, alternative methods, published critiques of CEAs, and criticisms of general CEA methods and reporting practices. Consensus Process. \u2014The panel developed recommendations through 21/2 years of discussions. Comments on preliminary drafts were solicited from federal government methodologists, health agency officials, and academic methodologists. Conclusion. \u2014These recommendations are proposed to enhance the transparency of study methods, assist analysts in providing complete information, and facilitate the presentation of comparable cost-effectiveness results across studies. Adherence to reporting conventions and attention to providing information required to understand and interpret study results will improve the relevance and accessibility of CEAs.", "authors": ["Joanna E. Siegel", "Milton C. Weinstein", "Louise B. Russell", "Marthe R. Gold"], "related_topics": ["3019080777", "2780233690", "148834064"], "citation_count": "1625", "reference_count": "16", "references": ["1512398135", "2013740670", "1595046345", "2094145886", "1997692902", "2077351095", "2318393109", "2593286047", "1997583013", "1987678351"], "date": "1996"}, {"id": "1966797434", "title": "An argument for basic emotions", "abstract": "Emotions are viewed as having evolved through their adaptive value in dealing with fundamental life-tasks. Each emotion has unique features: signal, physiology, and antecedent events. Each emotion ...", "authors": ["Paul Ekman"], "related_topics": ["206310091", "128534915", "110567168"], "citation_count": "9868", "reference_count": "71", "references": ["1984186949", "2006044072", "2167575933", "2154611638", "1975911018", "2995034616", "2141208341", "1483388411", "2146355519", "2080593835"], "date": "1992"}, {"id": "2098685541", "title": "A Partial Least Squares Latent Variable Modeling Approach for Measuring Interaction Effects: Results from a Monte Carlo Simulation Study and an Electronic-Mail Emotion/Adoption Study", "abstract": "The ability to detect and accurately estimate the strength of interaction effects are critical issues that are fundamental to social science research in general and IS research in particular. Within the IS discipline, a significant percentage of research has been devoted to examining the conditions and contexts under which relationships may vary, often under the general umbrella of contingency theory (cf. McKeen et al. 1994, Weill and Olson 1989). In our survey of such studies, the majority failed to either detect or provide an estimate of the effect size. In cases where effect sizes are estimated, the numbers are generally small. These results have led some researchers to question both the usefulness of contingency theory and the need to detect interaction effects (e.g., Weill and Olson 1989). This paper addresses this issue by providing a new latent variable modeling approach that can give more accurate estimates of interaction effects by accounting for the measurement error that attenuates the estimated relationships. The capacity of this approach at recovering true effects in comparison to summated regression is demonstrated in a Monte Carlo study that creates a simulated data set in which the underlying true effects are known. Analysis of a second, empirical data set is included to demonstrate the technique's use within IS theory. In this second analysis, substantial direct and interaction effects of enjoyment on electronic-mail adoption are shown to exist.", "authors": ["Wynne W. Chin", "Barbara L. Marcolin", "Peter R. Newsted"], "related_topics": ["65965080", "2777719215", "3020028006"], "citation_count": "4402", "reference_count": "117", "references": ["1995945562", "1791587663", "2797247465", "2037124948", "1484864026", "2122912498", "1987198869", "1487725643", "2107031757", "2104606180"], "date": "2003"}, {"id": "1496312651", "title": "The Complete Works of Aristotle the Revised Oxford Translation", "abstract": "The Oxford Translation of Aristotle was originally published in 12 volumes between 1912 and 1954. It is universally recognized as the standard English version of Aristotle. This revised edition contains the substance of the original Translation, slightly emended in light of recent scholarship; three of the original versions have been replaced by new translations; and a new and enlarged selection of Fragments has been added. The aim of the translation remains the same: to make the surviving works of Aristotle readily accessible to English speaking readers.", "authors": ["Jonathan Aristotle", "J. A. Barnes", "W. D. Smith", "Ross"], "related_topics": ["2776630830", "2778061430", "121662710"], "citation_count": "1783", "reference_count": "0", "references": ["2125576474", "2248695218", "2584955774", "91728902", "2049657642", "1507501311", "3125825110", "2997435195", "2093625353", "300260255"], "date": "1983"}, {"id": "2162870748", "title": "A practical guide to splines", "abstract": "This book is based on the author's experience with calculations involving polynomial splines. It presents those parts of the theory which are especially useful in calculations and stresses the representation of splines as linear combinations of B-splines. After two chapters summarizing polynomial approximation, a rigorous discussion of elementary spline theory is given involving linear, cubic and parabolic splines. The computational handling of piecewise polynomial functions (of one variable) of arbitrary order is the subject of chapters VII and VIII, while chapters IX, X, and XI are devoted to B-splines. The distances from splines with fixed and with variable knots is discussed in chapter XII. The remaining five chapters concern specific approximation methods, interpolation, smoothing and least-squares approximation, the solution of an ordinary differential equation by collocation, curve fitting, and surface fitting. The present text version differs from the original in several respects. The book is now typeset (in plain TeX), the Fortran programs now make use of Fortran 77 features. The figures have been redrawn with the aid of Matlab, various errors have been corrected, and many more formal statements have been provided with proofs. Further, all formal statements and equations have been numbered by the same numbering system, to make it easier to find any particular item. A major change has occured in Chapters IX-XI where the B-spline theory is now developed directly from the recurrence relations without recourse to divided differences. This has brought in knot insertion as a powerful tool for providing simple proofs concerning the shape-preserving properties of the B-spline series.", "authors": ["Carl R. de Boor"], "related_topics": ["78383375", "55259147", "183554904"], "citation_count": "17176", "reference_count": "0", "references": ["2049981393", "2102201073", "2006262236", "2964010366", "2080922987", "2003410902", "2162218551", "2154065358", "1990420052", "2032377318"], "date": "1977"}, {"id": "2125001590", "title": "Mixed-effects modeling with crossed random effects for subjects and items", "abstract": "This paper provides an introduction to mixed-effects models for the analysis of repeated measurement data with subjects and items as crossed random effects. A worked-out example of how to use recent software for mixed-effects modeling is provided. Simulation studies illustrate the advantages offered by mixed-effects analyses compared to traditional analyses based on quasi-F tests, by-subjects analyses, combined by-subjects and by-items analyses, and random regression. Applications and possibilities across a range of domains of inquiry are discussed.", "authors": ["R.H. Baayen", "D.J. Davidson", "D.M. Bates"], "related_topics": ["168743327", "114289077", "20589650"], "citation_count": "7391", "reference_count": "59", "references": ["2115709314", "1587094587", "2980908895", "2116649573", "2135194391", "2170210994", "2030769837", "1530839606", "1989314580", "2070706581"], "date": "2008"}, {"id": "2074599161", "title": "Shuffling Cards and Stopping Times", "abstract": "(1986). Shuffling Cards and Stopping Times. The American Mathematical Monthly: Vol. 93, No. 5, pp. 333-348.", "authors": ["David Aldous", "Persi Diaconis"], "related_topics": ["167927819", "94375191", "41008148"], "citation_count": "634", "reference_count": "21", "references": ["2752853835", "2083709540", "2056389572", "1601425725", "2076430891", "2079207922", "2083120484", "2058006306", "2114769645", "1967486764"], "date": "1986"}, {"id": "1993897382", "title": "Social contextual recommendation", "abstract": "Exponential growth of information generated by online social networks demands effective recommender systems to give useful results. Traditional techniques become unqualified because they ignore social relation data; existing social recommendation approaches consider social network structure, but social context has not been fully considered. It is significant and challenging to fuse social contextual factors which are derived from users' motivation of social behaviors into social recommendation. In this paper, we investigate social recommendation on the basis of psychology and sociology studies, which exhibit two important factors: individual preference and interpersonal influence. We first present the particular importance of these two factors in online item adoption and recommendation. Then we propose a novel probabilistic matrix factorization method to fuse them in latent spaces. We conduct experiments on both Facebook style bidirectional and Twitter style unidirectional social network datasets in China. The empirical result and analysis on these two large datasets demonstrate that our method significantly outperform the existing approaches.", "authors": ["Meng Jiang", "Peng Cui", "Rui Liu", "Qiang Yang", "Fei Wang", "Wenwu Zhu", "Shiqiang Yang"], "related_topics": ["86256295", "130064352", "21204594"], "citation_count": "337", "reference_count": "30", "references": ["1880262756", "2054141820", "2042281163", "1971040550", "1994389483", "2137245235", "2057763140", "2043403353", "2144487656", "2125027820"], "date": "2012"}, {"id": "1993819379", "title": "The implementation and performance of compressed databases", "abstract": "In this paper, we show how compression can be integrated into a relational database system. Specifically, we describe how the storage manager, the query execution engine, and the query optimizer of a database system can be extended to deal with compressed data. Our main result is that compression can significantly improve the response time of queries if very light-weight compression techniques are used. We will present such light-weight compression techniques and give the results of running the TPC-D benchmark on a so compressed database and a non-compressed database using the AODB database system, an experimental database system that was developed at the Universities of Mannheim and Passau. Our benchmark results demonstrate that compression indeed offers high performance gains (up to 50%) for IO-intensive queries and moderate gains for CPU-intensive queries. Compression can, however, also increase the running time of certain update operations. In all, we recommend to extend today's database systems with light-weight compression techniques and to make extensive use of this feature.", "authors": ["Till Westmann", "Donald Kossmann", "Sven Helmer", "Guido Moerkotte"], "related_topics": ["107535962", "148840519", "54239708"], "citation_count": "241", "reference_count": "26", "references": ["1515932031", "2129652681", "2158237121", "1990653637", "2140646908", "2161694911", "1538786304", "2133900260", "2156000104", "2122265344"], "date": "2000"}, {"id": "2131600418", "title": "Temporal difference learning and TD-Gammon", "abstract": "Ever since the days of Shannon's proposal for a chess-playing algorithm [12] and Samuel's checkers-learning program [10] the domain of complex board games such as Go, chess, checkers, Othello, and backgammon has been widely regarded as an ideal testing ground for exploring a variety of concepts and approaches in artificial intelligence and machine learning. Such board games offer the challenge of tremendous complexity and sophistication required to play at expert level. At the same time, the problem inputs and performance measures are clear-cut and well defined, and the game environment is readily automated in that it is easy to simulate the board, the rules of legal play, and the rules regarding when the game is over and determining the outcome.", "authors": ["Gerald Tesauro"], "related_topics": ["170828538", "99269900", "102234262"], "citation_count": "2330", "reference_count": "14", "references": ["2154642048", "1652505363", "2137983211", "3146803896", "2100677568", "2109779438", "2178806388", "2103626435", "2159920598", "2157305236"], "date": "1995"}, {"id": "2962717047", "title": "Learning to Ask: Neural Question Generation for Reading Comprehension", "abstract": "We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our system significantly outperforms the state-of-the-art rule-based system. In human evaluations, questions generated by our system are also rated as being more natural (i.e.,, grammaticality, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer).", "authors": ["Xinya Du", "Junru Shao", "Claire Cardie"], "related_topics": ["2779525943", "40506919", "2778780117"], "citation_count": "327", "reference_count": "36", "references": ["2964308564", "2250539671", "2130942839", "2157331557", "2064675550", "2101105183", "2963748441", "1902237438", "2123442489", "1514535095"], "date": "2017"}, {"id": "2159035740", "title": "Politeness: Some Universals in Language Usage", "abstract": "This study is about the principles for constructing polite speeches. The core of it first appeared in Questions and Politeness, edited by Esther N. Goody (now out of print). It is here reissued with a fresh introduction that surveys the considerable literature in linguistics, psychology and the social sciences that the original extended essay stimulated, and suggests distinct directions for research. The authors describe and account for some remarkable parallelisms in the linguistic construction of utterances with which people express themselves in different languages and cultures. A motive for these parallels is isolated and a universal model is constructed outlining the abstract principles underlying polite usages. This is based on the detailed study of three unrelated languages and cultures: the Tamil of South India, the Tzeltal spoken by Mayan Indians in Chiapas, Mexico, and the English of the USA and England. This volume will be of special interest to students in linguistic pragmatics, sociolinguistics, applied linguistics, anthropology, and the sociology and social psychology of interaction.", "authors": ["Penelope Brown", "Stephen C. Levinson"], "related_topics": ["58393919", "167055898", "2778356427"], "citation_count": "31452", "reference_count": "0", "references": ["2089457241", "1599835099", "2089594500", "2498260772", "2100772444", "2604799547", "1985945240", "2292422101", "2147463227", "2153355865"], "date": "1986"}, {"id": "2797148637", "title": "A mathematical theory of evidence", "abstract": "Both in science and in practical affairs we reason by combining facts only inconclusively supported by evidence. Building on an abstract understanding of this process of combination, this book constructs a new theory of epistemic probability. The theory draws on the work of A. P. Dempster but diverges from Depster's viewpoint by identifying his \"lower probabilities\" as epistemic probabilities and taking his rule for combining \"upper and lower probabilities\" as fundamental. The book opens with a critique of the well-known Bayesian theory of epistemic probability. It then proceeds to develop an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called \"monotone of order of infinity.\" and Dempster's rule for combining such set functions. This rule, together with the idea of \"weights of evidence,\" leads to both an extensive new theory and a better understanding of the Bayesian theory. The book concludes with a brief treatment of statistical inference and a discussion of the limitations of epistemic probability. Appendices contain mathematical proofs, which are relatively elementary and seldom depend on mathematics more advanced that the binomial theorem.", "authors": ["Glenn Shafer"], "related_topics": ["178011137", "2778905972", "2779193601"], "citation_count": "20987", "reference_count": "0", "references": ["2101840010", "2159080219", "2100235918", "2019950953", "2038420319", "2013093146", "2151376743", "2116817369", "1604936042", "1986721142"], "date": "1975"}, {"id": "2155711087", "title": "Positive Organizational Behavior in the Workplace The Impact of Hope, Optimism, and Resilience", "abstract": "Drawing from the foundation of positive psychology and the recently emerging positive organizational behavior, two studies (N = 1,032 and N = 232) test hypotheses on the impact that the selected positive psychological resource capacities of hope, optimism, and resilience have on desired work-related employee outcomes. These outcomes include performance (self-reported in Study 1 and organizational performance appraisals in Study 2), job satisfaction, work happiness, and organizational commitment. The findings generally support that employees\u2019 positive psychological re source capacities relate to, and contribute unique variance to, the outcomes. However, hope, and, to a lesser extent, optimism and resilience, do differentially contribute to the various outcomes. Utility analysis supports the practical implications of the study results.", "authors": ["Carolyn M. Youssef", "Fred Luthans"], "related_topics": ["2779077761", "2777991910", "83030740"], "citation_count": "2272", "reference_count": "117", "references": ["2106096361", "1665332082", "2007445014", "3126140319", "2045181804", "2174552938", "2020137493", "3122125999", "1802322323", "1746951143"], "date": "2007"}, {"id": "2149891956", "title": "Tangible bits: towards seamless interfaces between people, bits and atoms", "abstract": "This paper presents our vision of Human Computer Interaction (HCI): \"Tangible Bits.\" Tangible Bits allows users to \"grasp & manipulate\" bits in the center of users\u2019 attention by coupling the bits with everyday physical objects and architectural surfaces. Tangible Bits also enables users to be aware of background bits at the periphery of human perception using ambient display media such as light, sound, airflow, and water movement in an augmented space. The goal of Tangible Bits is to bridge the gaps between both cyberspace and the physical environment, as well as the foreground and background of human activities. This paper describes three key concepts of Tangible Bits: interactive surfaces; the coupling of bits with graspable physical objects; and ambient media for background awareness. We illustrate these concepts with three prototype systems \u2010 the metaDESK, transBOARD and ambientROOM \u2010 to identify underlying research issues.", "authors": ["Hiroshi Ishii", "Brygg Ullmer"], "related_topics": ["2777885485", "153715457", "172195944"], "citation_count": "5364", "reference_count": "20", "references": ["1647826363", "2340966270", "1983808135", "2167686873", "2023331673", "135070850", "2166175381", "101595803", "1556633365", "1993145239"], "date": "1997"}, {"id": "2125713050", "title": "Human Face Detection in Visual Scenes", "abstract": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image, and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with another state-of-the-art face detection system are presented; our system has better performance in terms of detection and false-positive rates.", "authors": ["Henry A. Rowley", "Shumeet Baluja", "Takeo Kanade"], "related_topics": ["4641261", "71681937", "205068"], "citation_count": "567", "reference_count": "14", "references": ["2138451337", "2046079134", "2159686933", "2147800946", "2098947662", "2173629880", "1575739010", "2084844503", "2056695679", "1479911746"], "date": "1995"}, {"id": "2096789154", "title": "A class of neural networks for independent component analysis", "abstract": "Independent component analysis (ICA) is a recently developed, useful extension of standard principal component analysis (PCA). The ICA model is utilized mainly in blind separation of unknown source signals from their linear mixtures. In this application only the source signals which correspond to the coefficients of the ICA expansion are of interest. In this paper, we propose neural structures related to multilayer feedforward networks for performing complete ICA. The basic ICA network consists of whitening, separation, and basis vector estimation layers. It can be used for both blind source separation and estimation of the basis vectors of ICA. We consider learning algorithms for each layer, and modify our previous nonlinear PCA type algorithms so that their separation capabilities are greatly improved. The proposed class of networks yields good results in test examples with both artificial and real-world data.", "authors": ["J. Karhunen", "E. Oja", "L. Wang", "R. Vigario", "J. Joutsensalo"], "related_topics": ["120317606", "51432778", "50644808"], "citation_count": "625", "reference_count": "45", "references": ["2124776405", "2099741732", "2108384452", "1996355918", "2133069808", "2137234026", "1977067929", "1555711139", "1563527684", "1562895369"], "date": "1997"}, {"id": "2005433550", "title": "Wide Baseline Stereo Matching based on Local, Affinely Invariant Regions", "abstract": "\u2018Invariant regions\u2019 are image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions are then described by a set of invariant features, which makes it relatively easy to match them between views and under changing illumination. In previous work, we have presented invariant regions that are based on a combination of corners and edges. The application discussed then was image database retrieval. Here, an alternative method for extracting (affinely) invariant regions is given, that does not depend on the presence of edges or corners in the image but is purely intensity-based. Also, we demonstrate the use of such regions for another application, which is wide baseline stereo matching. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system even further, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions.", "authors": ["Tinne Tuytelaars", "Luc J. Van Gool"], "related_topics": ["49209780", "97970142", "153077589"], "citation_count": "766", "reference_count": "11", "references": ["2124386111", "2085261163", "2145713909", "134171312", "1494702534", "2059871232", "2152739884", "2065695189", "1519278729", "1499458212"], "date": "1999"}, {"id": "2102666490", "title": "Canonical correspondence analysis and related multivariate methods in aquatic ecology", "abstract": "Canonical correspondence analysis (CCA) is a multivariate method to elucidate the relationships between biological assemblages of species and their environment. The method is designed to extract synthetic environmental gradients from ecological data-sets. The gradients are the basis for succinctly describing and visualizing the differential habitat preferences (niches) of taxa via an ordination diagram. Linear multivariate methods for relating two set of variables, such as twoblock Partial Least Squares (PLS2), canonical correlation analysis and redundancy analysis, are less suited for this purpose because habitat preferences are often unimodal functions of habitat variables. After pointing out the key assumptions underlying CCA, the paper focuses on the interpretation of CCA ordination diagrams. Subsequently, some advanced uses, such as ranking environmental variables in importance and the statistical testing of effects are illustrated on a typical macroinvertebrate data-set. The paper closes with comparisons with correspondence analysis, discriminant analysis, PLS2 and co-inertia analysis. In an appendix a new method, named CCA-PLS, is proposed that combines the strong features of CCA and PLS2.", "authors": ["Ter Cajo J.F. Braak", "Piet F.M. Verdonschot"], "related_topics": ["102720910", "148298330", "175570560"], "citation_count": "2072", "reference_count": "103", "references": ["1969423031", "1563636823", "2129476886", "2079775628", "1967075719", "2052696562", "1966089218", "2797502950", "2167941657", "2944952802"], "date": "1995"}, {"id": "2124101779", "title": "Kernel independent component analysis", "abstract": "We present a class of algorithms for independent component analysis (ICA) which use contrast functions based on canonical correlations in a reproducing kernel Hilbert space. On the one hand, we show that our contrast functions are related to mutual information and have desirable mathematical properties as measures of statistical dependence. On the other hand, building on recent developments in kernel methods, we show that these criteria and their derivatives can be computed efficiently. Minimizing these criteria leads to flexible and robust algorithms for ICA. We illustrate with simulations involving a wide variety of source distributions, showing that our algorithms outperform many of the presently known algorithms.", "authors": ["Francis R. Bach", "Michael I. Jordan"], "related_topics": ["182335926", "134517425", "122280245"], "citation_count": "2255", "reference_count": "53", "references": ["2148603752", "1548802052", "3023786531", "2752885492", "2798909945", "2099741732", "2140095548", "2108384452", "2141224535", "2797583072"], "date": "2003"}, {"id": "2156186849", "title": "New Directions in Cryptography", "abstract": "Two kinds of contemporary developments in cryptography are examined. Widening applications of teleprocessing have given rise to a need for new types of cryptographic systems, which minimize the need for secure key distribution channels and supply the equivalent of a written signature. This paper suggests ways to solve these currently open problems. It also discusses how the theories of communication and computation are beginning to provide the tools to solve cryptographic problems of long standing.", "authors": ["Whitfield Diffie", "Martin E. Hellman"], "related_topics": ["515488857", "165922616", "99674996"], "citation_count": "18992", "reference_count": "13", "references": ["1655990431", "2752853835", "1975442866", "1981663184", "1991374982", "2003647955", "2065410314", "2171545223", "2023719829", "2066356146"], "date": "1976"}, {"id": "2099964107", "title": "Efficient string matching: an aid to bibliographic search", "abstract": "This paper describes a simple, efficient algorithm to locate all occurrences of any of a finite number of keywords in a string of text. The algorithm consists of constructing a finite state pattern matching machine from the keywords and then using the pattern matching machine to process the text string in a single pass. Construction of the pattern matching machine takes time proportional to the sum of the lengths of the keywords. The number of state transitions made by the pattern matching machine in processing the text string is independent of the number of keywords. The algorithm has been used to improve the speed of a library bibliographic search program by a factor of 5 to 10.", "authors": ["Alfred V. Aho", "Margaret J. Corasick"], "related_topics": ["13052355", "32610155", "7757238"], "citation_count": "4399", "reference_count": "14", "references": ["1655990431", "1543281322", "1600795850", "1514735749", "2054801208", "2063013240", "2156429182", "2057439468", "2081272455", "2129414328"], "date": "1975"}, {"id": "1550832676", "title": "The Diffusion of Innovations", "abstract": "", "authors": ["Jade Coston", "Everett M. Rogers"], "related_topics": ["2780917687", "144133560", "40700"], "citation_count": "1536", "reference_count": "35", "references": ["2798643531", "1990513740", "2059092337", "1629076356", "2012691580", "2027476227", "1655241331", "1500850718", "1579135576", "3129907499"], "date": "2005"}, {"id": "2151857564", "title": "Verbs and adverbs: multidimensional motion interpolation", "abstract": "The article describes a system for real-time interpolated animation that addresses some of these problems. Through creating parameterized motions-which the authors call verbs parameterized by adverbs-a single authored verb produces a continuous range of subtle variations of a given motion at real-time rates. As a result, simulated figures alter their actions based on their momentary mood or in response to changes in their goals or environmental stimuli. For example, they demonstrate a walk verb that can show emotions such as happiness and sadness, and demonstrate subtle variations due to walking up or down hill while turning to the left and right. They also describe verb graphs, which act as the glue to assemble verbs and their adverbs into a runtime data structure. Verb graphs provide the means for seamless transition from verb to verb for the simulated figures within an interactive runtime system. Finally they briefly discuss the discrete event simulator that handles the runtime main loop.", "authors": ["C. Rose", "M.F. Cohen", "B. Bodenheimer"], "related_topics": ["2776397901", "2780870223", "72560505"], "citation_count": "991", "reference_count": "19", "references": ["1524100745", "2062165658", "2039402388", "2083382040", "2293431122", "2000366549", "2234200704", "1970552420", "2152377484", "2071214501"], "date": "1998"}, {"id": "2148963518", "title": "User cooperation diversity. Part I. System description", "abstract": "Mobile users' data rate and quality of service are limited by the fact that, within the duration of any given call, they experience severe variations in signal attenuation, thereby necessitating the use of some type of diversity. In this two-part paper, we propose a new form of spatial diversity, in which diversity gains are achieved via the cooperation of mobile users. Part I describes the user cooperation strategy, while Part II (see ibid., p.1939-48) focuses on implementation issues and performance analysis. Results show that, even though the interuser channel is noisy, cooperation leads not only to an increase in capacity for both users but also to a more robust system, where users' achievable rates are less susceptible to channel variations.", "authors": ["A. Sendonaris", "E. Erkip", "B. Aazhang"], "related_topics": ["6832461", "60069766", "2778079784"], "citation_count": "8330", "reference_count": "29", "references": ["2130509920", "2145417574", "2099111195", "1667950888", "2118040894", "2798333393", "2130347036", "2107689535", "2168571551", "2098257210"], "date": "2003"}, {"id": "2034728857", "title": "The modified gain extended Kalman filter and parameter identification in linear systems", "abstract": "Abstract For a special class of systems, a general formulation and stochastic stability analysis of a new nonlinear filter, called the modified gain extended Kalman filter (MGEKF), is presented. Used as an observer, it is globally exponentially convergent. In the presence of uncertainties a nominal nonrealizable filter algorithm is developed for which global stochastic stability is proven. With respect to this nominal filter algorithm, conditions are obtained such that the effective deviations of the realizable filter are not destabilizing. In an appropriate coordinate frame, the parameter identification problem of a linear system is shown to be a member of this special class. For the example problems, the MGEKF shows superior convergence characteristics without evidence of instability.", "authors": ["T L Song", "J L Speyer"], "related_topics": ["8639503", "206833254", "11588082"], "citation_count": "27", "reference_count": "15", "references": ["2125812768", "1981364618", "2158153584", "2010236714", "2009568893", "2155870584", "2051749895", "2087207481", "2164152021", "2031745605"], "date": "1985"}, {"id": "2165918462", "title": "ASYMPTOTIC THEORY FOR PRINCIPAL COMPONENT ANALYSIS", "abstract": "Abstract : The asymptotic distribution of the characteristic roots and (normalized) vectors of a sample covariance matrix is given when the observations are from a multivariate normal distribution whose covariance matrix has characteristic roots of arbitrary multiplicity. The elements of each characteristic vector are the coefficients of a principal component (with sum of squares of coefficients being unity), and the corresponding characteristic root is the variance of the principal component. Tests of hypotheses of equality of population roots are treated, and confidence intervals for assumed equal roots are given; these are useful in assessing the importance of principal components. A similar study for correlation matrices is considered. (Author)", "authors": ["T. W. Anderson"], "related_topics": ["27438332", "177384507", "185142706"], "citation_count": "1535", "reference_count": "0", "references": ["2001088254", "2125027820", "2148982591", "2014165366", "2146610201", "1520752838", "615589970", "2096710051", "2149755721", "2150244542"], "date": "1963"}, {"id": "2048192053", "title": "Surface reconstruction from outdoor image sequences", "abstract": "Abstract This paper describes the results of a study aimed at inferring the surface structure of outdoor scenes from video data acquired by a vehicle-mounted TV camera. The method is based on a decomposition of each frame of the video sequence into a dense set of feature points. Through the application of a structure-from-motion algorithm, the 3D locations of the time-consistent features are estimated and sequentially updated as each new frame is processed. The resultant point-based 3D representation has been found to be reliable, accurate and rich enough to enable the surface structure of the viewed scene to be reconstructed. Examples of the surfaces extracted by this \u2018bottom-up\u2019 approach from a 12 second video sequence are presented here. The implications of these results for autonomous vehicle navigation are discussed.", "authors": ["Debra Charnley", "Rod Blissett"], "related_topics": ["126042441", "175025161", "7374053"], "citation_count": "33", "reference_count": "13", "references": ["2111308925", "2069239883", "1502820991", "2063599328", "2039106392", "2155054718", "2166967166", "2020554914", "2160982455", "1999940778"], "date": "1989"}, {"id": "2013073142", "title": "The information visualizer, an information workspace", "abstract": "This paper proposes a concept for the user interface of information retrieval systems called an information workspace. The concept goes beyond the usual notion of an information retrieval system to encompass the cost structure of information from secondary storage to immediate use. As an implementation of the concept, the paper describes an experimental system, called the Information Visualizer, and its rationale. The system is based on (1) the use of 3D/Rooms for increasing the capacity of immediate storage avaitable to the user, (2) the Cognitive Co-processor scheduler-based user interface interaction architecture for coupling the user to information agents, and (3) the use of information visualization for interacting with information structure.", "authors": ["Stuart K. Card", "George G. Robertson", "Jock D. Mackinlay"], "related_topics": ["90288658", "89505385", "120588126"], "citation_count": "1059", "reference_count": "26", "references": ["1933657216", "2088563966", "1991691398", "2161581092", "2086050593", "1983989230", "2091579301", "2134835560", "2056276720", "2132881639"], "date": "1991"}, {"id": "2963504252", "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "abstract": "Abstract: Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.", "authors": ["Andrew M. Saxe", "James L. McClelland", "Surya Ganguli"], "related_topics": ["50644808", "108583219", "158622935"], "citation_count": "985", "reference_count": "22", "references": ["2618530766", "2100495367", "1533861849", "2072128103", "2117130368", "104184427", "2110798204", "2141125852", "1993882792", "1815076433"], "date": "2013"}, {"id": "2103414828", "title": "Neuro-Fuzzy and Soft Computing: A Computational Approach to Learning and Machine Intelligence", "abstract": "Included in Prentice Hall's MATLAB Curriculum Series, this text provides a comprehensive treatment of the methodologies underlying neuro-fuzzy and soft computing. The book places equal emphasis on theoretical aspects of covered methodologies, empirical observations, and verifications of various applications in practice.", "authors": ["Jyh-Shing Roger Jang", "Chuen-Tsai Sun"], "related_topics": ["140073362", "29470771", "50644808"], "citation_count": "8443", "reference_count": "0", "references": ["2123066915", "2135705692", "2054325787", "1560688497", "2101109743", "2086274107", "2055412520", "2151611062", "2009637664", "2163339363"], "date": "1995"}, {"id": "2161443453", "title": "A web-based kernel function for measuring the similarity of short text snippets", "abstract": "Determining the similarity of short text snippets, such as search queries, works poorly with traditional document similarity measures (e.g., cosine), since there are often few, if any, terms in common between two short text snippets. We address this problem by introducing a novel method for measuring the similarity between short text snippets (even those without any overlapping terms) by leveraging web search results to provide greater context for the short texts. In this paper, we define such a similarity kernel function, mathematically analyze some of its properties, and provide examples of its efficacy. We also show the use of this kernel function in a large-scale system for suggesting related queries to search engine users.", "authors": ["Mehran Sahami", "Timothy D. Heilman"], "related_topics": ["89604369", "98234853", "2780049985"], "citation_count": "972", "reference_count": "19", "references": ["1563088657", "2149684865", "2147152072", "1956559956", "1978394996", "2170654002", "1979459060", "2145001205", "1999817920", "2165612380"], "date": "2006"}, {"id": "2088049833", "title": "Selective Search for Object Recognition", "abstract": "This paper addresses the problem of generating possible object locations for use in object recognition. We introduce selective search which combines the strength of both an exhaustive search and segmentation. Like segmentation, we use the image structure to guide our sampling process. Like exhaustive search, we aim to capture all possible object locations. Instead of a single technique to generate possible object locations, we diversify our search and use a variety of complementary image partitionings to deal with as many image conditions as possible. Our selective search results in a small set of data-driven, class-independent, high quality locations, yielding 99 % recall and a Mean Average Best Overlap of 0.879 at 10,097 locations. The reduced number of locations compared to an exhaustive search enables the use of stronger machine learning techniques and stronger appearance models for object recognition. In this paper we show that our selective search enables the use of the powerful Bag-of-Words model for recognition. The selective search software is made publicly available (Software: http://disi.unitn.it/~uijlings/SelectiveSearch.html ).", "authors": ["J. R. Uijlings", "K. E. Sande", "T. Gevers", "A. W. Smeulders"], "related_topics": ["19889080", "171156551", "64876066"], "citation_count": "5522", "reference_count": "37", "references": ["2151103935", "2161969291", "2168356304", "2164598857", "2031489346", "3097096317", "2162915993", "2163352848", "2121947440", "2110158442"], "date": "2013"}, {"id": "2085121129", "title": "To fit a plane to a set of points by least squares", "abstract": "", "authors": ["D. M. Blow"], "related_topics": ["45923927", "176012381", "188649462"], "citation_count": "62", "reference_count": "0", "references": ["1968331067", "2118204502", "1568609060", "1967548201", "2022383289", "2041522432", "1982218430", "1579317282", "1584377288", "2008127123"], "date": "1960"}, {"id": "2034328688", "title": "Recognizing human actions: a local SVM approach", "abstract": "Local space-time features capture local events in video and can be adapted to the size, the frequency and the velocity of moving patterns. In this paper, we demonstrate how such features can be used for recognizing complex motion patterns. We construct video representations in terms of local space-time features and integrate such representations with SVM classification schemes for recognition. For the purpose of evaluation we introduce a new video database containing 2391 sequences of six human actions performed by 25 people in four different scenarios. The presented results of action recognition justify the proposed method and demonstrate its advantage compared to other relative approaches for action recognition.", "authors": ["C. Schuldt", "I. Laptev", "B. Caputo"], "related_topics": ["202474056", "14551309", "40608802"], "citation_count": "4337", "reference_count": "15", "references": ["2148603752", "1563088657", "2119799051", "3141200356", "2090110089", "2753461371", "2113856781", "2159727956", "2149613906", "2144761589"], "date": "2004"}, {"id": "2118858186", "title": "An analysis of single-layer networks in unsupervised feature learning", "abstract": "A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several othe-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR, NORB, and STL datasets using only singlelayer networks. We then present a detailed analysis of the eect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (\u201cstride\u201d) between extracted features, and the eect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance\u2014so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyperparameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.2% respectively).", "authors": ["Adam Coates", "Andrew Y. Ng", "Honglak Lee"], "related_topics": ["8038995", "59404180", "73555534"], "citation_count": "2602", "reference_count": "34", "references": ["2136922672", "3118608800", "2162915993", "2546302380", "2116064496", "2025768430", "2130325614", "2097018403", "2107034620", "1625255723"], "date": "2011"}, {"id": "1948751323", "title": "Hypercolumns for object segmentation and fine-grained localization", "abstract": "Recognition algorithms based on convolutional networks (CNNs) typically use the output of the last layer as a feature representation. However, the information in this layer may be too coarse spatially to allow precise localization. On the contrary, earlier layers may be precise in localization but will not capture semantics. To get the best of both worlds, we define the hypercolumn at a pixel as the vector of activations of all CNN units above that pixel. Using hypercolumns as pixel descriptors, we show results on three fine-grained localization tasks: simultaneous detection and segmentation [22], where we improve state-of-the-art from 49.7 mean APr [22] to 60.0, keypoint localization, where we get a 3.3 point boost over [20], and part labeling, where we show a 6.6 point gain over a strong baseline.", "authors": ["Bharath Hariharan", "Pablo Arbelaez", "Ross Girshick", "Jitendra Malik"], "related_topics": ["124504099", "160633673", "7374053"], "citation_count": "1486", "reference_count": "42", "references": ["2618530766", "2962835968", "2102605133", "1903029394", "2168356304", "2109255472", "2156303437", "2022508996", "2118585731", "1507506748"], "date": "2015"}, {"id": "2088563966", "title": "Unified Theories of Cognition", "abstract": "Introduction The Nature of Theories What Are Unified Theories of Cognition? Is Psychology Ready for Unified Theories? The Task of the Book Foundations of Cognitive Science Behaving Systems Knowledge Systems Representation Machines and Computation Symbols Architectures Intelligence Search and Problem Spaces Preparation and Deliberation Summary Human Cognitive Architecture The Human Is a Symbol System System Levels The Time Scale of Human Action The Biological Band The Neural Circuit Level The Real-Time Constraint on Cognition The Cognitive Band The Level of Simple Operations The First Level of Composed Operations The Intendedly Rational Band Higher Bands: Social, Historical, and Evolutionary Summary Symbolic Processing for Intelligence The Central Architecture for Performance Chunking The Total Cognitive System RI-Soar: Knowledge-Intensive and Knowledge-Lean Operation Designer-Soar: Difficult Intellectual Tasks Soar as an Intelligent System Mapping Soar onto Human Cognition Soar and the Shape of Human Cognition Summary Immediate Behavior The Scientific Role of Immediate-Response Data Methodological Preliminaries Functional Analysis of Immediate Responses The Simplest Response Task (SRI) The Two-Choice Response Task (2CRT) Stimulus-Response Compatibility (SRC) Discussion of the Three Analyses Item Recognition Typing Summary Memory, Learning, and Skill The Memory and Learning Hypothesis of Soar The Soar Qualitative Theory of Learning The Distinction between Episodic and Semantic Memory Data Chunking Skill Acquisition Short-Term Memory (STM) Summary Intendedly Rational Behavior Ciyptarithmetic Syllogisms Sentence Verification Summary Along the Frontiers Language Development The Biological Band The Social Band The Role of Applications How to Move toward Unified Theories of Cognition References Name Index Subject Index", "authors": ["Allen Newell"], "related_topics": ["2780583044", "161407221", "20854674"], "citation_count": "8281", "reference_count": "0", "references": ["2136518234", "2150375089", "2128672031", "1125023678", "2136823593", "1928882148", "1977308918", "2105931454", "2167366201", "382421368"], "date": "1990"}, {"id": "2015245929", "title": "Unsupervised learning of finite mixture models", "abstract": "This paper proposes an unsupervised algorithm for learning a finite mixture model from multivariate data. The adjective \"unsupervised\" is justified by two properties of the algorithm: 1) it is capable of selecting the number of components and 2) unlike the standard expectation-maximization (EM) algorithm, it does not require careful initialization. The proposed method also avoids another drawback of EM for mixture fitting: the possibility of convergence toward a singular estimate at the boundary of the parameter space. The novelty of our approach is that we do not use a model selection criterion to choose one among a set of preestimated candidate models; instead, we seamlessly integrate estimation and model selection in a single algorithm. Our technique can be applied to any type of parametric mixture model for which it is possible to write an EM algorithm; in this paper, we illustrate it with experiments involving Gaussian mixtures. These experiments testify for the good performance of our approach.", "authors": ["M.A.T. Figueiredo", "A.K. Jain"], "related_topics": ["61224824", "17061570", "8038995"], "citation_count": "2647", "reference_count": "59", "references": ["2798766386", "1579271636", "2132549764", "2488678869", "2482402870", "2117853077", "3017143921", "2168175751", "2567948266", "2146610201"], "date": "2002"}, {"id": "2138993731", "title": "Resource Allocation and Cross Layer Control in Wireless Networks", "abstract": "Information flow in a telecommunication network is accomplished through the interaction of mechanisms at various design layers with the end goal of supporting the information exchange needs of the applications. In wireless networks in particular, the different layers interact in a nontrivial manner in order to support information transfer. In this text we will present abstract models that capture the cross-layer interaction from the physical to transport layer in wireless network architectures including cellular, ad-hoc and sensor networks as well as hybrid wireless-wireline. The model allows for arbitrary network topologies as well as traffic forwarding modes, including datagrams and virtual circuits. Furthermore the time varying nature of a wireless network, due either to fading channels or to changing connectivity due to mobility, is adequately captured in our model to allow for state dependent network control policies. Quantitative performance measures that capture the quality of service requirements in these systems depending on the supported applications are discussed, including throughput maximization, energy consumption minimization, rate utility function maximization as well as general performance functionals. Cross-layer control algorithms with optimal or suboptimal performance with respect to the above measures are presented and analyzed. A detailed exposition of the related analysis and design techniques is provided.", "authors": ["Leonidas Georgiadis", "Michael J. Neely", "Leandros Tassiulas"], "related_topics": ["108037233", "158207573", "193415008"], "citation_count": "1623", "reference_count": "154", "references": ["2137775453", "2099111195", "2610335499", "2132932625", "1997834106", "2105831729", "2798766386", "2149959815", "1501077214", "2159715570"], "date": "2006"}, {"id": "2158733823", "title": "Random early detection gateways for congestion avoidance", "abstract": "The authors present random early detection (RED) gateways for congestion avoidance in packet-switched networks. The gateway detects incipient congestion by computing the average queue size. The gateway could notify connections of congestion either by dropping packets arriving at the gateway or by setting a bit in packet headers. When the average queue size exceeds a present threshold, the gateway drops or marks each arriving packet with a certain probability, where the exact probability is a function of the average queue size. RED gateways keep the average queue size low while allowing occasional bursts of packets in the queue. During congestion, the probability that the gateway notifies a particular connection to reduce its window is roughly proportional to that connection's share of the bandwidth through the gateway. RED gateways are designed to accompany a transport-layer congestion control protocol such as TCP. The RED gateway has no bias against bursty traffic and avoids the global synchronization of many connections decreasing their window at the same time. Simulations of a TCP/IP network are used to illustrate the performance of RED gateways. >", "authors": ["Sally Floyd", "Van Jacobson"], "related_topics": ["140518850", "195563490", "2775879146"], "citation_count": "11059", "reference_count": "40", "references": ["2753542457", "2571446175", "2104820473", "2050353731", "2098289156", "2011730388", "1993549051", "2096597645", "2096812769", "1986753211"], "date": "1993"}, {"id": "2343951702", "title": "Approved for Public Release; Distribution is Unlimited", "abstract": "PROTRACED COUNTERINSURGENCY: CHINESE COIN STRATEGY IN XINJIANG by MAJ J. Scott LaRonde, USA, 95 pages. In 1949, following the conclusion of its revolutionary war against the Chinese Nationalist forces, the People\u2019s Liberation Army (PLA) peacefully occupied China\u2019s western most province of Xinjiang. For nearly sixty years, the PLA has conducted a counterinsurgency against several, mostly Uyghur-led, separatist movements. Despite periods of significant violence, particularly in the early 1950s and again in the 1990s, the separatist forces have not gained momentum and remained at a level one insurgency. Mao ZeDeng is revered as a master insurgent and the father of Fourth Generation Warfare. Strategists in armies worldwide study his writings on revolutionary and guerilla warfare. This monograph concludes that Mao, as well as the communist leaders who followed him, was also successful at waging protracted counterinsurgency. For nearly sixty years, separatist movements in Xinjiang, Tibet, and Taiwan have all failed. This monograph analyzes the conflict in Xinjiang and concludes that the Chinese continue to defeat the separatist movement in Xinjiang through a strategy that counters Mao\u2019s seven fundamentals of revolutionary warfare.", "authors": ["Maj J. Scott LaRonde"], "related_topics": ["191935318", "2777119466", "510578393"], "citation_count": "826", "reference_count": "500", "references": ["2158714788", "1497256448", "2315214008", "2128635872", "2078204800", "2099641086", "2101157755", "1967073510", "2133671888", "2124192278"], "date": "2007"}, {"id": "2100677568", "title": "Learning to Predict by the Methods of Temporal Differences", "abstract": "This article introduces a class of incremental learning procedures specialized for prediction \u2013 that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage.", "authors": ["Richard S. Sutton"], "related_topics": ["196340769", "136389625", "173801870"], "citation_count": "6387", "reference_count": "33", "references": ["2154642048", "1652505363", "2895674046", "1535810436", "1507849272", "2178806388", "1596324102", "1583833196", "1569296262", "2075379212"], "date": "1988"}, {"id": "2140650302", "title": "Coherent Optical 25.8-Gb/s OFDM Transmission Over 4160-km SSMF", "abstract": "We discuss coherent optical orthogonal frequency division multiplexing (CO-OFDM) as a suitable modulation technique for long-haul transmission systems. Several design and implementation aspects of a CO-OFDM system are reviewed, but we especially focus on phase noise compensation. As conventional CO-OFDM transmission systems are very sensitive to laser phase noise a novel method to compensate for phase noise is introduced. With the help of this phase noise compensation method we show continuously detectable OFDM transmission at 25.8 Gb/s data rate (20 Gb/s after coding) over 4160-km SSMF without dispersion compensation.", "authors": ["S.L. Jansen", "I. Morita", "T.C.W. Schenk", "N. Takeda", "H. Tanaka"], "related_topics": ["89631360", "40409654", "163294075"], "citation_count": "466", "reference_count": "29", "references": ["2798333393", "1551517259", "2110774823", "2089393140", "2080911270", "2146419976", "2082897712", "2010791822", "2264270816", "1921119268"], "date": "2007"}, {"id": "1709784975", "title": "Loophole-free Bell inequality violation using electron spins separated by 1.3 kilometres", "abstract": "More than 50 years ago, John Bell proved that no theory of nature that obeys locality and realism can reproduce all the predictions of quantum theory: in any local-realist theory, the correlations between outcomes of measurements on distant particles satisfy an inequality that can be violated if the particles are entangled. Numerous Bell inequality tests have been reported; however, all experiments reported so far required additional assumptions to obtain a contradiction with local realism, resulting in 'loopholes'. Here we report a Bell experiment that is free of any such additional assumption and thus directly tests the principles underlying Bell's inequality. We use an event-ready scheme that enables the generation of robust entanglement between distant electron spins (estimated state fidelity of 0.92 \u00b1 0.03). Efficient spin read-out avoids the fair-sampling assumption (detection loophole), while the use of fast random-basis selection and spin read-out combined with a spatial separation of 1.3 kilometres ensure the required locality conditions. We performed 245 trials that tested the CHSH-Bell inequality S \u2264 2 and found S = 2.42 \u00b1 0.20 (where S quantifies the correlation between measurement outcomes). A null-hypothesis test yields a probability of at most P = 0.039 that a local-realist model for space-like separated sites could produce data with a violation at least as large as we observe, even when allowing for memory in the devices. Our data hence imply statistically significant rejection of the local-realist null hypothesis. This conclusion may be further consolidated in future experiments; for instance, reaching a value of P = 0.001 would require approximately 700 trials for an observed S = 2.4. With improvements, our experiment could be used for testing less-conventional theories, and for implementing device-independent quantum-secure communication and randomness certification.", "authors": ["B. Hensen", "H. Bernien", "", "A. E. Dr\u00e9au", "A. Reiserer", "N. Kalb", "M. S. Blok", "J. Ruitenberg", "R. F. L. Vermeulen", "R. N. Schouten", "C. Abell\u00e1n", "W. Amaya", "V. Pruneri", "", "M. W. Mitchell", "", "M. Markham", "D. J. Twitchen", "D. Elkouss", "S. Wehner", "T. H. Taminiau", "R. Hanson"], "related_topics": ["11511207", "198377831", "166537537"], "citation_count": "2073", "reference_count": "33", "references": ["2058302064", "2095410318", "2015914132", "2000884742", "3037170129", "2786198409", "1616015000", "2991858054", "1984279171", "2006166792"], "date": "2015"}, {"id": "1550206324", "title": "A comparison of event models for naive bayes text classification", "abstract": "Recent work in text classification has used two different first-order probabilistic models for classification, both of which make the naive Bayes assumption. Some use a multi-variate Bernoulli model, that is, a Bayesian Network with no dependencies between words and binary word features (e.g. Larkey and Croft 1996; Koller and Sahami 1997). Others use a multinomial model, that is, a uni-gram language model with integer word counts (e.g. Lewis and Gale 1994; Mitchell 1997). This paper aims to clarify the confusion by describing the differences and details of these two models, and by empirically comparing their classification performance on five text corpora. We find that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes--providing on average a 27% reduction in error over the multi-variate Bernoulli model at any vocabulary size.", "authors": ["Andrew McCallum", "Kamal Nigam"], "related_topics": ["52001869", "192065140", "2777601683"], "citation_count": "5029", "reference_count": "32", "references": ["2099111195", "2149684865", "2140785063", "1817561967", "2096152098", "2153283265", "1648885110", "1924689489", "2167044614", "2118234018"], "date": "1997"}, {"id": "2494370076", "title": "Nonresponse in Household Interview Surveys: Groves/Nonresponse", "abstract": "", "authors": ["Robert M. Groves", "Mick P. Couper"], "related_topics": ["15744967"], "citation_count": "795", "reference_count": "0", "references": ["2116971494", "3123061466", "2132365686", "1990824174", "2104063729", "2130653106", "1517794032", "1978871724", "2168218485", "2108623204"], "date": "1998"}, {"id": "1817265267", "title": "Overcoming the Odds: High Risk Children from Birth to Adulthood.", "abstract": "This study was a follow-up study of a 1955 cohort of births (614 births) on Kauai island in Hawaii. Follow-up was conducted at birth age one and two years age 10 years age 18 years and 31-32 years. The final sample in adulthood was 505 persons. The sample population was comprised of three ethnic groups (Japanese Filipino and part and full Hawaiian) and 54% grew up in poverty. Births were scored for complications as mild moderate or severe. The interviews conducted with mothers postpartum and at one and two years focused on maternal educational level socioeconomic status and family stability; environmental setting was evaluated as favorable to unfavorable on a five-point scale. The 10 year evaluation assessed school work and school behavioral problems mental abilities and stressful life events and illnesses occurring over the preceding 8 years. The home environment was evaluated on the level of educational stimulation emotional support and socioeconomic status. At 18 years a psychological inventory of self-assurance and interpersonal adequacy was conducted and community records were checked for serious mental health or criminal problems. Quality of life of the home environment was also assessed. The follow-up at age 31-32 years assessed the quality of adult adaptation from community records and interview questions which were self-evaluations of personal success satisfaction with family and social life and psychological well-being. Most of the sample led ordinary lives. Some of the stressful life events in childhood and adolescence were associated with coping problems in adulthood.", "authors": ["Emmy E. Werner", "Ruth S. Smith"], "related_topics": ["134362201", "2908647359", "201903717"], "citation_count": "3924", "reference_count": "0", "references": ["2020137493", "2118919126", "1579153183", "2158532959", "1985334364", "1991626747", "1788731187", "2152155693", "2080756469", "2050612518"], "date": "1991"}, {"id": "2049093093", "title": "Graded State Machines: The Representation of Temporal Contingencies in Simple Recurrent Networks", "abstract": "We explore a network architecture introduced by Elman (1990) for predicting successive elements of a sequence. The network uses the pattern of activation over a set of hidden units from time-step t-1, together with element t, to predict element t + 1. When the network is trained with strings from a particular finite-state grammar, it can learn to be a perfect finite-state recognizer for the grammar. When the net has a minimal number of hidden units, patterns on the hidden units come to correspond to the nodes of the grammars however, this correspondence is not necessary for the network to act as a perfect finite-state recognizer. Next, we provide a detailed analysis of how the network acquires its internal representations. We show that the network progressively encodes more and more temporal context by means of a probability analysis. Finally, we explore the conditions under which the network can carry information about distant sequential contingencies across intervening elements to distant elements. Such information is maintained with relative ease if it is relevant at each intermediate steps it tends to be lost when intervening elements do not depend on it. At first glance this may suggest that such networks are not relevant to natural language, in which dependencies may span indefinite distances. However, embeddings in natural language are not completely independent of earlier information. The final simulation shows that long distance sequential contingencies can be encoded by the network even if only subtle statistical properties of embedded strings depend on the early information. The network encodes long-distance dependencies by shading internal representations that are responsible for processing common embeddings in otherwise different sequences. This ability to represent simultaneously similarities and differences between several sequences relies on the graded nature of representations used by the network, which contrast with the finite states of traditional automata. For this reason, the network and other similar architectures may be called Graded State Machines.", "authors": ["David Servan-Schreiber", "Axel Cleeremans", "James L. McClelland"], "related_topics": ["13540734", "139940560", "193415008"], "citation_count": "309", "reference_count": "20", "references": ["2154642048", "1652505363", "2110485445", "3036751298", "1959983357", "1971844566", "2121553911", "2912225506", "2095461998", "2119796132"], "date": "1991"}, {"id": "2147246240", "title": "Distinct types of diffuse large B-cell lymphoma identified by gene expression profiling", "abstract": "12 Pathology and Microbiology, and 13 Diffuse large B-cell lymphoma (DLBCL), the most common subtype of non-Hodgkin's lymphoma, is clinically heterogeneous: 40% of patients respond well to current therapy and have prolonged survival, whereas the remainder succumb to the disease. We proposed that this variability in natural history reflects unrecognized molecular heterogeneity in the tumours. Using DNA microarrays, we have conducted a systematic characterization of gene expression in B-cell malignancies. Here we show that there is diversity in gene expression among the tumours of DLBCL patients, apparently reflecting the variation in tumour proliferation rate, host response and differentiation state of the tumour. We identified two molecularly distinct forms of DLBCL which had gene expression patterns indicative of different stages of B-cell differentiation. One type expressed genes characteristic of germinal centre B cells ('germinal centre B-like DLBCL'); the second type expressed genes normally induced during in vitro activation of peripheral blood B cells ('activated B-like DLBCL'). Patients with germinal centre B-like DLBCL had a significantly better overall survival than those with activated B-like DLBCL. The molecular classification of tumours on the basis of gene expression can thus identify previously undetected and clinically significant subtypes of cancer.", "authors": ["Ash A. Alizadeh", "Michael B. Eisen", "R. Eric Davis", "Izidore S. Lossos", "Andreas Rosenwald", "Jennifer C. Boldrick", "Hajeer Sabet", "Truc Tran", "Xin Yu", "John I. Powell", "Liming Yang", "Gerald E. Marti", "Troy Moore", "James Hudson", "Lisheng Lu", "David B. Lewis", "Robert Tibshirani", "Gavin Sherlock", "Wing C. Chan", "Timothy C. Greiner", "Dennis D. Weisenburger", "James O. Armitage", "Roger Warnke", "Ronald Levy", "Wyndham Wilson", "Michael R. Grever", "John C. Byrd", "David Botstein", "Patrick O. Brown", "Louis M. Staudt"], "related_topics": ["2778559949", "2777537477", "18431079"], "citation_count": "11369", "reference_count": "49", "references": ["2150926065", "2109363337", "1970156673", "2087684630", "2107202569", "238668910", "2155612034", "2605539363", "1549647993", "2608724752"], "date": "2000"}, {"id": "2003370853", "title": "Theory of Edge Detection", "abstract": "A theory of edge detection is presented. The analysis proceeds in two parts. (1) Intensity changes, which occur in a natural image over a wide range of scales, are detected separately at different scales. An appropriate filter for this purpose at a given scale is found to be the second derivative of a Gaussian, and it is shown that, provided some simple conditions are satisfied, these primary filters need not be orientation-dependent. Thus, intensity changes at a given scale are best detected by finding the zero values of delta 2G(x,y)*I(x,y) for image I, where G(x,y) is a two-dimensional Gaussian distribution and delta 2 is the Laplacian. The intensity changes thus discovered in each of the channels are then represented by oriented primitives called zero-crossing segments, and evidence is given that this representation is complete. (2) Intensity changes in images arise from surface discontinuities or from reflectance or illumination boundaries, and these all have the property that they are spatially. Because of this, the zero-crossing segments from the different channels are not independent, and rules are deduced for combining them into a description of the image. This description is called the raw primal sketch. The theory explains several basic psychophysical findings, and the operation of forming oriented zero-crossing segments from the output of centre-surround delta 2G filters acting on the image forms the basis for a physiological model of simple cells (see Marr & Ullman 1979).", "authors": ["D. Marr", "E. Hildreth"], "related_topics": ["193536780", "117068819", "170971919"], "citation_count": "9566", "reference_count": "52", "references": ["1622620102", "1995756857", "2105672294", "2130355536", "2116360511", "2117731089", "1999908130", "1964415410", "2074798463", "2019222286"], "date": "1980"}, {"id": "2082693041", "title": "High-performance sorting on networks of workstations", "abstract": "We report the performance of NOW-Sort, a collection of sorting implementations on a Network of Workstations (NOW). We find that parallel sorting on a NOW is competitive to sorting on the large-scale SMPs that have traditionally held the performance records. On a 64-node cluster, we sort 6.0 GB in just under one minute, while a 32-node cluster finishes the Datamation benchmark in 2.41 seconds.Our implementations can be applied to a variety of disk, memory, and processor configurations; we highlight salient issues for tuning each component of the system. We evaluate the use of commodity operating systems and hardware for parallel sorting. We find existing OS primitives for memory management and file access adequate. Due to aggregate communication and disk bandwidth requirements, the bottleneck of our system is the workstation I/O bus.", "authors": ["Andrea C. Arpaci-Dusseau", "Remzi H. Arpaci-Dusseau", "David E. Culler", "Joseph M. Hellerstein", "David A. Patterson"], "related_topics": ["147254959", "111696304", "64540648"], "citation_count": "241", "reference_count": "34", "references": ["2114728910", "2155066383", "2135131646", "2154207621", "2080427212", "2098815550", "2135652458", "2110468472", "2029131452", "2036398208"], "date": "1997"}, {"id": "2036109700", "title": "Stacked Autoencoders for Unsupervised Feature Learning and Multiple Organ Detection in a Pilot Study Using 4D Patient Data", "abstract": "Medical image analysis remains a challenging application area for artificial intelligence. When applying machine learning, obtaining ground-truth labels for supervised learning is more difficult than in many more common applications of machine learning. This is especially so for datasets with abnormalities, as tissue types and the shapes of the organs in these datasets differ widely. However, organ detection in such an abnormal dataset may have many promising potential real-world applications, such as automatic diagnosis, automated radiotherapy planning, and medical image retrieval, where new multimodal medical images provide more information about the imaged tissues for diagnosis. Here, we test the application of deep learning methods to organ identification in magnetic resonance medical images, with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier. A probabilistic patch-based method was employed for multiple organ detection, with the features learned from the deep learning model. This shows the potential of the deep learning model for application to medical images, despite the difficulty of obtaining libraries of correctly labeled training datasets and despite the intrinsic abnormalities present in patient datasets.", "authors": ["Hoo-Chang Shin", "M. R. Orton", "D. J. Collins", "S. J. Doran", "M. O. Leach"], "related_topics": ["8038995", "136389625", "59404180"], "citation_count": "434", "reference_count": "56", "references": ["2161969291", "2136922672", "2168356304", "1677409904", "2162915993", "2124386111", "2025768430", "2110798204", "2131241448", "2154422044"], "date": "2013"}, {"id": "2152328854", "title": "Singularity detection and processing with wavelets", "abstract": "The mathematical characterization of singularities with Lipschitz exponents is reviewed. Theorems that estimate local Lipschitz exponents of functions from the evolution across scales of their wavelet transform are reviewed. It is then proven that the local maxima of the wavelet transform modulus detect the locations of irregular structures and provide numerical procedures to compute their Lipschitz exponents. The wavelet transform of singularities with fast oscillations has a particular behavior that is studied separately. The local frequency of such oscillations is measured from the wavelet transform modulus maxima. It has been shown numerically that one- and two-dimensional signals can be reconstructed, with a good approximation, from the local maxima of their wavelet transform modulus. As an application, an algorithm is developed that removes white noises from signals by analyzing the evolution of the wavelet transform maxima across scales. In two dimensions, the wavelet transform maxima indicate the location of edges in images. >", "authors": ["S. Mallat", "W.L. Hwang"], "related_topics": ["2777293603", "1109138", "73339587"], "citation_count": "6973", "reference_count": "17", "references": ["2145023731", "2078206416", "1996021349", "2004217976", "2109863423", "2003370853", "2096684483", "1667165204", "2133155955", "1968245656"], "date": "1992"}, {"id": "1501731334", "title": "DESIGN AND SYNTHESIS OF SYNCHRONIZATION SKELETONS USING BRANCHING TIME TEMPORAL LOGIC", "abstract": "We Propose a method of constructing concurrent programs in which the synchronization skeletonof the program is automatically synthesized from a high-level (branching time) Temporal Logic specification. The synchronization skeleton is an abstraction of the actual program where detail irrelevant to synchronization is suppressed. For example, in the synchronization skeleton for a solution to the critical section problem each process's critical section may be viewed as a single node since the internal structure of the critical section is unimportant. Most solutions to synchronization problems in the literature are in fact given as synchronization skeletons. Because synchronization skeletons are in general finite state, the propositional version of Temporal Logic can be used to specify their properties.", "authors": ["Edmund M. Clarke", "E. Allen Emerson"], "related_topics": ["10784920", "124343487", "25016198"], "citation_count": "6066", "reference_count": "17", "references": ["2118382442", "2157319504", "2040127143", "2030926579", "2163751633", "2000138546", "2084910510", "2002128397", "1536217426", "2053068495"], "date": "2007"}, {"id": "22546692", "title": "Mind and Society", "abstract": "Immanuel Kant and the Baron Thiry d\u2019Holbach were born in Germany just one year apart at the start of the Enlightenment. If Kant had lived in sparkling Paris rather than in Konigsberg, and d\u2019Holbach had stayed in dark Edsheim, his native town, they might have exchanged philosophies: Kant might have become the great materialist and realist philosopher of the century, and d\u2019Holbach his idealist counterpart. Of course, the previous sentence is a counterfactual, and as such untestable, and therefore neither true nor false. But it is not a ludicrous fantasy, because we know that nurture and opportunity are just as important as nature.", "authors": ["Mario Bunge"], "related_topics": ["534859617", "144218379", "108650721"], "citation_count": "1029", "reference_count": "43", "references": ["2110631042", "2135943618", "2150671164", "2148337554", "2144225695", "2128662472", "2002062072", "1659631989", "2118450042", "1593516803"], "date": "2009"}, {"id": "2327022120", "title": "Discrete Multivariate Analysis", "abstract": "", "authors": ["D. V. Gokhale", "Y. M. M. Bishop", "S. E. Fienberg", "P. W. Holland"], "related_topics": ["161584116", "192424360", "73791607"], "citation_count": "2927", "reference_count": "0", "references": ["2049633694", "2119019497", "1524326598", "2154279165", "2089763487", "2289748525", "2019575783", "2096335861", "46452414", "2126028971"], "date": "2008"}, {"id": "3090556797", "title": "A statistical interpretation of term specificity and its application in retrieval", "abstract": "The exhaustivity of document descriptions and the specificity of index terms are usually regarded as independent. It is suggested that specificity should be interpreted statistically, as a function of term use rather than of term meaning. The effects on retrieval of variations in term specificity are examined, experiments with three test collections showing, in particular, that frequently-occurring terms are required for good overall performance. It is argued that terms should be weighted according to collection frequency, so that matches on less frequent, more specific, terms are of greater value than matches on frequent terms. Results for the test collections show that considerable improvements in performance are obtained with this very simple procedure.", "authors": ["Karen Sparck Jones"], "related_topics": ["61797465", "2776291640", "5509825"], "citation_count": "4822", "reference_count": "41", "references": ["1978394996", "2043909051", "2075006521", "1602667807", "1979346010", "2058089741", "2107668593", "1988344511", "1980880163", "2045787043"], "date": "1988"}, {"id": "1689272351", "title": "A VLSI Architecture for Concurrent Data Structures", "abstract": "Concurrent data structures simplify the development of concurrent programs by encapsulating commonly used mechanisms for synchronization and communication into data structures. This thesis develops a notation for describing concurrent data structures, presents examples of concurrent data structures, and describes an architecture to support concurrent data structures. Concurrent Smalltalk (CST), a derivative of Smalltalk-80 with extensions for concurrency, is developed to describe concurrent data structures. CST allows the programmer to specify objects that are distributed over the nodes of a concurrent computer. These distributed objects have many constituent objects and thus can process many messages simultaneously. They are the foundation upon which concurrent data structures are built. The balanced cube is a concurrent data structure for ordered sets. The set is distributed by a balanced recursive partition that maps to the subcubes of a binary n-cube using a Gray code. A search algorithm, VW search, based on the distance properties of the Gray code, searches a balanced cube in O(logN) time. Because it does not have the root bottleneck that limits all tree-based data structures to O(1) concurrency, the balanced cube achieves O(N/logN) concurrency. Considering graphs as concurrent data structures, graph algorithms are presented for the shortest path problem, the max-flow problem, and graph partitioning. These algorithms introduce new synchronization techniques to achieve better performance than existing algorithms. A message-passing, concurrent architecture is developed that exploits the characteristics of VLSI technology to support concurrent data structures. Interconnection topologies are compared on the basis of dimension. It is shown that minimum latency is achieved with a very low dimensional network. A deadlock-free routing strategy is developed for this class of networks, and a prototype VLSI chip implementing this strategy is described. A message-driven processor complements the network by responding to messages with a very low latency. The processor directly executes messages, eliminating a level of interpretation. To take advantage of the performance offered by specialization while at the same time retaining flexibility, processing elements can be specialized to operate on a single class of objects. These object experts accelerate the performance of all applications using this class.", "authors": ["William James Dally"], "related_topics": ["203222032", "3701939", "193702766"], "citation_count": "293", "reference_count": "0", "references": ["2172212694", "2154323564", "2128087858", "1573851380", "2008041840", "2253935813", "2124241059", "2485370138", "2913785580", "2160454978"], "date": "1986"}, {"id": "2081332171", "title": "Comparison of collaborative filtering algorithms: Limitations of current techniques and proposals for scalable, high-performance recommender systems", "abstract": "The technique of collaborative filtering is especially successful in generating personalized recommendations. More than a decade of research has resulted in numerous algorithms, although no comparison of the different strategies has been made. In fact, a universally accepted way of evaluating a collaborative filtering algorithm does not exist yet. In this work, we compare different techniques found in the literature, and we study the characteristics of each one, highlighting their principal strengths and weaknesses. Several experiments have been performed, using the most popular metrics and algorithms. Moreover, two new metrics designed to measure the precision on good items have been proposed.The results have revealed the weaknesses of many algorithms in extracting information from user profiles especially under sparsity conditions. We have also confirmed the good results of SVD-based techniques already reported by other authors. As an alternative, we present a new approach based on the interpretation of the tendencies or differences between users and items. Despite its extraordinary simplicity, in our experiments, it obtained noticeably better results than more complex algorithms. In fact, in the cases analyzed, its results are at least equivalent to those of the best approaches studied. Under sparsity conditions, there is more than a 20p improvement in accuracy over the traditional user-based algorithms, while maintaining over 90p coverage. Moreover, it is much more efficient computationally than any other algorithm, making it especially adequate for large amounts of data.", "authors": ["Fidel Cacheda", "V\u00edctor Carneiro", "Diego Fern\u00e1ndez", "Vreixo Formoso"], "related_topics": ["557471498", "21569690", "48044578"], "citation_count": "537", "reference_count": "44", "references": ["2042281163", "1971040550", "2110325612", "1994389483", "3121531027", "2085937320", "2124591829", "1966553486", "2043403353", "2049455633"], "date": "2011"}, {"id": "2084812103", "title": "Dialogues Concerning Natural Religion", "abstract": "Humankind has pondered many mysteries, but few more enticing than the existence of a divine creator who is said to have set the universe in motion. Imitating the well-known style of Platonic dialogues, the relentless inquirer and empiricist David Hume assembles a group to discuss the existence of God, his divine nature, his attributes, and the point of his creation. How do we come to have knowledge of God? Who has the burden of proof with respect to these matters of intense religious significance, and what sort of proof might gain universal assent? Can one argue from the orderliness of the universe to the conclusion that it must have had a purposeful creator at its helm? Hume has captured the nature of this intense debate in a classic work that has stood the test of time.", "authors": ["David Hume"], "related_topics": ["2776971825", "2776326447", "10038465"], "citation_count": "1126", "reference_count": "0", "references": ["1973826788", "2007179372", "2170504163", "1583306982", "2997435195", "1978692170", "2157439430", "2149140482", "2098940518", "3124116706"], "date": "2019"}, {"id": "2097028840", "title": "Noun Phrase Interpretation and Type\u2010shifting Principles", "abstract": "", "authors": ["Barbara H. Partee"], "related_topics": ["153962237", "88880766", "131042201"], "citation_count": "1786", "reference_count": "11", "references": ["1581218697", "2100513762", "3140168455", "2023460305", "2034277978", "2034034435", "2047106761", "116749288", "1969064559", "1504212504"], "date": "2008"}, {"id": "2017337590", "title": "Wrappers for feature subset selection", "abstract": "Abstract In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.", "authors": ["Ron Kohavi", "George H. John"], "related_topics": ["148483581", "16811321", "2776012861"], "citation_count": "10177", "reference_count": "122", "references": ["1639032689", "3124955340", "2912934387", "2122410182", "2084812512", "2125055259", "1594031697", "2149706766", "2340020088", "1680392829"], "date": "1997"}, {"id": "2964237352", "title": "Persistence images: a stable vector representation of persistent homology", "abstract": "Many data sets can be viewed as a noisy sampling of an underlying space, and tools from topological data analysis can characterize this structure for the purpose of knowledge discovery. One such tool is persistent homology, which provides a multiscale description of the homological features within a data set. A useful representation of this homological information is a persistence diagram (PD). Efforts have been made to map PDs into spaces with additional structure valuable to machine learning tasks. We convert a PD to a finite-dimensional vector representation which we call a persistence image (PI), and prove the stability of this transformation with respect to small perturbations in the inputs. The discriminatory power of PIs is compared against existing methods, showing significant performance gains. We explore the use of PIs with vector-based machine learning tools, such as linear sparse support vector machines, which identify features containing discriminating topological information. Finally, high accuracy inference of parameter values from the dynamic output of a discrete dynamical system (the linked twist map) and a partial differential equation (the anisotropic Kuramoto-Sivashinsky equation) provide a novel application of the discriminatory power of PIs.", "authors": ["Henry Adams", "Tegan Emerson", "Michael Kirby", "Rachel Neville", "Chris Peterson", "Patrick Shipman", "Sofya Chepushtanova", "Eric Hanson", "Francis Motta", "Lori Ziegelmeier"], "related_topics": ["2874115", "2776477805", "112972136"], "citation_count": "300", "reference_count": "46", "references": ["3040586665", "2113242816", "2147141800", "3140579943", "1991566301", "2083620785", "2037613900", "2071391326", "2149185044", "2130698119"], "date": "2016"}, {"id": "2281492572", "title": "The development and psychometric properties of LIWC2007", "abstract": "", "authors": ["James W Pennebaker", "Cindy K Chung", "Molly Ireland", "Amy Gonzales", "Roger J Booth"], "related_topics": ["70410870", "2776542497", "15744967"], "citation_count": "843", "reference_count": "109", "references": ["2118020653", "1581387623", "2148905283", "2097780989", "2019413183", "1791787674", "2166183437", "2100772444", "2091034860", "2106695994"], "date": "2006"}, {"id": "2069489095", "title": "Routing, merging, and sorting on parallel models of computation", "abstract": "Abstract A variety of models have been proposed for the study of synchronous parallel computation. These models are reviewed and some prototype problems are studied further. Two classes of models are recognized, fixed connection networks and models based on a shared memory. Routing and sorting are prototype problems for the networks; in particular, they provide the basis for simulating the more powerful shared memory models. It is shown that a simple but important class of deterministic strategies (oblivious routing) is necessarily inefficient with respect to worst case analysis. Routing can be viewed as a special case of sorting, and the existence of an O (log n ) sorting algorithm for some n processor fixed connection network has only recently been established by Ajtai, Komlos, and Szemeredi (\u201c15th ACM Sympos. on Theory of Comput.,\u201d Boston, Mass., 1983, pp. 1\u20139). If the more powerful class of shared memory models is considered then it is possible to simply achieve an O (log n loglog n ) sort via Valiant's parallel merging algorithm, which it is shown can be implemented on certain models. Within a spectrum of shared memory models, it is shown that loglog n is asymptotically optimal for n processors to merge two sorted lists containing n elements.", "authors": ["A. Borodin", "J. E. Hopcroft"], "related_topics": ["108094655", "133875982", "184596265"], "citation_count": "790", "reference_count": "21", "references": ["2060270693", "1976284552", "2076458424", "2004618348", "1977908721", "1836810876", "2089828587", "2058355999", "2089062581", "1972897119"], "date": "1985"}, {"id": "2045682702", "title": "Introduction to applied mathematics", "abstract": "Introduction to applied mathematics , Introduction to applied mathematics , \u0645\u0631\u06a9\u0632 \u0641\u0646\u0627\u0648\u0631\u06cc \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u0648 \u0627\u0637\u0644\u0627\u0639 \u0631\u0633\u0627\u0646\u06cc \u06a9\u0634\u0627\u0648\u0631\u0632\u06cc", "authors": ["G. Strang", "L. B. Freund"], "related_topics": ["118840557", "508216123", "203444496"], "citation_count": "2240", "reference_count": "0", "references": ["2139212933", "2134820502", "2141870784", "2137226992", "1988878180", "2166765763", "2160715448", "2159736423", "2042243448", "2144668858"], "date": "1985"}, {"id": "2135547275", "title": "Rules and Representations", "abstract": "Foreword by Norbert Hornstein Preface Part I 1. Mind and Body 2. Structures, Capacities, and Conventions 3. Knowledge of Grammar 4. Some Elements of Grammar Part II 5. On the Biological Basis of Language Capacities 6. Language and Unconscious Knowledge Notes Index", "authors": ["Noam A. Chomsky"], "related_topics": ["69298649", "39890363", "26022165"], "citation_count": "7618", "reference_count": "133", "references": ["2052417512", "2164934677", "2039107287", "2170716495", "2005814556", "2130355536", "1989304657", "2141538250", "1981724541", "1582364809"], "date": "1979"}, {"id": "2078206416", "title": "The Fractal Geometry of Nature", "abstract": "\"...a blend of erudition (fascinating and sometimes obscure historical minutiae abound), popularization (mathematical rigor is relegated to appendices) and exposition (the reader need have little knowledge of the fields involved) ...and the illustrations include many superb examples of computer graphics that are works of art in their own right.\" Nature", "authors": ["Benoit B. Mandelbrot"], "related_topics": ["60396315", "22184971", "2776285698"], "citation_count": "65384", "reference_count": "0", "references": ["1746819321", "2124637492", "2132984323", "1976969221", "2090037139", "1544329015", "2105818147", "2136913207", "2136931666", "2111271983"], "date": "1981"}, {"id": "1979459060", "title": "Quary Expansion Using Local and Global Document Analysis", "abstract": "Automatic query expansion has long been suggested as a technique for dealing with the fundamental issue of word mismatch in information retrieval. A number of approaches to expansion have been studied and, more recently, attention has focused on techniques that analyze the corpus to discover word relationship (global techniques) and those that analyze documents retrieved by the initial query ( local feedback). In this paper, we compare the effectiveness of these approaches and show that, although global analysis haa some advantages, local analysia is generally more effective. We also show that using global analysis techniques.", "authors": ["Jinxi Xu", "W. Bruce Croft"], "related_topics": ["99016210", "192028432", "61249035"], "citation_count": "1986", "reference_count": "16", "references": ["2147152072", "2105106523", "1987996059", "2887107689", "2019509999", "1554385128", "1515865104", "1980515494", "2439017901", "2568598316"], "date": "1996"}, {"id": "2126399065", "title": "Data-Intensive Text Processing with MapReduce", "abstract": "This half-day tutorial introduces participants to data-intensive text processing with the MapReduce programming model [1], using the open-source Hadoop implementation. The focus will be on scalability and the tradeoffs associated with distributed processing of large datasets. Content will include general discussions about algorithm design, presentation of illustrative algorithms, case studies in HLT applications, as well as practical advice in writing Hadoop programs and running Hadoop clusters.", "authors": ["Jimmy Lin", "Chris Dyer"], "related_topics": ["76831024", "2779500292", "34165917"], "citation_count": "840", "reference_count": "166", "references": ["2173213060", "2131629857", "2112090702", "2131726714", "1532325895", "2124637492", "2147880316", "1977367431", "1981420413", "2119565742"], "date": "2010"}, {"id": "2108770909", "title": "Polar Opposition and the Ontology of `Degrees'", "abstract": "This paper uses the distribution and interpretation of antonymous adjectives in comparative constructions as an empirical basis to argue that abstract representations of measurement, or \u2018degrees\u2019, must be modeled as intervals on a scale, rather than as points, as commonly assumed. I begin by demonstrating that the facts in this domain must be accounted for in terms of the interaction of the semantics of adjectival polarity and the semantics of the comparative, rather than principles governing the (overt) expression of particular types of adjectives in comparatives. I then show that a principled account of the full range of data under consideration can be constructed within a model in which degrees are formalized as intervals on a scale and adjectival polarity is characterized in terms of two structurally distinct and complementary sorts of `positive' and `negative' degrees.", "authors": ["Christopher Kennedy"], "related_topics": ["98202634", "2777683214", "5509825"], "citation_count": "432", "reference_count": "42", "references": ["2523440281", "2026725080", "2087099129", "2124374458", "1488267121", "50483736", "7270768", "2154755429", "2026043881", "620840771"], "date": "2001"}, {"id": "2012837062", "title": "Deducing linguistic structure from the statistics of large corpora", "abstract": "Within the last two years, approaches using both stochastic and symbolic techniques have proved adequate to deduce lexical ambiguity resolution rules with less than 3-4% error rate, when trained on moderate sized (500K word) corpora of English text (e.g. Church, 1988; Hindle, 1989). The success of these techniques suggests that much of the grammatical structure of language may be derived automatically through distributional analysis, an approach attempted and abandoned in the 1950s.", "authors": ["Eric Brill", "David Magerman", "Mitchell Marcus", "Beatrice Santorini"], "related_topics": ["40969351", "204321447", "191617201"], "citation_count": "224", "reference_count": "12", "references": ["2099247782", "1593045043", "2134237567", "1483126227", "2110190189", "3044664353", "2034274945", "2126477387", "1528321674", "2065585771"], "date": "1990"}, {"id": "2069613886", "title": "Scholarly Communication and Bibliometrics", "abstract": "Frontispiece - Derek J de Solla Price Introduction - Christine L Borgman PART ONE: THEORY AND PERSPECTIVE Understanding Science - Belver C Griffith Studies of Communication and Information Disciplinary Work and Interdisciplinary Areas - Sydney J Pierce Sociology and Bibliometrics Reconciling Structure and Process in the Study of Scholarly Communication - Leah A Lievrouw PART TWO: BIBLIOMETRIC RESEARCH METHODS A View of Studies on Bibliometrics and Related Subjects in Japan - S Miyamoto, N Midorikawa and K Nakayama Author Co-citation Studies - Howard D White Overview and Defense Who Carries the Field? Communication Between Literary Schools and Critics - Karl Erik Rosengren The Absence of Co-citation as a Clue to Undiscovered Causal Connections - Don R Swanson Hierarchies and Clusters Among Communication and Library and Information Science Journals, 1977 - 1987 - Ronald E Rice PART THREE: EMPIRICAL STUDIES An Author Co-citation Analysis of Two Research Traditions - Everett M Rogers and Charlotte A Cottrill Technology Transfer and the Diffusion of Innovations A Co-citation Study of AIDS Research - Henry Small and Edwin Greenlee Mapping Authors in Intellectual Space - Katherine W McCain Population Genetics in the 1980s International Scientific Cooperation and Awareness - H F Moed and R E DeBruin A Bibliometric Case Study of Agricultural Research Within the European Community Core Journals of the Rapidly Changing Research Front of \"Superconductivity\" - Terrance A Brooks Editors-in-Chief of Medical Journals - S Zsindely and A Schubert Identifying the Important Theorists of Communication - James R Beniger Use of Latent Measures to Test Manifest Assumptions in Scholarly Communication Conclusions - William Paisley The Future of Bibliometrics", "authors": ["Christine L. Borgman", "Jonathan Furner"], "related_topics": ["178315738", "2777462167", "105345328"], "citation_count": "1053", "reference_count": "195", "references": ["2112090702", "2008620264", "3013264884", "2138621811", "2769133055", "2175110005", "3125161049", "2147164982", "2154498027", "2129620481"], "date": "2005"}, {"id": "1910000781", "title": "Method and apparatus for detecting free fall", "abstract": "A data processing system including a data storage device having data stored on a data storage medium. Within said data processing system, a system electronics is operatively coupled to a sensor and to said data storage device. When the sensor senses a change in gravitational or inertial acceleration of said data processing system, it alerts system electronics to temporarily park a read/write head in a safe position.", "authors": ["Paul James Wehrenberg"], "related_topics": ["112118009", "194739806", "138331895"], "citation_count": "223", "reference_count": "49", "references": ["2108025625", "2816441015", "1927836086", "1822247641", "2147554423", "2818761848", "2111765369", "2856857306", "2565619261", "2404137995"], "date": "2003"}, {"id": "2117537207", "title": "Design aspects of network assisted device-to-device communications", "abstract": "Device-to-device (D2D) communications underlaying a cellular infrastructure has been proposed as a means of taking advantage of the physical proximity of communicating devices, increasing resource utilization, and improving cellular coverage. Relative to the traditional cellular methods, there is a need to design new peer discovery methods, physical layer procedures, and radio resource management algorithms that help realize the potential advantages of D2D communications. In this article we use the 3GPP Long Term Evolution system as a baseline for D2D design, review some of the key design challenges, and propose solution approaches that allow cellular devices and D2D pairs to share spectrum resources and thereby increase the spectrum and energy efficiency of traditional cellular networks. Simulation results illustrate the viability of the proposed design.", "authors": ["G. Fodor", "E. Dahlman", "G. Mildh", "S. Parkvall", "N. Reider", "G. Miklo\u0301s", "Z. Tura\u0301nyi"], "related_topics": ["153646914", "9765861", "56685638"], "citation_count": "1622", "reference_count": "10", "references": ["2140656373", "2026860654", "2100372817", "2156858898", "1975186862", "2096820671", "2104137227", "2079334758", "2101232420", "2169483051"], "date": "2012"}, {"id": "2049107599", "title": "Automatic recognition of multi-word terms:. the C-value/NC-value method", "abstract": "Technical terms (henceforth called terms ), are important elements for digital libraries. In this paper we present a domain-independent method for the automatic extraction of multi-word terms, from machine-readable special language corpora. The method, (C-value/NC-value ), combines linguistic and statistical information. The first part, C-value, enhances the common statistical measure of frequency of occurrence for term extraction, making it sensitive to a particular type of multi-word terms, the nested terms. The second part, NC-value, gives: 1) a method for the extraction of term context words (words that tend to appear with terms); 2) the incorporation of information from term context words to the extraction of terms.", "authors": ["Katerina T. Frantzi", "Sophia Ananiadou", "Hideki Mima"], "related_topics": ["2781183675", "61797465", "2780049985"], "citation_count": "1017", "reference_count": "14", "references": ["1956559956", "2116780029", "2163953154", "2044070623", "1554031433", "2107434887", "1537280846", "2116266212", "2075728986", "1537288903"], "date": "2000"}, {"id": "1490632837", "title": "Pyramid-based texture analysis/synthesis", "abstract": "This paper describes a method for synthesizing images that match the texture appearance of a given digitized sample. This synthesis is completely automatic and requires only the \"target\" texture as input. It allows generation of as much texture as desired so that any object can be covered. The approach is based on a model of human texture perception, and has potential to be a practically useful tool for image processing and graphics applications.", "authors": ["D.J. Heeger", "J.R. Bergen"], "related_topics": ["207183524", "144743038", "54243161"], "citation_count": "2020", "reference_count": "17", "references": ["1490632837", "2107790757", "2041752335", "2042755403", "2065301447", "2522324076", "2162413715", "2162703509", "2563709626", "2113834765"], "date": "1995"}, {"id": "2141487810", "title": "End-to-end routing behavior in the Internet", "abstract": "The large-scale behavior of routing In the Internet has gone virtually without any formal study, the exceptions being Chinoy's (1993) analysis of the dynamics of Internet routing information, and work, similar in spirit, by Labovitz, Malan, and Jahanian (see Proc. SIGCOMM'97, 1997). We report on an analysis of 40000 end-to-end route measurements conducted using repeated \"traceroutes\" between 37 Internet sites. We analyze the routing behavior for pathological conditions, routing stability, and routing symmetry. For pathologies, we characterize the prevalence of routing loops, erroneous routing, infrastructure failures, and temporary outages. We find that the likelihood of encountering a major routing pathology more than doubled between the end of 1994 and the end of 1995, rising from 1.5% to 3.3%. For routing stability, we define two separate types of stability, \"prevalence\", meaning the overall likelihood that a particular route is encountered, and \"persistence\", the likelihood that a route remains unchanged over a long period of time. We find that Internet paths are heavily dominated by a single prevalent route, but that the time periods over which routes persist show wide variation, ranging from seconds up to days. About two-thirds of the Internet paths had routes persisting for either days or weeks. For routing symmetry, we look at the likelihood that a path through the Internet visits at least one different city in the two directions. At the end of 1995, this was the case half the time, and at least one different autonomous system was visited 30% of the time.", "authors": ["Vern Paxson"], "related_topics": ["204948658", "101396714", "115443555"], "citation_count": "2118", "reference_count": "46", "references": ["1731982387", "2115770629", "2145721479", "2156725431", "2102907001", "2079994203", "1627303300", "2050353731", "2103312864", "2799087070"], "date": "1997"}, {"id": "2001088254", "title": "ESPRIT-estimation of signal parameters via rotational invariance techniques", "abstract": "High-resolution signal parameter estimation is a problem of significance in many signal processing applications. Such applications indude direction-of-arrival estimation, system identification, and time series analysis. A novel approach to the general problem of signal parameter estimation is described. Although discussed in the context of directionof- arrival estimation, ESPRIT can be applied to a wide variety of problems. It exploits an underlying rotational invariance among signal subspaces induced by an array of sensors with a translational invariance structure. The technique, when applicable, manifests significant performance and computational advantages over previous algorithms such as Burg's maximum entropy method, Capon's maximum likelihood method, and Schmidt's multiple signal classification.", "authors": ["R. Roy", "T. Kailath"], "related_topics": ["2780414254", "167928553", "33098168"], "citation_count": "7814", "reference_count": "0", "references": ["2001088254", "2064959416", "2123930706", "2130601302", "2157050350", "2111279618", "2151517138", "2041050174", "2070222581", "2139419267"], "date": "1990"}, {"id": "2103752582", "title": "Bose\u2013Einstein condensation of photons in an optical microcavity", "abstract": "Bose\u2013Einstein condensation has been observed in several physical systems, but is not predicted to occur for blackbody radiation such as photons. However, it becomes theoretically possible in the presence of thermalization processes that conserve photon number. Martin Weitz and colleagues have now realized such conditions experimentally, observing Bose\u2013Einstein condensation of photons in a dye-filled optical microcavity. The effect is of interest for fundamental studies and may lead to new coherent ultraviolet sources. Bose\u2013Einstein condensation has been observed in several physical systems, but is not predicted to occur for blackbody radiation such as photons. However, it becomes theoretically possible in the presence of thermalization processes that conserve photon number. These authors experimentally realise such conditions, observing Bose\u2013Einstein condensation of photons in a dye-filled optical microcavity. The effect is of interest for fundamental studies and may lead to new coherent ultraviolet sources. Bose\u2013Einstein condensation (BEC)\u2014the macroscopic ground-state accumulation of particles with integer spin (bosons) at low temperature and high density\u2014has been observed in several physical systems1,2,3,4,5,6,7,8,9, including cold atomic gases and solid-state quasiparticles. However, the most omnipresent Bose gas, blackbody radiation (radiation in thermal equilibrium with the cavity walls) does not show this phase transition. In such systems photons have a vanishing chemical potential, meaning that their number is not conserved when the temperature of the photon gas is varied10; at low temperatures, photons disappear in the cavity walls instead of occupying the cavity ground state. Theoretical works have considered thermalization processes that conserve photon number (a prerequisite for BEC), involving Compton scattering with a gas of thermal electrons11 or photon\u2013photon scattering in a nonlinear resonator configuration12,13. Number-conserving thermalization was experimentally observed14 for a two-dimensional photon gas in a dye-filled optical microcavity, which acts as a \u2018white-wall\u2019 box. Here we report the observation of a Bose\u2013Einstein condensate of photons in this system. The cavity mirrors provide both a confining potential and a non-vanishing effective photon mass, making the system formally equivalent to a two-dimensional gas of trapped, massive bosons. The photons thermalize to the temperature of the dye solution (room temperature) by multiple scattering with the dye molecules. Upon increasing the photon density, we observe the following BEC signatures: the photon energies have a Bose\u2013Einstein distribution with a massively populated ground-state mode on top of a broad thermal wing; the phase transition occurs at the expected photon density and exhibits the predicted dependence on cavity geometry; and the ground-state mode emerges even for a spatially displaced pump spot. The prospects of the observed effects include studies of extremely weakly interacting low-dimensional Bose gases9 and new coherent ultraviolet sources15.", "authors": ["Jan Klaers", "Julian Schmitt", "Frank Vewinger", "Martin Weitz"], "related_topics": ["204514805", "149337919", "62605544"], "citation_count": "777", "reference_count": "35", "references": ["2129995310", "2029715417", "1991602497", "2978343398", "2080769419", "3012119400", "2023858603", "2047049884", "2060198363", "2070250156"], "date": "2010"}, {"id": "1579937068", "title": "Identity Effects in Morphological Truncation", "abstract": "Morphologically truncated words may be phonologically irregular, constituting a class of exceptions to regular surface patterns.1 In this paper I propose that phonological irregularities in truncated words are identity effects forced by constraints demanding identity between truncated forms and their source words. These constraints, which are ranked and violable in the Optimality Theory model (Prince & Smolensky 1993), regulate the correspondence relation between the source word base and the truncated form, in the same way that faithfulness constraints require identity of base and copy in reduplicated words (McCarthy & Prince 1993a et seq.). I will show that truncated words mimic derived properties of their sources, and conclude that truncatory correspondence is a relation between two output forms. Building on proposals in McCarthy & Prince (1994b, 1995), this analysis of truncatory identity extends Correspondence Theory beyond basereduplicant and input-output relations, establishing correspondence between separate words.", "authors": ["Laura Benua"], "related_topics": ["2781082764", "2779511057", "90805587"], "citation_count": "375", "reference_count": "47", "references": ["1533473429", "1598851216", "1911232923", "1591993017", "2064318101", "1590251447", "2111523402", "2090266881", "1869853578", "2798490496"], "date": "1995"}, {"id": "2105818147", "title": "On the self-similar nature of Ethernet traffic (extended version)", "abstract": "Demonstrates that Ethernet LAN traffic is statistically self-similar, that none of the commonly used traffic models is able to capture this fractal-like behavior, that such behavior has serious implications for the design, control, and analysis of high-speed, cell-based networks, and that aggregating streams of such traffic typically intensifies the self-similarity (\"burstiness\") instead of smoothing it. These conclusions are supported by a rigorous statistical analysis of hundreds of millions of high quality Ethernet traffic measurements collected between 1989 and 1992, coupled with a discussion of the underlying mathematical and statistical properties of self-similarity and their relationship with actual network behavior. The authors also present traffic models based on self-similar stochastic processes that provide simple, accurate, and realistic descriptions of traffic scenarios expected during B-ISDN deployment. >", "authors": ["Will E. Leland", "Murad S. Taqqu", "Walter Willinger", "Daniel V. Wilson"], "related_topics": ["176715033", "113804518", "15970080"], "citation_count": "9496", "reference_count": "50", "references": ["2078206416", "2114001875", "2012712694", "2128796442", "2115122866", "2158712333", "109793532", "2165551776", "2121529758", "2798058877"], "date": "1994"}, {"id": "114088334", "title": "Private Set Intersection: Are Garbled Circuits Better than Custom Protocols?", "abstract": "Cryptographic protocols for Private Set Intersection (PSI) are the basis for many important privacy-preserving applications. Over the past few years, intensive research has been devoted to designing custom protocols for PSI based on homomorphic encryption and other public-key techniques, apparently due to the belief that solutions using generic approaches would be impractical. This paper explores the validity of that belief. We develop three classes of protocols targeted to different set sizes and domains, all based on Yao\u2019s generic garbled-circuit method. We then compare the performance of our protocols to the fastest custom PSI protocols in the literature. Our results show that a careful application of garbled circuits leads to solutions that can run on million-element sets on typical desktops, and that can be competitive with the fastest custom protocols. Moreover, generic protocols like ours can be used directly for performing more complex secure computations, something we demonstrate by adding a simple information-auditing mechanism to our PSI protocols.", "authors": ["Yan Huang", "David Evans", "Jonathan Katz"], "related_topics": ["33884865", "158338273", "177264268"], "citation_count": "319", "reference_count": "39", "references": ["1548880861", "2585483317", "2119948977", "1480225633", "1521253015", "1485800369", "1826277484", "1982146060", "2143824669", "2088492763"], "date": "2011"}, {"id": "2137622193", "title": "Mondrian memory protection", "abstract": "Mondrian memory protection (MMP) is a fine-grained protection scheme that allows multiple protection domains to flexibly share memory and export protected services. In contrast to earlier page-based systems, MMP allows arbitrary permissions control at the granularity of individual words. We use a compressed permissions table to reduce space overheads and employ two levels of permissions caching to reduce run-time overheads. The protection tables in our implementation add less than 9% overhead to the memory space used by the application. Accessing the protection tables adds than 8% additional memory references to the accesses made by the application. Although it can be layered on top of demand-paged virtual memory, MMP is also well-suited to embedded systems with a single physical address space. We extend MMP to support segment translation which allows a memory segment to appear at another location in the address space. We use this translation to implement zero-copy networking underneath the standard read system call interface, where packet payload fragments are connected together by the translation system to avoid data copying. This saves 52% of the memory references used by a traditional copying network stack.", "authors": ["Emmett Witchel", "Josh Cates", "Krste Asanovi\u0107"], "related_topics": ["18131444", "176649486", "74426580"], "citation_count": "415", "reference_count": "58", "references": ["2034711041", "2120230074", "1579850852", "2083469471", "2153950928", "2079029390", "2154207621", "1825457006", "2149984854", "2153904572"], "date": "2002"}, {"id": "2104505229", "title": "Method and device for operating mobile terminal based on sensor, and mobile terminal", "abstract": "A method for operating a mobile terminal based on a sensor is disclosed. The method includes: a sensor is triggered according to a preset trigger rule to make the sensor output a digital signal corresponding to the trigger rule; after receiving the digital signal which is corresponding to the trigger rule and is output from the sensor, ab operation type, which is corresponding to the digital signal, of the mobile terminal is determined; and a corresponding operation process is performed on the mobile terminal according to the operation type. The disclosure also provides a corresponding device and a mobile terminal including the device. The method for operating the mobile terminal based on the sensor provided in the disclosure completes power-on/off, wakeup, sleep and other operations on the mobile terminal through the sensor, so as to bring better use experience to a user while making the structure of the mobile terminal simpler.", "authors": ["Chuangye Shen", "Litian Liu", "Xiaomin Sun"], "related_topics": ["137921213", "207029474", "2777782449"], "citation_count": "21", "reference_count": "14", "references": ["1777897946", "1545482740", "945583746", "2877139772", "2835124161", "2853149405", "2866871669", "2868684096", "2569542151", "1777024049"], "date": "2012"}, {"id": "2963373786", "title": "Improved techniques for training GANs", "abstract": "We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.", "authors": ["Tim Salimans", "Ian Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen"], "related_topics": ["190502265", "178980831", "577917"], "citation_count": "4731", "reference_count": "20", "references": ["1836465849", "2183341477", "2963684088", "2964153729", "2271840356", "648143168", "2949416428", "2963685250", "830076066", "1487641199"], "date": "2016"}, {"id": "2106334424", "title": "Multiobjective evolutionary algorithms: a comparative case study and the strength Pareto approach", "abstract": "Evolutionary algorithms (EAs) are often well-suited for optimization problems involving several, often conflicting objectives. Since 1985, various evolutionary approaches to multiobjective optimization have been developed that are capable of searching for multiple solutions concurrently in a single run. However, the few comparative studies of different methods presented up to now remain mostly qualitative and are often restricted to a few approaches. In this paper, four multiobjective EAs are compared quantitatively where an extended 0/1 knapsack problem is taken as a basis. Furthermore, we introduce a new evolutionary approach to multicriteria optimization, the strength Pareto EA (SPEA), that combines several features of previous multiobjective EAs in a unique manner. It is characterized by (a) storing nondominated solutions externally in a second, continuously updated population, (b) evaluating an individual's fitness dependent on the number of external nondominated points that dominate it, (c) preserving population diversity using the Pareto dominance relationship, and (d) incorporating a clustering procedure in order to reduce the nondominated set without destroying its characteristics. The proof-of-principle results obtained on two artificial problems as well as a larger problem, the synthesis of a digital hardware-software multiprocessor system, suggest that SPEA can be very effective in sampling from along the entire Pareto-optimal front and distributing the generated solutions over the tradeoff surface. Moreover, SPEA clearly outperforms the other four multiobjective EAs on the 0/1 knapsack problem.", "authors": ["E. Zitzler", "L. Thiele"], "related_topics": ["159149176", "68781425", "105902424"], "citation_count": "8566", "reference_count": "45", "references": ["1639032689", "1497256448", "2125899728", "2151554678", "2116661285", "1504943474", "1905847227", "2121365620", "2261054240", "1558919105"], "date": "1999"}, {"id": "2171181782", "title": "Multichannel texture analysis using localized spatial filters", "abstract": "A computational approach for analyzing visible textures is described. Textures are modeled as irradiance patterns containing a limited range of spatial frequencies, where mutually distinct textures differ significantly in their dominant characterizing frequencies. By encoding images into multiple narrow spatial frequency and orientation channels, the slowly varying channel envelopes (amplitude and phase) are used to segregate textural regions of different spatial frequency, orientation, or phase characteristics. Thus, an interpretation of image texture as a region code, or carrier of region information, is emphasized. The channel filters used, known as the two-dimensional Gabor functions, are useful for these purposes in several senses: they have tunable orientation and radial frequency bandwidths and tunable center frequencies, and they optimally achieve joint resolution in space and in spatial frequency. By comparing the channel amplitude responses, one can detect boundaries between textures. Locating large variations in the channel phase responses allows discontinuities in the texture phase to be detected. Examples are given of both types of texture processing using a variety of real and synthetic textures. >", "authors": ["A.C. Bovik", "M. Clark", "W.S. Geisler"], "related_topics": ["9095184", "100921725", "63099799"], "citation_count": "2216", "reference_count": "59", "references": ["2911709767", "2003370853", "2044465660", "2006500012", "2103384342", "2059432853", "2108992228", "1756736144", "2155487652", "2032533296"], "date": "1989"}, {"id": "2028962062", "title": "Evaluating text categorization", "abstract": "While certain standard procedures are widely used for evaluating text retrieval systems and algorithms, the same is not true for text categorization. Omission of important data from reports is common and methods of measuring effectiveness vary widely. This has made judging the relative merits of techniques for text categorization difficult and has disguised important research issues.In this paper I discuss a variety of ways of evaluating the effectiveness of text categorization systems, drawing both on reported categorization experiments and on methods used in evaluating query-driven retrieval. I also consider the extent to which the same evaluation methods may be used with systems for text extraction, a more complex task. In evaluating either kind of system, the purpose for which the output is to be used is crucial in choosing appropriate evaluation methods.", "authors": ["David D. Lewis"], "related_topics": ["94124525", "23123220", "136197465"], "citation_count": "393", "reference_count": "17", "references": ["2079690930", "2095396650", "2008444575", "1517322531", "2066193647", "26282181", "1999869955", "2144845931", "1550961891", "2009190245"], "date": "1991"}, {"id": "2086172019", "title": "On the Recognition of Information With a Digital Computer", "abstract": "There exists a vast discrepancy in the power of discrimination exercised by a digital computer and in that of a human being. The recognition of information or data patterns is a simple task for the least experienced human clerk. Most people possess sufficiently sophisticated recognition capabilities so that a variation in the pattern of the data under scrutiny will not cause undue difficulty in the discrimination process. The recognition powers of a digital computer, however, are best demonstrated in an elementary table lookup operation, wherein the subject information is required to match exactly with a portion of the master list in order to be \u201crecognized\u201d. Machine recognition of data which is allowed to vary from the predetermined digital pattern is a vastly more complex problem. Since digital computers are inherently devices which are capable of only YES or NO answers, all MAYBE or PERHAPS responses are obtained only through painstaking effort. If the variations in the subject data are allowed a reasonable range in both position and type, there is no complete solution of the recognition problem available with present techniques and equipments. This paper will outline the general recognition problem in terms of a set of definitions and a mathematical model. I believe that a useful formulation of the problem, and a comprehension of the difficulties involved in discrimination, are prerequisites to any effort at obtaining a complete solution to the problem of data recognition.", "authors": ["Herbert T. Glantz"], "related_topics": ["44868376", "132900626", "177264268"], "citation_count": "30", "reference_count": "0", "references": ["2008819433", "2111192396", "2209732303", "2066102695", "2066792529", "2061681083", "2161123931", "2062235741", "2094953319", "2040717770"], "date": "1957"}, {"id": "2128572087", "title": "LINCS : A linear constraint solver for molecular simulations", "abstract": "In this article, we present a new LINear Constraint Solver (LINCS) for molecular simulations with bond constraints. The algorithm is inherently stable, as the constraints themselves are reset instead of derivatives of the constraints, thereby eliminating drift. Although the derivation of the algorithm is presented in terms of matrices, no matrix matrix multiplications are needed and only the nonzero matrix elements have to be stored, making the method useful for very large molecules. At the same accuracy, the LINCS algorithm is three to four times faster than the SHAKE algorithm. Parallelization of the algorithm is straightforward. (C) 1997 John Wiley & Sons, Inc.", "authors": ["Berk Hess", "Henk Bekker", "Herman J. C. Berendsen", "Johannes G. E. M. Fraaije"], "related_topics": ["17349429", "137127113", "199622910"], "citation_count": "11701", "reference_count": "12", "references": ["1981021420", "2103945336", "2106140689", "2011795318", "2149489299", "1994782559", "1980743549", "2109954383", "2951352984", "2156283242"], "date": "1997"}, {"id": "2165944385", "title": "Modeling and Analysis of Generalized Slotted-Aloha MAC Protocols in Cooperative, Competitive and Adversarial Environments", "abstract": "Aloha [1] and its slotted variant [2] are commonly deployed Medium Access Control (MAC) protocols in environments where multiple transmitting devices compete for a medium, yet may have difficulty sensing each other\u0092s presence. This paper models and evaluates the throughput that can be achieved in a system where nodes compete for bandwidth using a generalized version of slotted- Aloha protocols. We evaluate the channel utilization and fairness of these types of protocols for a variety of node objectives, including maximizing aggregate throughput of the channel, each node greedily maximizing its own throughput, and attacker nodes that attempt to jam the channel. If all nodes are selfish and greedily attempt to maximize their own throughputs, a situation similar to the traditional Prisoner\u0092s Dilemma[3] arises. Our results reveal that under heavy loads, greedy strategies reduce the utilization, and that attackers cannot do much better than attacking during randomly selected slots.", "authors": ["R.T.B. Ma", "V. Misra", "D. Rubenstein"], "related_topics": ["2776398200", "156643399", "157764524"], "citation_count": "62", "reference_count": "18", "references": ["2613173048", "2109100253", "2116682091", "109793532", "2100954602", "2010359062", "2044567090", "2162067775", "1605869111", "2151894309"], "date": "2006"}, {"id": "134171312", "title": "Content-Based Image Retrieval Based on Local Affinely Invariant Regions", "abstract": "This contribution develops a new technique for content-based image retrieval. Where most existing image retrieval systems mainly focus on color and color distribution or texture, we classify the images based on local invariants. These features represent the image in a very compact way and allow fast comparison and feature matching with images in the database. Using local features makes the system robust to occlusions and changes in the background. Using invariants makes it robust to changes in viewpoint and illumination.", "authors": ["Tinne Tuytelaars", "Luc J. Van Gool"], "related_topics": ["2780052074", "189391414", "63099799"], "citation_count": "337", "reference_count": "11", "references": ["2914885528", "2124087378", "2160835070", "2089366864", "2059871232", "2012515212", "2113593239", "1842680244", "1567192334", "2082602245"], "date": "1999"}, {"id": "1964857063", "title": "On random sampling over joins", "abstract": "A major bottleneck in implementing sampling as a primitive relational operation is the inefficiency of sampling the output of a query. It is not even known whether it is possible to generate a sample of a join tree without first evaluating the join tree completely. We undertake a detailed study of this problem and attempt to analyze it in a variety of settings. We present theoretical results explaining the difficulty of this problem and setting limits on the efficiency that can be achieved. Based on new insights into the interaction between join and sampling, we develop join sampling techniques for the settings where our negative results do not apply. Our new sampling algorithms are significantly more efficient than those known earlier. We present experimental evaluation of our techniques on Microsoft's SQL Server 7.0.", "authors": ["Surajit Chaudhuri", "Rajeev Motwani", "Vivek Narasayya"], "related_topics": ["90842384", "2778692605", "101056560"], "citation_count": "408", "reference_count": "13", "references": ["2295428206", "2296677182", "2119885577", "2118229812", "2026896584", "2090403603", "2000154402", "1592355944", "2165906949", "2079656678"], "date": "1999"}, {"id": "2130942839", "title": "Sequence to Sequence Learning with Neural Networks", "abstract": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.", "authors": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V. Le"], "related_topics": ["40506919", "2776224158", "2777530160"], "citation_count": "12919", "reference_count": "29", "references": ["2618530766", "2964308564", "2157331557", "2310919327", "2064675550", "2101105183", "179875071", "2147768505", "2132339004", "1753482797"], "date": "2014"}, {"id": "1556633365", "title": "Computer Augmented Environments : Back to the Real World", "abstract": "", "authors": ["Pierre Wellner", "Wendy Mackay", "Rich Gold"], "related_topics": ["41008148"], "citation_count": "318", "reference_count": "0", "references": ["2149891956", "2138727017", "1968211101", "2094982166", "2067779848", "2088337190", "2130306162", "2155207172", "2020214787", "2100953056"], "date": "1993"}, {"id": "2295428206", "title": "Randomized Algorithms", "abstract": "For many applications, a randomized algorithm is either the simplest or the fastest algorithm available, and sometimes both. This book introduces the basic concepts in the design and analysis of randomized algorithms. The first part of the text presents basic tools such as probability theory and probabilistic analysis that are frequently used in algorithmic applications. Algorithmic examples are also given to illustrate the use of each tool in a concrete setting. In the second part of the book, each chapter focuses on an important area to which randomized algorithms can be applied, providing a comprehensive and representative selection of the algorithms that might be used in each of these areas. Although written primarily as a text for advanced undergraduates and graduate students, this book should also prove invaluable as a reference for professionals and researchers.", "authors": ["Rajeev Motwani", "Prabhakar Raghavan"], "related_topics": ["24404364", "128669082", "113296540"], "citation_count": "7211", "reference_count": "50", "references": ["2068871408", "1963547452", "1979740015", "2052207834", "2070991879", "1972418517", "1593563200", "2148043549", "2069816168", "1568495775"], "date": "1994"}, {"id": "2003949305", "title": "PACKMOL: a package for building initial configurations for molecular dynamics simulations.", "abstract": "Adequate initial configurations for molecular dynamics simulations consist of arrangements of molecules distributed in space in such a way to approximately represent the system's overall structure. In order that the simulations are not disrupted by large van der Waals repulsive interactions, atoms from different molecules must keep safe pairwise distances. Obtaining such a molecular arrangement can be considered a packing problem: Each type molecule must satisfy spatial constraints related to the geometry of the system, and the distance between atoms of different molecules must be greater than some specified tolerance. We have developed a code able to pack millions of atoms, grouped in arbitrarily complex molecules, inside a variety of three-dimensional regions. The regions may be intersections of spheres, ellipses, cylinders, planes, or boxes. The user must provide only the structure of one molecule of each type and the geometrical constraints that each type of molecule must satisfy. Building complex mixtures, interfaces, solvating biomolecules in water, other solvents, or mixtures of solvents, is straightforward. In addition, different atoms belonging to the same molecule may also be restricted to different spatial regions, in such a way that more ordered molecular arrangements can be built, as micelles, lipid double-layers, etc. The packing time for state-of-the-art molecular dynamics systems varies from a few seconds to a few minutes in a personal computer. The input files are simple and currently compatible with PDB, Tinker, Molden, or Moldy coordinate files. The package is distributed as free software and can be downloaded from http://www.ime.unicamp.br/~martinez/packmol/.", "authors": ["Leandro Mart\u00ednez", "Ricardo Andrade", "Ernesto G. Birgin", "Jos\u00e9 Mario Mart\u00ednez"], "related_topics": ["2988821698", "59593255", "130253271"], "citation_count": "3661", "reference_count": "23", "references": ["2266946488", "2068484625", "2083206954", "2134762386", "136603598", "2067263573", "1546275378", "2028413406", "2065322107", "2027003344"], "date": "2009"}, {"id": "2154765457", "title": "Combinatorial pattern discovery for scientific data: some preliminary results", "abstract": "Suppose you are given a set of natural entities (e.g., proteins, organisms, weather patterns, etc.) that possess some important common externally observable properties. You also have a structural description of the entities (e.g., sequence, topological, or geometrical data) and a distance metric. Combinatorial pattern discovery is the activity of finding patterns in the structural data that might explain these common properties based on the metric.This paper presents an example of combinatorial pattern discovery: the discovery of patterns in protein databases. The structural representation we consider are strings and the distance metric is string edit distance permitting variable length don't cares. Our techniques incorporate string matching algorithms and novel heuristics for discovery and optimization, most of which generalize to other combinatorial structures. Experimental results of applying the techniques to both generated data and functionally related protein families obtained from the Cold Spring Harbor Laboratory show the effectiveness of the proposed techniques. When we apply the discovered patterns to perform protein classification, they give information that is complementary to the best protein classifier available today.", "authors": ["Jason Tsong-Li Wang", "Gung-Wei Chirn", "Thomas G. Marr", "Bruce Shapiro", "Dennis Shasha", "Kaizhong Zhang"], "related_topics": ["22820288", "44359876", "32610155"], "citation_count": "240", "reference_count": "40", "references": ["2166559705", "1487801850", "1787564306", "1501400124", "2045821558", "2100176599", "2040703580", "1976373002", "2156899368", "2175671778"], "date": "1994"}, {"id": "2470115906", "title": "Experimental designs, 2nd ed.", "abstract": "", "authors": ["William G. Cochran", "Gertrude M. Cox"], "related_topics": ["34559072", "145420912", "41008148"], "citation_count": "2729", "reference_count": "0", "references": ["2145702944", "2141884714", "2034942998", "1979345446", "1526491974", "2093584567", "2080039748", "987144911", "1983712865", "1984045421"], "date": "1956"}, {"id": "2021680564", "title": "Spectral analysis of data", "abstract": "Experimental evidence suggests that spectral techniques are valuable for a wide range of applications. A partial list of such applications include (i) semantic analysis of documents used to cluster documents into areas of interest, (ii) collaborative filtering --- the reconstruction of missing data items, and (iii) determining the relative importance of documents based on citation/link structure. Intuitive arguments can explain some of the phenomena that has been observed but little theoretical study has been done. In this paper we present a model for framing data mining tasks and a unified approach to solving the resulting data mining problems using spectral analysis. These results give strong justification to the use of spectral techniques for latent semantic indexing, collaborative filtering, and web site ranking.", "authors": ["Yossi Azar", "Amos Fiat", "Anna Karlin", "Frank McSherry", "Jared Saia"], "related_topics": ["21569690", "112933361", "511149849"], "citation_count": "356", "reference_count": "15", "references": ["2138621811", "2166559705", "2798909945", "2124591829", "2030144199", "2063392856", "2072773380", "2124029832", "2130891992", "1982114217"], "date": "2001"}, {"id": "2072876893", "title": "Publish your computer code: it is good enough.", "abstract": "Freely provided working code \u2014 whatever its quality \u2014 improves programming and enables others to engage with your research, says Nick Barnes.", "authors": ["Nick Barnes"], "related_topics": ["43126263", "167955471", "136764020"], "citation_count": "278", "reference_count": "0", "references": ["2056279562", "1574680346", "2008985174", "1995054497", "3113043731", "2771169143", "2045005060", "1968993977", "3123868826", "2112176043"], "date": "2010"}, {"id": "2115543075", "title": "Efficient use of side information in multiple-antenna data transmission over fading channels", "abstract": "We derive performance limits for two closely related communication scenarios involving a wireless system with multiple-element transmitter antenna arrays: a point-to-point system with partial side information at the transmitter, and a broadcast system with multiple receivers. In both cases, ideal beamforming is impossible, leading to an inherently lower achievable performance as the quality of the side information degrades or as the number of receivers increases. Expected signal-to-noise ratio (SNR) and mutual information are both considered as performance measures. In the point-to-point case, we determine when the transmission strategy should use some form of beamforming and when it should not. We also show that, when properly chosen, even a small amount of side information can be quite valuable. For the broadcast scenario with an SNR criterion, we find the efficient frontier of operating points and show that even when the number of receivers is larger than the number of antenna array elements, significant performance improvements can be obtained by tailoring the transmission strategy to the realized channel.", "authors": ["A. Narula", "M.J. Lopez", "M.D. Trott", "G.W. Wornell"], "related_topics": ["62191587", "54197355", "47798520"], "citation_count": "963", "reference_count": "24", "references": ["2118040894", "2133475491", "1991567646", "1634005169", "2085099144", "1596939795", "2128261358", "2064959416", "2120350343", "1974755392"], "date": "1998"}, {"id": "1893597428", "title": "Knowledge mining by imprecise querying: a classification-based approach", "abstract": "Knowledge mining is the process of discovering knowledge that is hitherto unknown. An approach to knowledge mining by imprecise querying that utilizes conceptual clustering techniques is presented. The query processor has both a deductive and an inductive component. The deductive component finds precise matches in the traditional sense, and the inductive component identifies ways in which imprecise matches may be considered similar. Ranking on similarity is done by using the database taxonomy, by which similar instances become members of the same class. Relative similarity is determined by depth in the taxonomy. The conceptual clustering algorithm, its use in query processing, and an example are presented. >", "authors": ["T.M. Anwar", "H.W. Beck", "S.B. Navathe"], "related_topics": ["39235581", "189430467", "94413719"], "citation_count": "120", "reference_count": "14", "references": ["2073308541", "2159525276", "2132513611", "952881364", "2156159857", "2108699731", "2138097335", "2041111138", "2179367542", "2032352315"], "date": "1992"}, {"id": "1548404105", "title": "Telephone Triage: A Timely Data Source for Surveillance of Influenza-like Diseases", "abstract": "We evaluated telephone triage (TT) data for public health early warning systems. TT data is electronically available and contains coded elements that include the demographics and description of a caller\u2019s medical complaints. In the study, we obtained emergency room TT data and after hours TT data from a commercial TT software and service company. We compared the timeliness of the TT data with influenza surveillance data from the Centers for Disease Control using the cross correlation function. Emergency room TT calls are one to five weeks ahead of surveillance data collected by the CDC.", "authors": ["Jeremy U. Espino", "William R. Hogan", "Michael M. Wagner"], "related_topics": ["2777120189", "545542383", "138816342"], "citation_count": "96", "reference_count": "14", "references": ["2161186998", "1995461208", "2049343097", "1581749826", "2017369055", "2134590684", "2119816712", "1789914165", "1997133513", "2234312460"], "date": "2002"}, {"id": "2057148748", "title": "Transforming homo economicus into homo ludens: A field experiment on gamification in a utilitarian peer-to-peer trading service", "abstract": "Abstract During recent years, the addition of game mechanisms to non-game services has gained a relatively large amount of attention. Popular discussion connects gamification to successful marketing and increased profitability through higher customer engagement, however, there is a dearth of empirical studies that confirm such expectations. This paper reports the results of a field experiment, which gamifies a utilitarian peer-to-peer trading service by implementing the game mechanism of badges that users can earn from a variety of tasks. There were 3234 users who were randomly assigned to treatment groups and subjected to different versions of the badge system in a 2 \u00d7 2 design. The results show that the mere implementation of gamification mechanisms does not automatically lead to significant increases in use activity in the studied utilitarian service, however, those users who actively monitored their own badges and those of others in the study showed increased user activity.", "authors": ["Juho Hamari"], "related_topics": ["503285160", "2776915394", "2780378061"], "citation_count": "791", "reference_count": "43", "references": ["2099697766", "2135526934", "2023718959", "1791587663", "1527994979", "1511827303", "2140205964", "10512124", "2110506823", "2007851141"], "date": "2013"}, {"id": "1736339626", "title": "A collaborative framework for 3D alignment and classification of heterogeneous subvolumes in cryo-electron tomography", "abstract": "The limitation of using low electron doses in non-destructive cryo-electron tomography of biological specimens can be partially offset via averaging of aligned and structurally homogeneous subsets present in tomograms. This type of sub-volume averaging is especially challenging when multiple species are present. Here, we tackle the problem of conformational separation and alignment with a \u201ccollaborative\u201d approach designed to reduce the effect of the \u201ccurse of dimensionality\u201d encountered in standard pair-wise comparisons. Our new approach is based on using the nuclear norm as a collaborative similarity measure for alignment of sub-volumes, and by exploiting the presence of symmetry early in the processing. We provide a strict validation of this method by analyzing mixtures of intact simian immunodeficiency viruses SIV mac239 and SIV CP-MAC. Electron microscopic images of these two virus preparations are indistinguishable except for subtle differences in conformation of the envelope glycoproteins displayed on the surface of each virus particle. By using the nuclear norm-based, collaborative alignment method presented here, we demonstrate that the genetic identity of each virus particle present in the mixture can be assigned based solely on the structural information derived from single envelope glycoproteins displayed on the virus surface.", "authors": ["Oleg Kuybeda", "Gabriel A. Frank", "Alberto Bartesaghi", "Mario Borgnia", "Sriram Subramaniam", "Guillermo Sapiro"], "related_topics": ["2777993257", "2776517306", "111030470"], "citation_count": "2208", "reference_count": "55", "references": ["2119667497", "2100556411", "2145962650", "2124608575", "2798766386", "2103972604", "2148694408", "2202343345", "1976709621", "1669104078"], "date": "2013"}, {"id": "1501400124", "title": "Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison", "abstract": "", "authors": ["David Sankoff", "Joseph B. Kruskal"], "related_topics": ["1462715", "156310545", "84301040"], "citation_count": "2510", "reference_count": "0", "references": ["2158714788", "2055043387", "2153233077", "2127774996", "2081681829", "2001496424", "2112132489", "2106678197", "2038044292", "1553004968"], "date": "1983"}, {"id": "1513874694", "title": "Structures of Social Action: Studies in Conversation Analysis", "abstract": "Preface Transcript notation 1. Introduction John Heritage and J. Maxwell Atkinson Part I. Orientations: 2. Notes on methodology Harvey Sacks 3. On some questions and ambiguities in conversation Emanuel A. Schegloff Part II. Preference Organization: 4. Agreeing and disagreeing with assessments: some features of preferred/dispreferred turn shapes Anita Pomerantz 5. Subsequent versions of invitations, offers, requests, and proposals, dealing with potential or actual rejection Judy Davidson 6. Speakers' reportings in invitation sequences Paul Drew 7. Pursuing a response Anita Pomerantz Part III. Topic Organization: 8. Generating topic: the use of topic initial elicitors Graham Button and Neil Casey 9. On stepwise transition from talk about a trouble to inappropriately next-positioned matters Gail Jefferson Part IV. The Integration of Talk With Nonvocal Activities: 10. Notes on story structure and the organization of participation Charles Goodwin 11. Talk and recipiency: sequential organization in speech and body movement Christian Health 12. On some gestures' relation to talk Emanuel A. Schegloff Part V. Aspects of Response: 13. A change-of-state token and aspects of its sequential placement John Heritage 14. On the organization of laughter in talk about troubles Gail Jefferson 15. Public speaking and audience responses: some techniques for inviting applause J. Maxwell Atkinson Part VI. Everyday Activities as Sociological Phenomena: 16. On doing 'being ordinary' Harvey Sacks References Subject index Index of names.", "authors": ["J. Maxwell Atkinson"], "related_topics": ["2780829048", "3019014099", "2777200299"], "citation_count": "4041", "reference_count": "0", "references": ["1979290264", "2109151141", "2498260772", "1735617816", "2019090278", "2138502971", "1978874520", "2336148134", "2063790518", "2031008034"], "date": "1984"}, {"id": "2086461330", "title": "Foundations of cognitive grammar", "abstract": "", "authors": ["Ronald W. Langacker"], "related_topics": ["69298649", "39890363", "61577278"], "citation_count": "4651", "reference_count": "0", "references": ["2150375089", "1503247412", "2023015865", "2078906720", "2157853130", "2124819629", "2066646430", "2156256694", "2130454225", "2129955048"], "date": "1982"}, {"id": "2152309982", "title": "Usability inspection methods", "abstract": "Usability inspection is the generic name for a set of costeffective ways of evaluating user interfaces to find usability problems. They are fairly informal methods and easy to use.", "authors": ["Jakob Nielsen"], "related_topics": ["23456302", "100302975", "87105883"], "citation_count": "4869", "reference_count": "32", "references": ["2342091124", "2913758505", "2162598207", "2099473180", "1982451263", "1977953443", "1526630818", "2109428365", "2027909523", "2118518941"], "date": "1994"}, {"id": "1659701168", "title": "Universals in language usage: Politeness phenomena", "abstract": "", "authors": ["Penelope Brown", "Stephen C. Levinson"], "related_topics": ["131053937", "58393919", "61123122"], "citation_count": "7522", "reference_count": "0", "references": ["2128842882", "2963790016", "2068343953", "2142241884", "2512532697", "1521240809", "2136058926", "1566440928", "2124003719", "407492923"], "date": "1977"}, {"id": "1969947998", "title": "Determining average program execution times and their variance", "abstract": "This paper presents a general framework for determining average program execution times and their variance, based on the program's interval structure and control dependence graph. Average execution times and variance values are computed using frequency information from an optimized counter-based execution profile of the program.", "authors": ["V. Sarkar"], "related_topics": ["2778067643", "136134403", "196083921"], "citation_count": "254", "reference_count": "21", "references": ["1491178396", "2144344516", "2144433126", "2125412556", "2026438857", "2076090418", "2096733429", "1549134103", "2092492242", "2126753236"], "date": "1989"}, {"id": "2162480849", "title": "Remote sensing digital image analysis", "abstract": "", "authors": ["J. A. Richards"], "related_topics": ["183365957", "104317675", "9417928"], "citation_count": "9755", "reference_count": "14", "references": ["2105536892", "2059432853", "3022893215", "1587863748", "3015384695", "2089366793", "2010313500", "2041811077", "605622536", "2166950106"], "date": "1985"}, {"id": "2121762798", "title": "CloudBurst: highly sensitive read mapping with MapReduce", "abstract": "Motivation: Next-generation DNA sequencing machines are generating an enormous amount of sequence data, placing unprecedented demands on traditional single-processor readmapping algorithms. CloudBurst is a new parallel read-mapping algorithm optimized for mapping next-generation sequence data to the human genome and other reference genomes, for use in a variety of biological analyses including SNP discovery, genotyping and personal genomics. It is modeled after the short read-mapping program RMAP, and reports either all alignments or the unambiguous best alignment for each read with any number of mismatches or differences. This level of sensitivity could be prohibitively time consuming, but CloudBurst uses the open-source Hadoop implementation of MapReduce to parallelize execution using multiple compute nodes. Results: CloudBurst\u2019s running time scales linearly with the number of reads mapped, and with near linear speedup as the number of processors increases. In a 24-processor core configuration, CloudBurst is up to 30 times faster than RMAP executing on a single core, while computing an identical set of alignments. Using a larger remote compute cloud with 96 cores, CloudBurst improved performance by >100-fold, reducing the running time from hours to mere minutes for typical jobs involving mapping of millions of short reads to the human genome. Availability: CloudBurst is available open-source as a model for parallelizing algorithms with MapReduce at http://cloudburst", "authors": ["Michael C. Schatz"], "related_topics": ["37739895", "68339613", "79974875"], "citation_count": "873", "reference_count": "20", "references": ["2173213060", "2124985265", "2055043387", "2119565742", "2112113834", "2012016911", "2165460636", "2139760555", "2001725958", "2113649367"], "date": "2009"}, {"id": "2121017700", "title": "Learning to model relatedness for news recommendation", "abstract": "With the explosive growth of online news readership, recommending interesting news articles to users has become extremely important. While existing Web services such as Yahoo! and Digg attract users' initial clicks by leveraging various kinds of signals, how to engage such users algorithmically after their initial visit is largely under-explored. In this paper, we study the problem of post-click news recommendation. Given that a user has perused a current news article, our idea is to automatically identify \"related\" news articles which the user would like to read afterwards. Specifically, we propose to characterize relatedness between news articles across four aspects: relevance, novelty, connection clarity, and transition smoothness. Motivated by this understanding, we define a set of features to capture each of these aspects and put forward a learning approach to model relatedness. In order to quantitatively evaluate our proposed measures and learn a unified relatedness function, we construct a large test collection based on a four-month commercial news corpus with editorial judgments. The experimental results show that the proposed heuristics can indeed capture relatedness, and that the learned unified relatedness function works quite effectively.", "authors": ["Yuanhua Lv", "Taesup Moon", "Pranam Kolari", "Zhaohui Zheng", "Xuanhui Wang", "Yi Chang"], "related_topics": ["87546605", "127705205", "35578498"], "citation_count": "111", "reference_count": "42", "references": ["1880262756", "2171960770", "1678356000", "3121531027", "2107743791", "1973435495", "2123427850", "2093390569", "2169213601", "2136542423"], "date": "2011"}, {"id": "2022951240", "title": "A comparison of several approximate algorithms for finding multiple (N-best) sentence hypotheses", "abstract": "The authors introduce a new, more efficient algorithm, the word-dependent N-best algorithm, for finding multiple sentence hypotheses. The proposed algorithm is based on the assumption that the beginning time of a word depends only on the preceding word. The authors compare this algorithm with two other algorithms for finding the N-best hypotheses: the exact sentence-dependent method and a computationally efficient lattice N-best method. Although the word-dependent algorithm is computationally much less expensive than the exact algorithm, it appears to result in the same accuracy. The lattice method, which is still more efficient, has a significantly higher error rate. It is demonstrated that algorithms that use Viterbi scoring have significantly higher error rates than those that use total likelihood scoring. >", "authors": ["R. Schwartz", "S. Austin"], "related_topics": ["2779799172", "75930677", "196455857"], "citation_count": "268", "reference_count": "10", "references": ["1643320849", "1920769845", "2036102925", "1990387894", "1524975733", "2171244697", "168442784", "2099529148", "2013932300", "2339580098"], "date": "1991"}, {"id": "2066646430", "title": "An Academic Formulas List: New Methods in Phraseology Research", "abstract": "This research creates an empirically derived, pedagogically useful list of formulaic sequences for academic speech and writing, comparable with the Academic Word List (Coxhead 2000), called the Academic Formulas List (AFL). The AFL includes formulaic sequences identified as (i) frequent recurrent patterns in corpora of written and spoken language, which (ii) occur significantly more often in academic than in non-academic discourse, and (iii) inhabit a wide range of academic genres. It separately lists formulas that are common in academic spoken and academic written language, as well as those that are special to academic written language alone and academic spoken language alone. The AFL further prioritizes these formulas using an empirically derived measure of utility that is educationally and psychologically valid and operationalizable with corpus linguistic metrics. The formulas are classified according to their predominant pragmatic function for descriptive analysis and in order to marshal the AFL for inclusion in English for Academic Purposes instruction.", "authors": ["Rita Simpson-Vlach", "Nick C. Ellis"], "related_topics": ["119867837", "2780790391", "2776230583"], "citation_count": "807", "reference_count": "51", "references": ["1574901103", "2114282361", "2086677051", "2145713659", "1996250712", "1550933260", "2066183922", "2021034890", "1502101714", "1967461618"], "date": "2010"}, {"id": "8870360", "title": "Modern Information Retrieval : A Brief Overview", "abstract": "For thousands of years people have realized the importance of archiving and finding information. With the advent of computers, it became possible to store large amounts of information; and finding useful information from such collections became a necessity. The field of Information Retrieval (IR) was born in the 1950s out of this necessity. Over the last forty years, the field has matured considerably. Several IR systems are used on an everyday basis by a wide variety of users. This article is a brief overview of the key advances in the field of Information Retrieval, and a description of where the state-of-the-art is at in the field.", "authors": ["Amit Singhal"], "related_topics": ["148773725", "136197465", "136764020"], "citation_count": "1794", "reference_count": "30", "references": ["1956559956", "1978394996", "2135909747", "2106365165", "2000569744", "2014415866", "1553682320", "2165612380", "1525341925", "2043909051"], "date": "2000"}, {"id": "2157457404", "title": "Dynamic Source Routing in Ad Hoc Wireless Networks", "abstract": "An ad hoc network is a collection of wireless mobile hosts forming a temporary network without the aid of any established infrastructure or centralized administration. In such an environment, it may be necessary for one mobile host to enlist the aid of other hosts in forwarding a packet to its destination, due to the limited range of each mobile host\u2019s wireless transmissions. This paper presents a protocol for routing in ad hoc networks that uses dynamic source routing. The protocol adapts quickly to routing changes when host movement is frequent, yet requires little or no overhead during periods in which hosts move less frequently. Based on results from a packet-level simulation of mobile hosts operating in an ad hoc network, the protocol performs well over a variety of environmental conditions such as host density and movement rates. For all but the highest rates of host movement simulated, the overhead of the protocol is quite low, falling to just 1% of total data packets transmitted for moderate movement rates in a network of 24 mobile hosts. In all cases, the difference in length between the routes used and the optimal route lengths is negligible, and in most cases, route lengths are on average within a factor of 1.01 of optimal.", "authors": ["David B. Johnson", "David A. Maltz"], "related_topics": ["204739117", "47318570", "190526755"], "citation_count": "15126", "reference_count": "21", "references": ["2124651399", "2099057525", "2248064281", "2148099880", "1994980566", "2102907001", "1540641082", "1590810061", "1728701145", "2175926720"], "date": "1995"}, {"id": "2058903936", "title": "Efficient processing of spatial joins using R-trees", "abstract": "Spatial joins are one of the most important operations for combining spatial objects of several relations. The efficient processing of a spatial join is extremely important since its execution time is superlinear in the number of spatial objects of the participating relations, and this number of objects may be very high. In this paper, we present a first detailed study of spatial join processing using R-trees, particularly R*-trees. R-trees are very suitable for supporting spatial queries and the R*-tree is one of the most efficient members of the R-tree family. Starting from a straightforward approach, we present several techniques for improving its execution time with respect to both, CPU- and I/O-time. Eventually, we end up with an algorithm whose total execution time is improved over the first approach by an order of magnitude. Using a buffer of reasonable size, I/O-time is almost optimal, i.e. it almost corresponds to the time for reading each required page of the relations exactly once. The performance of the various approaches is investigated in an experimental performance comparison where several large data sets from real applications are used.", "authors": ["Thomas Brinkhoff", "Hans-Peter Kriegel", "Bernhard Seeger"], "related_topics": ["203689450", "2778692605", "80444323"], "citation_count": "996", "reference_count": "23", "references": ["2151135734", "2118269922", "2074429597", "2005314985", "2101320768", "2162064942", "2096137215", "2015372451", "2169893912", "2111399468"], "date": "1993"}, {"id": "1555317068", "title": "Capacitive sensing keyboard and pointing device", "abstract": "A combination keyboard and pointing device is incorporated in a portable computer and includes a dielectric base member on a top side of which a spaced series of electrically conductive pad member portions of a capacitance-based proximity sensing system are formed. Manually depressible key members are positioned above the pads. With the sensing system switched to a typing mode, the pads capacitively sense the proximity, velocity and acceleration of a user's fingers depressing their associated keys and output signals useable by the computer to display the character associated with the depressed key. A sensed increased stroke velocity of each manually depressed key may be used to alter the key character image displayed on the screen, for example capitalizing, bolding or underlining the character. The sensing system may be manually or automatically switched from its typing mode to a pointing mode in which it capacitively senses various hand and finger motions and orientations to carry out various pointing functions, such as cursor movements, pick functions, and scrolling functions, in response to the sensed hand and finger motions and orientations.", "authors": ["Jr. Stephan A. Mato"], "related_topics": ["133489148", "59046462", "206755178"], "citation_count": "170", "reference_count": "16", "references": ["2107118797", "1976522035", "1834372499", "1956410333", "1969037571", "2262720745", "324491766", "131663217", "2148855229", "1816655863"], "date": "1997"}, {"id": "2126163471", "title": "Theory of probability", "abstract": "1. Fundamental notions 2. Direct probabilities 3. Estimation problems 4. Approximate methods and simplifications 5. Significance tests: one new parameter 6. Significance tests: various complications 7. Frequency definitions and direct methods 8. General questions", "authors": ["Harold Jeffreys", "R. Bruce Lindsay"], "related_topics": ["2778905972", "130648207", "123661907"], "citation_count": "11766", "reference_count": "0", "references": ["1880262756", "2315214008", "2045656233", "2159080219", "1506281249", "2047028564", "2025720061", "2160226180", "1545319692", "1978662219"], "date": "1938"}, {"id": "2113722075", "title": "Singular values and eigenvalues of tensors: a variational approach", "abstract": "We propose a theory of eigenvalues, eigenvectors, singular values, and singular vectors for tensors based on a constrained variational approach much like the Rayleigh quotient for symmetric matrix eigenvalues. These notions are particularly useful in generalizing certain areas where the spectral theory of matrices has traditionally played an important role. For illustration, we will discuss a multilinear generalization of the Perron-Frobenius theorem", "authors": ["Lek-Heng Lim"], "related_topics": ["109282560", "135909967", "158158286"], "citation_count": "821", "reference_count": "10", "references": ["2013912476", "2090208105", "1509568713", "1500921805", "2018282388", "1973652906", "1602307574", "2074447841", "1993670676", "2000204283"], "date": "2005"}, {"id": "1562911371", "title": "Optimality Theory: Constraint Interaction in Generative Grammar", "abstract": "Prefactory Note. Acknowledgments. 1. Preliminaries:. Background and Overview. Optimality. Overall Structure of the Argument. Overview of Part I. 2. Optimality in Grammar: Core Syllabification in Imdlawn Tashlhiyt Berber:. The Heart of Dell & Elmedlaoui. Optimality Theory. Summary of discussion to date. 3. Generalization--Forms in Domination Hierarchies IBlocking and Triggering: Profuseness and Economy:. Epenthetic Structure. Do Something Only When: The Failure of Bottom--up Constructionism. 4. Generalization--Forms in Domination Hierarchies IIDo Something Except When: Blocking, or The Theory of Profuseness:. Edge--Oriented Infixation. Interaction of Weight Effects with Extrametricality. Background: Prominence--Driven Stress Systems. The Interaction of Weight and Extrametricality: Kelkar's Hindi/Urdu. Nonfinality and Nonexhaustiveness. Nonfinality and the Laws of Foot Form: Raw Minimality. Nonfinality and the Laws of Foot Form:Extended Minimality Effects. Summary of Discussion of the Except When Effect. Except meets Only: Triggering and Blocking in a Single Grammar. 5. The Construction of Grammar in Optimality Theory:. Construction of Harmonic Orderings from Phonetic and Structural Scales. The Theory of Constraint Interaction. Comparison of Entire Candidates by a Single Constraint. Ons: Binary constraints. Hnuc: Non--binary constraints. Comparison of Entire Candidates by an Entire Constraint Hierarchy. Discussion. Non--locality of interaction. Strictness of domination. Serial vs. Parallel Harmony Evaluation and Gen. Binary vs. Non--binary constraints. Paoini's Theorem on Constraint Ranking. Overview of Part II. 6. Syllable Structure Typology I: the CV Theory:. The Jakobson Typology. The Faithfulness Interactions. Groundwork. Basic CV Syllable Theory. Onsets. Codas. The Theory of Epenthesis Sites. 7. Constraint Interaction in Lardil Phonology:. The Constraints. The Ranking. Some Ranking Logic. Ranking the Constraints. Verification of Forms. Consonant--Final Stems. Vowel Final Stems. Discussion. 8. Universal Syllable Theory II: Ordinal Construction of C/V and Onset/Coda Licensing Asymmetry:. Associational Harmony. Deconstructing Hnuc: Berber, Take 1. Restricting to Binary Marks. Reconstructing the C and V Classes: Emergent Parameter Setting via Constraint Ranking. Harmonic Completeness of Possible Onsets and Peaks. Peak-- and Margin--Affinity. Interactions with Parse. Restricting Deletion and Epenthesis. Further Necessary Conditions on Possible Onsets and Nuclei. Sufficient Conditions on Possible Onsets and Nuclei. The Typology of Onset, Nucleus, and Coda Inventories. The Typology of Onset and Nucleus Inventories. Onset/Coda Licensing Asymmetries. An Example: Berber, Take 2. Simplifying the Theory by Encapsulating Constraint Packages. Encapsulating the Association Hierarchies. An Example: Berber, Take 3. Sufficiency and Richness of the Encapsulated Theory. 9. Inventory Theory and the Lexicon:. Language--Particular Inventories. Harmonic Bounding and Nucleus, Syllable, and Word Inventories. Segmental Inventories. Universal Inventories. Segmental Inventories. Syllabic Inventories. Optimality in the Lexicon. 10. Foundational Issues and Theory--Comparisons:. Thinking about Optimality. Fear of Optimization. The Reassurance. The Connectionism Connection, and other Computation--based Comparisons. Why Optimality Theory has nothing to do with connectionism. Why Optimality Theory is deeply connected to connectionism. Harmony Maximization and Symbolic Cognition. Analysis of 'Phonotactics+Repair' Theories. CV Syllable Structure and Repair. General Structure of the Comparisons: Repair Analysis. Persistent Rule Theory. English Closed Syllable Shortening. Shona Tone Spreading. Summary. The Theory of Constraints and Repair Strategies. Appendix. A.1 The Cancellation and Cancellation/Domination Lemmas. A.2 CV Syllable Structure. A.3 Paoinia s Theorem on Constraint--ranking. References. Index of Constraints. Index of Languages. General Index", "authors": ["Alan S. Prince", "Paul Smolensky"], "related_topics": ["2781082764", "2776426709", "2776550342"], "citation_count": "5630", "reference_count": "161", "references": ["2293063825", "2110485445", "2177721432", "1586060904", "1547224907", "1565769722", "2310420328", "2023723978", "1608707468", "2123987305"], "date": "2004"}, {"id": "2020919487", "title": "Combining Fuzzy Information from Multiple Systems", "abstract": "In a traditional database system, the result of a query is a set of values (those values that satisfy the query). In other data servers, such as a system with queries based on image content, or many text retrieval systems, the result of a query is a sorted list. For example, in the case of a system with queries based on image content, the query might ask for objects that are a particular shade of red, and the result of the query would be a sorted list of objects in the database, sorted by how well the color of the object matches that given in the query. A multimedia system must somehow synthesize both types of queries (those whose result is a set and those whose result is a sorted list) in a consistent manner. In this paper we discuss the solution adopted by Garlic, a multimedia information system being developed at the IBM Almaden Research Center. This solution is based on \u201cgraded\u201d (or \u201cfuzzy\u201d) sets. Issues of efficient query evaluation in a multimedia system are very different from those in a traditional database system. This is because the multimedia system receives answers to subqueries from various subsystems, which can be accessed only in limited ways. For the important class of queries that are conjunctions of atomic queries (where each atomic query might be evaluated by a different subsystem), the naive algorithm must retrieve a number of elements that is linear in the database size. In contrast, in this paper an algorithm is given, which has been implemented in Garlic, such that if the conjuncts are independent, then with arbitrarily high probability, the total number of elements retrieved in evaluating the query is sublinear in the database size (in the case of two conjuncts, it is of the order of the square root of the database size). It is also shown that for such queries, the algorithm is optimal. The matching upper and lower bounds are robust, in the sense that they hold under almost any reasonable rule (including the standard min rule of fuzzy logic) for evaluating the conjunction. Finally, we find a query that is provably hard, in the sense that the naive linear algorithm is essentially optimal.", "authors": ["Ronald Fagin"], "related_topics": ["157692150", "136736807", "192028432"], "citation_count": "1985", "reference_count": "23", "references": ["2912565176", "2330022088", "2093191240", "1969294188", "2168605051", "1978304080", "2048288497", "2094320135", "2057399436", "2174826014"], "date": "1999"}, {"id": "2242695601", "title": "Von Femtosekunden zu Minuten", "abstract": "", "authors": ["Adam Nielsen"], "related_topics": ["33923547"], "citation_count": "0", "reference_count": "16", "references": ["2596156494", "2126794261", "2126479355", "234899517", "2012029966", "2261128835", "170127646", "1997204748", "2915870397", "1539138075"], "date": "2011"}, {"id": "1973436000", "title": "Face recognition using view-based and modular eigenspaces", "abstract": "In this paper we describe experiments using eigenfaces for recognition and interactive search in the FERET face database. A recognition accuracy of 99.35% is obtained using frontal views of 155 individuals. This figure is consistent with the 95% recognition rate obtained previously on a much larger database of 7,562 `mugshots' of approximately 3,000 individuals, consisting of a mix of all age and ethnic groups. We also demonstrate that we can automatically determine head pose without significantly lowering recognition accuracy; this is accomplished by use of a view-based multiple-observer eigenspace technique. In addition, a modular eigenspace description is used which incorporates salient facial features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields slightly higher recognition rates as well as a more robust framework for face recognition. In addition, a robust and automatic feature detection technique using eigentemplates is demonstrated.", "authors": ["Baback Moghaddam", "Alexander P. Pentland"], "related_topics": ["88799230", "31510193", "14551309"], "citation_count": "308", "reference_count": "0", "references": ["2120954940", "1997011019", "2128716185", "2008297189", "2144354855", "2159173611", "2163965432", "2102773363", "2062104878", "2160947254"], "date": "1994"}, {"id": "2070706581", "title": "Introducing multilevel modeling", "abstract": "Introduction Overview of Contextual Models Varying and Random Coefficient Models Analyses Frequently Asked Questions", "authors": ["Ita Kreft", "Jan de Leeuw"], "related_topics": ["53059260", "38180746", "149782125"], "citation_count": "4446", "reference_count": "0", "references": ["2125001590", "2127662631", "3123521572", "2137073380", "2124596021", "2104232463", "2112146495", "2095615036", "2067369167", "2100493403"], "date": "1997"}, {"id": "620840771", "title": "Structures for semantics", "abstract": "One: Logic and Set Theory.- 1.1. First Order Logic.- 1.1.1. Basic Concepts.- 1.1.2. Metalogic.- 1.2. Second Order Logic.- 1.2.1. Basic Concepts.- 1.2.2. The Expressive Power of Second Order Logic.- 1.3. First Order Theories.- 1.3.1. Some Examples of First Order Theories.- 1.3.2. Peano Arithmetics (PA).- 1.4. Zermelo-Fraenkel Set Theory.- 1.4.1. Basic Set Theory.- 1.4.2. The Set Theoretic Universe.- Two: Partial Orders.- 2.1. Universal Algebra.- 2.2. Partial Orders and Equivalence Relations.- 2.3. Chains and Linear Orders.- Three: Semantics with Partial Orders.- 3.1. Instant Tense Logic.- 3.2. Algebraic Semantics, Functional Completeness and Expressibility.- 3.3. Some Linguistic Considerations Concerning Instants.- 3.4. Information Structures.- 3.5. Partial Information and Vagueness.- Four: Constructions with Partial Orders.- 4.1. Period Structures.- 4.2. Event Structures.- Five: Intervals, Events and Change.- 5.1. Interval Semantics.- 5.2. The Logic of Change in Interval Semantics.- 5.3. The Moment of Change.- 5.4. Supervaluations.- 5.5. Kamp's Logic of Change.- Six: Lattices.- 6.1. Basic Concepts.- 6.2. Universal Algebra.- 6.3. Filters and Ideals.- Seven: Semantics with Lattices.- 7.1. Boolean Types.- 7.2. Plurals.- 7.3. Mass Nouns.- Answers To Exercises.- References.", "authors": ["Fred Landman"], "related_topics": ["2779729104", "100481476", "144791301"], "citation_count": "267", "reference_count": "0", "references": ["1482796826", "2118335099", "2130103043", "1978407936", "1570679045", "2108770909", "1546413557", "1986654669", "2913882240", "2064627497"], "date": "1990"}, {"id": "2278339107", "title": "A Review of Time-Scale Modification of Music Signals \u2020", "abstract": "Time-scale modification (TSM) is the task of speeding up or slowing down an audio signal\u2019s playback speed without changing its pitch. In digital music production, TSM has become an indispensable tool, which is nowadays integrated in a wide range of music production software. Music signals are diverse\u2014they comprise harmonic, percussive, and transient components, among others. Because of this wide range of acoustic and musical characteristics, there is no single TSM method that can cope with all kinds of audio signals equally well. Our main objective is to foster a better understanding of the capabilities and limitations of TSM procedures. To this end, we review fundamental TSM methods, discuss typical challenges, and indicate potential solutions that combine different strategies. In particular, we discuss a fusion approach that involves recent techniques for harmonic-percussive separation along with time-domain and frequency-domain TSM procedures.", "authors": ["Jonathan Driedger", "Meinard M\u00fcller"], "related_topics": ["64922751", "87687168", "84462506"], "citation_count": "21", "reference_count": "37", "references": ["2022554507", "2428180336", "2165130450", "1561135842", "2100772705", "2116428736", "2120847449", "2478051194", "2168510624", "2088432713"], "date": "2016"}, {"id": "2150169316", "title": "Computer program apparatus for determining behavioral profile of a computer user", "abstract": "Computer network method and apparatus provides targeting of appropriate audience based on psychographic or behavioral profiles of end users. The psychographic profile is formed by recording computer activity and viewing habits of the end user. Content of categories of interest and display format in each category are revealed by the psychographic profile, based on user viewing of agate information. Using the profile (with or without additional user demographics), advertisements are displayed to appropriately selected users. Based on regression analysis of recorded responses of a first set of users viewing the advertisements, the target user profile is refined. Viewing by and regression analysis of recorded responses of subsequent sets of users continually auto-targets and customizes ads for the optimal end user audience.", "authors": ["Thomas A. Gerace"], "related_topics": ["2780150774", "192481860", "91262260"], "citation_count": "3905", "reference_count": "19", "references": ["1586251642", "1911516445", "1845378197", "2102369945", "256274650", "1860291521", "2874872302", "3022179601", "1838923683", "2161956524"], "date": "1998"}, {"id": "2001642682", "title": "An Overview of the Tesseract OCR Engine", "abstract": "The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy, is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier.", "authors": ["R. Smith"], "related_topics": ["150921172", "546480517", "95623464"], "citation_count": "1613", "reference_count": "11", "references": ["2129249398", "2005661126", "2913698532", "2164371886", "56465887", "2022461881", "2098470001", "2468727120", "2171786315", "2117120770"], "date": "2007"}, {"id": "1632114991", "title": "Building a large annotated corpus of English: the penn treebank", "abstract": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant.", "authors": ["Mitchell P. Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini"], "related_topics": ["532629269", "2777744975", "206134035"], "citation_count": "9188", "reference_count": "12", "references": ["2099247782", "1483126227", "2439178139", "2334801970", "900993354", "2110190189", "2012837062", "2121407024", "2076526090", "2166675302"], "date": "1993"}, {"id": "2153268908", "title": "A Survey on Cyber Security for Smart Grid Communications", "abstract": "A smart grid is a new form of electricity network with high fidelity power-flow control, self-healing, and energy reliability and energy security using digital communications and control technology. To upgrade an existing power grid into a smart grid, it requires significant dependence on intelligent and secure communication infrastructures. It requires security frameworks for distributed communications, pervasive computing and sensing technologies in smart grid. However, as many of the communication technologies currently recommended to use by a smart grid is vulnerable in cyber security, it could lead to unreliable system operations, causing unnecessary expenditure, even consequential disaster to both utilities and consumers. In this paper, we summarize the cyber security requirements and the possible vulnerabilities in smart grid communications and survey the current solutions on cyber security for smart grid communications.", "authors": ["Ye Yan", "Yi Qian", "Hamid Sharif", "David Tipper"], "related_topics": ["10558101", "29983905", "121822524"], "citation_count": "637", "reference_count": "77", "references": ["1504052325", "2187326887", "2089758604", "2038651258", "2030949386", "1973309971", "2104692292", "2011284636", "2129609617", "1785492489"], "date": "2012"}, {"id": "2132932625", "title": "A performance comparison of multi-hop wireless ad hoc network routing protocols", "abstract": "", "authors": ["Josh Broch", "David A. Maltz", "David B. Johnson", "Yih-Chun Hu", "Jorjeta Jetcheva"], "related_topics": ["204739117", "190526755", "104503742"], "citation_count": "7436", "reference_count": "20", "references": ["2145417574", "2157457404", "2124651399", "2135035173", "2099057525", "1977439837", "2730758618", "2338403939", "2148099880", "2169746237"], "date": "1998"}, {"id": "2111271983", "title": "The random walk's guide to anomalous diffusion: a fractional dynamics approach", "abstract": "Abstract Fractional kinetic equations of the diffusion, diffusion\u2013advection, and Fokker\u2013Planck type are presented as a useful approach for the description of transport dynamics in complex systems which are governed by anomalous diffusion and non-exponential relaxation patterns. These fractional equations are derived asymptotically from basic random walk models, and from a generalised master equation. Several physical consequences are discussed which are relevant to dynamical processes in complex systems. Methods of solution are introduced and for some special cases exact solutions are calculated. This report demonstrates that fractional equations have come of age as a complementary tool in the description of anomalous transport processes.", "authors": ["Ralf Metzler", "Joseph Klafter"], "related_topics": ["2779760431", "2777451387", "164602753"], "citation_count": "8292", "reference_count": "269", "references": ["2078206416", "1774151066", "1991567646", "1530054495", "1553338987", "1512470852", "2032121576", "433794350", "2114849571", "2097246107"], "date": "2000"}, {"id": "2150169469", "title": "Phonetically Driven Phonology: The Role of Optimality Theory and Inductive Grounding 1", "abstract": "Functionalist phonetic literature has shown how the phonologies of human languages are arranged to facilitate ease of articulation and perception. The explanatory force of phonological theory is greatly increased if it can directly access these research results. There are two formal mechanisms that together can facilitate the link-up of formal to functional work. As others have noted, Optimality Theory, with its emphasis on directly incorporating principles of markedness, can serve as part of the bridge. Another mechanism is proposed here: an algorithm for inductive grounding permits the language learner to access the knowledge gained from experience in articulation and perception, and form from it the appropriate set of formal phonological constraints.", "authors": ["Bruce P. Hayes"], "related_topics": ["2781082764", "148934300", "2776134746"], "citation_count": "371", "reference_count": "64", "references": ["1562911371", "1515814298", "1575528222", "1608707468", "1583314545", "2162471372", "2108443500", "1801810991", "1598851216", "1591993017"], "date": "2008"}, {"id": "1570159982", "title": "E-Commerce Recommendation Applications", "abstract": "i>Recommender systems are being used by an ever-increasing number of E-commerce sites to help consumers find products to purchase. What started as a novelty has turned into a serious business tool. Recommender systems use product knowledge\u2014either hand-coded knowledge provided by experts or \u201cmined\u201d knowledge learned from the behavior of consumers\u2014to guide consumers through the often-overwhelming task of locating products they will like. In this article we present an explanation of how recommender systems are related to some traditional database analysis techniques. We examine how recommender systems help E-commerce sites increase sales and analyze the recommender systems at six market-leading sites. Based on these examples, we create a taxonomy of recommender systems, including the inputs required from the consumers, the additional knowledge required from the database, the ways the recommendations are presented to consumers, the technologies used to create the recommendations, and the level of personalization of the recommendations. We identify five commonly used E-commerce recommender application models, describe several open research problems in the field of recommender systems, and examine privacy implications of recommender systems technology.", "authors": ["J. Ben Schafer", "Joseph A. Konstan", "John Riedl"], "related_topics": ["557471498", "183003079", "78597825"], "citation_count": "2521", "reference_count": "22", "references": ["2166559705", "2110325612", "3121531027", "2085937320", "2124591829", "1999047234", "2043403353", "2030144199", "583583424", "1594945480"], "date": "2000"}, {"id": "3021916629", "title": "Content analysis : an introduction to its methodology", "abstract": "Krippendorff views content analysis (one of the most important techniques in communication research) in historical perspective, in contrast to other techniques and in terms of what it can and cannot do.", "authors": ["Klaus Krippendorff"], "related_topics": ["162446236", "204983594", "60509570"], "citation_count": "46198", "reference_count": "0", "references": ["2142225512", "2284386481", "2498731006", "1912037221", "2118033245", "2783275777", "1533168346", "2046550787", "2918215371", "2378907785"], "date": "1979"}, {"id": "2798500587", "title": "Applied optimal control", "abstract": "", "authors": ["Arthur E. Bryson"], "related_topics": ["91575142", "65244806", "41008148"], "citation_count": "9963", "reference_count": "0", "references": ["2310919327", "3022404379", "1521785144", "2000359213", "1652886962", "2165579389", "2162218551", "2136558239", "2962727772", "1983639748"], "date": "1968"}, {"id": "1500850718", "title": "Combating AIDS: Communication Strategies in Action", "abstract": "Preface History of the AIDS Epidemic AIDS Advocacy and Policies AIDS Drugs Targeting Unique Populations Cultural Strategies Overcoming Stigma Entertainment-Education Monitoring and Evaluation Lessons Learned about Combating HIV/AIDS References Index", "authors": ["Arvind Singhal", "Everett M. Rogers"], "related_topics": ["2781455916", "168285401", "2780815959"], "citation_count": "248", "reference_count": "0", "references": ["1550832676", "1973860140", "2129460014", "2019911170", "2494411441", "2183468000", "1487177573", "563441086", "1583920005", "2018829154"], "date": "2002"}, {"id": "1987256605", "title": "Spread of activation.", "abstract": "", "authors": ["John R. Anderson", "Peter L. Pirolli"], "related_topics": ["46312422", "15744967"], "citation_count": "322", "reference_count": "15", "references": ["1708874574", "2135255848", "74704794", "2082557450", "1502139053", "2053127376", "1990948551", "2088085451", "2052631493", "2093115586"], "date": "1984"}, {"id": "2024509488", "title": "Convergent and discriminant validation by the multitrait-multimethod matrix.", "abstract": "", "authors": ["Donald T. Campbell", "Donald W. Fiske"], "related_topics": ["26475177", "120107772", "70364389"], "citation_count": "24045", "reference_count": "27", "references": ["2015391954", "1964218847", "2041946231", "2056615219", "1972655304", "1964664458", "2060508800", "1897007643", "2252038015", "2005947980"], "date": "1959"}, {"id": "2150587481", "title": "Organizational Learning and Communities-of-Practice: Toward a Unified View of Working, Learning, and Innovation", "abstract": "Recent ethnographic studies of workplace practices indicate that the ways people actually work usually differ fundamentally from the ways organizations describe that work in manuals, training programs, organizational charts, and job descriptions. Nevertheless, organizations tend to rely on the latter in their attempts to understand and improve work practice. We examine one such study. We then relate its conclusions to compatible investigations of learning and of innovation to argue that conventional descriptions of jobs mask not only the ways people work, but also significant learning and innovation generated in the informal communities-of-practice in which they work. By reassessing work, learning, and innovation in the context of actual communities and actual practices, we suggest that the connections between these three become apparent. With a unified view of working, learning, and innovating, it should be possible to reconceive of and redesign organizations to improve all three.", "authors": ["John Seely Brown", "Paul Duguid"], "related_topics": ["37228920", "169735623", "2777602254"], "citation_count": "14274", "reference_count": "37", "references": ["2116199508", "2164599981", "2027320617", "2106470680", "31045409", "2026645894", "2118243939", "3126349953", "2046682842", "2099670044"], "date": "1991"}, {"id": "2134800885", "title": "KenLM: Faster and Smaller Language Model Queries", "abstract": "We present KenLM, a library that implements two data structures for efficient language model queries, reducing both time and memory costs. The Probing data structure uses linear probing hash tables and is designed for speed. Compared with the widely-used SRILM, our Probing model is 2.4 times as fast while using 57% of the memory. The Trie data structure is a trie with bit-level packing, sorted records, interpolation search, and optional quantization aimed at lower memory consumption. Trie simultaneously uses less memory than the smallest lossless baseline and less CPU than the fastest baseline. Our code is open-source, thread-safe, and integrated into the Moses, cdec, and Joshua translation systems. This paper describes the several performance techniques used and presents benchmarks against alternative implementations.", "authors": ["Kenneth Heafield"], "related_topics": ["46494658", "85447302", "190290938"], "citation_count": "1119", "reference_count": "16", "references": ["2101105183", "2124807415", "1631260214", "22168010", "1549285799", "2155607551", "16967297", "2061910127", "2128808215", "2172097231"], "date": "2011"}, {"id": "3162734203", "title": "A Survey of Data Augmentation Approaches for NLP.", "abstract": "Data augmentation has recently seen increased interest in NLP due to more work in low-resource domains, new tasks, and the popularity of large-scale neural networks that require large amounts of training data. Despite this recent upsurge, this area is still relatively underexplored, perhaps due to the challenges posed by the discrete nature of language data. In this paper, we present a comprehensive and unifying survey of data augmentation for NLP by summarizing the literature in a structured manner. We first introduce and motivate data augmentation for NLP, and then discuss major methodologically representative approaches. Next, we highlight techniques that are used for popular NLP applications and tasks. We conclude by outlining current challenges and directions for future research. Overall, our paper aims to clarify the landscape of existing literature in data augmentation for NLP and motivate additional work in this area. We also present a GitHub repository with a paper list that will be continuously updated at https://github.com/styfeng/DataAug4NLP", "authors": ["Steven Y. Feng", "Varun Gangal", "Jason Wei", "Sarath Chandar", "Soroush Vosoughi", "Teruko Mitamura", "Eduard H. Hovy"], "related_topics": ["195324797", "204321447", "41008148"], "citation_count": "0", "reference_count": "129", "references": ["2963341956", "2963012544", "2081580037", "2963399829", "2963216553", "2954996726", "1975244201", "2963751529", "2746314669", "2739046565"], "date": "2021"}, {"id": "3102908185", "title": "Langevin theory of fluctuations in the discrete Boltzmann equation", "abstract": "The discrete Boltzmann equation for both the ideal and a non-ideal fluid is extended by adding Langevin noise terms in order to incorporate the effects of thermal fluctuations. After casting the fluctuating discrete Boltzmann equation in a form appropriate to the Onsager\u2013Machlup theory of linear fluctuations, the statistical properties of the noise are determined by invoking a fluctuation-dissipation theorem at the kinetic level. By integrating the fluctuating discrete Boltzmann equation, a fluctuating lattice Boltzmann equation is obtained, which provides an efficient way to solve the equations of fluctuating hydrodynamics for ideal and non-ideal fluids. Application of the framework to a generic force-based non-ideal fluid model leads to ideal gas-type thermal noise. Simulation results indicate proper thermalization of all degrees of freedom.", "authors": ["M Gross", "M E Cates", "F Varnik", "", "R Adhikari"], "related_topics": ["165995430", "21821499", "5637370"], "citation_count": "24", "reference_count": "73", "references": ["2120900954", "1480586711", "2095283463", "2077508082", "2119950184", "2166776469", "2040259398", "1982933896", "2051029378", "3105011569"], "date": "2011"}, {"id": "2784619191", "title": "Basic local alignment search tool. Journal of Molecular Biology", "abstract": "", "authors": ["SF Altschul", "W Gish", "W Miller", "EW Myers", "DJ Lipman"], "related_topics": ["23123220", "41008148", "2909472471"], "citation_count": "2998", "reference_count": "0", "references": ["1988925586", "2158454296", "1971403296", "2097117811", "2338315908", "2032438721", "1499049447", "2128061541", "1767772592", "2094448442"], "date": "1990"}, {"id": "1980131304", "title": "Systems integration: a core capability of the modern corporation", "abstract": "Many of the world\u2019s leading firms are developing a new model of industrial organization based on systems integration. Rather than performing all productive tasks in-house, companies are building the capabilities to design and integrate systems, while managing networks of component and subsystem suppliers. This article illustrates how systems integration evolved from its military, engineering-based, origins in the 1940s and 1950s to a modern-day strategic capability across a wide variety of sectors. Taking a resource-based view of the firm, the article shows how systems integration capabilities underpin the way high-technology companies compete by moving selectively up- and downstream in the marketplace through the simultaneous \u201ctwin\u201d processes of vertical integration and disintegration. Systems integrators of capital goods move downstream into service-intensive offerings to expand revenue streams and increase profitability. By contrast, producers of high-volume components and consumer goods use systems integration capabilities to exploit upstream relationships with input suppliers. In both cases, strategic options and capabilities are shaped by the life cycle of each product. The article develops a clearer understanding of systems integration, arguing that it now represents a core capability of the modern high-technology corporation.", "authors": ["Michael Hobday", "Andrew Davies", "Andrea Prencipe"], "related_topics": ["19527686", "2779703919", "181169782"], "citation_count": "871", "reference_count": "48", "references": ["2061977616", "2013386523", "3121398446", "1580880025", "2005144066", "2032382473", "2164405127", "2128259769", "2993245062", "1570125503"], "date": "2005"}, {"id": "2150926065", "title": "Cluster analysis and display of genome-wide expression patterns", "abstract": "A system of cluster analysis for genome-wide expression data from DNA microarray hybridization is de- scribed that uses standard statistical algorithms to arrange genes according to similarity in pattern of gene expression. The output is displayed graphically, conveying the clustering and the underlying expression data simultaneously in a form intuitive for biologists. We have found in the budding yeast Saccharomyces cerevisiae that clustering gene expression data groups together efficiently genes of known similar function, and we find a similar tendency in human data. Thus patterns seen in genome-wide expression experiments can be inter- preted as indications of the status of cellular processes. Also, coexpression of genes of known function with poorly charac- terized or novel genes may provide a simple means of gaining leads to the functions of many genes for which information is not available currently.", "authors": ["Michael B. Eisen", "Paul T. Spellman", "Patrick O. Brown", "David Botstein"], "related_topics": ["95371953", "18431079", "36857842"], "citation_count": "19843", "reference_count": "14", "references": ["1679913846", "1970156673", "2165011536", "2130494035", "2010888033", "2135951244", "2030958510", "2161893150", "2753765968", "2106645421"], "date": "1998"}, {"id": "2038118137", "title": "Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis", "abstract": "Abstract We present a rule-based system for computer-aided circuit analysis. The set of rules, called EL, is written in a rule language called ARS. Rules are implemented by ARS as pattern-directed invocation demons monitoring an associative data base. Deductions are performed in an antecedent manner, giving EL's analysis a catch-as-catch-can flavour suggestive of the behavior of expert circuit analyzers. We call this style of circuit analysis propagation of constraints. The system threads deduced facts with justifications which mention the antecedent facts and the rule used. These justifications may be examined by the user to gain insight into the operation of the set of rules as they apply to a problem. The same justifications are used by the system to determine the currently active data-base context for reasoning in hypothetical situations. They are also used by the system in the analysis of failures to reduce the search space. This leads to effective control of combinatorial search which we call dependency-directed backtracking.", "authors": ["Richard M. Stallman", "Gerald Jay Sussman"], "related_topics": ["72670184", "156884757", "203208320"], "citation_count": "1058", "reference_count": "27", "references": ["2121773050", "2339337913", "1488252886", "1541540802", "2072755230", "1559427309", "1578830675", "1819699930", "2147072697", "2072868498"], "date": "1977"}, {"id": "2129940694", "title": "Hardware-Efficient Coherent Digital Receiver Concept With Feedforward Carrier Recovery for $M$ -QAM Constellations", "abstract": "This paper presents a novel digital feedforward carrier recovery algorithm for arbitrary M-ary quadrature amplitude modulation (M-QAM) constellations in an intradyne coherent optical receiver. The approach does not contain any feedback loop and is therefore highly tolerant against laser phase noise. This is crucial, especially for higher order QAM constellations, which inherently have a smaller phase noise tolerance due to the lower spacing between adjacent constellation points. In addition to the mathematical description of the proposed carrier recovery algorithm also a possible hardware-efficient implementation in a parallelized system is presented and the performance of the algorithm is evaluated by Monte Carlo simulations for square 4-QAM (QPSK), 16-QAM, 64-QAM, and 256-QAM. For the simulations ASE noise and laser phase noise are considered as well as analog-to-digital converter (ADC) and internal resolution effects. For a 1 dB penalty at BER = 10-3, linewidth times symbol duration products of 4.1 x 10-4 (4-QAM), 1.4 x 10-4 (16-QAM), 4.0 x 10-5 (64-QAM) and 8.0 x 10-6 (256-QAM) are tolerable.", "authors": ["T. Pfau", "S. Hoffmann", "R. Noe"], "related_topics": ["17877974", "32409245", "89631360"], "citation_count": "1016", "reference_count": "29", "references": ["2092754166", "1995131021", "2160298987", "2144778165", "2098604216", "2121376834", "1968083125", "2121181160", "2006776980", "2144901024"], "date": "2009"}, {"id": "1965514675", "title": "Implicit Social Cognition: Attitudes, Self-Esteem, and Stereotypes.", "abstract": "Social behavior is ordinarily treated as being under conscious (if not always thoughtful) control. However, considerable evidence now supports the view that social behavior often operates in an implicit or unconscious fashion. The identifying feature of implicit cognition is that past experience influences judgment in a fashion not introspectively known by the actor. The present conclusion--that attitudes, self-esteem, and stereotypes have important implicit modes of operation--extends both the construct validity and predictive usefulness of these major theoretical constructs of social psychology. Methodologically, this review calls for increased use of indirect measures--which are imperative in studies of implicit cognition. The theorized ordinariness of implicit stereotyping is consistent with recent findings of discrimination by people who explicitly disavow prejudice. The finding that implicit cognitive effects are often reduced by focusing judges' attention on their judgment task provides a basis for evaluating applications (such as affirmative action) aimed at reducing such unintended discrimination.", "authors": ["Anthony G. Greenwald", "Mahzarin R. Banaji"], "related_topics": ["204421591", "2777572989", "48329741"], "citation_count": "8693", "reference_count": "298", "references": ["2037124948", "1799750435", "2011744324", "1491644571", "2107031757", "1556033561", "2171975196", "2127629438", "1483679835", "2164558494"], "date": "1994"}, {"id": "2106005123", "title": "Low-rank matrix completion using alternating minimization", "abstract": "Alternating minimization represents a widely applicable and empirically successful approach for finding low-rank matrices that best fit the given data. For example, for the problem of low-rank matrix completion, this method is believed to be one of the most accurate and efficient, and formed a major component of the winning entry in the Netflix Challenge [17].In the alternating minimization approach, the low-rank target matrix is written in a bi-linear form, i.e. X = UV\u2020; the algorithm then alternates between finding the best U and the best V. Typically, each alternating step in isolation is convex and tractable. However the overall problem becomes non-convex and is prone to local minima. In fact, there has been almost no theoretical understanding of when this approach yields a good result.In this paper we present one of the first theoretical analyses of the performance of alternating minimization for matrix completion, and the related problem of matrix sensing. For both these problems, celebrated recent results have shown that they become well-posed and tractable once certain (now standard) conditions are imposed on the problem. We show that alternating minimization also succeeds under similar conditions. Moreover, compared to existing results, our paper shows that alternating minimization guarantees faster (in particular, geometric) convergence to the true matrix, while allowing a significantly simpler analysis.", "authors": ["Prateek Jain", "Praneeth Netrapalli", "Sujay Sanghavi"], "related_topics": ["90199385", "2778459887", "137127113"], "citation_count": "946", "reference_count": "25", "references": ["2129131372", "2054141820", "2145962650", "2124608575", "2798909945", "2103972604", "2202343345", "2134332047", "1975900269", "2144730813"], "date": "2013"}, {"id": "2128092632", "title": "Space in language and cognition: Explorations in cognitive diversity", "abstract": "Languages differ in how they describe space, and such differences between languages can be used to explore the relation between language and thought. This 2003 book shows that even in a core cognitive domain like spatial thinking, language influences how people think, memorize and reason about spatial relations and directions. After outlining a typology of spatial coordinate systems in language and cognition, it is shown that not all languages use all types, and that non-linguistic cognition mirrors the systems available in the local language. The book reports on collaborative, interdisciplinary research, involving anthropologists, linguists and psychologists, conducted in many languages and cultures around the world, which establishes this robust correlation. The overall results suggest that thinking in the cognitive sciences underestimates the transformative power of language on thinking. The book will be of interest to linguists, psychologists, anthropologists and philosophers, and especially to students of spatial cognition.", "authors": ["Stephen C. Levinson"], "related_topics": ["2777371692", "2777508679", "2777319359"], "citation_count": "2740", "reference_count": "233", "references": ["2085529605", "2166667242", "3126349953", "1993750641", "2004415003", "2133188546", "2148300948", "2624262714", "1485243506", "1540136915"], "date": "2003"}, {"id": "1603504818", "title": "Strategy and the Internet.", "abstract": "Many of the pioneers of Internet business, both dot-coms and established companies, have competed in ways that violate nearly every precept of good strategy. Rather than focus on profits, they have chased customers indiscriminately through discounting, channel incentives, and advertising. Rather than concentrate on delivering value that earns an attractive price from customers, they have pursued indirect revenues such as advertising and click-through fees. Rather than make trade-offs, they have rushed to offer every conceivable product or service. It did not have to be this way--and it does not have to be in the future. When it comes to reinforcing a distinctive strategy, Michael Porter argues, the Internet provides a better technological platform than previous generations of IT. Gaining competitive advantage does not require a radically new approach to business; it requires building on the proven principles of effective strategy. Porter argues that, contrary to recent thought, the Internet is not disruptive to most existing industries and established companies. It rarely nullifies important sources of competitive advantage in an industry; it often makes them even more valuable. And as all companies embrace Internet technology, the Internet itself will be neutralized as a source of advantage. Robust competitive advantages will arise instead from traditional strengths such as unique products, proprietary content, and distinctive physical activities. Internet technology may be able to fortify those advantages, but it is unlikely to supplant them. Porter debunks such Internet myths as first-mover advantage, the power of virtual companies, and the multiplying rewards of network effects. He disentangles the distorted signals from the marketplace, explains why the Internet complements rather than cannibalizes existing ways of doing business, and outlines strategic imperatives for dot-coms and traditional companies.", "authors": ["Porter Me"], "related_topics": ["58546491", "110875604", "541491724"], "citation_count": "8303", "reference_count": "0", "references": ["2041711461", "2164314939", "2049318638", "2169855821", "2147270415", "1993910593", "592138328", "2156218005", "2152604313", "1569292578"], "date": "2001"}, {"id": "2145155932", "title": "Global Lie\u2013Tresse theorem", "abstract": "We prove a global algebraic version of the Lie\u2013Tresse theorem which states that the algebra of differential invariants of an algebraic pseudogroup action on a differential equation is generated by a finite number of rational-polynomial differential invariants and invariant derivations.", "authors": ["Boris Kruglikov", "Valentin Lychagin"], "related_topics": ["97145343", "26959085", "23962028"], "citation_count": "79", "reference_count": "47", "references": ["1495410784", "2149557743", "290527292", "1595843857", "655852084", "2505055080", "2577509673", "560534796", "2143099520", "1787610124"], "date": "2016"}, {"id": "1992657881", "title": "The psychological implications of concealing a stigma: a cognitive-affective-behavioral model.", "abstract": "Many assume that individuals with a hidden stigma escape the difficulties faced by individuals with a visible stigma. However, recent research has shown that individuals with a concealable stigma also face considerable stressors and psychological challenges. The ambiguity of social situations combined with the threat of potential discovery makes possessing a concealable stigma a difficult predicament for many individuals. The increasing amount of research on concealable stigmas necessitates a cohesive model for integrating relevant findings. This article offers a cognitive-affective-behavioral process model for understanding the psychological implications of concealing a stigma. It ends with discussion of potential points of intervention in the model as well as potential future routes for investigation of the model.", "authors": ["John E. Pachankis"], "related_topics": ["168285401", "175202939", "2780665704"], "citation_count": "1307", "reference_count": "168", "references": ["2315207768", "2179683524", "1556033561", "2167884222", "1919982252", "2005637544", "656161623", "1975404309", "2132406025", "2102573486"], "date": "2007"}, {"id": "1516255585", "title": "Convergence of Baire measures", "abstract": "", "authors": ["R. M. Dudley"], "related_topics": ["189892329", "71923881", "202444582"], "citation_count": "229", "reference_count": "0", "references": ["2149305338", "1980073352", "2003706076", "3130321569", "2963841059", "2005522417", "2061521749", "2963159236", "1971021761", "1991977420"], "date": "1965"}, {"id": "2798461040", "title": "Probability theory", "abstract": "", "authors": ["Michel Lo\u00e8ve"], "related_topics": ["122203268", "41008148", "121864883"], "citation_count": "11039", "reference_count": "0", "references": ["2121601095", "2142827986", "2019950953", "1570963478", "1522579744", "2128716185", "1564947197", "2149498546", "2012352340", "2135463994"], "date": "1962"}, {"id": "2135764410", "title": "Good error-correcting codes based on very sparse matrices", "abstract": "We study two families of error-correcting codes defined in terms of very sparse matrices. \"MN\" (MacKay-Neal (1995)) codes are recently invented, and \"Gallager codes\" were first investigated in 1962, but appear to have been largely forgotten, in spite of their excellent properties. The decoding of both codes can be tackled with a practical sum-product algorithm. We prove that these codes are \"very good\", in that sequences of codes exist which, when optimally decoded, achieve information rates up to the Shannon limit. This result holds not only for the binary-symmetric channel but also for any channel with symmetric stationary ergodic noise. We give experimental results for binary-symmetric channels and Gaussian channels demonstrating that practical performance substantially better than that of standard convolutional and concatenated codes can be achieved; indeed, the performance of Gallager codes is almost as close to the Shannon limit as that of turbo codes.", "authors": ["D.J.C. MacKay"], "related_topics": ["157125643", "114504821", "2400350"], "citation_count": "5917", "reference_count": "67", "references": ["2099111195", "2159080219", "2121606987", "2987657883", "2102251435", "2156938362", "1597286183", "2129652681", "1606480398", "1593793857"], "date": "1997"}, {"id": "2152475379", "title": "Principles of Artificial Intelligence", "abstract": "A classic introduction to artificial intelligence intended to bridge the gap between theory and practice, \"Principles of Artificial Intelligence\" describes fundamental AI ideas that underlie applications such as natural language processing, automatic programming, robotics, machine vision, automatic theorem proving, and intelligent data retrieval. Rather than focusing on the subject matter of the applications, the book is organized around general computational concepts involving the kinds of data structures used, the types of operations performed on the data structures, and the properties of the control strategies used. \"Principles of Artificial Intelligence\"evolved from the author's courses and seminars at Stanford University and University of Massachusetts, Amherst, and is suitable for text use in a senior or graduate AI course, or for individual study.", "authors": ["N. J. Nilsson"], "related_topics": ["30112582", "207453521", "26205005"], "citation_count": "5224", "reference_count": "0", "references": ["2076063813", "2337098149", "2119717200", "1998442441", "1553004968", "2132029223", "2169033759", "2002440441", "2147405597", "2030021468"], "date": "1979"}, {"id": "2035782089", "title": "Availability: A heuristic for judging frequency and probability", "abstract": "Abstract This paper explores a judgmental heuristic in which a person evaluates the frequency of classes or the probability of events by availability, i.e., by the ease with which relevant instances come to mind. In general, availability is correlated with ecological frequency, but it is also affected by other factors. Consequently, the reliance on the availability heuristic leads to systematic biases. Such biases are demonstrated in the judged frequency of classes of words, of combinatorial outcomes, and of repeated events. The phenomenon of illusory correlation is explained as an availability bias. The effects of the availability of incidents and scenarios on subjective probability are discussed.", "authors": ["Amos Tversky", "Daniel Kahneman"], "related_topics": ["186150311", "132983000", "175285421"], "citation_count": "12799", "reference_count": "28", "references": ["1980054641", "2016377072", "1976624377", "2963241992", "2018507693", "1972320590", "2049059074", "1966204280", "2134321850", "2030859284"], "date": "1973"}, {"id": "2150418026", "title": "An 800 bit/s vector quantization LPC vocoder", "abstract": "An 800 bit/s vector quantization linear predictive coding (LPC) vocoder has been developed. The recently developed LPC vector quantization theory is applied to reduce the bit rate for LPC coefficients coding by a factor of four. Branch search techniques and separation of voiced and unvoiced codebooks are applied for better algorithm efficiency. Differential coding is applied to reduce the bit rate for the pitch and gain parameters by one third. Formal subjective evaluation shows that the 800 bit/s vocoder preserves most of the intelligibility of an LPC system. It is also robust under different transmission error and acoustic conditions. Informal listening comparisons show the quality to be acceptable and sometimes very close to 2400 bit/s LPC speech. The computational cost of the 800 bit/s vocoder is equivalent to or even lower than the 2400 bit/s LPC-10. Compatibility with any LPC-10 vocoder is guaranteed because the 800 bit/s design only differs in the quantization and encoding algorithms. Further bit rate reduction can be achieved by removing frame to frame redundancy in the code.", "authors": ["D. Wong", "Biing-Hwang Juang", "A. Gray"], "related_topics": ["80167644", "76862118", "2778763703"], "citation_count": "270", "reference_count": "19", "references": ["2022554507", "2118587067", "2583466288", "2164240509", "2163904446", "1566883001", "2117741782", "198103728", "2056133372", "2098972960"], "date": "1982"}, {"id": "2776017876", "title": "Ecological Momentary Assessment (Ema) in Behavioral Medicine", "abstract": "", "authors": ["Arthur A. Stone", "Saul Shiffman"], "related_topics": ["183698672", "169900460", "15744967"], "citation_count": "1893", "reference_count": "0", "references": ["2155002669", "2148112990", "2166190112", "2158836722", "2136175013", "2048799165", "2134176302", "2146545407", "2145419312", "2561174611"], "date": "1993"}, {"id": "2133109597", "title": "Toward principles for the design of ontologies used for knowledge sharing", "abstract": "Recent work in Artificial Intelligence is exploring the use of formal ontologies as a way of specifying content-specific agreements for the sharing and reuse of knowledge among software entities. We take an engineering perspective on the development of such ontologies. Formal ontologies are viewed as designed artifacts, formulated for specific purposes and evaluated against objective design criteria. We describe the role of ontologies in supporting knowledge sharing activities, and then present a set of criteria to guide the development of ontologies for these purposes. We show how these criteria are applied in case studies from the design of ontologies for engineering mathematics and bibliographic data. Selected design decisions are discussed, and alternative representation choices and evaluated against the design criteria.", "authors": ["Thomas R. Gruber"], "related_topics": ["118248724", "101230327", "2778177438"], "citation_count": "13927", "reference_count": "44", "references": ["2137079713", "2141824507", "1804031886", "1524870477", "2138162238", "1505839237", "2122540544", "2171344460", "1593983637", "2012170877"], "date": "1995"}, {"id": "2005348293", "title": "Development and Applications of the HYDRUS and STANMOD Software Packages and Related Codes", "abstract": "Mathematical models have become indispensable tools for studying vadose zone flow and transport processes. We reviewed the history of development, the main processes involved, and selected applications of HYDRUS and related models and software packages developed collaboratively by several groups in the United States, the Czech Republic, Israel, Belgium, and the Netherlands. Our main focus was on modeling tools developed jointly by the U.S. Salinity Laboratory of the USDA, Agricultural Research Service, and the University of California, Riverside. This collaboration during the past three decades has resulted in the development of a large number of numerical [e.g., SWMS_2D, HYDRUS-1D, HYDRUS-2D, HYDRUS (2D/3D), and HP1] as well as analytical (e.g., CXTFIT and STANMOD) computer tools for analyzing water flow and solute transport processes in soils and groundwater. The research also produced additional programs and databases (e.g., RETC, Rosetta, and UNSODA) for quantifying unsaturated soil hydraulic properties. All of the modeling tools, with the exception of HYDRUS-2D and HYDRUS (2D/3D), are in the public domain and can be downloaded freely from several websites.", "authors": ["Jir\u00ed \u0160im\u016fnek", "Martinus Th. van Genuchten", "Miroslav \u0160ejna"], "related_topics": ["2988574769", "35588792", "2778334997"], "citation_count": "1087", "reference_count": "116", "references": ["1604035276", "2123673345", "2162604832", "1980965960", "2986444355", "2099370652", "2142380524", "2289328577", "1990236303", "2048568378"], "date": "2008"}, {"id": "2166091242", "title": "The DaCapo benchmarks: java benchmarking development and analysis", "abstract": "Since benchmarks drive computer science research and industry product development, which ones we use and how we evaluate them are key questions for the community. Despite complex runtime tradeoffs due to dynamic compilation and garbage collection required for Java programs, many evaluations still use methodologies developed for C, C++, and Fortran. SPEC, the dominant purveyor of benchmarks, compounded this problem by institutionalizing these methodologies for their Java benchmark suite. This paper recommends benchmarking selection and evaluation methodologies, and introduces the DaCapo benchmarks, a set of open source, client-side Java benchmarks. We demonstrate that the complex interactions of (1) architecture, (2) compiler, (3) virtual machine, (4) memory management, and (5) application require more extensive evaluation than C, C++, and Fortran which stress (4) much less, and do not require (3). We use and introduce new value, time-series, and statistical metrics for static and dynamic properties such as code complexity, code size, heap composition, and pointer mutations. No benchmark suite is definitive, but these metrics show that DaCapo improves over SPEC Java in a variety of ways, including more complex code, richer object behaviors, and more demanding memory system requirements. This paper takes a step towards improving methodologies for choosing and evaluating benchmarks to foster innovation in system design and implementation for Java and other managed languages.", "authors": ["Stephen M. Blackburn", "Robin Garner", "Chris Hoffmann", "Asjad M. Khang", "Kathryn S. McKinley", "Rotem Bentzur", "Amer Diwan", "Daniel Feinberg", "Daniel Frampton", "Samuel Z. Guyer", "Martin Hirzel", "Antony Hosking", "Maria Jump", "Han Lee", "J. Eliot B. Moss", "Aashish Phansalkar", "Darko Stefanovi\u0107", "Thomas VanDrunen", "Daniel von Dincklage", "Ben Wiedermann"], "related_topics": ["132106392", "548217200", "8767382"], "citation_count": "1730", "reference_count": "32", "references": ["2158864412", "2078455576", "2112832394", "2152814480", "2002250868", "2119151382", "2107668421", "2146509778", "2154554979", "2116241918"], "date": "2006"}, {"id": "2063334178", "title": "WinGX suite for small-molecule single-crystal crystallography", "abstract": "The category Computer Program Abstracts provides a rapid means of communicating up-to-date information concerning both new programs or systems and signi\u00aecant updates to existing ones. Following normal submission, a Computer Program Abstract will be reviewed by one or two members of the IUCr Commission on Crystallographic Computing. It should not exceed 500 words in length and should follow the standard format given on page 189 of the June 1985 issue of the Journal [J. Appl. Cryst. (1985). 18, 189\u00b1 190] and on the World Wide Web at http://www.iucr. org/journals/jac/software/. Lists of software presented and/or reviewed in the Journal of Applied Crystallography are available on the World Wide Web at the above address, together with information about the availability of the software where this is known.", "authors": ["Louis J. Farrugia"], "related_topics": ["63449546", "2777904410", "198140048"], "citation_count": "30762", "reference_count": "12", "references": ["2059020082", "1969635440", "2144332006", "1972493784", "2080182825", "2080528351", "2026258231", "2070942956", "2101748147", "2026758097"], "date": "1999"}, {"id": "2145311040", "title": "ParaSite: mining structural information on the Web", "abstract": "Web information retrieval tools typically make use of only the text on pages, ignoring valuable information implicitly contained in links. At the other extreme, viewing the Web as a traditional hypertext system would also be mistake, because heterogeneity, cross-domain links, and the dynamic nature of the Web mean that many assumptions of typical hypertext systems do not apply. The novelty of the Web leads to new problems in information access, and it is necessary to make use of the new kinds of information available, such as multiple independent categorization, naming, and indexing of pages. This paper discusses the varieties of link information (not just hyperlinks) on the Web, how the Web differs from conventional hypertext, and how the links can be exploited to build useful applications. Specific applications presented as part of the ParaSite system find individuals' homepages, new locations of moved pages, and unindexed information.", "authors": ["Ellen Spertus"], "related_topics": ["61096286", "21959979", "130436687"], "citation_count": "356", "reference_count": "13", "references": ["2081580037", "2124591829", "2037498077", "3007065685", "1550771877", "2104967207", "1492582005", "1989393439", "1527127371", "2011843405"], "date": "1997"}, {"id": "2158046522", "title": "Hypertext: An Introduction and Survey", "abstract": "This article is a survey of existing hypertext systems, their applications, and their design. It is both an introduction to the world of hypertext and, at a deeper cut, a survey of some of the most important design issues that go into fashioning a hypertext environment. The concept of hypertext is quite simple: Windows on the screen are associated with objects in a database, and links are provided between these objects, both graphically (as labelled tokens) and in the database (as pointers). But this simple idea is creating much excitement. Several universities have created laboratories for research on hypertext, many articles have been written about the concept just within the last year, and the Smithsonian Institute has created a demonstration laboratory to develop and display hypertext technologies.", "authors": ["Conklin"], "related_topics": ["162215914", "142358594", "30088001"], "citation_count": "4002", "reference_count": "14", "references": ["2037717074", "2010793828", "2112883799", "2087311398", "2035159691", "2092955759", "2034967522", "1979887415", "2068578624", "2200839525"], "date": "1987"}, {"id": "2004618348", "title": "Parallelism in random access machines", "abstract": "A model of computation based on random access machines operating in parallel and sharing a common memory is presented. The computational power of this model is related to that of traditional models. In particular, deterministic parallel RAM's can accept in polynomial time exactly the sets accepted by polynomial tape bounded Turing machines; nondeterministic RAM's can accept in polynomial time exactly the sets accepted by nondeterministic exponential time bounded Turing machines. Similar results hold for other classes. The effect of limiting the size of the common memory is also considered.", "authors": ["Steven Fortune", "James Wyllie"], "related_topics": ["48415503", "176181172", "31402856"], "citation_count": "1397", "reference_count": "10", "references": ["2013259664", "2113097540", "2026191634", "1996028864", "2088300760", "2081608347", "2090533339", "1987540368", "2135913665", "2277064181"], "date": "1978"}, {"id": "2000138546", "title": "The temporal logic of branching time", "abstract": "A temporal logic is defined which contains both linear and branching operators. The underlying model is the tree of all possible computations. The following metatheoretical results are proven: 1) an exponential decision procedure for satisfiability; 2) a finite model property; 3) the completeness of an axiomatization.", "authors": ["Mordechai Ben-Ari", "Amir Pnueli", "Zohar Manna"], "related_topics": ["4777664", "162670838", "198008173"], "citation_count": "858", "reference_count": "16", "references": ["2157319504", "1970603830", "2030926579", "1490966766", "2084910510", "2971132570", "1536217426", "1997716585", "2053068495", "1967494119"], "date": "1983"}, {"id": "2112315008", "title": "Novel methods improve prediction of species' distributions from occurrence data", "abstract": "Prediction of species' distributions is central to diverse applications in ecology, evolution and conservation science. There is increasing electronic access to vast sets of occurrence records in museums and herbaria, yet little effective guidance on how best to use this information in the context of numerous approaches for modelling distributions. To meet this need, we compared 16 modelling methods over 226 species from 6 regions of the world, creating the most comprehensive set of model comparisons to date. We used presence-only data to fit models, and independent presence-absence data to evaluate the predictions. Along with well-established modelling methods such as generalised additive models and GARP and BIOCLIM, we explored methods that either have been developed recently or have rarely been applied to modelling species' distributions. These include machine-learning methods and community models, both of which have features that may make them particularly well suited to noisy or sparse information, as is typical of species' occurrence data. Presence-only data were effective for modelling species' distributions for many species and regions. The novel methods consistently outperformed more established methods. The results of our analysis are promising for the use of data from museums and herbaria, especially as methods suited to the noise inherent in such data improve.", "authors": ["Jane Elith", "Catherine H. Graham", "Robert P. Anderson", "Miroslav Dud\u00edk", "Simon Ferrier", "Antoine Guisan", "Robert J. Hijmans", "Falk Huettmann", "John R. Leathwick", "Anthony Lehmann", "Jin Li", "Lucia G. Lohmann", "Bette A. Loiselle", "Glenn Manion", "Craig Moritz", "Miguel Nakamura", "Yoshinori Nakazawa", "Jacob C. M. Mc Overton", "A. Townsend Peterson", "Steven J. Phillips", "Karen Richardson", "Ricardo Scachetti-Pereira", "Robert E. Schapire", "Jorge Sober\u00f3n", "Stephen Williams", "Mary S. Wisz", "Niklaus E. Zimmermann"], "related_topics": ["103215972", "2780049985", "62648534"], "citation_count": "7977", "reference_count": "110", "references": ["1554944419", "2009435671", "2135046866", "2112776483", "2139416101", "2115709314", "648151759", "2024046085", "2149507322", "2129905273"], "date": "2006"}, {"id": "1912037221", "title": "Traditional, Interpretive, and Reception Based Content Analyses: Improving the Ability of Content Analysis to Address Issues of Pragmatic and Theoretical Concern", "abstract": "This paper argues for a subtle but important shift in the way we view content analysis which allows for the introduction of two new variants on this methodology. Previously, content analysis has been seen as a method for quantifying the content of texts. This paper argues that we should view content analysis as a method for counting interpretations of content. Based on this reconceptualization, this paper suggests two new varieties of content analysis. Reception based content analysis allows researchers to quantify how different audiences will understand text. Interpretive content analysis is specially designed for latent content analysis, in which researchers go beyond quantifying the most straightforward denotative elements in a text. These new forms of content analysis are contrasted with traditional content analysis, and the appropriate conditions for their use are discussed.", "authors": ["Aaron C. Ahuvia"], "related_topics": ["162446236", "2522767166", "179518139"], "citation_count": "356", "reference_count": "52", "references": ["3022607203", "2070504353", "2004184632", "1483679835", "2016364797", "2018415007", "2053154970", "2125706233", "2006468167", "1997481215"], "date": "2001"}, {"id": "2171739182", "title": "The X Window System", "abstract": "An overview of the X Window System is presented, focusing on the system substrate and the low-level facilities provided to build applications and to manage the desktop. The system provides high-performance, high-level, device-independent graphics. A hierarchy of resizable, overlapping windows allows a wide variety of application and user interfaces to be built easily. Network-transparent access to the display provides an important degree of functional separation, without significantly affecting performance, which is crucial to building applications for a distributed environment. To a reasonable extent, desktop management can be custom-tailored to individual environments, without modifying the base system and typically without affecting applications.", "authors": ["Robert W. Scheifler", "Jim Gettys"], "related_topics": ["112999334", "89505385", "77660652"], "citation_count": "1762", "reference_count": "21", "references": ["2764466240", "1540641082", "2113547509", "2001438822", "179095166", "2157511281", "2075121558", "2055419062", "2070299543", "2011319041"], "date": "1990"}, {"id": "2134875103", "title": "\u2018Who Ate All the Pride?\u2019: Patriotic Sentiment and English National Football Support.", "abstract": "The growing popularity of English national insignia in international football tournaments has been widely interpreted as evidence of the emergence of a renewed English national consciousness. However, little empirical research has considered how people in England actually understand football support in relation to national identity. Interview data collected around the time of the Euro 2000 and the 2002 World Cup tournaments fail to substantiate the presumption that support for the England football team maps onto claims to patriotic sentiment in any straightforward way. People with far-right political affiliations did generally use national football support to symbolise a general pride in English national identity. However, other people either claimed not to support the England national team precisely because of its associations with nationalism, or else bracketed the domain of football support from more general connotations of English patriotism.", "authors": ["Jackie Abell", "Susan Condor", "Robert D. Lowe", "Stephen Gibson", "Clifford Stevenson"], "related_topics": ["2778444522", "2779547678", "2778407155"], "citation_count": "106", "reference_count": "34", "references": ["1556808170", "2480934907", "2087411274", "3134427541", "103927176", "2066337020", "2030289885", "2107499220", "1974932245", "2065145877"], "date": "2006"}, {"id": "1854196451", "title": "Backlight and ambient light sensor system", "abstract": "Apparatuses and methods to operate a display device of an electronic device. In some embodiments, a method includes receiving a user setting of a display control parameter, and altering, based on the user setting, an effect of an ambient light sensor value (ALS) on control of the display control parameter. Also, according to embodiments of the inventions, a method of operating a display of an electronic device includes receiving a change to one of a display brightness output level and an ambient light sensor output level, and altering, according to the change, a display contrast output level. In some embodiments, a method of operating a proximity sensor of an electronic device includes receiving a light sensor output, and altering, according to the output, an on/off setting of a proximity sensor. Other apparatuses and methods and data processing systems and machine readable media are also described.", "authors": ["Scott M. Herz", "Roberto G. Yepez", "Michael F. Culbert", "Scott Forstall"], "related_topics": ["164597639", "135403697", "171107226"], "citation_count": "301", "reference_count": "152", "references": ["1930456798", "1584397650", "1893940590", "1901544345", "2164252468", "2147555786", "1607518450", "2748207967", "1948825421", "1893741530"], "date": "2007"}, {"id": "2026575291", "title": "Reforms as experiments", "abstract": "Nach Campbell gibt es fur die Mehrzahl sozialer Pragramme noch immer keine interpretierbaren Evaluationen. Sein Artikel befast sich mit den Grunden dafur und versucht Wege aufzuzeigen, wie dies geandert werden konnte. Problem: Fur viele Reformen wird abgestimmt, als sei bereits sicher, das die gewunschte Wirkung auftritt. Zeigen die Ergebnisse spater etwas anderes an, last dies den Politiker unglaubwurdig wirken. Losungsvorschlag: Der Autor wunscht sich eine Politik, in der das Augenmerk nicht mehr auf die einzelnen Programme gerichtet ist, sondern auf die dahinter liegenden Probleme. Ziel sollte es sein, das Problem zu beseitigen. Wirkt ein bestimmtes Programm nicht, so konnten weitere Methoden ausprobiert werden.", "authors": ["Donald T. Campbell"], "related_topics": ["15708023", "17744445", "2986318677"], "citation_count": "2661", "reference_count": "31", "references": ["2024509488", "2073984231", "1993222074", "2035557811", "1986963893", "2067638289", "1982803242", "2141019942", "2472532806", "2323579418"], "date": "1969"}, {"id": "1998495461", "title": "A METHOD FOR JUDGING ALL CONTRASTS IN THE ANALYSIS OF VARIANCE", "abstract": "", "authors": ["Henry Scheff\u00e9"], "related_topics": ["152587130", "152732102", "192424360"], "citation_count": "2719", "reference_count": "13", "references": ["2801840425", "1515242458", "2797442763", "2314185483", "2034561638", "2056353558", "2022193726", "2166843037", "2059523379", "2034555244"], "date": "1953"}, {"id": "1504052325", "title": "Hierarchical control of droop-controlled DC and AC microgrids \u2014 a general approach towards standardization", "abstract": "DC and AC Microgrids are key elements to integrate renewable and distributed energy resources as well as distributed energy storage systems. In the last years, efforts toward the standardization of these Microgrids have been made. In this sense, this paper present the hierarchical control derived from ISA-95 and electrical dispatching standards to endow smartness and flexibility to microgrids. The hierarchical control proposed consist of three levels: i) the primary control is based on the droop method, including an output impedance virtual loop; ii) the secondary control allows restoring the deviations produced by the primary control; and iii) the tertiary control manage the power flow between the microgrid and the external electrical distribution system. Results from a hierarchical-controlled microgrid are provided to show the feasibility of the proposed approach.", "authors": ["J M Guerrero", "J C Vasquez", "J Matas", "L G de Vicuna", "M Castilla"], "related_topics": ["2776784348", "40760162", "108755667"], "citation_count": "4578", "reference_count": "44", "references": ["1763243278", "2089758604", "2130055347", "2149654885", "1966322913", "2124708943", "2105806216", "2118910576", "2079746763", "2162535598"], "date": "2009"}, {"id": "1565369953", "title": "Resistance against Differential Power Analysis for Elliptic Curve Cryptosystems", "abstract": "Differential Power Analysis, first introduced by Kocher et al. in [14], is a powerful technique allowing to recover secret smart card information by monitoring power signals. In [14] a specific DPA attack against smart-cards running the DES algorithm was described. As few as 1000 encryptions were sufficient to recover the secret key. In this paper we generalize DPA attack to elliptic curve (EC) cryptosystems and describe a DPA on EC Diffie-Hellman key exchange and EC EI-Gamal type encryption. Those attacks enable to recover the private key stored inside the smart-card. Moreover, we suggest countermeasures that thwart our attack.", "authors": ["Jean-S\u00e9bastien Coron"], "related_topics": ["71743495", "198690329", "203062551"], "citation_count": "1322", "reference_count": "17", "references": ["2156186849", "1613874182", "2108834246", "2036378739", "2199322517", "2031618446", "1981663184", "2099317248", "2128718974", "2003736153"], "date": "1999"}, {"id": "137653784", "title": "Distributions in Statistics: Discrete Distributions.", "abstract": "", "authors": ["B. S. Everitt", "N. L. Johnson", "S. Kotz"], "related_topics": ["84181548", "60775368", "55974624"], "citation_count": "852", "reference_count": "0", "references": ["2144775551", "2152828142", "2085943260", "2119634512", "2105039658", "2478103054", "2085950095", "2149914006", "2069629877", "3121402432"], "date": "1969"}, {"id": "2024372407", "title": "Connections: New Ways of Working in the Networked Organization", "abstract": "From the Publisher: Computer networking is changing the way people work and the way organizations function. \"Connections\" is an accessible guide to the promise and the pitfalls of this latest phase of the computer revolution.", "authors": ["Lee S. Sproull", "Sara Kiesler"], "related_topics": ["76950829", "545109879", "136764020"], "citation_count": "3983", "reference_count": "0", "references": ["2147050295", "2576297379", "2062866147", "2080957047", "1560831680", "2040817488", "2159730225", "2039688301", "1535174579", "1918878574"], "date": "1990"}, {"id": "2969165671", "title": "a cura di", "abstract": "", "authors": ["Calogero Massimo Cammalleri"], "related_topics": ["162324750"], "citation_count": "1025", "reference_count": "309", "references": ["2124758339", "2104129218", "2300567117", "2540627216", "2129813073", "13107481", "2147139740", "2099167504", "3122968539", "1568998819"], "date": "2017"}, {"id": "2033716058", "title": "Tensorial calibration. I: First-order calibration", "abstract": "Many analytical instruments now produce one-, two- or n-dimensional arrays of data that must be used for the analysis of samples. An integrated approach to linear calibration of such instruments is presented from a tensorial point of view. The data produced by these instruments are seen as the components of a first-, second- or nth-order tensor respectively. In this first paper, concepts of linear multivariate calibration are developed in the framework of first-order tensors, and it is shown that the problem of calibration is equivalent to finding the contravariant vector corresponding to the analyte being calibrated. A model of the subspace spanned by the variance in the calibration must be built to compute the contravarian vectors. It is shown that the only difference between methods such as least squares, principal components regression, latent root regression, ridge regression and partial least squres resides in the choice of the model.", "authors": ["Eugenio Sanchez", "Bruce R. Kowalski"], "related_topics": ["122027848", "74887250", "176012381"], "citation_count": "125", "reference_count": "36", "references": ["2158863190", "2034562813", "2797532987", "2166163519", "2091886411", "2097897435", "2166446427", "2005051528", "2055703272", "2058382695"], "date": "1988"}, {"id": "2102998034", "title": "What are emotions? And how can they be measured?:", "abstract": "Defining \u201cemotion\u201d is a notorious problem. Without consensual conceptualization and operationalization of exactly what phenomenon is to be studied, progress in theory and research is difficult to a...", "authors": ["Klaus R. Scherer"], "related_topics": ["9354725", "90734943", "117409633"], "citation_count": "4388", "reference_count": "64", "references": ["1984186949", "1966797434", "1556033561", "2149628368", "1533757021", "1880373995", "2010900569", "2900790966", "1714490037", "1567569044"], "date": "2005"}, {"id": "2049455633", "title": "Latent semantic models for collaborative filtering", "abstract": "Collaborative filtering aims at learning predictive models of user preferences, interests or behavior from community data, that is, a database of available user preferences. In this article, we describe a new family of model-based algorithms designed for this task. These algorithms rely on a statistical modelling technique that introduces latent class variables in a mixture model setting to discover user communities and prototypical interest profiles. We investigate several variations to deal with discrete and continuous response variables as well as with different objective functions. The main advantages of this technique over standard memory-based methods are higher accuracy, constant time prediction, and an explicit and compact model representation. The latter can also be used to mine for user communitites. The experimental evaluation shows that substantial improvements in accucracy over existing methods and published results can be obtained.", "authors": ["Thomas Hofmann"], "related_topics": ["21569690", "61224824", "114289077"], "citation_count": "1858", "reference_count": "26", "references": ["1880262756", "2042281163", "2147152072", "3121531027", "2107743791", "2049633694", "2085937320", "2124591829", "1966553486", "1999047234"], "date": "2003"}, {"id": "2138537392", "title": "Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)", "abstract": "This paper presents a novel evolutionary optimization strategy based on the derandomized evolution strategy with covariance matrix adaptation (CMA-ES). This new approach is intended to reduce the number of generations required for convergence to the optimum. Reducing the number of generations, i.e., the time complexity of the algorithm, is important if a large population size is desired: (1) to reduce the effect of noise; (2) to improve global search properties; and (3) to implement the algorithm on (highly) parallel machines. Our method results in a highly parallel algorithm which scales favorably with large numbers of processors. This is accomplished by efficiently incorporating the available information from a large population, thus significantly reducing the number of generations needed to adapt the covariance matrix. The original version of the CMA-ES was designed to reliably adapt the covariance matrix in small populations but it cannot exploit large populations efficiently. Our modifications scale up the efficiency to population sizes of up to 10n, where n is the problem dimension. This method has been applied to a large number of test problems, demonstrating that in many cases the CMA-ES can be advanced from quadratic to linear time complexity.", "authors": ["Nikolaus Hansen", "Sibylle D. M\u00fcller", "Petros Koumoutsakos"], "related_topics": ["205555498", "311688", "185142706"], "citation_count": "1940", "reference_count": "12", "references": ["2112036188", "2105217850", "2797530645", "2137514952", "1498178627", "206440355", "1976625337", "1628796138", "1970717464", "2002161478"], "date": "2003"}, {"id": "10512124", "title": "Gamification by Design: Implementing Game Mechanics in Web and Mobile Apps", "abstract": "What do Foursquare, Zynga, Nike+, and Groupon have in common? These and many other brands use gamification to deliver a sticky, viral, and engaging experience to their customers. This book provides the design strategy and tactics you need to integrate game mechanics into any kind of consumer-facing website or mobile app. Learn how to use core game concepts, design patterns, and meaningful code samples to a create fun and captivating social environment.Whether you're an executive, developer, producer, or product specialist, Gamification by Design will show you how game mechanics can help you build customer loyalty.Discover the motivational framework game designers use to segment and engage consumers Understand core game mechanics such as points, badges, levels, challenges, and leaderboards Engage your consumers with reward structures, positive reinforcement, and feedback loops Combine game mechanics with social interaction for activities such as collecting, gifting, heroism, and status Dive into case studies on Nike and Yahoo!, and analyze interactions at Google, Facebook, and Zynga Get the architecture and code to gamify a basic consumer site, and learn how to use mainstream gamification APIs from Badgeville \"Turning applications into games is a huge trend. This book does a great job of identifying the core lasting principals you need to inspire your users to visit again and again.\" Adam Loving Freelance Social Game Developer and founder of Twibes Twitter Groups", "authors": ["Gabe Zichermann", "Christopher Cunningham"], "related_topics": ["41826821", "503285160", "170828538"], "citation_count": "1539", "reference_count": "0", "references": ["2023718959", "1998933811", "2479485957", "2305130666", "2057148748", "2566152916", "3122294693", "2935399451", "1968522627", "1996046724"], "date": "2011"}, {"id": "1999736981", "title": "A survey of highly parallel computing", "abstract": "", "authors": ["Haynes", "Lau", "Siewiorek", "Mizell"], "related_topics": ["2776867014", "137364921", "167320929"], "citation_count": "206", "reference_count": "63", "references": ["2017369466", "2172307690", "2073491596", "2119241866", "1509443229", "1976284552", "2225811560", "2163929346", "2067021215", "2128703518"], "date": "1981"}, {"id": "2031248101", "title": "Cutting-plane training of structural SVMs", "abstract": "Discriminative training approaches like structural SVMs have shown much promise for building highly complex and accurate models in areas like natural language processing, protein structure prediction, and information retrieval. However, current training algorithms are computationally expensive or intractable on large datasets. To overcome this bottleneck, this paper explores how cutting-plane methods can provide fast training not only for classification SVMs, but also for structural SVMs. We show that for an equivalent \"1-slack\" reformulation of the linear SVM training problem, our cutting-plane method has time complexity linear in the number of training examples. In particular, the number of iterations does not depend on the number of training examples, and it is linear in the desired precision and the regularization parameter. Furthermore, we present an extensive empirical evaluation of the method applied to binary classification, multi-class classification, HMM sequence tagging, and CFG parsing. The experiments show that the cutting-plane algorithm is broadly applicable and fast in practice. On large datasets, it is typically several orders of magnitude faster than conventional training methods derived from decomposition methods like SVM-light, or conventional cutting-plane methods. Implementations of our methods are available at www.joachims.org .", "authors": ["Thorsten Joachims", "Thomas Finley", "Chun-Nam John Yu"], "related_topics": ["12267149", "66905080", "311688"], "citation_count": "1309", "reference_count": "46", "references": ["2153635508", "2156909104", "2148603752", "2147880316", "2119821739", "1512098439", "1576520375", "1632114991", "2035720976", "2150102617"], "date": "2009"}, {"id": "3003668884", "title": "Early Transmission Dynamics in Wuhan, China, of Novel Coronavirus-Infected Pneumonia.", "abstract": "Abstract Background The initial cases of novel coronavirus (2019-nCoV)\u2013infected pneumonia (NCIP) occurred in Wuhan, Hubei Province, China, in December 2019 and January 2020. We analyzed data on the...", "authors": ["Qun Li", "Xuhua Guan", "Peng Wu", "Xiaoye Wang", "Lei Zhou", "Yeqing Tong", "Ruiqi Ren", "Kathy S.M. Leung", "Eric H.Y. Lau", "Jessica Y. Wong", "Xuesen Xing", "Nijuan Xiang", "Yang Wu", "Chao Li", "Qi Chen", "Dan Li", "Tian Liu", "Jing Zhao", "Man Liu", "Wenxiao Tu", "Chuding Chen", "Lianmei Jin", "Rui Yang", "Qi Wang", "Suhua Zhou", "Rui Wang", "Hui Liu", "Yingbo Luo", "Yuan Liu", "Ge Shao", "Huan Li", "Zhongfa Tao", "Yang Yang", "Zhiqiang Deng", "Boxi Liu", "Zhitao Ma", "Yanping Zhang", "Guoqing Shi", "Tommy T.Y. Lam", "Joseph T. Wu", "George F. Gao", "Benjamin J. Cowling", "Bo Yang", "Gabriel M. Leung", "Zijian Feng"], "related_topics": ["2777648638", "2777914695", "2778137277"], "citation_count": "11868", "reference_count": "18", "references": ["3001897055", "3002539152", "3000834295", "3002533507", "2470646526", "3002715510", "1909499787", "3001971765", "2147166346", "2149508011"], "date": "2020"}, {"id": "2110157102", "title": "Security and privacy requirements analysis within a social setting", "abstract": "Security issues for software systems ultimately concern relationships among social actors stakeholders, system users, potential attackers - and the software acting on their behalf. We propose a methodological framework for dealing with security and privacy requirements based on i*, an agent-oriented requirements modeling language. The framework supports a set of analysis techniques. In particular, attacker analysis helps identify potential system abusers and their malicious intents. Dependency vulnerability analysis helps detect vulnerabilities in terms of organizational relationships among stakeholders. Countermeasure analysis supports the dynamic decision-making process of defensive system players in addressing vulnerabilities and threats. Finally, access control analysis bridges the gap between security requirement models and security implementation models. The framework is illustrated with an example involving security and privacy concerns in the design of agent-based health information systems. In addition, we discuss model evaluation techniques, including qualitative goal model analysis and property verification techniques based on model checking.", "authors": ["L. Liu", "E. Yu", "J. Mylopoulos"], "related_topics": ["121822524", "62913178", "29983905"], "citation_count": "550", "reference_count": "25", "references": ["2166602595", "2105539612", "2115179079", "2060440626", "2157437711", "3118517595", "2117818414", "1624528677", "54544099", "2150071393"], "date": "2003"}, {"id": "1480415088", "title": "Creation of favorable user perceptions: exploring the role of intrinsic motivation", "abstract": "A key issue facing information systems researchers and practitioners has been the difficulty in creating favorable user reactions to new technologies. Insufficient or ineffective training has been identified as one of the key factors underlying this disappointing reality. Among the various enhancements to training being examined in research, the role of intrinsic motivation as a lever to create favorable user perceptions has not been sufficiently exploited. In this research, two studies were conducted to compare a traditional training method with a training method that included a component aimed at enhancing intrinsic motivation. The results strongly favored the use of an intrinsic motivator during training. Key implications for theory and practice are discussed.", "authors": ["Viswanath Venkatesh"], "related_topics": ["206705377", "2776185967", "180198813"], "citation_count": "2166", "reference_count": "79", "references": ["1791587663", "2168569455", "2033943395", "2179683524", "1987198869", "1491644571", "2058428373", "2130801612", "1982210139", "2126512988"], "date": "1999"}, {"id": "205159212", "title": "Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure", "abstract": "", "authors": ["Ruslan Salakhutdinov", "Geoffrey E. Hinton"], "related_topics": ["113238511", "161677786", "80444323"], "citation_count": "507", "reference_count": "18", "references": ["2136922672", "2100495367", "2116064496", "2117154949", "2130556178", "2157364932", "2144935315", "2159737176", "2124914669", "2157444450"], "date": "2007"}, {"id": "2077375822", "title": "AUTOMATED COMPUTER ANALYSIS OF RADIOGRAPHIC IMAGES.", "abstract": "Lee B. Lusted in his Memorial Fund Lecture (1) anticipated the device: \u201can electronic \u2018scanner-computer\u2019 to look at chest photofluorograms and to separate the clearly normal chest films from the abnormal chest films. The abnormal chest films would be marked for later study by the radiologist.\u201d This automated computer analysis concept was based on some preliminary studies by Pendergrass and Tolles who showed that automatic scanning of photofluorograms could produce satisfactory density tracings. We are now reporting a method of automated computer analysis of radiographic images utilizing algorithms (a rule of procedure for solving a recurrent mathematical or logical problem) for recognizing parts of the radiographic image. Method and Results Thirty-seven 70 mm. photofluorograms were digitized and put on magnetic tape, using an improved image-scanning system similar to one previously reported (2). The radiographic image of the chest on magnetic tape contains 502 digit samples per line times 320 horizontal s...", "authors": ["Phillip H. Meyers", "Charles M. Nice", "Hal C. Becker", "Wilson J. Nettleton", "James W. Sweeney", "George R. Meckstroth"], "related_topics": ["2776805002", "2776140076", "36454342"], "citation_count": "102", "reference_count": "0", "references": ["2141619730", "1994062553", "2898197178", "2104775919", "2107166114", "2530279937", "2157117929", "3147329173", "2063945200", "2320139349"], "date": "1964"}, {"id": "2156899368", "title": "PROSITE : a dictionary of sites and patterns in proteins", "abstract": "PROSITE is a compilation of sites and patterns found in protein sequences. The use of protein sequence patterns (or motifs) to determine the function of proteins is becoming very rapidly one of the essential tools of sequence analysis. This reality has been recognized by many authors. While there have been a number of recent reports that review published patterns, no attempt had been made until very recently [5,6] to systematically collect biologically significant patterns or to discover new ones. It is for these reasons that we have developed, since 1988, a dictionary of sites and patterns which we call PROSITE. Some of the patterns compiled in PROSITE have been published in the literature, but the majority have been developed,in the last two years, by the author.", "authors": ["Amos Marc Bairoch"], "related_topics": ["76252022", "61053724", "10010492"], "citation_count": "1339", "reference_count": "0", "references": ["2143210482", "2102122585", "2098425296", "2761688050", "2020816856", "2155479906", "2147694156", "2154765457", "1970999032", "53898165"], "date": "1991"}, {"id": "3041188046", "title": "The sharing economy: Why people participate in collaborative consumption", "abstract": "Information and communications technologies ICTs have enabled the rise of so-called \"Collaborative Consumption\" CC: the peer-to-peer-based activity of obtaining, giving, or sharing the access to goods and services, coordinated through community-based online services. CC has been expected to alleviate societal problems such as hyper-consumption, pollution, and poverty by lowering the cost of economic coordination within communities. However, beyond anecdotal evidence, there is a dearth of understanding why people participate in CC. Therefore, in this article we investigate people's motivations to participate in CC. The study employs survey data N=168 gathered from people registered onto a CC site. The results show that participation in CC is motivated by many factors such as its sustainability, enjoyment of the activity as well as economic gains. An interesting detail in the result is that sustainability is not directly associated with participation unless it is at the same time also associated with positive attitudes towards CC. This suggests that sustainability might only be an important factor for those people for whom ecological consumption is important. Furthermore, the results suggest that in CC an attitude-behavior gap might exist; people perceive the activity positively and say good things about it, but this good attitude does not necessary translate into action.", "authors": ["Juho Hamari", "", "Mimmi Sj\u00f6klint", "Antti Ukkonen"], "related_topics": ["33199155", "187452473", "1374810"], "citation_count": "3762", "reference_count": "89", "references": ["2121001699", "2099697766", "2141846678", "2750954117", "2175723801", "3022734214", "1997321313", "3019273456", "1510316655", "1565831494"], "date": "2016"}, {"id": "2097268041", "title": "Deep AutoRegressive Networks", "abstract": "We introduce a deep, generative autoencoder capable of learning hierarchies of distributed representations from data. Successive deep stochastic hidden layers are equipped with autoregressive connections, which enable the model to be sampled from quickly and exactly via ancestral sampling. We derive an efficient approximate parameter estimation method based on the minimum description length (MDL) principle, which can be seen as maximising a variational lower bound on the log-likelihood, with a feedforward neural network implementing approximate inference. We demonstrate state-of-the-art generative performance on a number of classic data sets, including several UCI data sets, MNIST and Atari 2600 games.", "authors": ["Karol Gregor", "Ivo Danihelka", "Andriy Mnih", "Charles Blundell", "Daan Wierstra"], "related_topics": ["101738243", "2777472644", "47702885"], "citation_count": "225", "reference_count": "28", "references": ["2310919327", "3120740533", "2025768430", "3140968660", "1810943226", "2952509347", "189596042", "2096192494", "2108677974", "2134842679"], "date": "2014"}, {"id": "2066299564", "title": "DETENTE: practical support for practical action", "abstract": "", "authors": ["David A. Wroblewski", "Timothy P. McCandless", "William C. Hill"], "related_topics": ["2778032263", "41008148", "539667460"], "citation_count": "27", "reference_count": "13", "references": ["2004603793", "31045409", "2033337919", "1598089656", "1605067591", "2478175895", "2083799270", "150815164", "2504353039", "178067247"], "date": "1991"}, {"id": "2107990165", "title": "Discovering colocation patterns from spatial data sets: a general approach", "abstract": "Given a collection of Boolean spatial features, the colocation pattern discovery process finds the subsets of features frequently located together. For example, the analysis of an ecology data set may reveal symbiotic species. The spatial colocation rule problem is different from the association rule problem since there is no natural notion of transactions in spatial data sets which are embedded in continuous geographic space. We provide a transaction-free approach to mine colocation patterns by using the concept of proximity neighborhood. A new interest measure, a participation index, is also proposed for spatial colocation patterns. The participation index is used as the measure of prevalence of a colocation for two reasons. First, this measure is closely related to the cross-K function, which is often used as a statistical measure of interaction among pairs of spatial features. Second, it also possesses an antimonotone property which can be exploited for computational efficiency. Furthermore, we design an algorithm to discover colocation patterns. This algorithm includes a novel multiresolution pruning technique. Finally, experimental results are provided to show the strength of the algorithm and design decisions related to performance tuning.", "authors": ["Y. Huang", "S. Shekhar", "H. Xiong"], "related_topics": ["159620131", "193524817", "153180895"], "citation_count": "586", "reference_count": "16", "references": ["1484413656", "2143022286", "1549255393", "1870669718", "1530753374", "1976347887", "2125233616", "1877687928", "1483102573", "2144402047"], "date": "2004"}, {"id": "2023695725", "title": "From Semistructured Data to XML: Migrating the Lore Data Model and Query Language", "abstract": "Research on semistructured data over the last several years has focused on data models, query languages, and systems where the database is modeled as some form of labeled, directed graph. The recent emergence of eXtensible Markup Language (XML) as a new standard for data representation and exchange on the World-Wide Web has drawn significant attention. Researchers have casually observed a striking similarity between semistructured data models and XML. While similarities do abound, some key differences dictate changes to any existing data model, query language, or DBMS for semistructured data in order to fully support XML. This paper describes our experiences migrating the Lore database management system for semistructured data to work with XML. We present our modified data model, whose definition was a subtly challenging task given that XML itself is just a textual language. Based on this model, we describe changes to Lorel, Lore's query language. We also briefly discuss changes to Lore's dynamic structural summaries (DataGuides) and the relationship of DataGuides to XML's Document Type Definitions (DTDs).", "authors": ["Roy Goldman", "Jason McHugh", "Jennifer Widom"], "related_topics": ["183068750", "44883583", "34716815"], "citation_count": "554", "reference_count": "10", "references": ["2087060113", "2117849706", "2134356404", "2100674109", "1967062750", "2087898817", "2294792814", "1528249715", "2105505307", "1529930700"], "date": "1998"}, {"id": "2135255848", "title": "A spreading-activation theory of semantic processing", "abstract": "This paper presents a spreading-acti vation theory of human semantic processing, which can be applied to a wide range of recent experimental results. The theory is based on Quillian's theory of semantic memory search and semantic preparation, or priming. In conjunction with this, several of the miscondeptions concerning Qullian's theory are discussed. A number of additional assumptions are proposed for his theory in order to apply it to recent experiments. The present paper shows how the extended theory can account for results of several production experiments by Loftus, Juola and Atkinson's multiple-category experiment, Conrad's sentence-verification experiments, and several categorization experiments on the effect of semantic relatedness and typicality by Holyoak and Glass, Rips, Shoben, and Smith, and Rosch. The paper also provides a critique of the Smith, Shoben, and Rips model for categorization judgments. Some years ago, Quillian1 (1962, 1967) proposed a spreading-acti vation theory of human semantic processing that he tried to implement in computer simulations of memory search (Quillian, 1966) and comprehension (Quillian, 1969). The theory viewed memory search as activation spreading from two or more concept nodes in a semantic network until an intersection was found. The effects of preparation (or priming) in semantic memory were also explained in terms of spreading activation from the node of the primed concept. Rather than a theory to explain data, it was a theory designed to show how to build human semantic structure and processing into a computer.", "authors": ["Allan M. Collins", "Elizabeth F. Loftus"], "related_topics": ["511149849", "130318100", "65563180"], "citation_count": "12060", "reference_count": "44", "references": ["2064332540", "2109933556", "1502139053", "2106654511", "2011161709", "1990948551", "2142565826", "2014344082", "1989415743", "2127978962"], "date": "1975"}, {"id": "2131981140", "title": "Appropriate Assessment of Neighborhood Effects on Individual Health: Integrating Random and Fixed Effects in Multilevel Logistic Regression", "abstract": "The logistic regression model is frequently used in epidemiologic studies, yielding odds ratio or relative risk interpretations. Inspired by the theory of linear normal models, the logistic regression model has been extended to allow for correlated responses by introducing random effects. However, the model does not inherit the interpretational features of the normal model. In this paper, the authors argue that the existing measures are unsatisfactory (and some of them are even improper) when quantifying results from multilevel logistic regression analyses. The authors suggest a measure of heterogeneity, the median odds ratio, that quantifies cluster heterogeneity and facilitates a direct comparison between covariate effects and the magnitude of heterogeneity in terms of well-known odds ratios. Quantifying cluster-level covariates in a meaningful way is a challenge in multilevel logistic regression. For this purpose, the authors propose an odds ratio measure, the interval odds ratio, that takes these difficulties into account. The authors demonstrate the two measures by investigating heterogeneity between neighborhoods and effects of neighborhood-level covariates in two examples--public physician visits and ischemic heart disease hospitalizations--using 1999 data on 11,312 men aged 45-85 years in Malmo, Sweden.", "authors": ["Klaus Larsen", "Juan Merlo"], "related_topics": ["151956035", "117568660", "156957248"], "citation_count": "877", "reference_count": "17", "references": ["1978136073", "1976566530", "2044417549", "2169462149", "2119217392", "2149393522", "1968346944", "2124041619", "2029974256", "2149206332"], "date": "2004"}, {"id": "2112036188", "title": "Completely Derandomized Self-Adaptation in Evolution Strategies", "abstract": "This paper puts forward two useful methods for self-adaptation of the mutation distribution - the concepts of derandomization and cumulation. Principle shortcomings of the concept of mutative strategy parameter control and two levels of derandomization are reviewed. Basic demands on the self-adaptation of arbitrary (normal) mutation distributions are developed. Applying arbitrary, normal mutation distributions is equivalent to applying a general, linear problem encoding. The underlying objective of mutative strategy parameter control is roughly to favor previously selected mutation steps in the future. If this objective is pursued rigorously, a completely derandomized self-adaptation scheme results, which adapts arbitrary normal mutation distributions. This scheme, called covariance matrix adaptation (CMA), meets the previously stated demands. It can still be considerably improved by cumulation - utilizing an evolution path rather than single search steps. Simulations on various test functions reveal local and global search properties of the evolution strategy with and without covariance matrix adaptation. Their performances are comparable only on perfectly scaled functions. On badly scaled, non-separable functions usually a speed up factor of several orders of magnitude is observed. On moderately mis-scaled functions a speed up factor of three to ten can be expected.", "authors": ["Nikolaus Hansen", "Andreas Ostermeier"], "related_topics": ["205555498", "119007150", "207002847"], "citation_count": "3813", "reference_count": "42", "references": ["2981264952", "2144636407", "2105217850", "2020009149", "2072782187", "2101677491", "2486609979", "98056105", "2166739626", "206440355"], "date": "2001"}, {"id": "1543984587", "title": "Distributed morphology and the pieces of inflection", "abstract": "", "authors": ["M Halle", "Alec Marantz"], "related_topics": ["2779570750", "159403335", "41008148"], "citation_count": "2826", "reference_count": "0", "references": ["2002103405", "2128863839", "2149676521", "2124669395", "2109053132", "2142270908", "2111797102", "2112581312", "2144271548", "2124011124"], "date": "1992"}, {"id": "2132166479", "title": "Very Simple Classification Rules Perform Well on Most Commonly Used Datasets", "abstract": "This article reports an empirical investigation of the accuracy of rules that classify examples on the basis of a single attribute. On most datasets studied, the best of these very simple rules is as accurate as the rules induced by the majority of machine learning systems. The article explores the implications of this finding for machine learning research and applications.", "authors": ["Robert C. Holte"], "related_topics": ["199190896", "77967617", "50292564"], "citation_count": "2498", "reference_count": "47", "references": ["2149706766", "2136000097", "2073308541", "1604329830", "1973967548", "1534707631", "1927345150", "1597910678", "1570286060", "2146257637"], "date": "1993"}, {"id": "2127836646", "title": "A cache-based natural language model for speech recognition", "abstract": "Speech-recognition systems must often decide between competing ways of breaking up the acoustic input into strings of words. Since the possible strings may be acoustically similar, a language model is required; given a word string, the model returns its linguistic probability. Several Markov language models are discussed. A novel kind of language model which reflects short-term patterns of word use by means of a cache component (analogous to cache memory in hardware terminology) is presented. The model also contains a 3g-gram component of the traditional type. The combined model and a pure 3g-gram model were tested on samples drawn from the Lancaster-Oslo/Bergen (LOB) corpus of English text. The relative performance of the two models is examined, and suggestions for the future improvements are made. >", "authors": ["R. Kuhn", "R. De Mori"], "related_topics": ["39608478", "137293760", "115537543"], "citation_count": "757", "reference_count": "10", "references": ["2105594594", "1966812932", "2751601659", "1597533204", "2159782014", "1521239006", "2055528812", "1507680813", "2076639289", "340893908"], "date": "1990"}, {"id": "1992208280", "title": "Robust Stochastic Approximation Approach to Stochastic Programming", "abstract": "In this paper we consider optimization problems where the objective function is given in a form of the expectation. A basic difficulty of solving such stochastic optimization problems is that the involved multidimensional integrals (expectations) cannot be computed with high accuracy. The aim of this paper is to compare two computational approaches based on Monte Carlo sampling techniques, namely, the stochastic approximation (SA) and the sample average approximation (SAA) methods. Both approaches, the SA and SAA methods, have a long history. Current opinion is that the SAA method can efficiently use a specific (say, linear) structure of the considered problem, while the SA approach is a crude subgradient method, which often performs poorly in practice. We intend to demonstrate that a properly modified SA approach can be competitive and even significantly outperform the SAA method for a certain class of convex stochastic problems. We extend the analysis to the case of convex-concave stochastic saddle point problems and present (in our opinion highly encouraging) results of numerical experiments.", "authors": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"], "related_topics": ["194387892", "55479107", "137631369"], "citation_count": "1886", "reference_count": "26", "references": ["2038669746", "2169713291", "203276351", "2064076655", "1983916623", "2090359754", "2000257769", "2086161653", "1490324987", "2000953623"], "date": "2008"}, {"id": "1864836097", "title": "Clustered intrinsic connections in cat visual cortex", "abstract": "The intrinsic connections of the cortex have long been known to run vertically, across the cortical layers. In the present study we have found that individual neurons in the cat primary visual cortex can communicate over suprisingly long distances horizontally (up to 4 mm), in directions parallel to the cortical surface. For all of the cells having widespread projections, the collaterals within their axonal fields were distributed in repeating clusters, with an average periodicity of 1 mm. This pattern of extensive clustered projections has been revealed by combining the techniques of intracellular recording and injection of horseradish peroxidase with three- dimensional computer graphic reconstructions. The clustering pattern was most apparent when the cells were rotated to present a view parallel to the cortical surface. The pattern was observed in more than half of the pyramidal and spiny stellate cells in the cortex and was seen in all cortical layers. In our sample, cells made distant connections within their own layer and/or within another layer. The axon of one cell had clusters covering the same area in two layers, and the clusters in the deeper layer were located under those in the upper layer, suggesting a relationship between the clustering phenomenon and columnar cortical architecture. Some pyramidal cells did not project into the white matter, forming intrinsic connections exclusively. Finally, the axonal fields of all our injected cells were asymmetric, extending for greater distances along one cortical axis than along the orthogonal axis. The axons appeared to cover areas of cortex representing a larger part of the visual field than that covered by the excitatory portion of the cell9s own receptive field. These connections may be used to generate larger receptive fields or to produce the inhibitory flanks in other cells9 receptive fields.", "authors": ["CD Gilbert", "TN Wiesel"], "related_topics": ["163931696", "2779345533", "19071747"], "citation_count": "1355", "reference_count": "26", "references": ["2116360511", "1995708070", "2146567096", "2054549571", "1982150266", "2084577485", "2025959648", "2137203028", "1974447763", "2037424593"], "date": "1983"}, {"id": "2163741736", "title": "Towards an understanding of inequity", "abstract": "A theory of social inequity, with special consideration given to wage inequities is presented. A special case of Festinger's cognitive dissonance, the theory specifies the conditions under which inequity will arise and the means by which it may be reduced or eliminated. Observational field studies s", "authors": ["J S Adams"], "related_topics": ["202382195", "77513098", "106514582"], "citation_count": "10099", "reference_count": "11", "references": ["1966114254", "2084715591", "2157300266", "2111846090", "2034969428", "1507997145", "2318068098", "2072515635", "2086211531", "2162994934"], "date": "1963"}, {"id": "2147253850", "title": "A Database and Evaluation Methodology for Optical Flow", "abstract": "The quantitative evaluation of optical flow algorithms by Barron et al. (1994) led to significant advances in performance. The challenges for optical flow algorithms today go beyond the datasets and evaluation methods proposed in that paper. Instead, they center on problems associated with complex natural scenes, including nonrigid motion, real sensor noise, and motion discontinuities. We propose a new set of benchmarks and evaluation methods for the next generation of optical flow algorithms. To that end, we contribute four types of data to test different aspects of optical flow algorithms: (1) sequences with nonrigid motion where the ground-truth flow is determined by tracking hidden fluorescent texture, (2) realistic synthetic sequences, (3) high frame-rate video used to study interpolation error, and (4) modified stereo sequences of static scenes. In addition to the average angular error used by Barron et al., we compute the absolute flow endpoint error, measures for frame interpolation error, improved statistics, and results at motion discontinuities and in textureless regions. In October 2007, we published the performance of several well-known methods on a preliminary version of our data to establish the current state of the art. We also made the data freely available on the web at http://vision.middlebury.edu/flow/ . Subsequently a number of researchers have uploaded their results to our website and published papers using the data. A significant improvement in performance has already been achieved. In this paper we analyze the results obtained to date and draw a large number of conclusions from them.", "authors": ["Simon Baker", "Daniel Scharstein", "J. P. Lewis", "Stefan Roth", "Michael J. Black", "Richard Szeliski"], "related_topics": ["155542232", "72560505", "122383733"], "citation_count": "4608", "reference_count": "91", "references": ["2104974755", "2143516773", "2147253850", "2035379092", "2115733720", "2123921160", "2137659841", "2160014001", "2119781527", "1867429401"], "date": "2011"}, {"id": "2172651430", "title": "OSI reference model\u2014The ISO model of architecture for open systems interconnection", "abstract": "Considering the urgency of the need for standards which would allow constitution of heterogeneous computer networks, ISO created a new subcommittee for \"Open Systems Interconnection\" (ISO/ TC97/SC 16) in 1977. The first priority of subcommittee 16 was to develop an architecture for open systems interconnection which could serve as a framework for the definition of standard protocols. As a result of 18 months of studies and discussions, SC16 adopted a layered architecture comprising seven layers (Physical, Data Link, Network, Transport, Session, Presentation, and Application). In July 1979 the specifications of this architecture, established by SC16, were passed under the name of \"OSI Reference Model\" to Technical Committee 97 \"Data Processing\" along with recommendations to start officially, on this basis, a set of protocols standardization projects to cover the most urgent needs. These recommendations were adopted by T.C97 at the end of 1979 as the basis for the following development of standards for Open Systems Interconnectlon within ISO. The OSI Reference Model was also recognized by CCITT Rapporteur's Group on \"Layered Model for Public Data Network Services.\" This paper presents the model of architecture for Open Systems Interconnection developed by SC16. Some indications are also given on the initial set of protocols which will-likely be developed in this OSI Reference Model.", "authors": ["H. Zimmermann"], "related_topics": ["139449052", "168535184", "2779230994"], "citation_count": "2093", "reference_count": "0", "references": ["2023546887", "2132997891", "2073701540", "1993813153", "604465397", "2602977837", "2910653301", "2137250094", "2030301705", "2584619706"], "date": "1988"}, {"id": "2095999100", "title": "Face recognition using line edge map", "abstract": "The automatic recognition of human faces presents a significant challenge to the pattern recognition research community. Typically, human faces are very similar in structure with minor differences from person to person. They are actually within one class of \"human face\". Furthermore, lighting conditions change, while facial expressions and pose variations further complicate the face recognition task as one of the difficult problems in pattern analysis. This paper proposes a novel concept: namely, that faces can be recognized using a line edge map (LEM). The LEM, a compact face feature, is generated for face coding and recognition. A thorough investigation of the proposed concept is conducted which covers all aspects of human face recognition, i.e. face recognition under (1) controlled/ideal conditions and size variations, (2) varying lighting conditions, (3) varying facial expressions, and (4) varying pose. The system performance is also compared with the eigenface method, one of the best face recognition techniques, and with reported experimental results of other methods. A face pre-filtering technique is proposed to speed up the search process. It is a very encouraging to find that the proposed face recognition technique has performed better than the eigenface method in most of the comparison experiments. This research demonstrates that the LEM, together with the proposed generic line-segment Hausdorff distance measure, provides a new method for face coding and recognition.", "authors": ["Yongsheng Gao", "M.K.H. Leung"], "related_topics": ["88799230", "4641261", "54654163"], "citation_count": "671", "reference_count": "43", "references": ["2138451337", "2121647436", "2581275558", "2115689562", "2098947662", "2113341759", "2095757522", "2994340921", "2135463994", "2144354855"], "date": "2002"}, {"id": "2964199361", "title": "On the Properties of Neural Machine Translation: Encoder--Decoder Approaches", "abstract": "Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder\u2010Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.", "authors": ["Kyunghyun Cho", "Bart van Merrienboer", "Dzmitry Bahdanau", "Yoshua Bengio", "", ""], "related_topics": ["203005215", "81363708", "50644808"], "citation_count": "3650", "reference_count": "11", "references": ["2130942839", "2157331557", "6908809", "1753482797", "1810943226", "2153653739", "2395935897", "1828163288", "1905522558", "2341457423"], "date": "2014"}, {"id": "2155487652", "title": "On Edge Detection", "abstract": "Edge detection is the process that attempts to characterize the intensity changes in the image in terms of the physical processes that have originated them. A critical, intermediate goal of edge detection is the detection and characterization of significant intensity changes. This paper discusses this part of the edge detection problem. To characterize the types of intensity changes derivatives of different types, and possibly different scales, are needed. Thus, we consider this part of edge detection as a problem in numerical differentiation. We show that numerical differentiation of images is an ill-posed problem in the sense of Hadamard. Differentiation needs to be regularized by a regularizing filtering operation before differentiation. This shows that this part of edge detection consists of two steps, a filtering step and a differentiation step. Following this perspective, the paper discusses in detail the following theoretical aspects of edge detection. 1) The properties of different types of filters-with minimal uncertainty, with a bandpass spectrum, and with limited support-are derived. Minimal uncertainty filters optimize a tradeoff between computational efficiency and regularizing properties. 2) Relationships among several 2-D differential operators are established. In particular, we characterize the relation between the Laplacian and the second directional derivative along the gradient. Zero crossings of the Laplacian are not the only features computed in early vision. 3) Geometrical and topological properties of the zero crossings of differential operators are studied in terms of transversality and Morse theory.", "authors": ["Vincent Torre", "Tomaso A. Poggio"], "related_topics": ["193536780", "154181440", "165700671"], "citation_count": "1321", "reference_count": "27", "references": ["2740373864", "2109863423", "2003370853", "2006500012", "1995756857", "2133155955", "2007057443", "2121203842", "2038584908", "2073974819"], "date": "1986"}, {"id": "2037107113", "title": "High-speed high-security signatures", "abstract": "This paper shows that a $390 mass-market quad-core 2.4GHz Intel Westmere (Xeon E5620) CPU can create 109000 signatures per second and verify 71000 signatures per second on an elliptic curve at a 2128 security level. Public keys are 32 bytes, and signatures are 64 bytes. These performance figures include strong defenses against software side-channel attacks: there is no data flow from secret keys to array indices, and there is no data flow from secret keys to branch conditions.", "authors": ["DJ Daniel Bernstein", "N Niels Duif", "T Tanja Lange", "P Peter Schwabe", "BY Yang"], "related_topics": ["203062551", "145108525", "178489894"], "citation_count": "551", "reference_count": "50", "references": ["2108834246", "2169194339", "2095708839", "1910751411", "2154290215", "2224364690", "2109365902", "2326587081", "2134258244", "2164736940"], "date": "2012"}, {"id": "2022508996", "title": "Learning Hierarchical Features for Scene Labeling", "abstract": "Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a 320\u00d7240 image labeling in less than a second, including feature extraction.", "authors": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "related_topics": ["124504099", "63099799", "83665646"], "citation_count": "2778", "reference_count": "48", "references": ["2310919327", "2110158442", "2546302380", "2130325614", "1999478155", "2143516773", "1423339008", "2156163116", "2169551590", "2031342017"], "date": "2013"}, {"id": "2126263514", "title": "Evolution of scientific and technical information distribution", "abstract": "World Wide Web (WWW) and related information technologies are transforming the distribution of scientific and technical information (STI). We examine 11 recent, functioning digital libraries focusing on the distribution of STI publications, including journal articles, conference papers, and technical reports. We introduce 4 main categories of digital library projects: based on the architecture (distributed vs. centralized) and the contributor (traditional publisher vs. authoring individual/organization. Many digital library prototypes merely automate existing publishing practices or focus solely on the digitization of the publishing cycle output, not sampling and capturing elements of the input. Still others do not consider for distribution the large body of \"gray literature.\" We address these deficiencies in the current model of STI exchange by suggesting methods for expanding the scope and target of digital libraries by focusing on a greater source of technical publications and using \"buckets,\" an object-oriented construct for grouping logically related information objects, to include holdings other than technical publications.", "authors": ["Sandra L. Esler", "Michael L. Nelson"], "related_topics": ["64364511", "18599908", "513874922"], "citation_count": "60", "reference_count": "33", "references": ["1533109738", "2117085788", "1690636059", "2173701363", "2001450038", "2104039702", "2004331069", "2087021579", "2597849248", "2100061670"], "date": "1997"}, {"id": "2163057829", "title": "Method and apparatus for redirection of server external hyper-link references", "abstract": "A message is provided to a tracking server system in response to a client system referencing a predetermined resource locator that corresponds to a resource external to the tracking server system. The tracking server system indirectly provides for the client system to have an informational element selectable by the client system, where the informational element is graphically identified on the client system with informational content obtainable from a content server system through use of a content resource locator. The informational element includes a tracking resource locator, referencing the tracking server system, and data identifying the informational element. The selection of the informational element causes the client system to use the tracking resource locator to provide the data to the tracking server system and to use the content resource locator to obtain the informational content from the content server system.", "authors": ["Steven T. Kirsch", "Christopher J. Lindblad"], "related_topics": ["207539736", "77088390", "55472147"], "citation_count": "1059", "reference_count": "239", "references": ["2161461831", "2301975656", "2126825876", "2139020969", "1568713441", "2882023975", "2162310432", "1824793176", "2160566752", "2120827127"], "date": "1999"}, {"id": "2125412556", "title": "Partitioning and Scheduling Parallel Programs for Multiprocessing", "abstract": "From the Publisher: This book is one of the first to address the problem of forming useful parallelism from potential parallelism and to provide a general solution. The book presents two approaches to automatic partitioning and scheduling so that the same parallel program can be made to execute efficiently on widely different multiprocessors. The first approach is based on a macro dataflow model in which the program is partitioned into tasks at compile time and the tasks are scheduled on processors at run time. The second approach is based on a compile time scheduling model, where both the partitioning and scheduling are performed at compile time. Both approaches have been implemented in partition programs written in the single assignment language SISAL. The inputs to the partitioning and scheduling algorithms are a graphical representation of the parallel program and a list of parameters describing the target multiprocessor. Execution profile information is used to derive compile-time estimates of execution times and data sizes in the program. Both the macro dataflow and compile-time scheduling problems are expressed as optimization problems and are shown to be NP complete in the strong sense. Efficient approximation algorithms for these problems are presented. Finally, the effectiveness of the partitioning and scheduling algorithms is studied by multiprocessor simulations of various SISAL benchmark programs for different target multiprocessor parameters. Vivek Sarkar is a Member of Research Staff at the IBM T. J. Watson Research Center. Partitioning and Scheduling Parallel Programs for Multiprocessing is included in the series Research Monographs in Parallel and DistributedComputing. Copublished with Pitman Publishing.", "authors": ["Vivek Sarkar"], "related_topics": ["85924588", "31689143", "119948110"], "citation_count": "783", "reference_count": "0", "references": ["2133468529", "2040466547", "2095483845", "2049890071", "2023753260", "2097911714", "2124146147", "2020268805", "2118396891", "2114719509"], "date": "1989"}, {"id": "1647826363", "title": "The computer for the 21st century", "abstract": "Specialized elements of hardware and software, connected by wires, radio waves and infrared, will soon be so ubiquitous that no-one will notice their presence.", "authors": ["Mark Weiser"], "related_topics": ["96513508", "2779913896", "2777904410"], "citation_count": "20565", "reference_count": "0", "references": ["2152445175", "2035787713", "143895753", "1980168285", "2049398110", "2072737142", "2133826943", "2012806959", "21728024", "1736024740"], "date": "1995"}, {"id": "1625255723", "title": "Visual categorization with bags of keypoints", "abstract": "We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information.", "authors": ["G. Csurka"], "related_topics": ["167611913", "52001869", "94124525"], "citation_count": "6448", "reference_count": "25", "references": ["2148603752", "2164598857", "2124386111", "2177274842", "2154422044", "2149684865", "1676552347", "2124351082", "2155511848", "1484228140"], "date": "2003"}, {"id": "2036035292", "title": "Beyond Kalman filters: practical design of nonlinear filters", "abstract": "This paper describes a new exact nonlinear filter which generalizes the Kalman filter. The filter will be explained using block diagrams, for maximal clarity, in addition to detailed equations. A comparison with the Kalman filter will be given, highlighting the similar structure and low computational complexity. Using this block diagram comparison, engineers who are familiar with the Kalman filter will readily grasp the new nonlinear filter technique.\u00a9 (1995) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.", "authors": ["Frederick E. Daum"], "related_topics": ["206833254", "8639503", "11588082"], "citation_count": "16", "reference_count": "11", "references": ["2122512809", "2073283839", "2113373687", "2021982605", "1981762376", "2045807947", "2062062720", "2108391895", "1967009834", "1970586951"], "date": "1995"}, {"id": "2155174176", "title": "Multi-Cell MIMO Cooperative Networks: A New Look at Interference", "abstract": "This paper presents an overview of the theory and currently known techniques for multi-cell MIMO (multiple input multiple output) cooperation in wireless networks. In dense networks where interference emerges as the key capacity-limiting factor, multi-cell cooperation can dramatically improve the system performance. Remarkably, such techniques literally exploit inter-cell interference by allowing the user data to be jointly processed by several interfering base stations, thus mimicking the benefits of a large virtual MIMO array. Multi-cell MIMO cooperation concepts are examined from different perspectives, including an examination of the fundamental information-theoretic limits, a review of the coding and signal processing algorithmic developments, and, going beyond that, consideration of very practical issues related to scalability and system-level integration. A few promising and quite fundamental research avenues are also suggested.", "authors": ["D Gesbert", "S Hanly", "H Huang", "S Shamai Shitz", "O Simeone", "Wei Yu"], "related_topics": ["165650700", "91330434", "207987634"], "citation_count": "1873", "reference_count": "177", "references": ["1490674876", "1979408141", "2133475491", "2912369344", "2151795416", "2157989362", "2098249016", "2330078975", "2106929598", "2030546921"], "date": "2010"}, {"id": "2516809705", "title": "\u201cWhy Should I Trust You?\u201d: Explaining the Predictions of Any Classifier", "abstract": "Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.", "authors": ["Marco T\u00falio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "related_topics": ["2781376004", "50644808", "178621042"], "citation_count": "5388", "reference_count": "12", "references": ["2516809705", "2251939518", "2063978378", "2143996311", "2134584261", "2963499246", "2500139799", "2162651021", "2963790016", "2010158189"], "date": "2016"}, {"id": "1990079212", "title": "A streaming ensemble algorithm (SEA) for large-scale classification", "abstract": "Ensemble methods have recently garnered a great deal of attention in the machine learning community. Techniques such as Boosting and Bagging have proven to be highly effective but require repeated resampling of the training data, making them inappropriate in a data mining context. The methods presented in this paper take advantage of plentiful data, building separate classifiers on sequential chunks of training points. These classifiers are combined into a fixed-size ensemble using a heuristic replacement strategy. The result is a fast algorithm for large-scale or streaming data that classifies as well as a single decision tree built on all the data, requires approximately constant memory, and adjusts quickly to concept drift.", "authors": ["W. Nick Street", "YongSeog Kim"], "related_topics": ["45942800", "46686674", "60777511"], "citation_count": "1343", "reference_count": "18", "references": ["2912934387", "2084812512", "2125055259", "2110325612", "2112076978", "2152761983", "2068714596", "2093717447", "2100805904", "2022775778"], "date": "2001"}, {"id": "2033367330", "title": "Orthonormal ridgelets and linear singularities", "abstract": "We construct a new orthonormal basis for $L^2({\\Bbb R}^2)$, whose elements are angularly integrated ridge functions---{\\it orthonormal ridgelets}. The basis elements are smooth and of rapid decay in the spatial domain, and in the frequency domain are localized near angular wedges which, at radius $r = 2^j$, have radial extent $\\Delta r \\approx 2^j$ and angular extent $\\Delta \\theta \\approx 2\\pi/2^{j}$.Orthonormal ridgelet expansions expose an interesting phenomenon in nonlinear approximation: they give very efficient approximations to objects such as $1_{\\{ x_1\\cos\\theta+ x_2\\sin\\theta > a\\}} \\ e^{-x^2_1-x^2_2}$ which are smooth away from a discontinuity along a line. The orthonormal ridgelet coefficients of such objects are sparse: they belong to every $\\ell^p$, p > 0. This implies that simple thresholding in the ridgelet orthobasis is, in a certain sense, a near-ideal nonlinear approximation scheme for such objects.Orthonormal ridgelets may be viewed as L2 substitutes for approximation by sums of ridge ...", "authors": ["David L. Donoho"], "related_topics": ["5806529", "12426560", "12843"], "citation_count": "298", "reference_count": "10", "references": ["2098914003", "191129667", "2096613063", "2013987111", "1527329021", "2032322171", "1988487165", "2034648888", "2047990508", "1971622337"], "date": "2000"}, {"id": "2095150974", "title": "HyPursuit: a hierarchical network search engine that exploits content-link hypertext clustering", "abstract": "HyPursuit is a new hierarchical network search engine that clusters hypertext documents to structure a given information space for browsing and search act ivities. Our content-link clustering algorithm is based on the semantic information embedded in hyperlink structures and document contents. HyPursuit admits multiple, coexisting cluster hierarchies based on different principles for grouping documents, such as the Library of Congress catalog scheme and automatically created hypertext clusters. HyPursuit\u2019s abstraction functions summarize cluster contents to support scalable query processing. The abstraction functions satisfy system resource limitations with controlled information 10SS. The result of query processing operations on a cluster summary approximates the result of performing the operations on the entire information space. We constructed a prototype system comprising 100 leaf WorldWide Web sites and a hierarchy of 42 servers that route queries to the leaf sites. Experience with our system suggests that abstraction functions based on hypertext clustering can be used to construct meaningful and scalable cluster hierarchies. We are also encouraged by preliminary results on clustering based on both document contents and hyperlink structures.", "authors": ["Ron Weiss", "Bienvenido V\u00e9lez", "Mark A. Sheldon"], "related_topics": ["30088001", "73555534", "162215914"], "citation_count": "427", "reference_count": "20", "references": ["1978394996", "1996764654", "1828150029", "110443600", "2049994230", "2008375984", "2002132475", "2025288694", "2082398795", "1891699204"], "date": "1996"}, {"id": "2094320135", "title": "Fuzzy queries in multimedia database systems", "abstract": "There are essential differences between multimedia databases (which may contain complicated objects, such as images), and traditional databases. These differences lead to interesting new issues, and in particular cause us to consider new typos of queries. Wr example, in a multimedia database it is reasonable and natural to ask for images that are somehow \u201csimilar to\u201d some fixed image. Furthermore, there are different ways of obtaining and accessing information in a multimedia database than information in a traditional database. For example, in a multimedia database, it might be reasonable to have a query that asks for, say, the top 10 images that are similar to a fixed image. This is in contrast to a rolationnl database, where the answer to a query is simply a set, In this paper, we survey some new issues that arise for multimedia queries, with a particular focus on recent research by the author, developed in the context of the Garlic system at the IBM Almaden Research Center.", "authors": ["Ronald Fagin"], "related_topics": ["2779061030", "162189203", "54239708"], "citation_count": "416", "reference_count": "39", "references": ["2912565176", "2330022088", "2100115174", "2151135734", "2093191240", "2074429597", "1975830550", "1969294188", "2118783153", "2020919487"], "date": "1998"}, {"id": "2127014113", "title": "Model Predictive Control of thermal energy storage in building cooling systems", "abstract": "A preliminary study on the control of thermal energy storage in building cooling systems is presented. We focus on buildings equipped with a water tank used for actively storing cold water produced by a series of chillers. Typically the chillers are operated each night to recharge the storage tank in order to meet the buildings demand on the following day. A Model Predictive Control (MPC) for the chillers operation is designed in order to optimally store the thermal energy in the tank by using predictive knowledge of building loads and weather conditions. This paper addresses real-time implementation and feasibility issues of the MPC scheme by using a (1) simplified hybrid model of the system, (2) periodic robust invariant sets as terminal constraints and (3) a moving window blocking strategy.", "authors": ["Yudong Ma", "Francesco Borrelli", "Brandon Hencey", "Andrew Packard", "Scott Bortoff"], "related_topics": ["4638862", "172205157", "183287310"], "citation_count": "238", "reference_count": "21", "references": ["1978956894", "2108152153", "1608758704", "1576823098", "2088693678", "1485467598", "2034198196", "2212654072", "2019254379", "2151032674"], "date": "2009"}, {"id": "2036378739", "title": "Elliptic curve cryptosystems", "abstract": "We discuss analogs based on elliptic curves over finite fields of public key cryptosystems which use the multiplicative group of a finite field. These elliptic curve cryptosystems may be more secure, because the analog of the discrete logarithm problem on elliptic curves is likely to be harder than the classical discrete logarithm problem, especially over GF(2'). We discuss the question of primitive points on an elliptic curve modulo p, and give a theorem on nonsmoothness of the order of the cyclic subgroup generated by a global point.", "authors": ["Neal Koblitz"], "related_topics": ["121444067", "117121985", "68782407"], "citation_count": "7256", "reference_count": "12", "references": ["2156186849", "2108834246", "1490994218", "1589201628", "2075252632", "2046025532", "1503140737", "2036546151", "2599866313", "189366260"], "date": "1986"}, {"id": "2164284962", "title": "Exploration and Exploitation in Organizational Learning", "abstract": "This paper considers the relation between the exploration of new possibilities and the exploitation of old certainties in organizational learning. It examines some complications in allocating resources between the two, particularly those introduced by the distribution of costs and benefits across time and space, and the effects of ecological interaction. Two general situations involving the development and use of knowledge in organizations are modeled. The first is the case of mutual learning between members of an organization and an organizational code. The second is the case of learning and competitive advantage in competition for primacy. The paper develops an argument that adaptive processes, by refining exploitation more rapidly than exploration, are likely to become effective in the short run but self-destructive in the long run. The possibility that certain common organizational practices ameliorate that tendency is assessed.", "authors": ["James G. March"], "related_topics": ["169735623", "2775963222", "129018949"], "citation_count": "32052", "reference_count": "25", "references": ["1497256448", "2133469585", "1495886451", "1989218902", "1498488428", "2028436159", "2322605814", "1992135478", "2013419496", "2642534790"], "date": "1991"}, {"id": "1550258693", "title": "Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program", "abstract": "The UMLS Metathesaurus, the largest thesaurus in the biomedical domain, provides a representation of biomedical knowledge consisting of concepts classified by semantic type and both hierarchical and non-hierarchical relationships among the concepts. This knowledge has proved useful for many applications including decision support systems, management of patient records, information retrieval (IR) and data mining. Gaining effective access to the knowledge is critical to the success of these applications. This paper describes MetaMap, a program developed at the National Library of Medicine (NLM) to map biomedical text to the Metathesaurus or, equivalently, to discover Metathesaurus concepts referred to in text. MetaMap uses a knowledge intensive approach based on symbolic, natural language processing (NLP) and computational linguistic techniques. Besides being applied for both IR and data mining applications, MetaMap is one of the foundations of NLM's Indexing Initiative System which is being applied to both semi-automatic and fully automatic indexing of the biomedical literature at the library.", "authors": ["Alan R. Aronson"], "related_topics": ["69505689", "110615152", "2777309117"], "citation_count": "2555", "reference_count": "29", "references": ["2046224275", "1605873790", "2023736097", "2130160813", "1829379010", "24765167", "198852883", "195729069", "1557757161", "1580481679"], "date": "2000"}, {"id": "205765513", "title": "Entailment above the word level in distributional semantics", "abstract": "We introduce two ways to detect entailment using distributional semantic representations of phrases. Our first experiment shows that the entailment relation between adjective-noun constructions and their head nouns (big cat|= cat), once represented as semantic vector pairs, generalizes to lexical entailment among nouns (dog|= animal). Our second experiment shows that a classifier fed semantic vector pairs can similarly generalize the entailment relation among quantifier phrases (many dogs|= some dogs) to entailment involving unseen quantifiers (all cats|= several cats). Moreover, nominal and quantifier phrase entailment appears to be cued by different distributional correlates, as predicted by the type-based view of entailment in formal semantics.", "authors": ["Marco Baroni", "Raffaella Bernardi", "Ngoc-Quynh Do", "Chung-chieh Shan"], "related_topics": ["73686799", "95318506", "2778828372"], "citation_count": "245", "reference_count": "33", "references": ["2153635508", "1532325895", "1563088657", "1662133657", "1983578042", "1647729745", "1984052055", "2068737686", "1593045043", "1608322251"], "date": "2012"}, {"id": "2106491486", "title": "Structural risk minimization over data-dependent hierarchies", "abstract": "The paper introduces some generalizations of Vapnik's (1982) method of structural risk minimization (SRM). As well as making explicit some of the details on SRM, it provides a result that allows one to trade off errors on the training sample against improved generalization performance. It then considers the more general case when the hierarchy of classes is chosen in response to the data. A result is presented on the generalization performance of classifiers with a \"large margin\". This theoretically explains the impressive generalization performance of the maximal margin hyperplane algorithm of Vapnik and co-workers (which is the basis for their support vector machines). The paper concludes with a more general result in terms of \"luckiness\" functions, which provides a quite general way for exploiting serendipitous simplicity in observed data to obtain better prediction accuracy from small training sets. Four examples are given of such functions, including the Vapnik-Chervonenkis (1971) dimension measured on the sample.", "authors": ["J. Shawe-Taylor", "P.L. Bartlett", "R.C. Williamson", "M. Anthony"], "related_topics": ["154507838", "12267149", "177148314"], "citation_count": "682", "reference_count": "47", "references": ["2156909104", "2099111195", "2119821739", "1965324089", "2087347434", "3017143921", "2010353172", "1530699444", "2099579348", "2124503759"], "date": "1998"}, {"id": "2132454116", "title": "A Dynamic Theory of Organizational Knowledge Creation", "abstract": "This paper proposes a paradigm for managing the dynamic aspects of organizational knowledge creating processes. Its central theme is that organizational knowledge is created through a continuous dialogue between tacit and explicit knowledge. The nature of this dialogue is examined and four patterns of interaction involving tacit and explicit knowledge are identified. It is argued that while new knowledge is developed by individuals, organizations play a critical role in articulating and amplifying that knowledge. A theoretical framework is developed which provides an analytical perspective on the constituent dimensions of knowledge creation. This framework is then applied in two operational models for facilitating the dynamic creation of appropriate organizational knowledge.", "authors": ["Ikujiro Nonaka"], "related_topics": ["169735623", "2779561248", "56814567"], "citation_count": "26063", "reference_count": "65", "references": ["1495419098", "1708874574", "2007180942", "1933657216", "2052417512", "2150587481", "2004603793", "31045409", "2555803551", "2024135760"], "date": "1994"}, {"id": "2086235321", "title": "Learning analytics: drivers, developments and challenges", "abstract": "Learning analytics is a significant area of technology-enhanced learning that has emerged during the last decade. This review of the field begins with an examination of the technological, educational and political factors that have driven the development of analytics in educational settings. It goes on to chart the emergence of learning analytics, including their origins in the 20th century, the development of data-driven analytics, the rise of learning-focused perspectives and the influence of national economic concerns. It next focuses on the relationships between learning analytics, educational data mining and academic analytics. Finally, it examines developing areas of learning analytics research, and identifies a series of future challenges.", "authors": ["Rebecca Ferguson"], "related_topics": ["79158427", "2777648619", "171981572"], "citation_count": "1249", "reference_count": "61", "references": ["1780382453", "23685451", "2116199508", "2125910575", "2158997610", "2116339812", "1978710835", "193988059", "2135943618", "1539947443"], "date": "2011"}, {"id": "1521566952", "title": "Lexical Phonology and Morphology", "abstract": "", "authors": ["P. Kiparsky"], "related_topics": ["81868936", "148934300", "499950583"], "citation_count": "494", "reference_count": "0", "references": ["1562911371", "1575528222", "2120321299", "1493009933", "2176118107", "1533473429", "2067854309", "2158910967", "2144862731", "1976724989"], "date": "1981"}, {"id": "1522579744", "title": "Gradient Flows: In Metric Spaces and in the Space of Probability Measures", "abstract": "Notation.- Notation.- Gradient Flow in Metric Spaces.- Curves and Gradients in Metric Spaces.- Existence of Curves of Maximal Slope and their Variational Approximation.- Proofs of the Convergence Theorems.- Uniqueness, Generation of Contraction Semigroups, Error Estimates.- Gradient Flow in the Space of Probability Measures.- Preliminary Results on Measure Theory.- The Optimal Transportation Problem.- The Wasserstein Distance and its Behaviour along Geodesics.- Absolutely Continuous Curves in p(X) and the Continuity Equation.- Convex Functionals in p(X).- Metric Slope and Subdifferential Calculus in (X).- Gradient Flows and Curves of Maximal Slope in p(X).", "authors": ["Luigi Ambrosio", "Nicola Gigli", "Giuseppe Savar\u00e9"], "related_topics": ["196613150", "41261874", "2777634741"], "citation_count": "3135", "reference_count": "97", "references": ["3141151088", "1585160083", "1480714962", "1593038947", "2595348797", "1985506636", "2071048859", "2130401121", "2028712970", "2127674094"], "date": "2004"}, {"id": "2103017472", "title": "Gene ontology: tool for the unification of biology. The Gene Ontology Consortium.", "abstract": "Genomic sequencing has made it clear that a large fraction of the genes specifying the core biological functions are shared by all eukaryotes. Knowledge of the biological role of such shared proteins in one organism can often be transferred to other organisms. The goal of the Gene Ontology Consortium is to produce a dynamic, controlled vocabulary that can be applied to all eukaryotes even as knowledge of gene and protein roles in cells is accumulating and changing. To this end, three independent ontologies accessible on the World-Wide Web (http://www.geneontology.org) are being constructed: biological process, molecular function and cellular component.", "authors": ["M Ashburner", "C A Ball", "J A Blake", "D Botstein", "H Butler", "J M Cherry", "A P Davis", "K Dolinski", "S S Dwight", "J T Eppig", "M A Harris", "D P Hill", "L Issel-Tarver", "A Kasarskis", "S Lewis", "J C Matese", "J E Richardson", "M Ringwald", "G M Rubin", "G Sherlock"], "related_topics": ["2776814858", "137982476", "2776381358"], "citation_count": "30969", "reference_count": "30", "references": ["2150926065", "2141885858", "2141652419", "2103453943", "2003144438", "2981209166", "2153283265", "2133790733", "2106013076", "2137786672"], "date": "2000"}, {"id": "2112774031", "title": "A history of Haskell: being lazy with class", "abstract": "This paper describes the history of Haskell, including its genesis and principles, technical contributions, implementations and tools, and applications and impact.", "authors": ["Paul Hudak", "John Hughes", "Simon Peyton Jones", "Philip Wadler"], "related_topics": ["2780624054", "512554520", "199360897"], "citation_count": "439", "reference_count": "269", "references": ["1557561422", "2129990308", "2032401773", "2119717320", "1829244603", "1546727036", "1495226832", "1997143185", "2145691535", "2078944436"], "date": "2007"}, {"id": "2018201949", "title": "Comparative fit indexes in structural models", "abstract": "Normed and nonnormed fit indexes are frequently used as adjuncts to chi-square statistics for evaluating the fit of a structural model. A drawback of existing indexes is that they estimate no known population parameters. A new coefficient is proposed to summarize the relative reduction in the noncentrality parameters of two nested models. Two estimators of the coefficient yield new normed (CFI) and nonnormed (FI) fit indexes. CFI avoids the underestimation of fit often noted in small samples for Bentler and Bonett's (1980) normed fit index (NFI). FI is a linear function of Bentler and Bonett's non-normed fit index (NNFI) that avoids the extreme underestimation and overestimation often found in NNFI. Asymptotically, CFI, FI, NFI, and a new index developed by Bollen are equivalent measures of comparative fit, whereas NNFI measures relative fit by comparing noncentrality per degree of freedom. All of the indexes are generalized to permit use of Wald and Lagrange multiplier statistics. An example illustrates the behavior of these indexes under conditions of correct specification and misspecification. The new fit indexes perform very well at all sample sizes.", "authors": ["Peter M. Bentler"], "related_topics": ["132480984", "2908647359", "185429906"], "citation_count": "28759", "reference_count": "26", "references": ["2056434135", "2149608872", "2006779932", "1994263489", "1981903823", "2118769530", "2042539525", "2014543370", "2056453713", "2317982673"], "date": "1990"}, {"id": "2028593080", "title": "User comments for news recommendation in forum-based social media", "abstract": "News recommendation and user interaction are important features in many Web-based news services. The former helps users identify the most relevant news for further information. The latter enables collaborated information sharing among users with their comments following news postings. This research is intended to marry these two features together for an adaptive recommender system that utilizes reader comments to refine the recommendation of news in accordance with the evolving topic. This then turns the traditional \"push-data\" type of news recommendation to \"discussion\" moderator that can intelligently assist online forums. In addition, to alleviate the problem of recommending essentially identical articles, the relationship (duplicate, generalization, or specialization) between recommended news articles and the original posting is investigated. Our experiments indicate that our proposed solutions provide an improved news recommendation service in forum-based social media.", "authors": ["Qing Li", "Jia Wang", "Yuanzhu Peter Chen", "Zhangxi Lin"], "related_topics": ["180505990", "557471498", "21569690"], "citation_count": "170", "reference_count": "33", "references": ["1660390307", "2123427850", "2093390569", "2169213601", "2153111836", "2014415866", "2128629010", "1510348757", "2075893676", "2015338694"], "date": "2010"}, {"id": "1595210733", "title": "The Prosodic Structure of Function Words", "abstract": "", "authors": ["Elisabeth Selkirk"], "related_topics": ["60048249", "26022165", "542774811"], "citation_count": "874", "reference_count": "52", "references": ["1562911371", "1496771994", "1608707468", "2087099129", "1533473429", "207108878", "1504955803", "1598851216", "1591993017", "2115316195"], "date": "2008"}, {"id": "2061079066", "title": "Inductive Inference: Theory and Methods", "abstract": "There has been a great deal of theoretical and experimental work in computer science on inductive inference systems, that is, systems that try to infer general rules from examples. However, a complete and applicable theory of such systems is still a distant goal. This survey highlights and explains the main ideas that have been developed in the study of inductive inference, with special emphasis on the relations between the general theory and the specific algorithms and implementations. 154 references.", "authors": ["Dana Angluin", "Carl H. Smith"], "related_topics": ["197352929", "21563000", "6489637"], "citation_count": "1354", "reference_count": "113", "references": ["2009207944", "1514468887", "2067642555", "2103219113", "1965415591", "1488252886", "2017603160", "2009720124", "2019001600", "2020311636"], "date": "1983"}, {"id": "2734408173", "title": "An Introduction to Deep Learning for the Physical Layer", "abstract": "We present and discuss several novel applications of deep learning for the physical layer. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. This paper is concluded with a discussion of open challenges and areas for future investigation.", "authors": ["Timothy O'Shea", "Jakob Hoydis"], "related_topics": ["108583219", "101738243", "50644808"], "citation_count": "1168", "reference_count": "59", "references": ["2962835968", "2964121744", "2099471712", "2095705004", "2101234009", "2155893237", "1677182931", "2136922672", "2187089797", "1665214252"], "date": "2017"}, {"id": "2136518234", "title": "An Integrated Theory of the Mind.", "abstract": "Adaptive control of thought\u2013rational (ACT\u2013R; J. R. Anderson & C. Lebiere, 1998) has evolved into a theory that consists of multiple modules but also explains how these modules are integrated to produce coherent cognition. The perceptual-motor modules, the goal module, and the declarative memory module are presented as examples of specialized systems in ACT\u2013R. These modules are associated with distinct cortical regions. These modules place chunks in buffers where they can be detected by a production system that responds to patterns of information in the buffers. At any point in time, a single production rule is selected to respond to the current pattern. Subsymbolic processes serve to guide the selection of rules to fire as well as the internal operations of some modules. Much of learning involves tuning of these subsymbolic processes. A number of simple and complex empirical examples are described to illustrate how these modules function singly and in concert.", "authors": ["John R. Anderson", "Daniel Bothell", "Michael D. Byrne", "Scott Douglass", "Christian Lebiere", "Yulin Qin"], "related_topics": ["20854674", "107464732", "76950829"], "citation_count": "3882", "reference_count": "141", "references": ["1708874574", "1988520084", "2179427518", "1674947250", "1679907412", "2093353037", "2088563966", "2149095485", "2111609296", "2162792036"], "date": "2004"}, {"id": "2079746763", "title": "Wireless-Control Strategy for Parallel Operation of Distributed-Generation Inverters", "abstract": "In this paper, a method for the parallel operation of inverters in an ac-distributed system is proposed. This paper explores the control of active and reactive power flow through the analysis of the output impedance of the inverters and its impact on the power sharing. As a result, adaptive virtual output impedance is proposed in order to achieve a proper reactive power sharing, regardless of the line-impedance unbalances. A soft-start operation is also included, avoiding the initial current peak, which results in a seamless hot-swap operation. Active power sharing is achieved by adjusting the frequency in load transient situations only, owing to which the proposed method obtains a constant steady-state frequency and amplitude. As opposed to the conventional droop method, the transient response can be modified by acting on the main control parameters. Linear and nonlinear loads can be properly shared due to the addition of a current harmonic loop in the control strategy. Experimental results are presented from a two-6-kVA parallel-connected inverter system, showing the feasibility of the proposed approach", "authors": ["J.M. Guerrero", "J. Matas", "L.G. de Vicuna", "M. Castilla", "J. Miret"], "related_topics": ["108755667", "58112919", "40760162"], "citation_count": "831", "reference_count": "30", "references": ["2124708943", "2105806216", "2103457274", "2162156389", "2098484968", "2108922822", "1654140683", "2564513595", "2153425781", "2103874561"], "date": "2006"}, {"id": "2163352848", "title": "Multiresolution gray-scale and rotation invariant texture classification with local binary patterns", "abstract": "Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed \"uniform,\" are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the \"uniform\" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns.", "authors": ["T. Ojala", "M. Pietikainen", "T. Maenpaa"], "related_topics": ["87335442", "144121637", "63099799"], "citation_count": "16231", "reference_count": "46", "references": ["2039051707", "3017143921", "2098347925", "2106798282", "2132047332", "2159988601", "2021751319", "1993655741", "2136343973", "2124353687"], "date": "2002"}, {"id": "1977308918", "title": "Being There: Putting Brain, Body, and World Together Again", "abstract": "From the Publisher: The old opposition of matter versus mind stubbornly persists in the way we study mind and brain. In treating cognition as problem solving, Andy Clark suggests, we may often abstract too far from the very body and world in which our brains evolved to guide us. Whereas the mental has been treated as a realm that is distinct from the body and the world, Clark forcefully attests that a key to understanding brains is to see them as controllers of embodied activity. From this paradigm shift he advances the construction of a cognitive science of the embodied mind.", "authors": ["Andy Clark"], "related_topics": ["2778171780", "2777471729", "100609095"], "citation_count": "7338", "reference_count": "240", "references": ["1639032689", "1497256448", "2152150600", "2085529605", "2147800946", "1554576613", "2108020239", "22297218", "1933657216", "2004603793"], "date": "1996"}, {"id": "1849545308", "title": "Method of deactivating lock and portable electronic device", "abstract": "The invention relates to a method of deactivating the touch screen lock in a portable electronic device comprising a touch screen and means for locking the touch screen. The method comprises detecting touches on predetermined contact areas on the touch screen in a given order during touch screen lock and deactivating the touch screen lock once said touches on said predetermined contact areas are detected. The invention also relates to a portable electronic device comprising a touch screen and means for locking the touch screen. The device comprises means for detecting touches on predetermined contact areas on the touch screen in a given order during touch screen lock and deactivating the touch screen lock once said touches on said predetermined contact areas are detected.", "authors": ["Markku Rytivaara", "Mika Mustonen", "Timo Tokkonen"], "related_topics": ["42690194", "12096594", "9390403"], "citation_count": "391", "reference_count": "13", "references": ["1877200526", "1943153373", "1566917564", "1580416919", "3142742671", "1898285880", "385104935", "1522976812", "2836015177", "3150303245"], "date": "2003"}, {"id": "2133966932", "title": "Distributed active catalogs and meta-data caching in descriptive name services", "abstract": "Today's global internetworks challenge the ability of name services and other information services to locate data quickly. The authors introduce distributed active catalog and meta-data caching for optimizing queries in this environment. The active catalog constrains the search space for a query by returning a list of data repositories where the answer to the query is likely to be found. Meta-data caching improves performance by keeping frequently used characterizations of the search space close to the user, and eliminating active catalog communication and processing costs. When searching for query responses, the techniques contact only the small percentage of the data repositories with actual responses, resulting in search times of a few seconds. A distributed active catalog and meta-data caching method was implemented in a prototype descriptive name service called Nomenclator. Performance results for Nomenclator in a search space of 1000 data repositories are presented. >", "authors": ["J.J. Ordille", "P.B. Miller"], "related_topics": ["164120249", "118689300", "99016210"], "citation_count": "70", "reference_count": "16", "references": ["2016758618", "1502629466", "2043671329", "2066636971", "2064453341", "1964111545", "2073987830", "2036318949", "2110449607", "2156817947"], "date": "1993"}, {"id": "2043872160", "title": "A meta-analytic review of depression prevention programs for children and adolescents: factors that predict magnitude of intervention effects", "abstract": "In this meta-analytic review, the authors summarized the effects of depression prevention programs for youth as well as investigated participant, intervention, provider, and research design features associated with larger effects. They identified 47 trials that evaluated 32 prevention programs, producing 60 intervention effect sizes. The average effect for depressive symptoms from pre-to-posttreatment (r = .15) and pretreatment to-follow-up (r = .11) were small, but 13 (41%) prevention programs produced significant reductions in depressive symptoms and 4 (13%) produced significant reductions in risk for future depressive disorder onset relative to control groups. Larger effects emerged for programs targeting high-risk individuals, samples with more females, samples with older adolescents, programs with a shorter duration and with homework assignments, and programs delivered by professional interventionists. Intervention content (e.g., a focus on problem-solving training or reducing negative cognitions) and design features (e.g., use of random assignment and structured interviews) were unrelated to effect sizes. Results suggest that depression prevention efforts produce a higher yield if they incorporate factors associated with larger intervention effects (e.g., selective programs with a shorter duration that include homework).", "authors": ["Eric Stice", "Heather Shaw", "Cara Bohon", "C. Nathan Marti", "Paul Rohde"], "related_topics": ["129410224", "2779318504", "95190672"], "citation_count": "614", "reference_count": "87", "references": ["1973948212", "2037124948", "2012186625", "612372977", "1999649023", "2107031757", "2797811632", "2141403362", "1562193183", "2110531929"], "date": "2009"}, {"id": "1983578042", "title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.", "abstract": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched.", "authors": ["Thomas K. Landauer", "Susan T. Dumais"], "related_topics": ["112933361", "2777743986", "170133592"], "citation_count": "7840", "reference_count": "106", "references": ["2147152072", "2293063825", "1898014694", "1593045043", "2001467963", "1540136915", "2059975159", "2152632951", "1594369375", "2163953154"], "date": "1997"}, {"id": "2101196063", "title": "What is Twitter, a social network or a news media?", "abstract": "Twitter, a microblogging service less than three years old, commands more than 41 million users as of July 2009 and is growing fast. Twitter users tweet about any topic within the 140-character limit and follow others to receive their tweets. The goal of this paper is to study the topological characteristics of Twitter and its power as a new medium of information sharing.We have crawled the entire Twitter site and obtained 41.7 million user profiles, 1.47 billion social relations, 4,262 trending topics, and 106 million tweets. In its follower-following topology analysis we have found a non-power-law follower distribution, a short effective diameter, and low reciprocity, which all mark a deviation from known characteristics of human social networks [28]. In order to identify influentials on Twitter, we have ranked users by the number of followers and by PageRank and found two rankings to be similar. Ranking by retweets differs from the previous two rankings, indicating a gap in influence inferred from the number of followers and that from the popularity of one's tweets. We have analyzed the tweets of top trending topics and reported on their temporal behavior and user participation. We have classified the trending topics based on the active period and the tweets and show that the majority (over 85%) of topics are headline news or persistent news in nature. A closer look at retweets reveals that any retweeted tweet is to reach an average of 1,000 users no matter what the number of followers is of the original tweet. Once retweeted, a tweet gets retweeted almost instantly on next hops, signifying fast diffusion of information after the 1st retweet.To the best of our knowledge this work is the first quantitative study on the entire Twittersphere and information diffusion on it.", "authors": ["Haewoon Kwak", "Changhyun Lee", "Hosung Park", "Sue Moon"], "related_topics": ["143275388", "529147693", "2779172887"], "citation_count": "8718", "reference_count": "36", "references": ["2112090702", "1854214752", "2402962589", "2046804949", "2130354913", "2076219102", "3122139608", "2127492100", "1994473607", "2047443612"], "date": "2010"}, {"id": "1998186877", "title": "From piecemeal to configurational representation of faces", "abstract": "Unlike older children and adults, children of less than about 10 years of age remember photographs of faces presented upside down almost as well as those shown upright and are easily fooled by simple disguises. The development at age 10 of the ability to encode orientation-specific configurational aspects of a face may reflect completion of certain maturational changes in the right cerebral hemisphere.", "authors": ["Susan Carey", "Rhea Diamond"], "related_topics": ["195704467", "140441792", "109260823"], "citation_count": "1079", "reference_count": "12", "references": ["2139220163", "2046442873", "2056115137", "2044703390", "2329045102", "2022737180", "2031378282", "1990279616", "2009214135", "1976622121"], "date": "1977"}, {"id": "2015275764", "title": "Multiphoton entanglement and interferometry", "abstract": "Multiphoton interference reveals strictly nonclassical phenomena. Its applications range from fundamental tests of quantum mechanics to photonic quantum information processing, where a significant fraction of key experiments achieved so far comes from multiphoton state manipulation. The progress, both theoretical and experimental, of this rapidly advancing research is reviewed. The emphasis is given to the creation of photonic entanglement of various forms, tests of the completeness of quantum mechanics (in particular, violations of local realism), quantum information protocols for quantum communication (e.g., quantum teleportation, entanglement purification, and quantum repeater), and quantum computation with linear optics. The scope of the review is limited to ``few-photon'' phenomena involving measurements of discrete observables.", "authors": ["Jian-Wei Pan", "Zeng-Bing Chen", "Chao-Yang Lu", "Harald Weinfurter", "Anton Zeilinger", "Marek Zukowski", ""], "related_topics": ["190463098", "190474826", "89143813"], "citation_count": "1131", "reference_count": "500", "references": ["1631356911", "1977733098", "3038067977", "3037737784", "1620538313", "2132764286", "2163525631", "2068895447", "1978553093", "2011208902"], "date": "2012"}, {"id": "2039107287", "title": "Toward a model of text comprehension and production.", "abstract": "The semantic structure of texts can be described both at the local microlevel and at a more global macrolevel. A model for text comprehension based on this notion accounts for the formation of a coherent semantic text base in terms of a cyclical process constrained by limitations of working memory. Furthermore, the model includes macro-operators, whose purpose is to reduce the information in a text base to its gist, that is, the theoretical macrostructure. These operations are under the control of a schema, which is a theoretical formulation of the comprehender's goals. The macroprocesses are predictable only when the control schema can be made explicit. On the production side, the model is concerned with the generation of recall and summarization protocols. This process is partly reproductive and partly constructive, involving the inverse operation of the macro-operators. The model is applied to a paragraph from a psychological research report, and methods for the empirical testing of the model are developed.", "authors": ["Walter Kintsch", "Teun A. van Dijk"], "related_topics": ["170858558", "171276312", "2778701210"], "citation_count": "8735", "reference_count": "47", "references": ["2232925767", "2121773050", "2135255848", "74704794", "2045597501", "1970185999", "2045178568", "1878893887", "2033240844", "1550372748"], "date": "1978"}, {"id": "2060667324", "title": "Morphology: A study of the relation between meaning and form", "abstract": "This is a textbook right in the thick of current interest in morphology. It proposes principles to predict properties previously considered arbitrary and brings together the psychological and the diachronic to explain the recurrent properties of morphological systems in terms of the processes that create them. For the student, the clear discussion of morphology and morphophonemics and the rich variety of data brought in on the way to the theoretical conclusion is material for a direct learning experience.", "authors": ["Joan L. Bybee"], "related_topics": ["2780876879", "499950583", "136197465"], "citation_count": "6089", "reference_count": "0", "references": ["1562911371", "2078906720", "382421368", "2161070585", "1973826788", "1597744023", "2087360383", "2030831236", "651037503", "2029447880"], "date": "1984"}, {"id": "2045929671", "title": "Semantic text similarity using corpus-based word similarity and string similarity", "abstract": "We present a method for measuring the semantic similarity of texts using a corpus-based measure of semantic word similarity and a normalized and modified version of the Longest Common Subsequence (LCS) string matching algorithm. Existing methods for computing text similarity have focused mainly on either large documents or individual words. We focus on computing the similarity between two sentences or two short paragraphs. The proposed method can be exploited in a variety of applications involving textual knowledge representation and knowledge discovery. Evaluation results on two different data sets show that our method outperforms several competing methods.", "authors": ["Aminul Islam", "Diana Inkpen"], "related_topics": ["130318100", "84828104", "89604369"], "citation_count": "606", "reference_count": "51", "references": ["2101105183", "2038721957", "1983578042", "2158997610", "1647729745", "2102381086", "2110693578", "1567365482", "2150824314", "2100935296"], "date": "2008"}, {"id": "2172193860", "title": "Bridging Space Over Time: Global Virtual Team Dynamics and Effectiveness", "abstract": "Global virtual teams are internationally distributed groups of people with an organizational mandate to make or implement decisions with international components and implications. They are typically assigned tasks that are strategically important and highly complex. They rarely meet in person, conducting almost all of their interaction and decision making using communications technology. Although they play an increasingly important role in multinational organizations, little systematic is known about their dynamics or effectiveness. This study built a grounded theory of global virtual team processes and performance over time. We built a template based on Adaptive Structuration Theory (DeSanctis and Poole 1994) to guide our research, and we conducted a case study, observing three global virtual teams over a period of 21 months. Data were gathered using multiple methods, and qualitative methods were used to analyze them and generate a theory of global virtual team dynamics and effectiveness. First, we propose that effective global virtual team interaction comprises a series of communication incidents, each configured by aspects of the team's structural and process elements. Effective outcomes were associated with a fit among an interaction incident's form, decision process, and complexity. Second, effective global virtual teams sequence these incidents to generate a deep rhythm of regular face-to-face incidents interspersed with less intensive, shorter incidents using various media. These two insights are discussed with respect to other literature and are elaborated upon in several propositions. Implications for research and practice are also outlined.", "authors": ["Martha L. Maznevski", "Katherine M. Chudoba"], "related_topics": ["2776647852", "57035238", "156325361"], "citation_count": "2452", "reference_count": "92", "references": ["1527311855", "1556808170", "2000117884", "3144127399", "2141951329", "1978311462", "2576297379", "1983998663", "2318735428", "1491087240"], "date": "2000"}, {"id": "2097726431", "title": "Opinion Mining and Sentiment Analysis", "abstract": "An important part of our information-gathering behavior has always been to find out what other people think. With the growing availability and popularity of opinion-rich resources such as online review sites and personal blogs, new opportunities and challenges arise as people now can, and do, actively use information technologies to seek out and understand the opinions of others. The sudden eruption of activity in the area of opinion mining and sentiment analysis, which deals with the computational treatment of opinion, sentiment, and subjectivity in text, has thus occurred at least in part as a direct response to the surge of interest in new systems that deal directly with opinions as a first-class object. This survey covers techniques and approaches that promise to directly enable opinion-oriented information-seeking systems. Our focus is on methods that seek to address the new challenges raised by sentiment-aware applications, as compared to those that are already present in more traditional fact-based analysis. We include material on summarization of evaluative text and on broader issues regarding privacy, manipulation, and economic impact that the development of opinion-oriented information-access services gives rise to. To facilitate future work, a discussion of available resources, benchmark datasets, and evaluation campaigns is also provided.", "authors": ["Bo Pang", "Lillian Lee"], "related_topics": ["66402592", "170858558", "121017731"], "citation_count": "8720", "reference_count": "314", "references": ["1880262756", "3013264884", "2147880316", "2038721957", "2138621811", "2166706824", "2160660844", "2118020653", "3146306708", "2114524997"], "date": "2008"}, {"id": "1924689489", "title": "Naive (Bayes) at forty: the independence assumption in information retrieval", "abstract": "The naive Bayes classifier, currently experiencing a renaissance in machine learning, has long been a core technique in information retrieval. We review some of the variations of naive Bayes models used for text retrieval and classification, focusing on the distributional assumptions made about word occurrences in documents.", "authors": ["David D. Lewis"], "related_topics": ["52001869", "37061001", "2779532271"], "citation_count": "2906", "reference_count": "50", "references": ["2149684865", "1956559956", "2140785063", "3017143921", "1997841190", "2000672666", "2085989833", "1969572066", "2000569744", "2014415866"], "date": "1998"}, {"id": "2066102695", "title": "Automatic spelling correction using a trigram similarity measure", "abstract": "Abstract A nearest neighbour search procedure is described for the automatic correction of misspellings. The procedure involves the replacement of a misspelt word by that word in a dictionary which best matches the misspelling, the degree of match being calculated using a similarity coefficient based on the number of trigrams common to the two words. Experiments with a collection of 1544 misspellings and a dictionary of 64,636 words suggest that the procedure results in the unique identification of the correct spelling for over 75% of the misspellings if the correct form of the word is in the dictionary, and that this figure may be increased to over 90% if near, rather than nearest, neighbours are acceptable.", "authors": ["Richard C. Angell", "George E. Freund", "Peter Willett"], "related_topics": ["137546455", "2776517306", "2777801307"], "citation_count": "275", "reference_count": "25", "references": ["1970026646", "2007780422", "2111192396", "2010392031", "2066792529", "1974025666", "2016768890", "2023358833", "2161123931", "2055846397"], "date": "1982"}, {"id": "2133546079", "title": "Pizza into Java: translating theory into practice", "abstract": "Pizza is a strict superset of Java that incorporates three ideas from the academic community: parametric polymorphism, higher-order functions, and algebraic data types. Pizza is defined by translation into Java and compiles into the Java Virtual Machine, requirements which strongly constrain the design space. Nonetheless, Pizza fits smoothly to Java, with only a few rough edges.", "authors": ["Martin Odersky", "Philip Wadler"], "related_topics": ["168702491", "172482141", "174954855"], "citation_count": "689", "reference_count": "24", "references": ["1644882639", "2987803397", "1533109738", "10589072", "2027657506", "1507693023", "1484366641", "2163976959", "2059895047", "2120348241"], "date": "1996"}, {"id": "2087718299", "title": "A collection of outdoor robotic datasets with centimeter-accuracy ground truth", "abstract": "The lack of publicly accessible datasets with a reliable ground truth has prevented in the past a fair and coherent comparison of different methods proposed in the mobile robot Simultaneous Localization and Mapping (SLAM) literature. Providing such a ground truth becomes specially challenging in the case of visual SLAM, where the world model is 3-dimensional and the robot path is 6-dimensional. This work addresses both the practical and theoretical issues found while building a collection of six outdoor datasets. It is discussed how to estimate the 6-d vehicle path from readings of a set of three Real Time Kinematics (RTK) GPS receivers, as well as the associated uncertainty bounds that can be employed to evaluate the performance of SLAM methods. The vehicle was also equipped with several laser scanners, from which reference point clouds are built as a testbed for other algorithms such as segmentation or surface fitting. All the datasets, calibration information and associated software tools are available for download http://babel.isa.uma.es/mrpt/papers/dataset2009/ .", "authors": ["Jose-Luis Blanco", "Francisco-Angel Moreno", "Javier Gonzalez"], "related_topics": ["146849305", "86369673", "19966478"], "citation_count": "185", "reference_count": "20", "references": ["2167667767", "2049981393", "2152671441", "2146881125", "2168210109", "2118428504", "2162870748", "1993267444", "1545923740", "2986444355"], "date": "2009"}, {"id": "2107272354", "title": "Lifted first-order probabilistic inference", "abstract": "Most probabilistic inference algorithms are specified and processed on a propositional level. In the last decade, many proposals for algorithms accepting first-order specifications have been presented, but in the inference stage they still operate on a mostly propositional representation level. [Poole, 2003] presented a method to perform inference directly on the first-order level, but this method is limited to special cases. In this paperwe present the first exact inference algorithm that operates directly on a first-order level, and that can be applied to any first-order model (specified in a language that generalizes undirected graphical models). Our experiments show superior performance in comparison with propositional exact inference.", "authors": ["Rodrigo De Salvo Braz", "Eyal Amir", "Dan Roth"], "related_topics": ["162376815", "95167961", "2776214188"], "citation_count": "386", "reference_count": "20", "references": ["2159080219", "1977970897", "2126185296", "73939759", "1988095917", "2090761873", "1965552673", "1971883645", "1723714545", "1483839075"], "date": "2005"}, {"id": "2154627749", "title": "Methods for Distributed Information Retrieval", "abstract": "Published methods for distributed information retrieval generally rely on cooperation from search servers. But most real servers, particularly the tens of thousands available on the Web, are not engineered for such cooperation. This means that the majority of methods proposed, and evaluated in simulated environments of homogeneous cooperating servers, are never applied in practice. This thesis introduces new methods for server selection and results merging. The methods do not require search servers to cooperate, yet are as effective as the best methods which do. Two large experiments evaluate the new methods against many previously published methods. In contrast to previous experiments they simulate a Web-like environment, where servers employ varied retrieval algorithms and tend not to sub-partition documents from a single source. The server selection experiment uses pages from 956 real Web servers, three different retrieval systems and TREC ad hoc topics. Results show that a broker using queries to sample servers\u2019 documents can perform selection over non-cooperating servers without loss of effectiveness. However, using the same queries to estimate the effectiveness of servers, in order to favour servers with high quality retrieval systems, did not consistently improve selection effectiveness. The results merging experiment uses documents from five TREC sub-collections, five different retrieval systems and TREC ad hoc topics. Results show that a broker using a reference set of collection statistics, rather than relying on cooperation to collate true statistics, can perform merging without loss of effectiveness. Since application of the reference statistics method requires that the broker download the documents to be merged, experiments were also conducted on effective merging based on partial documents. The new ranking method developed was not highly effective on partial documents, but showed some promise on fully downloaded documents. Using the new methods, an effective search broker can be built, capable of addressing any given set of available search servers, without their cooperation.", "authors": ["Nicholas Eric Craswell"], "related_topics": ["93996380", "116425068", "87546605"], "citation_count": "65", "reference_count": "62", "references": ["1779735989", "2107252390", "1482214997", "1997841190", "166263196", "2753176400", "1976959760", "1775663022", "2073788020", "1550771877"], "date": "1999"}, {"id": "3019273456", "title": "Intrinsic Motivation and Self-Determination in Human Behavior", "abstract": "", "authors": ["Karen A. Miller", "Edward L. Deci", "Richard M. Ryan"], "related_topics": ["206705377", "76217610", "146854351"], "citation_count": "31828", "reference_count": "0", "references": ["2141846678", "2560140854", "2122517769", "2170899200", "2127662631", "3041188046", "2010348352", "2169570446", "1976439938", "2153610778"], "date": "1988"}, {"id": "1990391007", "title": "Incomplete Information in Relational Databases", "abstract": "ABSTRACT This paper concerns the semantics of Codd's relational model of data. Formulated are precise conditions that should be satisfied in a semantically meaningful extension of the usual relational operators, such as projection, selection, union, and join, from operators on relations to operators on tables with \u201cnull values\u201d of various kinds allowed. These conditions require that the system be safe in the sense that no incorrect conclusion is derivable by using a specified subset \u03a9 of the relational operators; and that it be complete in the sense that all valid conclusions expressible by relational expressions using operators in \u03a9 are in fact derivable in this system. Two such systems of practical interest are shown. The first, based on the usual Codd's null values, supports projection and selection. The second, based on many different (\u201cmarked\u201d) null values or variables allowed to appear in a table, is shown to correctly support projection, positive selection (with no negation occurring in the selection condition), union, and renaming of attributes, which allows for processing arbitrary conjunctive queries. A very desirable property enjoyed by this system is that all relational operators on tables are performed in exactly the same way as in the case of the usual relations. A third system, mainly of theoretical interest, supporting projection, selection, union, join, and renaming, is also discussed. Under a so-called closed world assumption, it can also handle the operator of difference. It is based on a device called a conditional table and is crucial to the proof of the correctness of the second system. All systems considered allow for relational expressions containing arbitrarily many different relation symbols, and no form of the universal relation assumption is required. Categories and Subject Descriptors: H.2.3 [Database Management]: Languages\u2014 query languages; H.2.4 [Database Management]: Systems\u2014 query processing General Terms: Theory", "authors": ["Tomasz Imieli\u0144ski", "Witold Lipski"], "related_topics": ["40207289", "16739119", "99436015"], "citation_count": "1243", "reference_count": "27", "references": ["2011039300", "2988119170", "2123858323", "2122789628", "1496815773", "1979514837", "2003017562", "1975714036", "1983428002", "1994581962"], "date": "1984"}, {"id": "2314185483", "title": "The assumptions underlying the analysis of variance.", "abstract": "", "authors": ["Churchill Eisenhart"], "related_topics": ["99476002", "105795698", "33923547"], "citation_count": "708", "reference_count": "0", "references": ["2124632458", "2056581871", "1989314580", "217328182", "2009172303", "2157291679", "2122284985", "3099103476", "1973922847", "1995045651"], "date": "1947"}, {"id": "2157795344", "title": "Significance analysis of microarrays applied to the ionizing radiation response", "abstract": "Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.", "authors": ["Virginia Goss Tusher", "Robert Tibshirani", "Gilbert Chu"], "related_topics": ["77360908", "18431079", "95371953"], "citation_count": "13831", "reference_count": "34", "references": ["2150926065", "1679913846", "2089218510", "1986179131", "2165054897", "2796677525", "1982516880", "2006873092", "2014170738", "1966645907"], "date": "2001"}, {"id": "2128423220", "title": "Haptic feedback for touchpads and other touch control", "abstract": "A haptic feedback planar touch control used to provide input to a computer. A touch input device includes a planar touch surface that inputs a position signal to a processor of the computer based on a location of user contact on the touch surface. The computer can position a cursor in a displayed graphical environment based at least in part on the position signal, or perform a different function. At least one actuator is also coupled to the touch input device and outputs a force to provide a haptic sensation to the user contacting the touch surface. The touch input device can be a touchpad separate from the computer's display screen, or can be a touch screen. Output haptic sensations on the touch input device can include pulses, vibrations, and spatial textures. The touch input device can include multiple different regions to control different computer functions.", "authors": ["Louis B. Rosenberg", "James R. Riegel"], "related_topics": ["152086174", "121449826", "43199551"], "citation_count": "1530", "reference_count": "500", "references": ["2113918921", "2107118797", "1973922175", "1893741530", "2855313633", "1824236464", "2133300032", "2117464700", "2122448302", "2111063174"], "date": "2007"}, {"id": "195465510", "title": "Probabilistic Inference Using Markov Chain Monte Carlo Methods", "abstract": "Probabilistic inference is an attractive approach to uncertain reasoning and empirical learning in artificial intelligence. Computational difficulties arise, however, because probabilistic models with the necessary realism and flexibility lead to complex distributions over high-dimensional spaces. Related problems in other fields have been tackled using Monte Carlo methods based on sampling using Markov chains, providing a rich array of techniques that can be applied to problems in artificial intelligence. The \u201cMetropolis algorithm\u201d has been used to solve difficult problems in statistical physics for over forty years, and, in the last few years, the related method of \u201cGibbs sampling\u201d has been applied to problems of statistical inference. Concurrently, an alternative method for solving problems in statistical physics by means of dynamical simulation has been developed as well, and has recently been unified with the Metropolis algorithm to produce the \u201chybrid Monte Carlo\u201d method. In computer science, Markov chain sampling is the basis of the heuristic optimization technique of \u201csimulated annealing\u201d, and has recently been used in randomized algorithms for approximate counting of large sets. In this review, I outline the role of probabilistic inference in artificial intelligence, present the theory of Markov chains, and describe various Markov chain Monte Carlo algorithms, along with a number of supporting techniques. I try to present a comprehensive picture of the range of methods that have been developed, including techniques from the varied literature that have not yet seen wide application in artificial intelligence, but which appear relevant. As illustrative examples, I use the problems of probabilistic inference in expert systems, discovery of latent classes from data, and Bayesian learning for neural networks.", "authors": ["Radford M. Neal"], "related_topics": ["111350023", "52421305", "204493344"], "citation_count": "2121", "reference_count": "107", "references": ["2581275558", "1498436455", "1997063559", "2049633694", "1988520084", "2148534890", "2083875149", "1593793857", "2111051539", "2914275007"], "date": "2010"}, {"id": "2000858991", "title": "Monitoring batch processes using multiway principal component analysis", "abstract": "Multivariate statistical procedures for monitoring the progress of batch processes are developed. The only information needed to exploit the procedures is a historical database of past successful batches. Multiway principal component analysis is used to extract the information in the multivariate trajectory data by projecting them onto low-dimensional spaces defined by the latent variables or principal components. This leads to simple monitoring charts, consistent with the philosophy of statistical process control, which are capable of tracking the progress of new batch runs and detecting the occurrence of observable upsets. The approach is contrasted with other approaches which use theoretical or knowledge-based models, and its potential is illustrated using a detailed simulation study of a semibatch reactor for the production of styrene-butadiene latex.", "authors": ["Paul Nomikos", "John F. MacGregor"], "related_topics": ["113644684", "27438332", "161584116"], "citation_count": "1835", "reference_count": "0", "references": ["2135663228", "2000651380", "1966863755", "2147129131", "2322097696", "1978994389", "1982275278", "1990384678", "2072857564", "1992742133"], "date": "1994"}, {"id": "2180838288", "title": "What is the goal of sensory coding", "abstract": "A number of recent attempts have been made to describe early sensory coding in terms of a general information processing strategy. In this paper, two strategies are contrasted. Both strategies take advantage of the redundancy in the environment to produce more effective representations. The first is described as a \"compact\" coding scheme. A compact code performs a transform that allows the input to be represented with a reduced number of vectors (cells) with minimal RMS error. This approach has recently become popular in the neural network literature and is related to a process called Principal Components Analysis (PCA). A number of recent papers have suggested that the optimal compact code for representing natural scenes will have units with receptive field profiles much like those found in the retina and primary visual cortex. However, in this paper, it is proposed that compact coding schemes are insufficient to account for the receptive field properties of cells in the mammalian visual pathway. In contrast, it is proposed that the visual system is near to optimal in representing natural scenes only if optimality is defined in terms of \"sparse distributed\" coding. In a sparse distributed code, all cells in the code have an equal response probability across the class of images but have a low response probability for any single image. In such a code, the dimensionality is not reduced. Rather, the redundancy of the input is transformed into the redundancy of the firing pattern of cells. It is proposed that the signature for a sparse code is found in the fourth moment of the response distribution (i.e., the kurtosis). In measurements with 55 calibrated natural scenes, the kurtosis was found to peak when the bandwidths of the visual code matched those of cells in the mammalian visual cortex. Codes resembling \"wavelet transforms\" are proposed to be effective because the response histograms of such codes are sparse (i.e., show high kurtosis) when presented with natural scenes. It is proposed that the structure of the image that allows sparse coding is found in the phase spectrum of the image. It is suggested that natural scenes, to a first approximation, can be considered as a sum of self-similar local functions (the inverse of a wavelet). Possible reasons for why sensory systems would evolve toward sparse coding are presented.", "authors": ["David J. Field"], "related_topics": ["77637269", "167955471", "47432892"], "citation_count": "1662", "reference_count": "0", "references": ["2097074225", "2140499889", "2142940228", "2133180260", "2124731682", "2151035455", "2037090920", "2124486835", "2167804690", "2113466552"], "date": "1999"}, {"id": "59771946", "title": "Translation-Invariant De-Noising", "abstract": "De-Noising with the traditional (orthogonal, maximally-decimated) wavelet transform sometimes exhibits visual artifacts; we attribute some of these\u2014for example, Gibbs phenomena in the neighborhood of discontinuities\u2014to the lack of translation invariance of the wavelet basis. One method to suppress such artifacts, termed \u201ccycle spinning\u201d by Coifman, is to \u201caverage out\u201d the translation dependence. For a range of shifts, one shifts the data (right or left as the case may be), De-Noises the shifted data, and then unshifts the de-noised data. Doing this for each of a range of shifts, and averaging the several results so obtained, produces a reconstruction subject to far weaker Gibbs phenomena than thresholding based De-Noising using the traditional orthogonal wavelet transform.", "authors": ["R. R. Coifman", "D. L. Donoho"], "related_topics": ["2777451244", "73339587", "196216189"], "citation_count": "3174", "reference_count": "17", "references": ["2062024414", "2158940042", "2151693816", "2079724595", "2156447271", "191129667", "2107790757", "1604810369", "2050880896", "1653130573"], "date": "1994"}, {"id": "2176028050", "title": "Connectionist learning procedures", "abstract": "A major goal of research on networks of neuron-like processing units is to discover efficient learning procedures that allow these networks to construct complex internal representations of their environment. The learning procedures must be capable of modifying the connection strengths in such a way that internal units which are not part of the input or output come to represent important features of the task domain. Several interesting gradient-descent procedures have recently been discovered. Each connection computes the derivative, with respect to the connection strength, of a global measure of the error in the performance of the network. The strength is then adjusted in the direction that decreases the error. These relatively simple, gradient-descent learning procedures work well for small tasks and the new challenge is to find ways of improving their convergence rate and their generalization abilities so that they can be applied to larger, more realistic tasks.", "authors": ["Geoffrey E. Hinton"], "related_topics": ["50644808", "8521452", "2777884278"], "citation_count": "3990", "reference_count": "85", "references": ["1497256448", "2581275558", "2154642048", "1498436455", "1997063559", "2049633694", "2293063825", "2895674046", "1597286183", "22297218"], "date": "1990"}, {"id": "2107520978", "title": "Network coding for large scale content distribution", "abstract": "We propose a new scheme for content distribution of large files that is based on network coding. With network coding, each node of the distribution network is able to generate and transmit encoded blocks of information. The randomization introduced by the coding process eases the scheduling of block propagation, and, thus, makes the distribution more efficient. This is particularly important in large unstructured overlay networks, where the nodes need to make block forwarding decisions based on local information only. We compare network coding to other schemes that transmit unencoded information (i.e. blocks of the original file) and, also, to schemes in which only the source is allowed to generate and transmit encoded packets. We study the performance of network coding in heterogeneous networks with dynamic node arrival and departure patterns, clustered topologies, and when incentive mechanisms to discourage free-riding are in place. We demonstrate through simulations of scenarios of practical interest that the expected file download time improves by more than 20-30% with network coding compared to coding at the server only and, by more than 2-3 times compared to sending unencoded information. Moreover, we show that network coding improves the robustness of the system and is able to smoothly handle extreme situations where the server and nodes leave the system.", "authors": ["C. Gkantsidis", "P.R. Rodriguez"], "related_topics": ["138293262", "169851745", "199845137"], "citation_count": "1481", "reference_count": "31", "references": ["2105831729", "239964209", "1513710402", "2079041580", "2166245380", "2016312880", "2130350209", "2148037789", "2127494222", "2135980240"], "date": "2005"}, {"id": "1174849168", "title": "AntNet: A Mobile Agents Approach to Adaptive Routing", "abstract": "This paper introduces AntNet, a new routing algorithm for communications networks. AntNet is an adaptive, distributed, mobile-agents-based algorithm which was inspired by recent work on the ant colony metaphor. We apply AntNet to a datagram network and compare it with both static and adaptive state-of-the-art routing algorithms. We ran experiments for various paradigmatic temporal and spatial tra c distributions. AntNet showed both very good performance and robustness under all the experimental conditions with respect to its competitors.", "authors": ["Gianni Di Caro"], "related_topics": ["89305328", "32244324", "9659607"], "citation_count": "352", "reference_count": "20", "references": ["2107941094", "2154929945", "2098432798", "2107726111", "2112495447", "1492640216", "2078500988", "1583833196", "1748611583", "3137299218"], "date": "1998"}, {"id": "2163640453", "title": "Cognitive Tutors: Lessons Learned", "abstract": "This paper review the 10-year history of tutor development based on the ACT theory (Anderson, 1983,1993). We developed production system models in ACT ofhow students solved problems in LISP, geometry, and algebra. Computer tutors were developed around these cognitive models. Construction ofthese tutors was guided by a set of eight principles loosely based on the ACT theory. Early evaluations of these tutors usually but not always showed significant achievement gains. Best-case evaluations showed that students could achieve at least the same level of proficiency as conventional instruction in one third the time. Empirical studies showed that students were learning skills in production-rule units and that the best tutorial interaction style was one in which the tutor provides immediate feedback, consisting of short and directed error messages. The tutors appear to work better if they present themselves to students as nonhuman tools to assist learning rather than as emulations of human tutors. Students working with these tutors display transfer to other environments to the degree that they can map the tutor environment into the test environment. These experiences have coalesced into a new system for developing and deploying tutors. This system involves first selecting a problem-solving interface, then constructing a curriculum under the guidance of a domain expert, then designing a cognitive model for solving problems in that environment, then building instruction around the productions in that model, and finally deploying the tutor in the classroom. New tutors are being built in this system to achieve the NCTM standards for high school mathematics in an urban setting. (http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA312246)", "authors": ["John R. Anderson", "Albert T. Corbett", "Kenneth R. Koedinger", "Ray Pelletier"], "related_topics": ["2776818741", "2778371403", "88610354"], "citation_count": "2676", "reference_count": "47", "references": ["2116199508", "2164599981", "2134917048", "1708874574", "2612211396", "2130736456", "2162792036", "2489865376", "2136208491", "1752512628"], "date": "1995"}, {"id": "2167282885", "title": "Obstruction-free synchronization: double-ended queues as an example", "abstract": "We introduce obstruction-freedom, a new nonblocking property for shared data structure implementations. This property is strong enough to avoid the problems associated with locks, but it is weaker than previous nonblocking properties-specifically lock-freedom and wait-freedom-allowing greater flexibility in the design of efficient implementations. Obstruction-freedom admits substantially simpler implementations, and we believe that in practice it provides the benefits of wait-free and lock-free implementations. To illustrate the benefits of obstruction-freedom, we present two obstruction-free CAS-based implementations of double-ended queues (deques); the first is implemented on a linear array, the second on a circular array. To our knowledge, all previous nonblocking deque implementations are based on unrealistic assumptions about hardware support for synchronization, have restricted functionality, or have operations that interfere with operations at the opposite end of the deque even when the deque has many elements in it. Our obstruction-free implementations have none of these drawbacks, and thus suggest that it is much easier to design obstruction-free implementations than lock-free and wait-free ones. We also briefly discuss other obstruction-free data structures and operations that we have implemented.", "authors": ["M. Herlihy", "V. Luchangco", "M. Moir"], "related_topics": ["162319229", "102602991", "160403385"], "citation_count": "654", "reference_count": "17", "references": ["2752853835", "2105055683", "1993449345", "2101939036", "1981393723", "2098147619", "1996931099", "1965708711", "2072035527", "2166115541"], "date": "2003"}, {"id": "2023460305", "title": "Semantics and property theory", "abstract": "", "authors": ["Gennaro Chierchia", "Raymond Turner"], "related_topics": ["156325763", "150607116", "207648694"], "citation_count": "371", "reference_count": "29", "references": ["1972573551", "2151157246", "1491525124", "2048953720", "1519238856", "1606864731", "2092961256", "2057885880", "2003992319", "1989383196"], "date": "1988"}, {"id": "2165225874", "title": "A new look at infant pointing.", "abstract": "The current article proposes a new theory of infant pointing involving multiple layers of intentionality and shared intentionality. In the context of this theory, evidence is presented for a rich interpretation of prelinguistic communication, that is, one that posits that when 12-month-old infants point for an adult they are in some sense trying to influence her mental states. Moreover, evidence is also presented for a deeply social view in which infant pointing is best understoodFon many levels and in many waysFas depending on uniquely human skills and motivations for cooperation and shared intentionality (e.g., joint intentions and attention with others). Children\u2019s early linguistic skills are built on this already existing platform of prelinguistic communication. Human beings communicate with one another in unique ways. Most obviously, humans communicate with one another linguistically, that is, with socially learned, intersubjectively shared symbols of a type not used by other animal species in their natural forms of communication. But humans also communicate with one another in unique ways gesturally. Many of the most important gestures humans useFfor example, for greeting or leaving, for threatening or insulting, for agreeing or disagreeingFare also socially learned, intersubjectively shared, symbolic conventions that vary across cultures in much the same way as linguistic symbols (Kendon, 2004; McNeil, 1992). An especially important gesture that has a number of unique features is human pointing. Although there may be some variations of form (e.g., in some cultures the norm is lip- or chin-pointing), the basic interpersonal function of directing someone\u2019s attention to something is very likely a human universal (Kita, 2003). Pointing is a special gesture functionally in that directing someone\u2019s attention to something does not convey a specific meaning in the manner of most conventionalized, symbolic gestures. Rather, pointing can convey an almost infinite variety of meanings by saying, in effect, \u2018\u2018If you look over there, you\u2019ll know what I mean.\u2019\u2019 To recover the intended meaning of a pointing gesture, therefore, requires some fairly serious \u2018\u2018mindreading.\u2019\u2019 Infants begin to point to things for other persons from around 11 to 12 months of age (Carpenter,", "authors": ["Michael Tomasello", "Malinda Carpenter", "Ulf Liszkowski"], "related_topics": ["207347870", "3019014099", "2780876879"], "citation_count": "1058", "reference_count": "83", "references": ["1542722502", "1978246972", "2106980598", "2168488947", "1498883201", "2118163921", "1969787028", "2264742718", "1424744123", "751470531"], "date": "2007"}, {"id": "2172097231", "title": "Tightly Packed Tries: How to Fit Large Models into Memory, and Make them Load Fast, Too", "abstract": "We present Tightly Packed Tries (TPTs), a compact implementation of read-only, compressed trie structures with fast on-demand paging and short load times. We demonstrate the benefits of TPTs for storing n-gram back-off language models and phrase tables for statistical machine translation. Encoded as TPTs, these databases require less space than flat text file representations of the same data compressed with the gzip utility. At the same time, they can be mapped into memory quickly and be searched directly in time linear in the length of the key, without the need to decompress the entire file. The overhead for local decompression during search is marginal.", "authors": ["Ulrich Germann", "Eric Joanis", "Samuel Larkin"], "related_topics": ["50954386", "190290938", "100850083"], "citation_count": "54", "reference_count": "20", "references": ["2124807415", "1631260214", "2109664771", "2611071497", "2134237567", "1549285799", "2069074882", "1797288984", "2115918455", "132913264"], "date": "2009"}, {"id": "2161070585", "title": "Understanding normal and impaired word reading: computational principles in quasi-regular domains.", "abstract": "A connectionist approach to processing in quasi-regular domains, as exemplified by English word reading, is developed. Networks using appropriately structured orthographic and phonological representations were trained to read both regular and exception words, and yet were also able to read pronounceable nonwords as well as skilled readers. A mathematical analysis of a simplified system clarifies the close relationship of word frequency and spelling-sound consistency in influencing naming latencies. These insights were verified in subsequent simulations, including an attractor network that accounted for latency data directly in its time to settle on a response. Further analyses of the ability of networks to reproduce data on acquired surface dyslexia support a view of the reading system that incorporates a graded division of labor between semantic and phonological processes, and contrasts in important ways with the standard dual-route account.", "authors": ["David C. Plaut", "James L. McClelland", "Mark S. Seidenberg", "Karalyn Patterson"], "related_topics": ["2778815305", "2776228482", "175293574"], "citation_count": "3532", "reference_count": "189", "references": ["2154642048", "1652505363", "1498436455", "1535810436", "3036751298", "2160208155", "2286699414", "2047057213", "2936428940", "2176028050"], "date": "1995"}, {"id": "2147504831", "title": "A case for redundant arrays of inexpensive disks (RAID)", "abstract": "Increasing performance of CPUs and memories will be squandered if not matched by a similar performance increase in I/O. While the capacity of Single Large Expensive Disks (SLED) has grown rapidly, the performance improvement of SLED has been modest. Redundant Arrays of Inexpensive Disks (RAID), based on the magnetic disk technology developed for personal computers, offers an attractive alternative to SLED, promising improvements of an order of magnitude in performance, reliability, power consumption, and scalability. This paper introduces five levels of RAIDs, giving their relative cost/performance, and compares RAID to an IBM 3380 and a Fujitsu Super Eagle.", "authors": ["David A. Patterson", "Garth Gibson", "Randy H. Katz"], "related_topics": ["140994810", "113610685", "115454934"], "citation_count": "4490", "reference_count": "15", "references": ["2296226841", "2912230285", "1990771431", "2004731091", "2150871235", "2059033977", "2480823060", "2130360419", "2018929990", "2104931717"], "date": "1988"}, {"id": "1507680813", "title": "The tagged LOB Corpus : user's manual", "abstract": "", "authors": ["Stig Johansson", "Eric Atwell", "Roger Garside", "Geoffrey Leech"], "related_topics": ["41008148"], "citation_count": "143", "reference_count": "0", "references": ["1810943226", "2122585011", "2167898728", "2147393756", "2127836646", "2021043164", "2152550252", "2127589659", "2406273144", "2156526142"], "date": "1985"}, {"id": "1964415410", "title": "A four mechanism model for threshold spatial vision.", "abstract": "Abstract Data on the threshold visibility of spatially localized, aperiodic patterns are used to derive the properties of a general model for threshold spatial vision. The model consists of four different size-tuned mechanisms centered at each eccentricity, each with a center-surround sensitivity profile described by the difference of two Gaussian functions. The two smaller mechanisms show relatively sustained temporal characteristics, while the larger two exhibit transient properties. All four mechanisms increase linearly in size with eccentricity. Mechanism responses are combined through spatial probability summation to predict visual thresholds. The model quantitatively predicts the spatial modulation transfer function (cosine grating thresholds) under both sustained and transient conditions with no free parameters.", "authors": ["Hugh R. Wilson", "James R. Bergen"], "related_topics": ["190538878", "147504629", "163716315"], "citation_count": "966", "reference_count": "39", "references": ["1999908130", "2167553001", "1988849438", "2146567096", "2010814572", "2334869595", "2066658588", "2069726594", "2113192608", "2033890757"], "date": "1978"}, {"id": "2130355536", "title": "Early processing of visual information", "abstract": "An introduction is given to a theory of early visual information processing. The theory has been implemented, and examples are given of images at various stages of analysis. It is argued that the first step of consequence is to compute a primitive but rich description of the grey-level changes present in an image. The description is expressed in a vocabulary of kinds of intensity change (EDGE, SHADING-EDGE, EXTENDED-EDGE, LINE, BLOB etc.). Modifying parameters are bound to the elements in the description, specifying their POSITION, ORIENTATION, TERMINATION points, CONTRAST, SIZE and FUZZINESS. This description is obtained from the intensity array by fixed techniques, and it is called the primal sketch. For most images, the primal sketch is large and unwieldy. The second important step in visual information processing is to group its contents in a way that is appropriate for later recognition. From our ability to interpret drawings with little semantic content, one may infer the presence in our perceptual equipment of symbolic processes that can define \"place-tokens\" in an image in various ways, and can group them according to certain rules. Homomorphic techniques fail to account for many of these grouping phenomena, whose explanations require mechanisms of construction rather than mechanisms of detection. The necessary grouping of elements in the primal sketch may be achieved by a mechanism that has available the processes inferred from above, together with the ability to select items by first order discriminations acting on the elements' parameters. Only occasionally do these mechanisms use downward-flowing information about the contents of the particular image being processed. It is argued that \"non-attentive\" vision is in practice implemented by these grouping operations and first order discriminations acting on the primal sketch. The class of computations so obtained differs slightly from the class of second order operations on the intensity array. The extraction of a form from the primal sketch using these techniques amounts to the separation of figure from ground. It is concluded that most of the separation can be carried out by using techniques that do not depend upon the particular image in question. Therefore, figure-ground separation can normally precede the description of the shape of the extracted form. Up to this point, higher-level knowledge and purpose are brought to bear on only a few of the decisions taken during the processing. This relegates the widespread use of downward-flowing information to a later stage than is found in current machine-vision programs, and implies that such knowledge should influence the control of, rather than interfering with, the actual data-processing that is taking place lower down.", "authors": ["David Marr"], "related_topics": ["2779231336", "9417928", "87868495"], "citation_count": "1228", "reference_count": "17", "references": ["1968245656", "2116360511", "1980429329", "2028750032", "2119051448", "2057683929", "2017600612", "2066548055", "2041181954", "1967767463"], "date": "1975"}, {"id": "2165205968", "title": "Channel coding with multilevel/phase signals", "abstract": "A coding technique is described which improves error performance of synchronous data links without sacrificing data rate or requiring more bandwidth. This is achieved by channel coding with expanded sets of multilevel/phase signals in a manner which increases free Euclidean distance. Soft maximum--likelihood (ML) decoding using the Viterbi algorithm is assumed. Following a discussion of channel capacity, simple hand-designed trellis codes are presented for 8 phase-shift keying (PSK) and 16 quadrature amplitude-shift keying (QASK) modulation. These simple codes achieve coding gains in the order of 3-4 dB. It is then shown that the codes can be interpreted as binary convolutional codes with a mapping of coded bits into channel signals, which we call \"mapping by set partitioning.\" Based on a new distance measure between binary code sequences which efficiently lower-bounds the Euclidean distance between the corresponding channel signal sequences, a search procedure for more powerful codes is developed. Codes with coding gains up to 6 dB are obtained for a variety of multilevel/phase modulation schemes. Simulation results are presented and an example of carrier-phase tracking is discussed.", "authors": ["G. Ungerboeck"], "related_topics": ["157125643", "78944582", "2400350"], "citation_count": "6307", "reference_count": "19", "references": ["2142384583", "2142901448", "1577906631", "2153810958", "2113421553", "2104919811", "2015635521", "2136168787", "2139397562", "2744859341"], "date": "1981"}, {"id": "1686196694", "title": "The Organization of Phonology", "abstract": "", "authors": ["Stephen R. Anderson"], "related_topics": ["148934300", "41895202", "15744967"], "citation_count": "757", "reference_count": "0", "references": ["2068447135", "2165018253", "2104420809", "2120159535", "2059665001", "2155767793", "1579605689", "2043199434", "2135259627", "165916515"], "date": "1973"}, {"id": "2123825896", "title": "Energy-efficient computing for wildlife tracking: design tradeoffs and early experiences with ZebraNet", "abstract": "Over the past decade, mobile computing and wireless communication have become increasingly important drivers of many new computing applications. The field of wireless sensor networks particularly focuses on applications involving autonomous use of compute, sensing, and wireless communication devices for both scientific and commercial purposes. This paper examines the research decisions and design tradeoffs that arise when applying wireless peer-to-peer networking techniques in a mobile sensor network designed to support wildlife tracking for biology research.The ZebraNet system includes custom tracking collars (nodes) carried by animals under study across a large, wild area; the collars operate as a peer-to-peer network to deliver logged data back to researchers. The collars include global positioning system (GPS), Flash memory, wireless transceivers, and a small CPU; essentially each node is a small, wireless computing device. Since there is no cellular service or broadcast communication covering the region where animals are studied, ad hoc, peer-to-peer routing is needed. Although numerous ad hoc protocols exist, additional challenges arise because the researchers themselves are mobile and thus there is no fixed base station towards which to aim data. Overall, our goal is to use the least energy, storage, and other resources necessary to maintain a reliable system with a very high `data homing' success rate. We plan to deploy a 30-node ZebraNet system at the Mpala Research Centre in central Kenya. More broadly, we believe that the domain-centric protocols and energy tradeoffs presented here for ZebraNet will have general applicability in other wireless and sensor applications.", "authors": ["Philo Juang", "Hidekazu Oki", "Yong Wang", "Margaret Martonosi", "Li Shiuan Peh", "Daniel Rubenstein"], "related_topics": ["41971633", "24590314", "144543869"], "citation_count": "2936", "reference_count": "26", "references": ["2106335692", "2102258543", "2099574482", "2148251644", "2104532741", "2157457404", "2121255383", "2124651399", "2127949150", "2045028348"], "date": "2002"}, {"id": "2104974755", "title": "A taxonomy and evaluation of dense two-frame stereo correspondence algorithms", "abstract": "Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can be easily extended to include new algorithms. We have also produced several new multiframe stereo data sets with ground truth, and are making both the code and data sets available on the Web.", "authors": ["D. Scharstein", "R. Szeliski", "R. Zabih"], "related_topics": ["35861506", "31451488", "12229352"], "citation_count": "6635", "reference_count": "135", "references": ["2033819227", "2167667767", "2143516773", "2145023731", "1997063559", "2113137767", "3003662786", "1963623641", "2103504761", "2121781154"], "date": "2001"}, {"id": "3145042860", "title": "The MD5 Message-Digest Algorithm", "abstract": "", "authors": ["Rivest"], "related_topics": ["8343483", "7608002", "184565465"], "citation_count": "5885", "reference_count": "0", "references": ["2097725665", "2099040451", "2102182691", "2263124607", "2033751220", "2513506562", "2140372921", "2103239853", "2126087831", "3112127769"], "date": "1991"}, {"id": "2122759946", "title": "Theory of point estimation", "abstract": "Preface to the Second Edition.- Preface to the First Edition.- List of Tables.- List of Figures.- List of Examples.- Table of Notation.- Preparations.- Unbiasedness.- Equivariance.- Average Risk Optimality.- Minimaxity and Admissibility.- Asymptotic Optimality.- References.- Author Index.- Subject Index.", "authors": ["Erich Leo Lehmann"], "related_topics": ["45357846", "2778773198", "2777855551"], "citation_count": "7111", "reference_count": "0", "references": ["2020925091", "2074682976", "2169495281", "2079724595", "2025720061", "1883186006", "2963676935", "2116601594", "2162376048", "2135647798"], "date": "1949"}, {"id": "2150102617", "title": "RCV1: A New Benchmark Collection for Text Categorization Research", "abstract": "Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection's properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices.", "authors": ["David D. Lewis", "Yiming Yang", "Tony G. Rose", "Fan Li"], "related_topics": ["56666940", "136389625", "23123220"], "citation_count": "3020", "reference_count": "35", "references": ["2118020653", "2149684865", "2118202495", "2098162425", "2435251607", "2114535528", "2005422315", "2107008379", "2000672666", "1620204465"], "date": "2004"}, {"id": "2171776966", "title": "Simulated Annealing: Theory and Applications", "abstract": "1 Introduction.- 2 Simulated annealing.- 3 Asymptotic convergence results.- 4 The relation with statistical physics.- 5 Towards implementing the algorithm.- 6 Performance of the simulated annealing algorithm.- 7 Applications.- 8 Some miscellaneous topics.- 9 Summary and conclusions.", "authors": ["P. J. M. Laarhoven", "E. H. L. Aarts"], "related_topics": ["46714192", "126980161", "71923881"], "citation_count": "4693", "reference_count": "0", "references": ["2096765155", "2017337590", "2114652055", "2135194391", "2118044993", "1771326151", "2156626839", "1993377828", "2055936398", "2130343325"], "date": "1987"}, {"id": "1604945782", "title": "Small Ramsey Numbers", "abstract": "We present data which, to the best of our knowledge, includes all known nontrivial values and bounds for specific graph, hypergraph and multicolor Ramsey numbers, where the avoided graphs are complete or complete without one edge. Many results pertaining to other more studied cases are also presented. We give references to all cited bounds and values, as well as to previous similar compilations. We do not attempt complete coverage of asymptotic behavior of Ramsey numbers, but concentrate on their specific values.", "authors": ["Stanis\u0142aw P. Radziszowski"], "related_topics": ["44115641", "2781221856", "118615104"], "citation_count": "680", "reference_count": "424", "references": ["1479863711", "2595622513", "2798428635", "2047039514", "2106456894", "173271850", "2275005719", "2133795933", "2127163760", "1569699670"], "date": "2011"}, {"id": "1982288607", "title": "All-Optical Label Swapping of Scalable In-Band Address Labels and 160-Gb/s Data Packets", "abstract": "Scalability and photonic integration of packet switched cross-connect nodes that utilize all-optical signal processing is a crucial issue that eventually determines the future role of photonic signal processing in optical networks. We present a 1times4 all-optical packet switch based on label swapping technique that utilizes a scalable and asynchronous label processor and label rewriter. By combining N in-band labels at different wavelengths (within the bandwidth of the payload), up to 2N possible addresses can be encoded. The proposed label processor requires only N active devices to process the 2N addresses that makes this label processing technique scalable with the number of addresses. Experimental results showed error-free packet switching operation at 160 Gb/s. The label erasing and new label insertion operation introduces only 0.5 dB of power penalty. These results indicate a potential utilization of the presented technique in a multi-hop packet switched network.", "authors": ["N. Calabretta", "Hyun-Do Jung", "J.H. Llorente", "E. Tangdiongga", "T.A.M. Koonen", "H.J.S. Dorren"], "related_topics": ["19986899", "123467649", "161831712"], "citation_count": "28", "reference_count": "19", "references": ["2161111878", "2107620828", "2121830575", "2119962572", "1603640481", "1527987129", "2141914860", "2155490021", "2133594367", "2134840916"], "date": "2009"}, {"id": "2313581450", "title": "Statistical methods for rates and proportions", "abstract": "Preface.Preface to the Second Edition.Preface to the First Edition.1. An Introduction to Applied Probability.2. Statistical Inference for a Single Proportion.3. Assessing Significance in a Fourfold Table.4. Determining Sample Sizes Needed to Detect a Difference Between Two Proportions.5. How to Randomize.6. Comparative Studies: Cross-Sectional, Naturalistic, or Multinomial Sampling.7. Comparative Studies: Prospective and Retrospective Sampling.8. Randomized Controlled Trials.9. The Comparison of Proportions from Several Independent Samples.10. Combining Evidence from Fourfold Tables.11. Logistic Regression.12. Poisson Regression.13. Analysis of Data from Matched Samples.14. Regression Models for Matched Samples.15. Analysis of Correlated Binary Data.16. Missing Data.17. Misclassification Errors: Effects, Control, and Adjustment.18. The Measurement of Interrater Agreement.19. The Standardization of Rates.Appendix A. Numerical Tables.Appendix B. The Basic Theory of Maximum Likelihood Estimation.Appendix C. Answers to Selected Problems.Author Index.Subject Index.", "authors": ["Joseph L. Fleiss"], "related_topics": ["129848803", "152877465", "134261354"], "citation_count": "33607", "reference_count": "0", "references": ["2161633633", "2087484885", "2119472226", "2022167001", "2132505348", "2103943262", "2120718661", "2330496155", "2315207768", "2128349740"], "date": "1980"}, {"id": "2138584836", "title": "Text-translation alignment", "abstract": "We present an algorithm for aligning texts with their translations that is based only on internal evidence. The relaxation process rests on a notion of which word in one text corresponds to which word in the other text that is essentially based on the similarity of their distributions. It exploits a partial alignment of the word level to induce a maximum likelihood alignment of the sentence level, which is in turn used, in the next iteration, to refine the word level estimate. The algorithm appears to converge to the correct sentence alignment in only a few iterations.", "authors": ["Martin Kay", "Martin R\u00f6scheisen"], "related_topics": ["61249035", "2777530160", "103278499"], "citation_count": "657", "reference_count": "12", "references": ["2752853835", "2097333193", "1593045043", "1489181569", "2117652747", "1600795850", "2799137445", "2011008859", "2111173177", "2066873261"], "date": "1993"}, {"id": "2095153677", "title": "Gauge quantization for spin-32 fields", "abstract": "Abstract The free massless Rarita-Schwinger equation and a recently constructed interacting field theory known as supergravity are invariant under fermionic gauge transformations. Gauge field quantization techniques are applied in both cases. For the free field the Faddeev-Popov ansatz for the generating functional is justified by showing that it is equivalent to canonical quantization in a particular gauge. Propagators are obtained in several gauges and are shown to be ghost-free and causal. For supergravity the Faddeev-Popov ansatz is presented and the gauge fixing and determinant terms are discussed in detail in a Lorentz covariant gauge. The Slavnov-Taylor identity is obtained. It is argued that supergravity theory is free from the difficulty of acausal wave propagation of the type found by Velo and Zwanziger and that pole residues in tree approximation S-matrix elements are positive as required by unitarity.", "authors": ["Ashok Das", "Daniel Z. Freedman"], "related_topics": ["39366733", "65266758", "27428435"], "citation_count": "102", "reference_count": "18", "references": ["1990464293", "2101531402", "2033870813", "2026169595", "2584039307", "2016939318", "2018666383", "1974281514", "1969230123", "1974512611"], "date": "1976"}, {"id": "300260255", "title": "The Disaster-Knowledge Matrix \u2013 Reframing and evaluating the knowledge challenges in disaster risk reduction", "abstract": "Within the context of disaster risk reduction, including climate change adaptation, significant thematic discourse has been dedicated to the difficulty of implementing research-based knowledge in policy and practise. Not only has the discussion focused on the causes of this issue, but many recommendations for enhancing the use of information and knowledge have also been made. The authors first frame the knowledge challenges and, second, introduce a systematic means to identify the factors hindering the use of information and knowledge. The approach proposed allows determining core barriers in the co-production, exchange, and use of knowledge. Subsequently, we illustrate where further advancement is needed in the field of knowledge development, means of transmission and use for disaster risk reduction. We suggest a method that analyses cases considering the success or failure of information flows from and to different stakeholder groups. The aim is to identify causes for knowledge fragmentation at different phases in the disaster management continuum, and, subsequently, to strengthen both individual and institutional learning, as well as to determine social and functional changes required to address pressing issues of disaster risk reduction, including climate change adaptation, in a competent manner.", "authors": ["Raphael Spiekermann", "Stefan Kienberger", "John Norton", "Fernando Briones", "Juergen Weichselgartner", ""], "related_topics": ["2780750338", "162696548", "62555980"], "citation_count": "102", "reference_count": "47", "references": ["3148233289", "3156965743", "2120012334", "81360671", "2007180942", "2002520967", "1527452312", "2124611226", "1546831332", "2122445336"], "date": "2015"}, {"id": "1677409904", "title": "SURF: speeded up robust features", "abstract": "In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (in casu, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper presents experimental results on a standard evaluation set, as well as on imagery obtained in the context of a real-life object recognition application. Both show SURF's strong performance.", "authors": ["Herbert Bay", "Tinne Tuytelaars", "Luc Van Gool"], "related_topics": ["61265191", "52779249", "38785706"], "citation_count": "19564", "reference_count": "36", "references": ["2151103935", "2164598857", "2124386111", "2177274842", "2128017662", "2012778485", "1980911747", "2145072179", "2172188317", "2124404372"], "date": "2006"}, {"id": "1532394360", "title": "Cognitive Therapy and the Emotional Disorders", "abstract": "Is the emotionally disturbed person a victim of forces beyond his awareness, over which he has no control? This is the belief on which neuropsychiatry, psychoanalysis, and behaviour therapy are all based. But what if this premise is wrong? What if a person's psychological difficulties stem from his own erroneous assumptions and faulty concepts of himself and the world? Such a person can be helped to recognize and correct distortions in thinking that cause his emotional disturbance. Now one of the founders of cognitive therapy has written a clear, comprehensive guide to its theory and practice, highlighting such important concepts as learning the meaning of hidden messages - listening to your automatic thoughts - the role of sadness, anger and anxiety - understanding and overcoming phobias and depression.", "authors": ["Aaron T. Beck"], "related_topics": ["2779477915", "2779812673", "2778589756"], "citation_count": "11360", "reference_count": "0", "references": ["2074503869", "1989756802", "1969348782", "1982210139", "2130142026", "2009819148", "2075585362", "2038130137", "2110004174", "2003898298"], "date": "1974"}, {"id": "3124459288", "title": "The Role of Hubs in the Adoption Process", "abstract": "The authors explore the role of hubs (people with an exceptionally large number of social ties) in diffusion and adoption. Using data on a large network with multiple adoptions, they identify two types of hubs\u2014innovative and follower hubs. Contrary to recent arguments, hubs tend to adopt earlier in the diffusion process, even though they are not necessarily innovative. Although innovative hubs have a greater impact on the speed of the adoption process, follower hubs have a greater impact on market size (total number of adoptions). Importantly, a small sample of hubs offers accurate success versus failure predictions early in the diffusion process.", "authors": ["Jacob Goldenberg", "Sangman Han", "Donald R. Lehmann", "Jae Weon Hong"], "related_topics": ["86256295", "142189719", "139268390"], "citation_count": "837", "reference_count": "66", "references": ["2008620264", "3121584743", "2030539428", "2150375325", "2113880421", "2798365711", "2158551555", "2038790402", "2056944867", "2031114635"], "date": "2009"}, {"id": "1977735896", "title": "Tree queries: a simple class of relational queries", "abstract": "One can partition the class of relational database schemas into tree schemas and cyclic schemas. (These are called acyclic hypergraphs and cyclic hypergraphs elsewhere in the literature.) This partition has interesting implications in query processing, dependency theory, and graph theory.The tree/cyclic partitioning of database schemas originated with a similar partition of equijoin queries. Given an arbitrary equijoin query one can obtain an equivalent query that calculates the natural join of all relations in (an efficiently) derived database; such a query is called a natural join (NJ) query. If the derived database is a tree schema the original query is said to be a tree query, and otherwise a cyclic query.In this paper we analyze query processing consequences of the tree/cyclic partitioning. We are able to argue, qualitatively, that queries which imply a tree schema are easier to process than those implying a cyclic schema. Our results also extend the study of the semijoin operator.", "authors": ["Nathan Goodman", "Oded Shmueli"], "related_topics": ["157692150", "192939062", "192028432"], "citation_count": "113", "reference_count": "28", "references": ["2153329411", "2110810394", "2169012378", "2023195086", "1964111545", "2153485419", "2125223317", "2039610696", "1495302482", "2143377704"], "date": "1982"}, {"id": "1480225633", "title": "Fairplay\u2014a secure two-party computation system", "abstract": "Advances in modern cryptography coupled with rapid growth in processing and communication speeds make secure two-party computation a realistic paradigm. Yet, thus far, interest in this paradigm has remained mostly theoretical. This paper introduces Fairplay [28], a full-fledged system that implements generic secure function evaluation (SFE). Fairplay comprises a high level procedural definition language called SFDL tailored to the SFE paradigm; a compiler of SFDL into a one-pass Boolean circuit presented in a language called SHDL; and Bob/Alice programs that evaluate the SHDL circuit in the manner suggested by Yao in [39]. This system enables us to present the first evaluation of an overall SFE in real settings, as well as examining its components and identifying potential bottlenecks. It provides a test-bed of ideas and enhancements concerning SFE, whether by replacing parts of it, or by integrating with it. We exemplify its utility by examining several alternative implementations of oblivious transfer within the system, and reporting on their effect on overall performance.", "authors": ["Dahlia Malkhi", "Noam Nisan", "Benny Pinkas", "Yaron Sella"], "related_topics": ["13652956", "53076038", "2776827251"], "citation_count": "1063", "reference_count": "38", "references": ["1996360405", "2156186849", "2052267638", "1499934958", "1548880861", "2013623332", "1988374166", "2150307013", "2027471022", "2017464959"], "date": "2004"}, {"id": "2035091448", "title": "Lexical Phrases and Language Teaching", "abstract": "PART ONE LEXICAL PHRASES IN LANGUAGE DESCRIPTION PART TWO APPLICATIONS FOR LANGUAGE TEACHING", "authors": ["James R. Nattinger", "Jeanette S. DeCarrico"], "related_topics": ["2778167880", "126706616", "93258239"], "citation_count": "1279", "reference_count": "0", "references": ["2133518763", "1561412240", "2073552557", "2066646430", "2102866687", "2093920276", "1975978582", "2103286062", "2071343301", "1989502969"], "date": "1992"}, {"id": "2156303437", "title": "Two-Stream Convolutional Networks for Action Recognition in Videos", "abstract": "We investigate architectures of discriminatively trained deep Convolutional Networks (ConvNets) for action recognition in video. The challenge is to capture the complementary information on appearance from still frames and motion between frames. We also aim to generalise the best performing hand-crafted features within a data-driven learning framework. Our contribution is three-fold. First, we propose a two-stream ConvNet architecture which incorporates spatial and temporal networks. Second, we demonstrate that a ConvNet trained on multi-frame dense optical flow is able to achieve very good performance in spite of limited training data. Finally, we show that multitask learning, applied to two different action classification datasets, can be used to increase the amount of training data and improve the performance on both. Our architecture is trained and evaluated on the standard video actions benchmarks of UCF-101 and HMDB-51, where it is competitive with the state of the art. It also exceeds by a large margin previous attempts to use deep nets for video classification.", "authors": ["Karen Simonyan", "Andrew Zisserman"], "related_topics": ["28006648", "774472", "155542232"], "citation_count": "5123", "reference_count": "30", "references": ["2618530766", "2161969291", "2155893237", "1849277567", "2117130368", "2016053056", "2963173190", "2105101328", "2142194269", "1983364832"], "date": "2014"}, {"id": "2154755429", "title": "Much-support as a last resort", "abstract": "In this article I present evidence for Bresnan's (1973) proposal that there is an underlying QP within the adjective phrase and that a distinction should be made between two types of functional degree words, Deg (heading DegP) and Q (heading QP). The evidence comes from so-pronominalization phenomena in English adjective phrases. I show that in certain pronominalization contexts a dummy adjectival element much is inserted in the functional Q position. This phenomenon of much-support is similar to the phenomenon of do-support in the verbal domain. I further argue that much-insertion is blocked in contexts in which the more economical A-to-Q raising operation can apply.", "authors": ["Norbert Corver"], "related_topics": ["2776568922", "2777683214", "2778678256"], "citation_count": "208", "reference_count": "18", "references": ["2796493717", "1565769722", "1496771994", "1586944595", "1981818098", "12733023", "25538197", "2798434063", "1555082340", "2073784029"], "date": "1996"}, {"id": "1485033854", "title": "The design and analysis of graphical passwords", "abstract": "In this paper we propose and evaluate new graphical password schemes that exploit features of graphical input displays to achieve better security than text-based passwords. Graphical input devices enable the user to decouple the position of inputs from the temporal order in which those inputs occur, and we show that this decoupling can be used to generate password schemes with substantially larger (memorable) password spaces. In order to evaluate the security of one of our schemes, we devise a novel way to capture a subset of the \"memorable\" passwords that, we believe, is itself a contribution. In this work we are primarily motivated by devices such as personal digital assistants (PDAs) that offer graphical input capabilities via a stylus, and we describe our prototype implementation of one of our password schemes on such a PDA, namely the Palm PilotTM.", "authors": ["Ian Jermyn", "Alain Mayer", "Fabian Monrose", "Michael K. Reiter", "Aviel D. Rubin"], "related_topics": ["98705547", "23875713", "89479133"], "citation_count": "1101", "reference_count": "25", "references": ["2060755870", "269917250", "1505010935", "2149929743", "12010980", "1984314602", "2025668003", "2063239745", "1548067747", "2053030258"], "date": "1999"}, {"id": "1988095917", "title": "Constraint satisfaction in logic programming", "abstract": "This book tackles classic problems from operations research and circuit design using a logic programming language embedding consistency techniques, a paradigm emerging from artificial intelligence research. Van Hentenryck proposes a new approach to solving discrete combinatorial problems using these techniques.Logic programming serves as a convenient language for stating combinatorial problems, but its \"generate and test\" paradigm leads to inefficient programs. Van Hentenryck's approach preserves one of the most useful features of logic programming - the duality of its semantics - yet allows a short development time for the programs while preserving most of the efficiency of special purpose programs written in a procedural language.Embedding consistency techniques in logic programming allows for ease and flexibility of programming and short development time because constraint propagation and tree-search programming are abstracted away from the user. It also enables logic programs to be executed efficiently as consistency techniques permit an active use of constraints to remove combinations of values that cannot appear in a solution Van Hentenryck presents a comprehensive overview of this new approach from its theoretical foundations to its design and implementation, including applications to real life combinatorial problems.The ideas introduced in \"Constraint Satisfaction in Logic Programming \"have been used successfully to solve more than a dozen practical problems in operations research and circuit design, including disjunctive scheduling, warehouse location, cutting stock car sequencing, and microcode labeling problems.Pascal Van Hentenryck is a member of the research staff at the European Computer Industry Research Centre. \"Constraint Satisfaction in Logic Programming\" is based on research for the Centre's CHIP project. As an outgrowth of this project, a new language (CHIP) that will include consistency techniques has been developed for commercial use. The book is included in the Logic Programming series edited by Ehud Shapiro.", "authors": ["Pascal Van Hentenryck"], "related_topics": ["128838566", "96315309", "173404611"], "citation_count": "2033", "reference_count": "0", "references": ["2337098149", "47957325", "2155900361", "2038345112", "2132210624", "1733489975", "1587191403", "2063727779", "2014856631", "2570710533"], "date": "1988"}, {"id": "1963910623", "title": "On the regular representation of a nonunimodular locally compact group", "abstract": "Abstract We study the discrete part of the regular representation of a locally compact group and also its Type I part if the group is separable. Our results extend to nonunimodular groups' known results for unimodular groups about formal degrees of square integrable representations, and the Plancherel formula. We establish orthogonality relations for matrix coefficients of square integrable representations and we show that the formal degree in general is not a positive number, but a positive self-adjoint unbounded operator, semi-invariant under the representation. Integrable representations are also studied in this context. Finally we show that when the group is nonunimodular, \u201cPlancherel measure\u201d is not a true measure, but a measure multiplied by a section of a certain real oriented line bundle on the dual space of the group.", "authors": ["M Duflo", "Calvin C Moore"], "related_topics": ["171322552", "2776038885", "120047569"], "citation_count": "425", "reference_count": "19", "references": ["2032220545", "91102539", "595513302", "2335362681", "2316150937", "2597213247", "2036312696", "2227420806", "2015683036", "579380505"], "date": "1976"}, {"id": "2806619258", "title": "Temporal logic can be more expressive", "abstract": "It is first proved that there are properties of sequences that are not expressible in temporal logic, even though they are easily expressible using, for instance, regular expressions. Then, it is shown how temporal logic can be extended to express any property definable by a right-linear grammar and hence a regular expression. Finally, a complete axiomatization and a decision procedure for the extended temporal logic are given and the complexity of the extended logic is examined.", "authors": ["Pierre Wolper"], "related_topics": ["25016198", "121329065", "26022165"], "citation_count": "1163", "reference_count": "20", "references": ["2023808162", "2069709605", "2040127143", "50233445", "1490966766", "1982129592", "2084910510", "2971132570", "1536217426", "1988903622"], "date": "1982"}, {"id": "1504955803", "title": "Phonology and Syntax: The Relation between Sound and Structure", "abstract": "A fundamentally new approach to the theory of phonology and its relation to syntax is developed in this book, which is the first to address the question of the relation between syntax and phonology in a systematic way.This general theory differs from its predecessors in the generative tradition in several respects. By arguing that the intonational structure of a sentence determines certain aspects of its stress pattern or rhythmic structure, and not vice versa, it provides a novel view of the intonation-stress relation. It also offers a new theory of the focus-prosody relation that solves a variety of classic puzzles and involves an appeal to the place of a focused constituent in the predicate-argument structure of the sentence. The book also includes other novel features, among them a development of the metrical grid theory of stress (including a complete treatment of English word stress in this framework), the representation of juncture in terms of \"silent\" positions in the metrical grid (with a treatment of sandhi in terms of this rhythmic juncture), and a \"rhythmic\" nonsyntactic approach to the basic phonology of function words in EnglishElisabeth 0. Selkirk is Professor of Linguistics at the University of Massachusetts, Amherst. This book is tenth in the series, Current Studies in Linguistics.", "authors": ["E O Selkirk"], "related_topics": ["148934300", "2780519453", "2777530160"], "citation_count": "2720", "reference_count": "0", "references": ["1562911371", "1560265695", "2147221824", "2140615673", "1608101656", "2164770604", "1595210733", "2097609022", "1999201450", "854457695"], "date": "1984"}, {"id": "2126736494", "title": "On sequential Monte Carlo sampling methods for Bayesian filtering", "abstract": "In this article, we present an overview of methods for sequential simulation from posterior distributions. These methods are of particular interest in Bayesian filtering for discrete time dynamic models that are typically nonlinear and non-Gaussian. A general importance sampling framework is developed that unifies many of the methods which have been proposed over the last few decades in several different scientific disciplines. Novel extensions to the existing methods are also proposed. We show in particular how to incorporate local linearisation methods similar to those which have previously been employed in the deterministic filtering literatures these lead to very effective importance distributions. Furthermore we describe a method which uses Rao-Blackwellisation in order to take advantage of the analytic structure present in some important classes of state-space models. In a final section we develop algorithms for prediction, smoothing and evaluation of the likelihood in dynamic models.", "authors": ["Arnaud Doucet", "Simon Godsill", "Christophe Andrieu"], "related_topics": ["52421305", "52740198", "111350023"], "citation_count": "5982", "reference_count": "35", "references": ["2098613108", "2131598171", "2064480843", "1561837455", "2615953416", "2293807537", "2151926297", "2082542916", "2277000961", "2057565703"], "date": "2000"}, {"id": "2132424367", "title": "Deep, big, simple neural nets for handwritten digit recognition", "abstract": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35% error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.", "authors": ["Dan Claudiu Cire\u015fan", "Ueli Meier", "Luca Maria Gambardella", "J\u00fcrgen Schmidhuber"], "related_topics": ["190502265", "50644808", "22019652"], "citation_count": "1219", "reference_count": "24", "references": ["2310919327", "2100495367", "2064675550", "2122410182", "2110798204", "1652505363", "2156163116", "2029949252", "2139427956", "2172174689"], "date": "2010"}, {"id": "2170439548", "title": "Generalized low-density parity-check codes for optical communication systems", "abstract": "This paper is concerned with investigating the performance of regular and irregular, randomlike and structured generalized low-density parity-check (GLDPC) codes for long-haul transmission. The proposed GLDPC codes outperform currently known turbo and low-density parity-check (LDPC) coding schemes with comparable parameters utilized in optical communication systems. For a GLDPC coding scheme with 23.6% redundancy, the largest so far reported coding gain of at least 11dB (at 40 Gb/s) is demonstrated.", "authors": ["I.B. Djordjevic", "O. Milenkovic", "B. Vasic"], "related_topics": ["202932441", "67692717", "76862118"], "citation_count": "102", "reference_count": "35", "references": ["1606480398", "1484692004", "2114468914", "2107301532", "1562979145", "2045407304", "2133068391", "2170864594", "2128765501", "2129681561"], "date": "2005"}, {"id": "1911516445", "title": "User interface for information retrieval system", "abstract": "An improved information retrieval system user interface for retrieving information from a plurality of sources and for storing information source descriptions in a knowledge base. The user interface includes a hypertext browser and a knowledge base browser/editor. The hypertext browser allows a user to browse an unstructured information space through the use of interactive hypertext links. The knowledge base browser/editor displays a directed graph representing a generalization taxonomy of the knowledge base, with the nodes representing concepts and edges representing relationships between concepts. The system allows users to store information source descriptions in the knowledge base via graphical pointing means. By dragging an iconic representation of an information source from the hypertext browser to a node in the directed graph, the system will store an information source description object in the knowledge base. The knowledge base browser/editor is also used to browse the information source descriptions previously stored in the knowledge base. The result of such browsing is an interactive list of information source descriptions which may be used to retrieve documents into the hypertext browser. The system also allows for querying a structured information source and using query results to focus the hypertext browser on the most relevant unstructured data sources.", "authors": ["Thomas Kirk", "Alon Yitzchak Levy"], "related_topics": ["61096286", "4554734", "162215914"], "citation_count": "758", "reference_count": "11", "references": ["2080402044", "1922612438", "1929371344", "2835550548", "1946436916", "1711675143", "1903084584", "1918406110", "2099739723", "2123040449"], "date": "1995"}, {"id": "2056669483", "title": "Is There a Sensory Threshold", "abstract": "", "authors": ["John A. Swets"], "related_topics": ["110235638", "15123163", "130093455"], "citation_count": "444", "reference_count": "0", "references": ["1990748933", "2045968318", "2130244962", "1992510928", "2103833776", "2001162634", "1977354344", "3022825995", "2168154763", "1600194558"], "date": "1961"}, {"id": "2061078082", "title": "Solid-state ion sensors with a liquid junction-free polymer membrane-based reference electrode for blood analysis", "abstract": "Abstract A set of ion-selective membranes for the measurement of clinically relevant electrolytes, i.e., K+, Na+, Ca2+, H+ and Cl\u2212, and a solvent-processible polyurethane (PU)-based reference membrane were cast on metal electrodes patterned on small ceramic plates, and on silicon-based sensors. Since the liquid junction-free PU membrane-based reference electrode provides a constant potentiometric signal for an extended period of time, accurate determination of blood electrolytes could be made without using a separate reference flow. The PU membrane-based reference electrodes not only improve the mass producibility of miniaturized solid-state ion sensors but also simplify the configuration of flow cell cartridges without compromising their analytical performance.", "authors": ["Hyo Jung Yoon", "Jae Ho Shin", "Sung Dong Lee", "Hakhyun Nam", "Geun Sig Cha", "Timothy D Strong", "Richard B Brown"], "related_topics": ["40290423", "124614425", "2777207949"], "citation_count": "72", "reference_count": "13", "references": ["1600828810", "2089733753", "2053204009", "2051027652", "2025159138", "2020741596", "2157654560", "2024378716", "1891121680", "2073168107"], "date": "2000"}, {"id": "2002257715", "title": "A set of level 3 basic linear algebra subprograms", "abstract": "This paper describes an extension to the set of Basic Linear Algebra Subprograms. The extensions are targeted at matrix-vector operations that should provide for efficient and portable implementations of algorithms for high-performance computers", "authors": ["J. J. Dongarra", "Jeremy Du Croz", "Sven Hammarling", "I. S. Duff"], "related_topics": ["163297316", "139352143", "177264268"], "citation_count": "2530", "reference_count": "28", "references": ["133977063", "2038469228", "1988425770", "2057711597", "2006384005", "2152320213", "1998318713", "2073260424", "2164895445", "2040256453"], "date": "1990"}, {"id": "2138162238", "title": "Some philosophical problems from the standpoint of artificial intelligence", "abstract": "Abstract A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what knowledge is and how it is obtained. Thus, some of the major traditional problems of philosophy arise in artificial intelligence. More specifically, we want a computer program that decides what to do by inferring in a formal language that a certain strategy will achieve its assigned goal. This requires formalizing concepts of causality, ability, and knowledge. Such formalisms are also considered in philosophical logic. The first part of the paper begins with a philosophical point of view that seems to arise naturally once we take seriously the idea of actually making an intelligent machine. We go on to the notions of metaphysically and epistemo-logically adequate representations of the world and then to an explanation of can, causes, and knows in terms of a representation of the world by a system of interacting automata. A proposed resolution of the problem of freewill in a deterministic universe and of counterfactual conditional sentences is presented. The second part is mainly concerned with formalisms within which it can be proved that a strategy will achieve a goal. Concepts of situation, fluent, future operator, action, strategy, result of a strategy and knowledge are formalized. A method is given of constructing a sentence of first-order logic which will be true in all models of certain axioms if and only if a certain strategy will achieve a certain goal. The formalism of this paper represents an advance over McCarthy (1963) and Green (1969) in that it permits proof of the correctness of strategies that contain loops and strategies that involve the acquisition of knowledge; and it is also somewhat more concise. The third part discusses open problems in extending the formalism of part 2. The fourth part is a review of work in philosophical logic in relation to problems of artificial intelligence and a discussion of previous efforts to program \u2018general intelligence\u2019 from the point of view of this paper.", "authors": ["J. McCarthy", "P. J. Hayes"], "related_topics": ["5065155", "2777521030", "22497172"], "citation_count": "5488", "reference_count": "46", "references": ["2041833446", "2124141583", "1684304711", "3149025087", "205043379", "2119409989", "2075277371", "2145482038", "1964011508", "3144889436"], "date": "1987"}, {"id": "2009172303", "title": "Quantifying individual variation in behaviour: mixed-effect modelling approaches", "abstract": "Growing interest in proximate and ultimate causes and consequences of between- and within-individual variation in labile components of the phenotype - such as behaviour or physiology - characterizes current research in evolutionary ecology. The study of individual variation requires tools for quantification and decomposition of phenotypic variation into between- and within-individual components. This is essential as variance components differ in their ecological and evolutionary implications. We provide an overview of how mixed-effect models can be used to partition variation in, and correlations among, phenotypic attributes into between- and within-individual variance components. Optimal sampling schemes to accurately estimate (with sufficient power) a wide range of repeatabilities and key (co)variance components, such as between- and within-individual correlations, are detailed. Mixed-effect models enable the usage of unambiguous terminology for patterns of biological variation that currently lack a formal statistical definition (e.g. 'animal personality' or 'behavioural syndromes'), and facilitate cross-fertilisation between disciplines such as behavioural ecology, ecological physiology and quantitative genetics.", "authors": ["Niels Jeroen Dingemanse", "", "Ned A. Dochtermann"], "related_topics": ["135811302", "34885642", "2778946008"], "citation_count": "743", "reference_count": "69", "references": ["2141088880", "2161498332", "1587094587", "2155988679", "1592263067", "2144673831", "1577941315", "2890373521", "2021148103", "2045443942"], "date": "2012"}, {"id": "2162792036", "title": "Rules of the Mind", "abstract": "Contents: Production Systems and the ACT-R Theory. Knowledge Representation. Performance. Learning. N. Kushmerick, C. Lebiere, Navigation and Conflict Resolution. N. Kushmerick, C. Lebiere, The Tower of Hanoi and Goal Structures. F.G. Conrad, A.T. Corbett, The LISP Tutor and Skill Acquisition. F.S. Bellezza, C.F. Boyle, The Geometry Tutor and Skill Acquisition. M.K. Singley, The Identical Elements Theory of Transfer. F.G. Conrad, A.T. Corbett, J.M. Fincham, D. Hoffman, Q. Wu, Computer Programming and Transfer. A.T. Corbett, Tutoring of Cognitive Skill. Creating Production-Rule Models. Reflections on the Theory.", "authors": ["John Robert Anderson"], "related_topics": ["2776818741", "2777938197", "2778371403"], "citation_count": "4782", "reference_count": "0", "references": ["2136518234", "2150375089", "1984052055", "1679907412", "1928882148", "2773929027", "2123376091", "2037498077", "2147070375", "2163640453"], "date": "1993"}, {"id": "3029645440", "title": "Numerical Optimization", "abstract": "Numerical Optimization presents a comprehensive and up-to-date description of the most effective methods in continuous optimization. It responds to the growing interest in optimization in engineering, science, and business by focusing on the methods that are best suited to practical problems. For this new edition the book has been thoroughly updated throughout. There are new chapters on nonlinear interior methods and derivative-free methods for optimization, both of which are used widely in practice and the focus of much current research. Because of the emphasis on practical methods, as well as the extensive illustrations and exercises, the book is accessible to a wide audience. It can be used as a graduate text in engineering, operations research, mathematics, computer science, and business. It also serves as a handbook for researchers and practitioners in the field. The authors have strived to produce a text that is pleasant to read, informative, and rigorous - one that reveals both the beautiful nature of the discipline and its practical side.", "authors": ["Jorge Nocedal", "Stephen J. Wright"], "related_topics": ["92995354", "115527620", "34127721"], "citation_count": "14252", "reference_count": "0", "references": ["2164278908", "2145096794", "2134967712", "2577537660", "2123871098", "2159211495", "2142058898", "2156598602", "2109449402", "196761320"], "date": "2008"}, {"id": "1969294188", "title": "Similarity of color images", "abstract": "We describe two new color indexing techniques. The first one is a more robust version of the commonly used color histogram indexing. In the index we store the cumulative color histograms. The L1-, L2-, L(infinity )-distance between two cumulative color histograms can be used to define a similarity measure of these two color distributions. We show that this method produces slightly better results than color histogram methods, but it is significantly more robust with respect to the quantization parameter of the histograms. The second technique is an example of a new approach to color indexing. Instead of storing the complete color distributions, the index contains only their dominant features. We implement this approach by storing the first three moments of each color channel of an image in the index, i.e., for a HSV image we store only 9 floating point numbers per image. The similarity function which is used for the retrieval is a weighted sum of the absolute differences between corresponding moments. Our tests clearly demonstrate that a retrieval based on this technique produces better results and runs faster than the histogram-based methods.\u00a9 (1995) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.", "authors": ["Markus Andreas Stricker", "Markus Orengo"], "related_topics": ["12043971", "142616399", "44404184"], "citation_count": "2578", "reference_count": "0", "references": ["2130660124", "2143668817", "2007972815", "3105577662", "2125238156", "1541459201", "2125101937", "2166502676", "2119742615", "2096933452"], "date": "1995"}, {"id": "1590251447", "title": "Principles of English Stress", "abstract": "1. General introduction Part I. The Stress of Undesired Items: 2. Null vowels and extrametricality 3. The stress pattern of English 4. Stress without destressing and vowel reduction 5. Stress and vowel length Part II: Stress and Word Formation: 6. Weak preservation 7. The range of stress 'placing' suffixes 8. Strong preservation 9. The range of neutral suffixes 10. Extensions and refinements.", "authors": ["Luigi Burzio"], "related_topics": ["21036866", "2776550342", "2777061557"], "citation_count": "330", "reference_count": "0", "references": ["1562911371", "1575528222", "1586401530", "1533473429", "2108443500", "2059824090", "2117350000", "1981210802", "1546485226", "1963920542"], "date": "2005"}, {"id": "3125645205", "title": "How Does Mixup Help With Robustness and Generalization", "abstract": "Mixup is a popular data augmentation technique based on on convex combinations of pairs of examples and their labels. This simple technique has shown to substantially improve both the model's robustness as well as the generalization of the trained model. However, it is not well-understood why such improvement occurs. In this paper, we provide theoretical analysis to demonstrate how using Mixup in training helps model robustness and generalization. For robustness, we show that minimizing the Mixup loss corresponds to approximately minimizing an upper bound of the adversarial loss. This explains why models obtained by Mixup training exhibits robustness to several kinds of adversarial attacks such as Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup augmentation corresponds to a specific type of data-adaptive regularization which reduces overfitting. Our analysis provides new insights and a framework to understand Mixup.", "authors": ["Linjun Zhang", "Zhun Deng", "Kenji Kawaguchi", "Amirata Ghorbani", "James Zou"], "related_topics": ["97970142", "22019652", "177148314"], "citation_count": "13", "reference_count": "45", "references": ["2194775991", "2963341956", "2156909104", "3118608800", "2963207607", "2964153729", "2302255633", "2970971581", "2335728318", "2964137095"], "date": "2021"}, {"id": "1983012012", "title": "Emerging topic detection on Twitter based on temporal and social terms evaluation", "abstract": "Twitter is a user-generated content system that allows its users to share short text messages, called tweets, for a variety of purposes, including daily conversations, URLs sharing and information news. Considering its world-wide distributed network of users of any age and social condition, it represents a low level news flashes portal that, in its impressive short response time, has the principal advantage.In this paper we recognize this primary role of Twitter and we propose a novel topic detection technique that permits to retrieve in real-time the most emergent topics expressed by the community. First, we extract the contents (set of terms) of the tweets and model the term life cycle according to a novel aging theory intended to mine the emerging ones. A term can be defined as emerging if it frequently occurs in the specified time interval and it was relatively rare in the past. Moreover, considering that the importance of a content also depends on its source, we analyze the social relationships in the network with the well-known Page Rank algorithm in order to determine the authority of the users. Finally, we leverage a navigable topic graph which connects the emerging terms with other semantically related keywords, allowing the detection of the emerging topics, under user-specified time constraints. We provide different case studies which show the validity of the proposed approach.", "authors": ["Mario Cataldi", "Luigi Di Caro", "Claudio Schifanella"], "related_topics": ["61797465", "144559511", "165120375"], "citation_count": "721", "reference_count": "30", "references": ["1854214752", "2124499489", "2001082470", "1966553486", "2043403353", "1978394996", "2127785456", "2146008005", "2113858518", "1549874165"], "date": "2010"}, {"id": "2130347036", "title": "User cooperation diversity. Part II. Implementation aspects and performance analysis", "abstract": "For pt.I see ibid., p.1927-38. This is the second of a two-part paper on a new form of spatial diversity, where diversity gains are achieved through the cooperation of mobile users. Part I described the user cooperation concept and proposed a cooperation strategy for a conventional code-division multiple-access (CDMA) system. Part II investigates the cooperation concept further and considers practical issues related to its implementation. In particular, we investigate the optimal and suboptimal receiver design, and present performance analysis for the conventional CDMA implementation proposed in Part I. We also consider a high-rate CDMA implementation and a cooperation strategy when assumptions about the channel state information at the transmitters are relaxed. We illustrate that, under all scenarios studied, cooperation is beneficial in terms of increasing system throughput and cell coverage, as well as decreasing sensitivity to channel variations.", "authors": ["A. Sendonaris", "E. Erkip", "B. Aazhang"], "related_topics": ["6832461", "60069766", "148063708"], "citation_count": "3596", "reference_count": "13", "references": ["2130509920", "2099111195", "1667950888", "2118040894", "2148963518", "2798333393", "2912369344", "2168571551", "2098257210", "1596939795"], "date": "2003"}, {"id": "639708223", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features\u2014using the recently popular terminology of neural networks with \u2019attention\u2019 mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3] , our detection system has a frame rate of 5 fps ( including all steps ) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.", "authors": ["Shaoqing Ren", "Kaiming He", "Ross Girshick", "Jian Sun"], "related_topics": ["2776151529", "81363708", "108583219"], "citation_count": "27656", "reference_count": "39", "references": ["2194775991", "2618530766", "2962835968", "2097117768", "2102605133", "2117539524", "1903029394", "2155893237", "1536680647", "2168356304"], "date": "2017"}, {"id": "2177274842", "title": "A performance evaluation of local descriptors", "abstract": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.", "authors": ["K. Mikolajczyk", "C. Schmid"], "related_topics": ["186926958", "153077589", "52779249"], "citation_count": "20408", "reference_count": "47", "references": ["2151103935", "2033819227", "2124386111", "2163352848", "2131846894", "2057175746", "2154422044", "2145023731", "1980911747", "2145072179"], "date": "2005"}, {"id": "2011301580", "title": "Basic theory of fractional differential equations", "abstract": "Abstract In this paper, the basic theory for the initial value problem of fractional differential equations involving Riemann\u2013Liouville differential operators is discussed employing the classical approach. The theory of inequalities, local existence, extremal solutions, comparison result and global existence of solutions are considered.", "authors": ["V. Lakshmikantham", "A.S. Vatsala"], "related_topics": ["97826883", "78045399", "26955809"], "citation_count": "1161", "reference_count": "10", "references": ["2787959293", "1530054495", "1975670568", "1523640391", "1599013339", "2050533316", "2094706142", "2079905092", "1574435983", "2134837756"], "date": "2008"}, {"id": "1980627546", "title": "Target transformation factor analysis", "abstract": "Abstract This tutorial article provides an introduction to target transformation factor analysis (TTFA). TTFA is a method of apportioning the measured value of a system to a series of independent causal processes. Such systems can be mixtures of components for which aggregate properties such as the absorption spectrum have been measured and the nature and amounts of the constituents need to be determined. The use of the TTFA method will be illustrated with an example of mass spectra of mixtures of cyclohexane and hexane.", "authors": ["Philip K. Hopke"], "related_topics": ["40325409", "113976600", "2777077568"], "citation_count": "61", "reference_count": "18", "references": ["1980380772", "2012113589", "2004729241", "12310307", "2020000945", "2071688319", "1971601246", "1561529224", "2044077545", "1988645234"], "date": "1989"}, {"id": "2912099989", "title": "High-Dimensional Statistics: A Non-Asymptotic Viewpoint", "abstract": "Recent years have witnessed an explosion in the volume and variety of data collected in all scientific disciplines and industrial settings. Such massive data sets present a number of challenges to researchers in statistics and machine learning. This book provides a self-contained introduction to the area of high-dimensional statistics, aimed at the first-year graduate level. It includes chapters that are focused on core methodology and theory - including tail bounds, concentration inequalities, uniform laws and empirical process, and random matrices - as well as chapters devoted to in-depth exploration of particular model classes - including sparse linear models, matrix models with rank constraints, graphical models, and various types of non-parametric models. With hundreds of worked examples and exercises, this text is intended both for courses and for self-study by graduate students and researchers in statistics, machine learning, and related fields who must understand, apply, and adapt modern statistical methods suited to large-scale data.", "authors": ["Martin J. Wainwright"], "related_topics": ["155846161", "179583182", "163175372"], "citation_count": "769", "reference_count": "397", "references": ["2296319761", "2099111195", "2129131372", "2135046866", "2122825543", "2145962650", "2124608575", "1488435683", "2078204800", "3023786531"], "date": "2019"}, {"id": "2149959815", "title": "Mobility increases the capacity of ad hoc wireless networks", "abstract": "The capacity of ad hoc wireless networks is constrained by the mutual interference of concurrent transmissions between nodes. We study a model of an ad hoc network where n nodes communicate in random source-destination pairs. These nodes are assumed to be mobile. We examine the per-session throughput for applications with loose delay constraints, such that the topology changes over the time-scale of packet delivery. Under this assumption, the per-user throughput can increase dramatically when nodes are mobile rather than fixed. This improvement can be achieved by exploiting a form of multiuser diversity via packet relaying.", "authors": ["Matthias Grossglauser", "David N. C. Tse"], "related_topics": ["94523657", "192448918", "204739117"], "citation_count": "8064", "reference_count": "11", "references": ["2137775453", "2107689535", "2158116199", "2141431231", "87098551", "2150240794", "2751862591", "2098117176", "2166107594", "2322605814"], "date": "2002"}, {"id": "2148534890", "title": "Inference from Iterative Simulation Using Multiple Sequences", "abstract": "The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were contin- ued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normal- ity after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random- effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.", "authors": ["Andrew Gelman", "Donald B. Rubin"], "related_topics": ["160234255", "158424031", "61224824"], "citation_count": "13846", "reference_count": "29", "references": ["1997063559", "2118502261", "2083875149", "2017899835", "2615953416", "2152977846", "2331182131", "1628017834", "1967639437", "2017696952"], "date": "1992"}, {"id": "2020009149", "title": "An overview of evolutionary algorithms for parameter optimization", "abstract": "Three main streams of evolutionary algorithms (EAs), probabilistic optimization algorithms based on the model of natural evolution, are compared in this article: evolution strategies (ESs), evolutionary programming (EP), and genetic algorithms (GAs). The comparison is performed with respect to certain characteristic components of EAs: the representation scheme of object variables, mutation, recombination, and the selection operator. Furthermore, each algorithm is formulated in a high-level notation as an instance of the general, unifying basic algorithm, and the fundamental theoretical results on the algorithms are presented. Finally, after presenting experimental results for three test functions representing a unimodal and a multimodal case as well as a step function with discontinuities, similarities and differences of the algorithms are elaborated, and some hints to open research questions are sketched.", "authors": ["Thomas B\u00e4ck", "Hans-Paul Schwefel"], "related_topics": ["105902424", "159149176", "121835503"], "citation_count": "2649", "reference_count": "35", "references": ["1639032689", "1497256448", "2142183404", "2166843422", "2154808242", "2028569720", "2156728410", "2151676833", "2096590200", "1587100796"], "date": "1993"}, {"id": "3022618749", "title": "Computational geometry : algorithms and applications", "abstract": "", "authors": ["Mark Overmars", "Mark de Berg", "Marc J van Kreveld"], "related_topics": ["29123130", "41008148", "11413529"], "citation_count": "1979", "reference_count": "0", "references": ["2157855380", "2105837036", "2137642864", "2167627514", "2137145600", "2088386938", "2168003214", "2135301926", "2039245308", "2124435169"], "date": "1999"}, {"id": "2103972604", "title": "A Singular Value Thresholding Algorithm for Matrix Completion", "abstract": "This paper introduces a novel algorithm to approximate the matrix with minimum nuclear norm among all matrices obeying a set of convex constraints. This problem may be understood as the convex relaxation of a rank minimization problem and arises in many important applications as in the task of recovering a large matrix from a small subset of its entries (the famous Netflix problem). Off-the-shelf algorithms such as interior point methods are not directly amenable to large problems of this kind with over a million unknown entries. This paper develops a simple first-order and easy-to-implement algorithm that is extremely efficient at addressing problems in which the optimal solution has low rank. The algorithm is iterative, produces a sequence of matrices $\\{\\boldsymbol{X}^k,\\boldsymbol{Y}^k\\}$, and at each step mainly performs a soft-thresholding operation on the singular values of the matrix $\\boldsymbol{Y}^k$. There are two remarkable features making this attractive for low-rank matrix completion problems. The first is that the soft-thresholding operation is applied to a sparse matrix; the second is that the rank of the iterates $\\{\\boldsymbol{X}^k\\}$ is empirically nondecreasing. Both these facts allow the algorithm to make use of very minimal storage space and keep the computational cost of each iteration low. On the theoretical side, we provide a convergence analysis showing that the sequence of iterates converges. On the practical side, we provide numerical examples in which $1,000\\times1,000$ matrices are recovered in less than a minute on a modest desktop computer. We also demonstrate that our approach is amenable to very large scale problems by recovering matrices of rank about 10 with nearly a billion unknowns from just about 0.4% of their sampled entries. Our methods are connected with the recent literature on linearized Bregman iterations for $\\ell_1$ minimization, and we develop a framework in which one can understand these algorithms in terms of well-known Lagrange multiplier algorithms.", "authors": ["Jian-Feng Cai", "Emmanuel J. Cand\u00e8s", "Zuowei Shen"], "related_topics": ["2778459887", "90199385", "137127113"], "citation_count": "4938", "reference_count": "47", "references": ["2296319761", "2296616510", "2145096794", "2129638195", "2129131372", "2124608575", "403935824", "2115706991", "2109357213", "2006262045"], "date": "2009"}, {"id": "1986362177", "title": "Dynamic capabilities: A review and research agenda", "abstract": "The notion of dynamic capabilities complements the premise of the resource-based view of the firm, and has injected new vigour into empirical research in the last decade. Nonetheless, several issues surrounding its conceptualization remain ambivalent. In light of empirical advancement, this paper aims to clarify the concept of dynamic capabilities, and then identify three component factors which reflect the common features of dynamic capabilities across firms and which may be adopted and further developed into a measurement construct in future research. Further, a research model is developed encompassing antecedents and consequences of dynamic capabilities in an integrated framework. Suggestions for future research and managerial implications are also discussed.", "authors": ["Catherine L. Wang", "Pervaiz K. Ahmed"], "related_topics": ["2780504989", "120936955", "90734943"], "citation_count": "3169", "reference_count": "119", "references": ["2061977616", "3121398446", "2108795964", "2089402107", "1566172004", "2119652992", "2137358449", "2179492332", "2018514036", "2140956556"], "date": "2007"}, {"id": "2099256741", "title": "Recognizing objects in adversarial clutter: breaking a visual CAPTCHA", "abstract": "In this paper we explore object recognition in clutter. We test our object recognition techniques on Gimpy and EZ-Gimpy, examples of visual CAPTCHAs. A CAPTCHA (\"Completely Automated Public Turing test to Tell Computers and Humans Apart\") is a program that can generate and grade tests that most humans can pass, yet current computer programs can't pass. EZ-Gimpy, currently used by Yahoo, and Gimpy are CAPTCHAs based on word recognition in the presence of clutter. These CAPTCHAs provide excellent test sets since the clutter they contain is adversarial; it is designed to confuse computer programs. We have developed efficient methods based on shape context matching that can identify the word in an EZ-Gimpy image with a success rate of 92%, and the requisite 3 words in a Gimpy image 33% of the time. The problem of identifying words in such severe clutter provides valuable insight into the more general problem of object recognition in scenes. The methods that we present are instances of a framework designed to tackle this general problem.", "authors": ["G. Mori", "J. Malik"], "related_topics": ["163339463", "150856459", "546480517"], "citation_count": "851", "reference_count": "21", "references": ["2310919327", "3097096317", "2057175746", "1990061958", "2142069714", "2099606917", "2610179052", "2072410439", "938539187", "2504108613"], "date": "2003"}, {"id": "2023718959", "title": "From game design elements to gamefulness: defining \"gamification\"", "abstract": "Recent years have seen a rapid proliferation of mass-market consumer software that takes inspiration from video games. Usually summarized as \"gamification\", this trend connects to a sizeable body of existing concepts and research in human-computer interaction and game studies, such as serious games, pervasive games, alternate reality games, or playful design. However, it is not clear how \"gamification\" relates to these, whether it denotes a novel phenomenon, and how to define it. Thus, in this paper we investigate \"gamification\" and the historical origins of the term in relation to precursors and similar concepts. It is suggested that \"gamified\" applications provide insight into novel, gameful phenomena complementary to playful phenomena. Based on our research, we propose a definition of \"gamification\" as the use of game design elements in non-game contexts.", "authors": ["Sebastian Deterding", "Dan Dixon", "Rilla Khaled", "Lennart Nacke"], "related_topics": ["503285160", "2723826", "50335755"], "citation_count": "8159", "reference_count": "61", "references": ["1527994979", "1511827303", "2140205964", "10512124", "2049080106", "2035683813", "2108682032", "1603545804", "606509746", "1787442784"], "date": "2011"}, {"id": "98607287", "title": "Conceptions of the transition to adulthood: Perspectives from adolescence through midlife.", "abstract": "Conceptions of the transition to adulthood were examined among adolescents (age 13\u201319, N = 171), emerging adults (age 20\u201329, N = 179), and young-to-midlife adults (age 30\u201355, N = 165). The focus was on whether conceptions of the transition to adulthood would be different among young-to-midlife adults compared to the younger age groups. In all age groups, individualistic criteria were the most likely to be considered important markers of the transition to adulthood, specifically accepting responsibility for one's actions, deciding on one's beliefs and values, establishing an equal relationship with parents, and becoming financially independent. However, young-to-midlife adults were less likely than adolescents to consider biological transitions to be important, and more likely than adolescents or emerging adults to view norm compliance (such as avoiding drunk driving) as a necessary part of the transition to adulthood. In all three groups, role transitions (e.g., marriage) ranked lowest in importance.", "authors": ["Jeffrey Jensen Arnett"], "related_topics": ["205545832", "117250062", "138496976"], "citation_count": "1468", "reference_count": "23", "references": ["2012186625", "2798304687", "1973060063", "2014198383", "2027261724", "2116332126", "2056651636", "2075010153", "2032178818", "2025516360"], "date": "2001"}, {"id": "2130256523", "title": "Grassmannian beamforming for multiple-input multiple-output wireless systems", "abstract": "Multiple-input multiple-output (MIMO) wireless systems provides capacity much larger than that provided by traditional single-input single-output (SISO) wireless systems. Beamforming is a low complexity technique that increases the receive signal-to-noise ratio (SNR), however, it requires channel knowledge. Since in practice channel knowledge at the transmitter is difficult to realize, we propose a technique where the receiver designs the beamforming vector and sends it to the transmitter by transmitting a label in a finite set, or codebook, of beamforming vectors. A codebook design method for quantized versions of maximum ratio transmission, equal gain transmission, and generalized selection diversity with maximum ratio combining at the receiver is presented. The codebook design criterion exploits the quantization problem's relationship with Grassmannian line packing. Systems using the beamforming codebooks are shown to have a diversity order of the product of the number of transmit and the number of receive antennas. Monte Carlo simulations compare the performance of systems using this new codebook method with the performance of systems using previously proposed quantized and unquantized systems.", "authors": ["D.J. Love", "R.W. Heath", "T. Strohmer"], "related_topics": ["160562895", "93372532", "207987634"], "citation_count": "2992", "reference_count": "44", "references": ["2107080958", "2130509920", "1667950888", "2118040894", "2110659753", "2129766733", "1508642566", "1981745143", "1518384680", "2120302973"], "date": "2003"}, {"id": "2117900366", "title": "Representation of Random Waveforms by Relational Trees", "abstract": "In a number of applications of image processing, much information about objects or textures in the image can be obtained by sequential analysis of individual scan lines.", "authors": ["Ehrich", "Foith"], "related_topics": ["9417928", "142748172", "50341643"], "citation_count": "123", "reference_count": "10", "references": ["2044465660", "2043735243", "2031435600", "1970144710", "2056918046", "1498289939", "2141794434", "2004350592", "129965471", "1507502112"], "date": "1976"}, {"id": "1965447681", "title": "Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays", "abstract": "Recent advances in sensing technology have enabled a new generation of tabletop displays that can sense multiple points of input from several users simultaneously. However, apart from a few demonstration techniques [17], current user interfaces do not take advantage of this increased input bandwidth. We present a variety of multifinger and whole hand gestural interaction techniques for these displays that leverage and extend the types of actions that people perform when interacting on real physical tabletops. Apart from gestural input techniques, we also explore interaction and visualization techniques for supporting shared spaces, awareness, and privacy. These techniques are demonstrated within a prototype room furniture layout application, called RoomPlanner.", "authors": ["Mike Wu", "Ravin Balakrishnan"], "related_topics": ["207347870", "107457646", "14669888"], "citation_count": "707", "reference_count": "20", "references": ["2158707444", "2005198142", "1968211101", "2150874632", "2911311425", "2094982166", "2118041291", "2167670020", "2033492428", "2024661959"], "date": "2003"}, {"id": "1698657956", "title": "A Dynamic systems approach to the development of cognition and action", "abstract": "A Dynamic Systems Approach to the Development of Cognition and Action presents a comprehensive and detailed theory of early human development based on the principles of dynamic systems theory. Beginning with their own research in motor, perceptual, and cognitive development, Thelen and Smith raise fundamental questions about prevailing assumptions in the field. They propose a new theory of the development of cognition and action, unifying recent advances in dynamic systems theory with current research in neuroscience and neural development. In particular, they show how by processes of exploration and selection, multimodal experiences form the bases for self-organizing perception-action categories. Thelen and Smith offer a radical alternative to current cognitive theory, both in their emphasis on dynamic representation and in their focus on processes of change. Among the first attempt to apply complexity theory to psychology, they suggest reinterpretations of several classic issues in early cognitive development. The book is divided into three sections. The first discusses the nature of developmental processes in general terms, the second covers dynamic principles in process and mechanism, and the third looks at how a dynamic theory can be applied to enduring puzzles of development. Cognitive Psychology series", "authors": ["Esther Thelen", "Linda B. Smith"], "related_topics": ["161407221", "140441792", "2779113360"], "citation_count": "7603", "reference_count": "0", "references": ["2153791616", "2136719407", "1928882148", "393180982", "1977308918", "2023015865", "2101524054", "2035090004", "2105895381", "2096578021"], "date": "1993"}, {"id": "2963748441", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL", "authors": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"], "related_topics": ["44291984", "2778780117", "554936623"], "citation_count": "2884", "reference_count": "27", "references": ["2108598243", "1544827683", "1632114991", "2125436846", "2964267515", "2962809918", "2171278097", "2962790689", "2251818205", "2251349042"], "date": "2016"}, {"id": "2121863487", "title": "Reinforcement Learning: An Introduction", "abstract": "Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.", "authors": ["R.S. Sutton", "A.G. Barto"], "related_topics": ["199190896", "97541855", "2780254194"], "citation_count": "44248", "reference_count": "84", "references": ["1639032689", "2154642048", "3017143921", "2100677568", "1535810436", "1603765807", "3011120880", "1569320505", "94523489", "2178806388"], "date": "1987"}, {"id": "2039942287", "title": "ANALYSIS OF SOUND PATTERNS THROUGH WAVELET TRANSFORMS", "abstract": "This paper starts with a brief discussion of so-called wavelet transforms, i.e., decompositions of arbitrary signals into localized contributions labelled by a scale parameter. The main features of the method are first illustrated through simple mathematical examples. Then we present the first applications of the method to the recognition and visualisation of characteristic features of speech and of musical sounds.", "authors": ["Richard Kronland-Martinet", "Jean Morlet", "Alexander Grossmann"], "related_topics": ["47432892", "46286280", "155777637"], "citation_count": "776", "reference_count": "0", "references": ["2132984323", "2098914003", "1970352604", "2166982406", "2048508162", "2116988482", "2093265755", "2065757249", "2169756567", "2126777570"], "date": "1987"}, {"id": "2034555244", "title": "Extended and corrected tables of the upper percentage points of the \u2018Studentized\u2019 range", "abstract": "", "authors": ["Joyce M. May"], "related_topics": ["125918824", "44648626", "105795698"], "citation_count": "59", "reference_count": "0", "references": ["2887171365", "1998495461", "2905458417", "2055389338", "2003406265", "2108834623", "2052090923", "2328056838", "2060813465", "2046294138"], "date": "1952"}, {"id": "2039037800", "title": "Temporal lobe volume measurement from MR images: accuracy and left-right asymmetry in normal persons", "abstract": "The effect of several magnetic resonance (MR) variables on the accuracy of volume measurements in phantom objects was investigated by use of an off-line automatic border-outlining and internal area pixel-counting computer program, and an optimal set of imaging variables was identified. Measurements were made of the temporal lobe volumes of a gross fixed brain specimen from MR image data. The range in accuracy was from -2 to +7%, and the standard deviation of the difference in right minus left lobe volume measurements obtained from the MR images and those obtained by use of Archimedes' principle was 1 cm3. This volumetric technique was applied to 25 normal persons, most of whom were right-handed. The median ratio of right to left temporal lobe volume was 1.16 (range 0.99-1.23). The nondominant temporal lobe was significantly larger than the dominant. The mean difference (95% confidence interval) between right and left volumes was 7 cm3 (6-9 cm3). This confidence interval was similar to that obtained when the variability within a subject (estimated from the gross fixed brain specimen) was taken into account. Unilateral temporal lobe atrophy, particularly in patients with temporal lobe epilepsy, should be interpreted from MR images with this range of discrepancy in normal left-right size in mind.", "authors": ["Clifford R. Jack", "Dale G. Gehring", "Frank W. Sharbrough", "Joel P. Felmlee", "Glenn Forbes", "Victoria S. Hench", "Alan R. Zinsmeister"], "related_topics": ["2781099131", "44249647", "104293457"], "citation_count": "170", "reference_count": "0", "references": ["2063136428", "2114545663", "2012133068", "2032398883", "1970677142", "2095102390", "2080211545", "2048185492", "2011176622", "2114092300"], "date": "1987"}, {"id": "1606347560", "title": "Theano: new features and speed improvements", "abstract": "Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.", "authors": ["Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "James Bergstra", "Ian J. Goodfellow", "Arnaud Bergeron", "Nicolas Bouchard", "David Warde-Farley", "Yoshua Bengio"], "related_topics": ["2776159882", "169590947", "147168706"], "citation_count": "1557", "reference_count": "10", "references": ["2011301426", "2154642048", "2061939373", "753012316", "3005347330", "1408639475", "2110114082", "2185726469", "2254715784", "2006903949"], "date": "2012"}, {"id": "1997716585", "title": "A near-optimal method for reasoning about action\u2606", "abstract": "Abstract We give an algorithm for \u201cbefore-after\u201d reasoning about action. The algorithm decides satisfiability and validity of formulas of propositional dynamic logic, a recently developed logic of change of state that subsumes the zero-order component of most other action-oriented logics. The algorithm requires time at most proportional to an exponentially growing function of the length (number of occurrences of variables and connectives) of the input. Fischer and Ladner have shown that that every algorithm for this problem must take exponential time, making this algorithm optimal to within a polynomial. Application areas include program verification, program synthesis, and discourse analysis. The algorithm is based on the method of semantic tableaux, appropriately generalized to dynamic logic. A formal treatment of the generalization, called Hintikka structures, is developed.", "authors": ["Vaughan R. Pratt"], "related_topics": ["137488015", "168773769", "2776937632"], "citation_count": "201", "reference_count": "18", "references": ["2103953153", "3146075203", "1574129634", "2987907651", "2079275582", "1536217426", "1980738498", "2066949643", "2026191634", "1978367838"], "date": "1980"}, {"id": "2337098149", "title": "Constraint Processing", "abstract": "Constraint satisfaction is a simple but powerful tool. Constraints identify the impossible and reduce the realm of possibilities to effectively focus on the possible, allowing for a natural declarative formulation of what must be satisfied, without expressing how. The field of constraint reasoning has matured over the last three decades with contributions from a diverse community of researchers in artificial intelligence, databases and programming languages, operations research, management science, and applied mathematics. Today, constraint problems are used to model cognitive tasks in vision, language comprehension, default reasoning, diagnosis, scheduling, temporal and spatial reasoning. In Constraint Processing, Rina Dechter, synthesizes these contributions, along with her own significant work, to provide the first comprehensive examination of the theory that underlies constraint processing algorithms. Throughout, she focuses on fundamental tools and principles, emphasizing the representation and analysis of algorithms. \u00b7Examines the basic practical aspects of each topic and then tackles more advanced issues, including current research challenges \u00b7Builds the reader's understanding with definitions, examples, theory, algorithms and complexity analysis \u00b7Synthesizes three decades of researchers work on constraint processing in AI, databases and programming languages, operations research, management science, and applied mathematics Table of Contents Preface; Introduction; Constraint Networks; Consistency-Enforcing Algorithms: Constraint Propagation; Directional Consistency; General Search Strategies; General Search Strategies: Look-Back; Local Search Algorithms; Advanced Consistency Methods; Tree-Decomposition Methods; Hybrid of Search and Inference: Time-Space Trade-offs; Tractable Constraint Languages; Temporal Constraint Networks; Constraint Optimization; Probabilistic Networks; Constraint Logic Programming; Bibliography", "authors": ["Rina Dechter"], "related_topics": ["176783269", "44616089", "173404611"], "citation_count": "2652", "reference_count": "298", "references": ["2752885492", "2581275558", "2159080219", "2011039300", "2142785340", "2104670598", "2057361103", "1524764420", "1593793857", "1561016548"], "date": "2002"}, {"id": "2110505033", "title": "Vehicle-to-Vehicle Communication: Fair Transmit Power Control for Safety-Critical Information", "abstract": "Direct radio-based vehicle-to-vehicle communication can help prevent accidents by providing accurate and up-to-date local status and hazard information to the driver. In this paper, we assume that two types of messages are used for traffic safety-related communication: 1) Periodic messages (ldquobeaconsrdquo) that are sent by all vehicles to inform their neighbors about their current status (i.e., position) and 2) event-driven messages that are sent whenever a hazard has been detected. In IEEE 802.11 distributed-coordination-function-based vehicular networks, interferences and packet collisions can lead to the failure of the reception of safety-critical information, in particular when the beaconing load leads to an almost-saturated channel, as it could easily happen in many critical vehicular traffic conditions. In this paper, we demonstrate the importance of transmit power control to avoid saturated channel conditions and ensure the best use of the channel for safety-related purposes. We propose a distributed transmit power control method based on a strict fairness criterion, i.e., distributed fair power adjustment for vehicular environments (D-FPAV), to control the load of periodic messages on the channel. The benefits are twofold: 1) The bandwidth is made available for higher priority data like dissemination of warnings, and 2) beacons from different vehicles are treated with ldquoequal rights,rdquo and therefore, the best possible reception under the available bandwidth constraints is ensured. We formally prove the fairness of the proposed approach. Then, we make use of the ns-2 simulator that was significantly enhanced by realistic highway mobility patterns, improved radio propagation, receiver models, and the IEEE 802.11p specifications to show the beneficial impact of D-FPAV for safety-related communications. We finally put forward a method, i.e., emergency message dissemination for vehicular environments (EMDV), for fast and effective multihop information dissemination of event-driven messages and show that EMDV benefits of the beaconing load control provided by D-FPAV with respect to both probability of reception and latency.", "authors": ["M. Torrent-Moreno", "J. Mittag", "P. Santi", "H. Hartenstein"], "related_topics": ["30095986", "192448918", "56685638"], "citation_count": "648", "reference_count": "47", "references": ["2613173048", "2018468667", "598996319", "2142347946", "2078938638", "2143388966", "2068691410", "1975310123", "2031035035", "2099411281"], "date": "2009"}, {"id": "2095483845", "title": "Remote sensing big data computing", "abstract": "As we have entered an era of high resolution earth observation, the RS data are undergoing an explosive growth. The proliferation of data also give rise to the increasing complexity of RS data, like the diversity and higher dimensionality characteristic of the data. RS data are regarded as RS \"Big Data\". Fortunately, we are witness the coming technological leapfrogging. In this paper, we give a brief overview on the Big Data and data-intensive problems, including the analysis of RS Big Data, Big Data challenges, current techniques and works for processing RS Big Data. This paper identifies the properties and features of remote sensing big data.This paper reviews the stat-of-the-arts of remote sensing big data computing.This paper discusses the \"data-intensive computing\" issues in remote sensing big data processing.", "authors": ["Yan Ma", "Haiping Wu", "Lizhe Wang", "Bormin Huang", "Rajiv Ranjan", "Albert Zomaya", "Wei Jie"], "related_topics": ["75684735", "76831024", "39399123"], "citation_count": "430", "reference_count": "88", "references": ["2173213060", "1981420413", "2153704625", "2170616854", "2087946700", "2109574129", "2073965851", "2131697388", "2138973222", "2115583184"], "date": "2015"}, {"id": "1618905105", "title": "Probabilistic Outputs for Support vector Machines and Comparisons to Regularized Likelihood Methods", "abstract": "", "authors": ["John C. Platt"], "related_topics": ["14948415", "173102733", "125168437"], "citation_count": "6451", "reference_count": "0", "references": ["2153635508", "2122646361", "1648445109", "2964212410", "1825604117", "2115150266", "2963466845", "2115252128", "1999954155", "9657784"], "date": "1998"}, {"id": "2142241884", "title": "Social Emergence: Societies As Complex Systems", "abstract": "Can we understand important social issues by studying individual personalities and decisions? Or are societies somehow more than the people in them? Sociologists have long believed that psychology can't explain what happens when people work together in complex modern societies. In contrast, most psychologists and economists believe that if we have an accurate theory of how individuals make choices and act on them, we can explain pretty much everything about social life. Social Emergence takes a new approach to these longstanding questions. Sawyer argues that societies are complex dynamical systems, and that the best way to resolve these debates is by developing the concept of emergence, focusing on multiple levels of analysis - individuals, interactions, and groups - and with a dynamic focus on how social group phenomena emerge from communication processes among individual members. This book makes a unique contribution not only to complex systems research but also to social theory.", "authors": ["R. Keith Sawyer"], "related_topics": ["180872759", "41852734", "53001019"], "citation_count": "1495", "reference_count": "373", "references": ["2116199508", "1652505363", "2153943092", "2062663664", "1999410909", "1554576613", "2150312211", "1751769270", "2170756108", "2063460205"], "date": "2004"}, {"id": "2079667200", "title": "Understanding HRM\u2013Firm Performance Linkages: The Role of the \u201cStrength\u201d of the HRM System", "abstract": "Theory building has lagged on the intermediate linkages responsible for the relationship between HRM and firm performance. We introduce the construct \u201cstrength of the HRM system\u201d and describe the meta-features of an HRM system that result in a strong organizational climate, analogous to Mischel's \u201cstrong situation,\u201d in which individuals share a common interpretation of what behaviors are expected and rewarded. The strength of the HRM system can help explain how individual employee attributes accumulate to affect organizational effectiveness.", "authors": ["David E. Bowen", "Cheri Ostroff"], "related_topics": ["165672731", "185654502", "108363010"], "citation_count": "3844", "reference_count": "76", "references": ["201578715", "3122125999", "2110162191", "2027636702", "1981724520", "2060514481", "2117942482", "1539896512", "2169962981", "2154261609"], "date": "2004"}, {"id": "1979071892", "title": "Automatic programming of behavior-based robots using reinforcement learning", "abstract": "Abstract This paper describes a general approach for automatically programming a behavior-based robot. New behaviors are learned by trial and error using a performance feedback function as reinforcement. Two algorithms for behavior learning are described that combine Q learning, a well-known scheme for propagating reinforcement values temporally across actions, with statistical clustering and Hamming distance, two ways of propagating reinforcement values spatially across states. A real behavior-based robot called OBELIX is described that learns several component behaviors in an example task involving pushing boxes. A simulator for the box pushing task is also used to gather data on the learning techniques. A detailed experimental study using the real robot and the simulator suggests two conclusions. 1. (1) The learning techniques are able to learn the individual behaviors, sometimes outperforming a handcoded program. 2. (2) Using a behavior-based architecture speeds up reinforcement learning by converting the problem of learning a complex task into that of learning a simpler set of special-purpose reactive subtasks.", "authors": ["Sridhar Mahadevan", "Jonathan Connell"], "related_topics": ["188888258", "199190896", "97541855"], "citation_count": "1056", "reference_count": "28", "references": ["2149706766", "2528268528", "2100677568", "3011120880", "1583833196", "2154418813", "1491843047", "2180885055", "1569296262", "2009207944"], "date": "1992"}, {"id": "1483147224", "title": "Everyday Cognition: Development in Social Context", "abstract": "", "authors": ["Barbara Rogoff", "Jean Lave"], "related_topics": ["86658582", "123950299", "206836424"], "citation_count": "2466", "reference_count": "0", "references": ["10833075", "2164599981", "1992069980", "2124371079", "2112959653", "2133196698", "2580252561", "2501918302", "2121110499", "2158195849"], "date": "1999"}, {"id": "2085989833", "title": "A sequential algorithm for training text classifiers", "abstract": "The ability to cheaply train text classifiers is critical to their use in information retrieval, content analysis, natural language processing, and other tasks involving data which is partly or fully textual. An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task. This method, which we call uncertainty sampling, reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness.", "authors": ["David D. Lewis", "William A. Gale"], "related_topics": ["2777493441", "2779532271", "148483581"], "citation_count": "2629", "reference_count": "27", "references": ["1528905581", "3017143921", "2000672666", "2151023586", "2139709458", "2080021732", "1513874326", "1977182536", "2088538739", "2126502509"], "date": "1994"}, {"id": "2112050062", "title": "Correlated Topic Models", "abstract": "Topic models, such as latent Dirichlet allocation (LDA), can be useful tools for the statistical analysis of document collections and other discrete data. The LDA model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A limitation of LDA is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than x-ray astronomy. This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions. In this paper we develop the correlated topic model (CTM), where the topic proportions exhibit correlation via the logistic normal distribution [1]. We derive a mean-field variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. The CTM gives a better fit than LDA on a collection of OCRed articles from the journal Science. Furthermore, the CTM provides a natural way of visualizing and exploring this and other unstructured data sets.", "authors": ["John D. Lafferty", "David M. Blei"], "related_topics": ["500882744", "181389423", "171686336"], "citation_count": "1447", "reference_count": "11", "references": ["1880262756", "2098126593", "2140124448", "2171706135", "2112971401", "2166325326", "2118079529", "1601553142", "2963074323", "2144250161"], "date": "2005"}, {"id": "2167357515", "title": "Approaching the Capacity of Wireless Networks through Distributed Interference Alignment", "abstract": "Recent results establish the optimality of interference alignment to approach the Shannon capacity of interference networks at high SNR. However, the extent to which interference can be aligned over a finite number of signalling dimensions remains unknown. Another important concern for interference alignment schemes is the requirement of global channel knowledge. In this work we provide examples of iterative algorithms that utilize the reciprocity of wireless networks to achieve interference alignment with only local channel knowledge at each node. These algorithms also provide numerical insights into the feasibility of interference alignment that are not yet available in theory.", "authors": ["K. Gomadam", "V.R. Cadambe", "S.A. Jafar"], "related_topics": ["155437304", "108037233", "97744766"], "citation_count": "918", "reference_count": "22", "references": ["1997834106", "2136608712", "2106549261", "2002937495", "2121233130", "2163844889", "2153946652", "2171681635", "2120445834", "2130444183"], "date": "2008"}, {"id": "1916559533", "title": "Statistical Machine Translation", "abstract": "This introductory text to statistical machine translation (SMT) provides all of the theories and methods needed to build a statistical machine translator, such as Google Language Tools and Babelfish. In general, statistical techniques allow automatic translation systems to be built quickly for any language-pair using only translated texts and generic software. With increasing globalization, statistical machine translation will be central to communication and commerce. Based on courses and tutorials, and classroom-tested globally, it is ideal for instruction or self-study, for advanced undergraduates and graduate students in computer science and/or computational linguistics, and researchers in natural language processing. The companion website provides open-source corpora and tool-kits.", "authors": ["Philipp Koehn"], "related_topics": ["2780206684", "203005215", "24687705"], "citation_count": "2012", "reference_count": "68", "references": ["2101105183", "1574901103", "2049633694", "2006969979", "2135843243", "2117400858", "2101210369", "1973923101", "2097333193", "2122922578"], "date": "2010"}, {"id": "2097571405", "title": "An Introduction to Genetic Algorithms", "abstract": "From the Publisher: \"This is the best general book on Genetic Algorithms written to date. It covers background, history, and motivation; it selects important, informative examples of applications and discusses the use of Genetic Algorithms in scientific models; and it gives a good account of the status of the theory of Genetic Algorithms. Best of all the book presents its material in clear, straightforward, felicitous prose, accessible to anyone with a college-level scientific background. If you want a broad, solid understanding of Genetic Algorithms -- where they came from, what's being done with them, and where they are going -- this is the book. -- John H. Holland, Professor, Computer Science and Engineering, and Professor of Psychology, The University of Michigan; External Professor, the Santa Fe Institute. Genetic algorithms have been used in science and engineering as adaptive algorithms for solving practical problems and as computational models of natural evolutionary systems. This brief, accessible introduction describes some of the most interesting research in the field and also enables readers to implement and experiment with genetic algorithms on their own. It focuses in depth on a small set of important and interesting topics -- particularly in machine learning, scientific modeling, and artificial life -- and reviews a broad span of research, including the work of Mitchell and her colleagues. The descriptions of applications and modeling projects stretch beyond the strict boundaries of computer science to include dynamical systems theory, game theory, molecular biology, ecology, evolutionary biology, and population genetics, underscoring the exciting \"general purpose\" nature of genetic algorithms as search methods that can be employed across disciplines. An Introduction to Genetic Algorithms is accessible to students and researchers in any scientific discipline. It includes many thought and computer exercises that build on and reinforce the reader's understanding of the text. The first chapter introduces genetic algorithms and their terminology and describes two provocative applications in detail. The second and third chapters look at the use of genetic algorithms in machine learning (computer programs, data analysis and prediction, neural networks) and in scientific models (interactions among learning, evolution, and culture; sexual selection; ecosystems; evolutionary activity). Several approaches to the theory of genetic algorithms are discussed in depth in the fourth chapter. The fifth chapter takes up implementation, and the last chapter poses some currently unanswered questions and surveys prospects for the future of evolutionary computation.", "authors": ["Melanie Mitchell"], "related_topics": ["110332635", "105902424", "138379479"], "citation_count": "17058", "reference_count": "72", "references": ["1639032689", "2581275558", "2133671888", "2062663664", "2028569720", "2156728410", "2326587081", "1606791384", "123765585", "1587100796"], "date": "1995"}, {"id": "2179492332", "title": "Knowledge of the Firm, Combinative Capabilities, and the Replication of Technology", "abstract": "How should we understand why firms exist? A prevailing view has been that they serve to keep in check the transaction costs arising from the self-interested motivations of individuals. We develop in this article the argument that what firms do better than markets is the sharing and transfer of the knowledge of individuals and groups within an organization. This knowledge consists of information (e.g., who knows what) and of know-how (e.g., how to organize a research team). What is central to our argument is that knowledge is held by individuals, but is also expressed in regularities by which members cooperate in a social community (i.e., group, organization, or network). If knowledge is only held at the individual level, then firms could change simply by employee turnover. Because we know that hiring new workers is not equivalent to changing the skills of a firm, an analysis of what firms can do must understand knowledge as embedded in the organizing principles by which people cooperate within organizatio...", "authors": ["Bruce Kogut", "Udo Zander"], "related_topics": ["2777455136", "191628500", "169735623"], "citation_count": "19274", "reference_count": "0", "references": ["2169667133", "2108183214", "2089402107", "2132081716", "2002779084", "2172157658", "2018514036", "2095659828", "2132924891", "1998271713"], "date": "1992"}, {"id": "2145889472", "title": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images", "abstract": "The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.", "authors": ["Bruno A. Olshausen", "", "David J. Field"], "related_topics": ["133219170", "2778837399", "28297318"], "citation_count": "6557", "reference_count": "20", "references": ["2108384452", "1993845689", "2180838288", "2167034998", "2120838001", "2122925692", "1914401667", "2106884367", "2911607583", "2117731089"], "date": "1996"}, {"id": "2042388195", "title": "Solving Ordinary Differential Equations I: Nonstiff Problems", "abstract": "This book deals with methods for solving nonstiff ordinary differential equations. The first chapter describes the historical development of the classical theory, and the second chapter includes a modern treatment of Runge-Kutta and extrapolation methods. Chapter three begins with the classical theory of multistep methods, and concludes with the theory of general linear methods. The reader will benefit from many illustrations, a historical and didactic approach, and computer programs which help him/her learn to solve all kinds of ordinary differential equations. This new edition has been rewritten and new material has been included.", "authors": ["Ernst Hairer", "Syvert Paul Norsett", "Gerhard Wanner"], "related_topics": ["51544822", "139645642", "164991812"], "citation_count": "5056", "reference_count": "0", "references": ["2963755523", "2947056241", "1509146820", "1981115560", "280536263", "2008590430", "2020615058", "1978349032", "2773396578", "2050840600"], "date": "1986"}, {"id": "2077274398", "title": "MARIA: A universal, declarative, multiple abstraction-level language for service-oriented applications in ubiquitous environments", "abstract": "One important evolution in software applications is the spread of service-oriented architectures in ubiquitous environments. Such environments are characterized by a wide set of interactive devices, with interactive applications that exploit a number of functionalities developed beforehand and encapsulated in Web services. In this article, we discuss how a novel model-based UIDL can provide useful support both at design and runtime for these types of applications. Web service annotations can also be exploited for providing hints for user interface development at design time. At runtime the language is exploited to support dynamic generation of user interfaces adapted to the different devices at hand during the user interface migration process, which is particularly important in ubiquitous environments.", "authors": ["Fabio Paterno", "Carmen Santoro", "Lucio Davide Spano"], "related_topics": ["149229913", "35578498", "89505385"], "citation_count": "374", "reference_count": "22", "references": ["2131415946", "2112469617", "2152342394", "2134816385", "1806335491", "2131555591", "2148334620", "2102072895", "2049287964", "2094096463"], "date": "2009"}, {"id": "2124807415", "title": "Moses: Open Source Toolkit for Statistical Machine Translation", "abstract": "We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks.", "authors": ["Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens", "Chris Dyer", "Ondrej Bojar", "Alexandra Constantin", "Evan Herbst"], "related_topics": ["2780206684", "110046852", "2776866485"], "citation_count": "6107", "reference_count": "13", "references": ["2101105183", "2153653739", "2156985047", "1631260214", "2146574666", "1498238796", "2113788796", "2105891181", "2056250865", "2130450156"], "date": "2007"}, {"id": "2101933716", "title": "Independent component filters of natural images compared with simple cells in primary visual cortex", "abstract": "Properties of the receptive fields of simple cells in macaque cortex were compared with properties of independent component filters generated by independent component analysis (ICA) on a large set of natural images. Histograms of spatial frequency bandwidth, orientation tuning bandwidth, aspect ratio and length of the receptive fields match well. This indicates that simple cells are well tuned to the expected statistics of natural stimuli. There is no match, however, in calculated and measured distributions for the peak of the spatial frequency response: the filters produced by ICA do not vary their spatial scale as much as simple cells do, but are fixed to scales close to the finest ones allowed by the sampling lattice. Possible ways to resolve this discrepancy are discussed.", "authors": ["J H van Hateren", "A van der Schaaf"], "related_topics": ["100921725", "19071747", "133219170"], "citation_count": "1425", "reference_count": "40", "references": ["2145889472", "2019502123", "2105464873", "2137234026", "2180838288", "2022735534", "2167034998", "2120838001", "2170319235", "2042755403"], "date": "1998"}, {"id": "1814775863", "title": "Time-frequency analysis: theory and applications", "abstract": "", "authors": ["Leon Cohen"], "related_topics": ["142433447", "24326235", "41008148"], "citation_count": "781", "reference_count": "0", "references": ["2112844139", "2025797281", "2054878302", "2163049891", "1980721798", "1992137233", "2771148491", "642667799", "2337001254", "2963396373"], "date": "1995"}, {"id": "1986936900", "title": "The psychology of interpersonal relations", "abstract": "The psychology of interpersonal relations , The psychology of interpersonal relations , \u06a9\u062a\u0627\u0628\u062e\u0627\u0646\u0647 \u062f\u06cc\u062c\u06cc\u062a\u0627\u0644 \u0648 \u0641\u0646 \u0622\u0648\u0631\u06cc \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u062f\u0627\u0646\u0634\u06af\u0627\u0647 \u0627\u0645\u0627\u0645 \u0635\u0627\u062f\u0642(\u0639)", "authors": ["Fritz Heider"], "related_topics": ["61997241", "91034043", "638126"], "citation_count": "17636", "reference_count": "141", "references": ["1501573641", "1513104673", "2061230487", "1984591136", "1527935828", "2002010034", "2122741244", "2476065884", "2047125192", "2114051435"], "date": "1957"}, {"id": "2060605975", "title": "The Measurement of Power Spectra", "abstract": "", "authors": ["R. B. Blackman", "J. W. Tukey", "T. Teichmann"], "related_topics": ["163258240", "4839761", "30475298"], "citation_count": "2796", "reference_count": "0", "references": ["1582484699", "2098746383", "2155722796", "2138309709", "1496971974", "2531578105", "2137632745", "2088017846", "2903091095", "2025196967"], "date": "1960"}, {"id": "2117909082", "title": "Predicting the dative alternation", "abstract": "Theoretical linguists have traditionally relied on linguistic intuitions such as grammaticality judgments for their data. But the massive growth of computer-readable texts and recordings, the availability of cheaper, more powerful computers and software, and the development of new probabilistic models for language have now made the spontaneous useoflanguageinnaturalsettingsarichandeasilyaccessiblealternativesourceofdata. Surprisingly, many linguists believe that such \u2018usage data\u2019 are irrelevant to the theory of grammar. Four problems are repeatedly brought up in the critiques of usage data: 1. Correlated factors seeming to support reductive theories; 2. Pooled data invalidating grammatical inference; 3. Syntactic choices reducing to lexical biases; and 4. Cross-corpus differences undermining corpus studies. Presenting a case study of work on the English dative alternation, we show first,that linguistic intuitions of grammaticality are deeply flawed and seriously underestimate the space of grammatical possibility, and second, that the four problems in the critique of usage data are empirical issues that can be resolved by using modern statistical theory and modeling strategies widely used in other fields. The new models allow linguistic theory to solve more difficult problems than it has in the past, and to build convergent projects with psychology, computer science, and allied fields of cognitive science.", "authors": ["Joan Bresnan", "Anna Cueni", "Tatiana Nikitina", "R. Harald Baayen"], "related_topics": ["2779525943", "26022165", "56601403"], "citation_count": "1076", "reference_count": "45", "references": ["1995945562", "2115709314", "1587094587", "1632114991", "2328425223", "2039217078", "2004415003", "2112688502", "2166637769", "1497748330"], "date": "2006"}, {"id": "1482810025", "title": "Analysis and design of cognitive radio networks and distributed radio resource management algorithms", "abstract": "Cognitive radio is frequently touted as a platform for implementing dynamic distributed radio resource management algorithms. In the envisioned scenarios, radios react to measurements of the network state and change their operation according to some goal driven algorithm. Ideally this flexibility and reactivity yields tremendous gains in performance. However, when the adaptations of the radios also change the network state, an interactive decision process is spawned and once desirable algorithms can lead to catastrophic failures when deployed in a network. This document presents techniques for modeling and analyzing the interactions of cognitive radio for the purpose of improving the design of cognitive radio and distributed radio resource management algorithms with particular interest towards characterizing the algorithms' steady-state, convergence, and stability properties. This is accomplished by combining traditional engineering and nonlinear programming analysis techniques with techniques from game to create a powerful model based approach that permits rapid characterization of a cognitive radio algorithm's properties. Insights gleaned from these models are used to establish novel design guidelines for cognitive radio design and powerful low-complexity cognitive radio algorithms. This research led to the creation of a new model of cognitive radio network behavior, an extensive number of new results related to the convergence, stability, and identification of potential and supermodular games, numerous design guidelines, and several novel algorithms related to power control, dynamic frequency selection, interference avoidance, and network formation. It is believed that by applying the analysis techniques and the design guidelines presented in this document, any wireless engineer will be able to quickly develop cognitive radio and distributed radio resource management algorithms that will significantly improve spectral efficiency and network and device performance while removing the need for significant post-deployment site management.", "authors": ["Jeffrey H. Reed", "James O'Daniell Neel"], "related_topics": ["149946192", "32542511", "182448111"], "citation_count": "313", "reference_count": "87", "references": ["2071707134", "2153090463", "2062663664", "2109100253", "3011621684", "2164271287", "2002937495", "1601490018", "1570822527", "1603765807"], "date": "2005"}, {"id": "2135622428", "title": "Introduction to matrix computations", "abstract": "Preliminaries. Practicalities. The Direct Solution of Linear Systems. Norms, Limits, and Condition Numbers. The Linear Least Squares Problem. Eigenvalues and Eigenvectors. The QR Algorithm. The Greek Alphabet and Latin Notational Correspondents. Determinants. Rounding-Error Analysis of Solution of Triangular Systems and of Gaussian Elimination. Of Things Not Treated. Bibliography. Index.", "authors": ["G. W. Stewart"], "related_topics": ["2776436786", "188060507", "126312332"], "citation_count": "2875", "reference_count": "0", "references": ["1506342804", "2130116522", "616418331", "210359992", "2140153041", "2088900896", "2062914653", "2187548090", "1553004968", "1984714339"], "date": "1973"}, {"id": "3093382707", "title": "Uniform Priors for Data-Efficient Transfer", "abstract": "Deep Neural Networks have shown great promise on a variety of downstream applications; but their ability to adapt and generalize to new data and tasks remains a challenging problem. However, the ability to perform few or zero-shot adaptation to novel tasks is important for the scalability and deployment of machine learning models. It is therefore crucial to understand what makes for good, transferable features in deep networks that best allow for such adaptation. In this paper, we shed light on this by showing that features that are most transferable have high uniformity in the embedding space and propose a uniformity regularization scheme that encourages better transfer and feature reuse. We evaluate the regularization on its ability to facilitate adaptation to unseen tasks and data, for which we conduct a thorough experimental study covering four relevant, and distinct domains: few-shot Meta-Learning, Deep Metric Learning, Zero-Shot Domain Adaptation, as well as Out-of-Distribution classification. Across all experiments, we show that uniformity regularization consistently offers benefits over baseline methods and is able to achieve state-of-the-art performance in Deep Metric Learning and Meta-Learning.", "authors": ["Samarth Sinha", "Karsten Roth", "Anirudh Goyal", "Marzyeh Ghassemi", "Hugo Larochelle", "Animesh Garg"], "related_topics": ["2781002164", "150899416", "205617318"], "citation_count": "0", "reference_count": "73", "references": ["2194775991", "2964121744", "2963341956", "2963403868", "1836465849", "1901129140", "2117539524", "1903029394", "2099471712", "1536680647"], "date": "2021"}, {"id": "1968243487", "title": "A comparison and elaboration of two models of metacontrast.", "abstract": "", "authors": ["Naomi Weisstein", "Gregory Ozog", "Ronald Szoc"], "related_topics": ["178253425", "2779192218", "180747234"], "citation_count": "226", "reference_count": "35", "references": ["2164847484", "1999908130", "2154634575", "2018809434", "2041181954", "2163875444", "2042236083", "1975080851", "2062793957", "2074165728"], "date": "1975"}, {"id": "1766888123", "title": "Discrete-Time Signal Processing", "abstract": "For senior/graduate-level courses in Discrete-Time Signal Processing. THE definitive, authoritative text on DSP -- ideal for those with an introductory-level knowledge of signals and systems. Written by prominent, DSP pioneers, it provides thorough treatment of the fundamental theorems and properties of discrete-time linear systems, filtering, sampling, and discrete-time Fourier Analysis. By focusing on the general and universal concepts in discrete-time signal processing, it remains vital and relevant to the new challenges arising in the field --without limiting itself to specific technologies with relatively short life spans.", "authors": ["Alan V. Oppenheim", "Ronald W. Schafer"], "related_topics": ["501101116", "84462506", "146749787"], "citation_count": "32525", "reference_count": "0", "references": ["2133865602", "2143267104", "1991252559", "1582484699", "2124890704", "210359992", "2165949425", "2154278880", "2141116650", "2114004090"], "date": "1988"}, {"id": "773929776", "title": "Assessing Vocabulary: Acknowledgements", "abstract": "", "authors": ["John Read"], "related_topics": ["167055898", "2777601683", "166007726"], "citation_count": "654", "reference_count": "0", "references": ["2074350771", "2101956761", "2028223792", "2111466409", "2105933041", "1976538119", "2095682275", "2037170747", "2072790586", "2150663108"], "date": "1999"}, {"id": "118993750", "title": "Visibility of Displayed Information", "abstract": "Abstract : This report is concerned with the visibility of displayed luminance information, that is, predicting what an observer can see when he views a display. Some of the specific practical problems addressed are: When does a change in display modulation transfer become visible. What are the perceptual effects of sampling and a visible raster structure. How does the perceived information vary with display signal-to-noise ratio. What perceptual effect does a change in display luminance have on the perceived information. And, finally, what display conditions are required in order to produce a perceptually 'perfect' displayed image.", "authors": ["Curtis R Carlson", "Roger W Cohen"], "related_topics": ["73313986", "181844469", "178253425"], "citation_count": "12", "reference_count": "0", "references": ["2103504761", "2056755798", "129753384", "2158328095", "2153163374", "2163899221", "2885803498", "240975220", "1993711838", "2220767570"], "date": "1978"}, {"id": "1506342804", "title": "Iterative Methods for Sparse Linear Systems", "abstract": "Preface 1. Background in linear algebra 2. Discretization of partial differential equations 3. Sparse matrices 4. Basic iterative methods 5. Projection methods 6. Krylov subspace methods Part I 7. Krylov subspace methods Part II 8. Methods related to the normal equations 9. Preconditioned iterations 10. Preconditioning techniques 11. Parallel implementations 12. Parallel preconditioners 13. Multigrid methods 14. Domain decomposition methods Bibliography Index.", "authors": ["Y. Saad"], "related_topics": ["147060835", "136954975", "137119250"], "citation_count": "18168", "reference_count": "159", "references": ["2798909945", "2128978199", "2140153041", "1546004968", "2155216327", "1507795625", "2098841537", "1975442866", "2114030927", "1514324734"], "date": "1996"}, {"id": "2032075694", "title": "Hill shading and the reflectance map", "abstract": "Shaded overlays for maps give the user an immediate appreciation for the surface topography since they appeal to an important visual depth cue. A brief review of the history of manual methods is followed by a discussion of a number of methods that have been proposed for the automatic generation of shaded overlays. These techniques are compared using the reflectance map as a common representation for the dependence of tone or gray level on the orientation of surface elements.", "authors": ["B.K.P. Horn"], "related_topics": ["9095184", "120881857", "21442007"], "citation_count": "1122", "reference_count": "57", "references": ["2007846652", "2063087073", "2161446118", "2114162350", "1589761358", "2073220759", "2050744010", "75556296", "2363701881", "2092686707"], "date": "1980"}, {"id": "2097360283", "title": "Regularization Paths for Generalized Linear Models via Coordinate Descent", "abstract": "We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multinomial regression problems while the penalties include l(1) (the lasso), l(2) (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.", "authors": ["Jerome Friedman", "Trevor Hastie", "Robert Tibshirani"], "related_topics": ["203868755", "52306562", "157553263"], "citation_count": "10804", "reference_count": "37", "references": ["2135046866", "2109363337", "2122825543", "2063978378", "2078204800", "2138019504", "2158940042", "2020925091", "2074682976", "2132555912"], "date": "2010"}, {"id": "2340966270", "title": "Being Digital", "abstract": "From the Publisher: Being Digital decodes the mysteries and debunks the hype surrounding bandwidth, multimedia, virtual reality, and the Internet. It forecasts technologies that will make your telephone as context-sensitive as an English butler and replace TV broadcasters with intelligent \"broadcatchers\" that assemble and deliver only the programming you want. And this book suggests what being digital will mean for our laws, education, politics, and amusements - in short, for the way we live.", "authors": ["Nicholas Negroponte", "Marty Asher"], "related_topics": ["110875604", "194969405", "2778858076"], "citation_count": "10773", "reference_count": "0", "references": ["2149891956", "2128672031", "2576297379", "1673918140", "2312302756", "2100347631", "2891966433", "2290345546", "1890961823", "2512365341"], "date": "1994"}, {"id": "1939330307", "title": "Danger warning and emergency response system and method", "abstract": "Surveillance platforms in airborne craft (8,10), land based vehicles (12), vessels at sea or fixed structures (14) detect dangers using conventional scanners and transmit information signals describing the dangers to a control center (2) which analyzes the data and determines the degree of danger and its geographic extent. The center generates a danger warning and emergency response including a danger index. The warning/response message identifies the degree of danger (danger index 144) and the GPS coordinates (142) of the impacted geographic area for a wide region or regions of the earth (FIGS. 2-6). A vulnerability index (FIG. 16) determined using neural networks (FIGS. 13-14) and fuzzy logic (FIGS. 15-20) enables a prioritized warning/response. The center broadcasts (18) the danger warning and emergency response (FIG. 9) to a large population of remotely located warning devices (11), such as a network of pagers each of which has a GPS receiver (6,28). The pagers compare the received danger coordinates with their own GPS coordinates and each pager determines the extent to which it is in danger. The warning device automatically issues a warning signal or signals, which may be audible, visual or vibratory, appropriate to the degree of danger. Emergency manned vehicles may also directly receive the broadcast warning/response and be immediately alerted to act appropriately relative to the degree of danger. One embodiment broadcasts (16) directly to home T.V.'s and radios (17) which have internal GPS receivers and which display/annunciate an emergency message customized to that receiver resulting from the internal comparison of the danger coordinates versus the local receiver coordinates.", "authors": ["Jerome H. Lemelson", "Robert D. Pedersen"], "related_topics": ["198613851", "127611570", "60229501"], "citation_count": "733", "reference_count": "53", "references": ["2032521963", "2133321814", "2141566947", "1954660482", "1545923740", "2096392036", "2823619050", "2130079657", "2166704170", "1954739421"], "date": "1997"}, {"id": "2095293504", "title": "Finding and evaluating community structure in networks.", "abstract": "We propose and study a set of algorithms for discovering community structure in networks-natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using any one of a number of possible \"betweenness\" measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems.", "authors": ["M. E. J. Newman", "", "M. Girvan", ""], "related_topics": ["128243737", "180029405", "2779982251"], "citation_count": "14593", "reference_count": "54", "references": ["3145128584", "2112090702", "2148606196", "2124637492", "1971421925", "2011039300", "2164727176", "3122657004", "1976969221", "2769133055"], "date": "2004"}, {"id": "220082382", "title": "BREAKING THE COST BARRIER IN AUTOMATIC CLASSIFICATION", "abstract": "Abstract : A low-cost automatic classification method is reported that uses computer time in proportion to NlogN, where N is the number of information items and the base is a parameter. Some barriers besides cost are treated briefly in the opening section, including types of intellectual resistance to the idea of doing classification by content-word similarity. The second section explains the basic processes of document grouping by similarity, and discusses the advantages of the reported method over methods commonly experimented with. The operation of an iterative procedure using word profiles to progressively improve the grouping of content-word lists is described. Then some possible applications aside from document classification are enumerated. The final section begins by presenting theoretical underpinnings that explain the form taken by the components of the method. An account of the struggle to make the method work is sketched, followed by a cycle-by-cycle description of a feasibility demonstration. The conclusion states that mere cheapness is not enough and analyzes what researchers and developers might have to do before user acceptance of automatic classification can be assured.", "authors": ["L. B. Doyle"], "related_topics": ["2780479914", "3019080777", "33857546"], "citation_count": "11", "reference_count": "0", "references": ["1979412257", "2015547952", "2004913349", "2004580339", "1567934494", "2044074933", "2143695058", "2054369500", "1980776671", "1987823569"], "date": "1966"}, {"id": "2131986285", "title": "Parsing strategies with 'lexicalized' grammars: application to tree adjoining grammars", "abstract": "In this paper we present a general parsing strategy that arose from the development of an Earley-type parsing algorithm for TAGs (Schabes and Joshi 1988) and from recent linguistic work in TAGs (Abeille 1988).In our approach elementary structures are associated with their lexical heads. These structures specify extended domains of locality (as compared to a context-free grammar) over which constraints can be stated. These constraints either hold within the elementary structure itself or specify what other structures can be composed with a given elementary structure.We state the conditions under which context-free based grammars can be 'lexicalized' without changing the linguistic structures originally produced. We argue that even if one extends the domain of locality of CFGs to trees, using only substitution does not give the freedom to choose the head of each structure. We show how adjunction allows us to 'lexicalize' a CFG freely.We then show how a 'lexicalized' grammar naturally follows from the extended domain of locality of TAGs and present some of the linguistic advantages of our approach.A novel general parsing strategy for 'lexicalized' grammars is discussed. In a first stage, the parser builds a set structures corresponding to the input sentence and in a second stage, the sentence is parsed with respect to this set. The strategy is independent of the linguistic theory adopted and of the underlying grammar formalism. However, we focus our attention on TAGs. Since the set of trees needed to parse an input sentence is supposed to be finite, the parser can use in principle any search strategy. Thus, in particular, a top-down strategy can be used since problems due to recursive structures are eliminated. The parser is also able to use non-local information to guide the search.We then explain how the Earley-type parser for TAGs can be modified to take advantage of this approach.", "authors": ["Yves Schabes", "Anne Abeille", "Aravind K. Joshi"], "related_topics": ["42560504", "118364021", "146810361"], "citation_count": "327", "reference_count": "22", "references": ["1586060904", "1972573551", "2151157246", "2143745167", "2153198088", "2169842528", "2147350240", "2131504185", "2152055978", "2143144395"], "date": "1988"}, {"id": "1506806321", "title": "Pattern Recognition and Machine Learning (Information Science and Statistics)", "abstract": "", "authors": ["Christopher M. Bishop"], "related_topics": ["40608802", "8038995", "153180895"], "citation_count": "14082", "reference_count": "0", "references": ["2076063813", "2395611524", "2166851633", "2964074409", "1977655452", "2054279472", "2157881433", "2083842231", "2096873754", "2087692915"], "date": "2006"}, {"id": "2126087831", "title": "Practical Byzantine fault tolerance", "abstract": "This paper describes a new replication algorithm that is able to tolerate Byzantine faults. We believe that Byzantinefault-tolerant algorithms will be increasingly important in the future because malicious attacks and software errors are increasingly common and can cause faulty nodes to exhibit arbitrary behavior. Whereas previous algorithms assumed a synchronous system or were too slow to be used in practice, the algorithm described in this paper is practical: it works in asynchronous environments like the Internet and incorporates several important optimizations that improve the response time of previous algorithms by more than an order of magnitude. We implemented a Byzantine-fault-tolerant NFS service using our algorithm and measured its performance. The results show that our service is only 3% slower than a standard unreplicated NFS.", "authors": ["Miguel Castro", "Barbara Liskov"], "related_topics": ["17532199", "168021876", "49265948"], "citation_count": "3663", "reference_count": "79", "references": ["1996360405", "3145042860", "2611515161", "3021428210", "2169600013", "2141420453", "1973501242", "2104112849", "2005373714", "2079994203"], "date": "1999"}, {"id": "2730758618", "title": "The dynamic source routing protocol for mobile ad-hoc networks", "abstract": "", "authors": ["J. Broach"], "related_topics": ["204739117", "190526755", "47318570"], "citation_count": "837", "reference_count": "0", "references": ["2132932625", "2133794215", "1965703925", "2103902040", "2014550373", "2033751220", "2000548713", "2161457646", "2213553754", "2095206774"], "date": "1997"}, {"id": "1979104937", "title": "Link prediction in complex networks: A survey", "abstract": "Abstract Link prediction in complex networks has attracted increasing attention from both physical and computer science communities. The algorithms can be used to extract missing information, identify spurious interactions, evaluate network evolving mechanisms, and so on. This article summaries recent progress about link prediction algorithms, emphasizing on the contributions from physical perspectives and approaches, such as the random-walk-based methods and the maximum likelihood methods. We also introduce three typical applications: reconstruction of networks, evaluation of network evolving mechanism and classification of partially labeled networks. Finally, we introduce some applications and outline future challenges of link prediction algorithms.", "authors": ["Linyuan L\u00fc", "", "", "Tao Zhou", ""], "related_topics": ["34947359", "124101348", "89611455"], "citation_count": "2417", "reference_count": "171", "references": ["2112090702", "2008620264", "1532325895", "2148606196", "2124637492", "3013264884", "2095293504", "1971421925", "2070722739", "1971040550"], "date": "2011"}, {"id": "1973286131", "title": "Concentration of measure and isoperimetric inequalities in product spaces", "abstract": "The concentration of measure phenomenon in product spaces roughly states that, if a set A in a product \u03a9N of probability spaces has measure at least one half, \u201cmost\u201d of the points of \u03a9n are \u201cclose\u201d to A. We proceed to a systematic exploration of this phenomenon. The meaning of the word \u201cmost\u201d is made rigorous by isoperimetrictype inequalities that bound the measure of the exceptional sets. The meaning of the work \u201cclose\u201d is defined in three main ways, each of them giving rise to related, but different inequalities. The inequalities are all proved through a common scheme of proof. Remarkably, this simple approach not only yields qualitatively optimal results, but, in many cases, captures near optimal numerical constants. A large number of applications are given, in particular to Percolation, Geometric Probability, Probability in Banach Spaces, to demonstrate in concrete situations the extremely wide range of application of the abstract tools.", "authors": ["Michel Talagrand"], "related_topics": ["55606962", "178042281", "84498859"], "citation_count": "937", "reference_count": "40", "references": ["2068871408", "188867022", "2989661724", "1526777878", "2103012681", "2036777551", "2082249316", "2166965860", "2028816357", "4516790"], "date": "1995"}, {"id": "2093390569", "title": "A language modeling approach to information retrieval", "abstract": "In today's world, there is no shortage of information. However, for a specific information need, only a small subset of all of the available information will be useful. The field of information retrieval (IR) is the study of methods to provide users with that small subset of information relevant to their needs and to do so in a timely fashion. Information sources can take many forms, but this thesis will focus on text based information systems and investigate problems germane to the retrieval of written natural language documents. Central to these problems is the notion of \"topic.\" In other words, what are documents about? However, topics depend on the semantics of documents and retrieval systems are not endowed with knowledge of the semantics of natural language. The approach taken in this thesis will be to make use of probabilistic language models to investigate text based information retrieval and related problems. One such problem is the prediction of topic shifts in text, the topic segmentation problem. It will be shown that probabilistic methods can be used to predict topic changes in the context of the task of new event detection. Two complementary sets of features are studied individually and then combined into a single language model. The language modeling approach allows this problem to be approached in a principled way without complex semantic modeling. Next, the problem of document retrieval in response to a user query will be investigated. Models of document indexing and document retrieval have been extensively studied over the past three decades. The integration of these two classes of models has been the goal of several researchers but it is a very difficult problem. Much of the reason for this is that the indexing component requires inferences as to the semantics of documents. Instead, an approach to retrieval based on probabilistic language modeling will be presented. Models are estimated for each document individually. The approach to modeling is non-parametric and integrates the entire retrieval process into a single model. One advantage of this approach is that collection statistics, which are used heuristically for the assignment of concept probabilities in other probabilistic models, are used directly in the estimation of language model probabilities in this approach. The language modeling approach has been implemented and tested empirically and performs very well on standard test collections and query sets. In order to improve retrieval effectiveness, IR systems use additional techniques such as relevance feedback, unsupervised query expansion and structured queries. These and other techniques are discussed in terms of the language modeling approach and empirical results are given for several of the techniques developed. These results provide further proof of concept for the use of language models for retrieval tasks.", "authors": ["Jay M. Ponte", "W. Bruce Croft"], "related_topics": ["149189445", "21025794", "161156560"], "citation_count": "3661", "reference_count": "19", "references": ["2129905273", "2120062331", "1570542661", "2166698530", "2014415866", "2043909051", "1482854515", "2118020555", "36244633", "1971666241"], "date": "1998"}, {"id": "2118173122", "title": "The Development of Dynamic Inquiry Performances within an Open Inquiry Setting: A Comparison to Guided Inquiry Setting", "abstract": "Dynamic inquiry learning emphasizes aspects of change, intellectual flexibility, and critical thinking. Dynamic inquiry learning is characterized by the following criteria: learning as a process, changes during the inquiry, procedural understanding, and affective points of view. This study compared the influence of open versus guided inquiry learning approaches on dynamic inquiry performances among high-school biology students. We hypothesized that open inquiry students who engage in the inquiry process from its initial stage, participating in the decision making process of asking inquiry questions and planning all aspects of the inquiry, will outperform students who experienced guided inquiry, in terms of developing dynamic inquiry performances. Students were divided into two groups: guided and open inquiry learning approaches. Both groups were followed throughout their 2-year inquiry learning process. The data sources included interviews, students' inquiry summary papers, logbooks, and reflections. A quantitative content analysis of the two groups, using a dynamic inquiry performances index, revealed that open inquiry students used significantly higher levels of performances in the criteria ''changes during inquiry'' and ''procedural understanding.'' However, the study's results indicated no significant differences in the criteria ''learning as a process'' and ''affective points of view.'' The implementation of dynamic inquiry performances during inquiry learning may shed light on the procedural and epistemological scientific understanding of students conducting inquiries. 2009 Wiley Periodicals, Inc. J Res Sci Teach 46: 1137-1160, 2009", "authors": ["Irit Sadeh", "Michal Zion"], "related_topics": ["2779532063", "135355979", "2779786715"], "citation_count": "225", "reference_count": "48", "references": ["2033952602", "2037687914", "2520660681", "2782878764", "2158234052", "2078113882", "2114182155", "2091299887", "1995434502", "594315339"], "date": "2009"}, {"id": "2156471645", "title": "On the second eigenvalue of random regular graphs", "abstract": "Expanders have many applications in Computer Science. It is known that random d-regular graphs are very efficient expanders, almost surely. However, checking whether a particular graph is a good expander is co-NP-complete. We show that the second eigenvalue of d-regular graphs, \u03bb2, is concentrated in an interval of width O(\u221ad) around its mean, and that its mean is O(d3/4). The result holds under various models for random d-regular graphs. As a consequence a random d-regular graph on n vertices, is, with high probability a certifiable efficient expander for n sufficiently large. The bound on the width of the interval is derived from martingale theory and the bound on E(\u03bb2) is obtained by exploring the properties of random walks in random graphs.", "authors": ["Andrei Broder", "Eli Shamir"], "related_topics": ["47458327", "4255713", "74133993"], "citation_count": "143", "reference_count": "16", "references": ["2905110430", "2165469059", "2752853835", "1631603072", "1993111701", "2074599161", "2088164510", "2168256531", "2046097442", "2006544720"], "date": "1987"}, {"id": "2162059449", "title": "Adapting boosting for information retrieval measures", "abstract": "We present a new ranking algorithm that combines the strengths of two previous methods: boosted tree classification, and LambdaRank, which has been shown to be empirically optimal for a widely used information retrieval measure. Our algorithm is based on boosted regression trees, although the ideas apply to any weak learners, and it is significantly faster in both train and test phases than the state of the art, for comparable accuracy. We also show how to find the optimal linear combination for any two rankers, and we use this method to solve the line search problem exactly during boosting. In addition, we show that starting with a previously trained model, and boosting using its residuals, furnishes an effective technique for model adaptation, and we give significantly improved results for a particularly pressing problem in web search--training rankers for markets for which only small amounts of labeled data are available, given a ranker trained on much more data from a larger market.", "authors": ["Qiang Wu", "Christopher J. Burges", "Krysta M. Svore", "Jianfeng Gao"], "related_topics": ["46686674", "86037889", "137293760"], "citation_count": "501", "reference_count": "25", "references": ["1678356000", "2143331230", "2108862644", "1985554184", "2142537246", "2127176025", "2120391124", "2136583886", "2108263314", "2160825952"], "date": "2010"}, {"id": "2140359845", "title": "A Proposal for Structured Reporting of Randomized Controlled Trials", "abstract": "A RANDOMIZED controlled trial (RCT) is the most reliable method of assessing the efficacy of health care interventions.1,2Reports of RCTs should provide readers with adequate information about what went on in the design, execution, analysis, and interpretation of the trial. Such reports will help readers judge the validity of the trial. There have been several investigations evaluating how RCTs are reported. In an early study, Mahon and Daniel3reviewed 203 reports of drug trials published between 1956 and 1960 in theCanadian Medical Association Journal. Only 11 reports (5.4%) fulfilled their criteria of a valid report. In a review of 45 trials published during 1985 in three leading general medical journals, Pocock and colleagues4reported that a statement about sample size was only mentioned in five (11.1%) of the reports, that only six (13.3%) made use of confidence intervals, and that the statistical analyses tended to", "authors": ["Erik Andrew", "Aslam Anis", "Tom Chalmers", "Mildred Cho", "Mike Clarke", "David Felson", "Peter G\u00f8tzsche", "Richard Greene", "Alejandro Jadad", "Wayne Jonas", "Terry Klassen", "Paul Knipschild", "Andreas Laupacis", "Curtis L. Meinert", "David Moher", "Graham Nichol", "Andy Oxman", "Stuart Pocock", "Joan Reisch", "David Sackett", "Kenneth Schulz", "Judy Snider", "Peter Tugwell", "Jon Tyson", "Wikke Walop", "Sharon Walsh", "George Wells"], "related_topics": ["168563851", "160735492", "129848803"], "citation_count": "352", "reference_count": "60", "references": ["2019398887", "2031385454", "1577524338", "2002374666", "2087425662", "1976018371", "2104312285", "1971785694", "2068959829", "2078110114"], "date": "1994"}, {"id": "2159687282", "title": "Secure Communication Over Fading Channels", "abstract": "The fading broadcast channel with confidential messages (BCC) is investigated, where a source node has common information for two receivers (receivers 1 and 2), and has confidential information intended only for receiver 1. The confidential information needs to be kept as secret as possible from receiver 2. The broadcast channel from the source node to receivers 1 and 2 is corrupted by multiplicative fading gain coefficients in addition to additive Gaussian noise terms. The channel state information (CSI) is assumed to be known at both the transmitter and the receivers. The parallel BCC with independent subchannels is first studied, which serves as an information-theoretic model for the fading BCC. The secrecy capacity region of the parallel BCC is established, which gives the secrecy capacity region of the parallel BCC with degraded subchannels. The secrecy capacity region is then established for the parallel Gaussian BCC, and the optimal source power allocations that achieve the boundary of the secrecy capacity region are derived. In particular, the secrecy capacity region is established for the basic Gaussian BCC. The secrecy capacity results are then applied to study the fading BCC. The ergodic performance is first studied. The ergodic secrecy capacity region and the optimal power allocations that achieve the boundary of this region are derived. The outage performance is then studied, where a long-term power constraint is assumed. The power allocation is derived that minimizes the outage probability where either the target rate of the common message or the target rate of the confidential message is not achieved. The power allocation is also derived that minimizes the outage probability where the target rate of the confidential message is not achieved subject to the constraint that the target rate of the common message must be achieved for all channel states.", "authors": ["Yingbin Liang", "H.V. Poor", "S. Shamai"], "related_topics": ["148063708", "81978471", "97744766"], "citation_count": "1015", "reference_count": "68", "references": ["2099111195", "2156214717", "2107689535", "2080693943", "2072563372", "2142102521", "2266946488", "2102654676", "2949672874", "2106833918"], "date": "2008"}, {"id": "2341328702", "title": "Predicting User Satisfaction with Intelligent Assistants", "abstract": "There is a rapid growth in the use of voice-controlled intelligent personal assistants on mobile devices, such as Microsoft's Cortana, Google Now, and Apple's Siri. They significantly change the way users interact with search systems, not only because of the voice control use and touch gestures, but also due to the dialogue-style nature of the interactions and their ability to preserve context across different queries. Predicting success and failure of such search dialogues is a new problem, and an important one for evaluating and further improving intelligent assistants. While clicks in web search have been extensively used to infer user satisfaction, their significance in search dialogues is lower due to the partial replacement of clicks with voice control, direct and voice answers, and touch gestures. In this paper, we propose an automatic method to predict user satisfaction with intelligent assistants that exploits all the interaction signals, including voice commands and physical touch gestures on the device. First, we conduct an extensive user study to measure user satisfaction with intelligent assistants, and simultaneously record all user interactions. Second, we show that the dialogue style of interaction makes it necessary to evaluate the user experience at the overall task level as opposed to the query level. Third, we train a model to predict user satisfaction, and find that interaction signals that capture the user reading patterns have a high impact: when including all available interaction signals, we are able to improve the prediction accuracy of user satisfaction from 71% to 81% over a baseline that utilizes only click and query features.", "authors": ["Julia Kiseleva", "Kyle Williams", "Ahmed Hassan Awadallah", "Aidan C. Crook", "Imed Zitouni", "Tasos Anastasakos"], "related_topics": ["63880386", "67712803", "201025465"], "citation_count": "101", "reference_count": "52", "references": ["1678356000", "2047221353", "2069870183", "2152314154", "2125771191", "2123937625", "2035569891", "2096946253", "1975566260", "2117488952"], "date": "2016"}, {"id": "2023753260", "title": "Dynamic critical-path scheduling: an effective technique for allocating task graphs to multiprocessors", "abstract": "In this paper, we propose a static scheduling algorithm for allocating task graphs to fully connected multiprocessors. We discuss six recently reported scheduling algorithms and show that they possess one drawback or the other which can lead to poor performance. The proposed algorithm, which is called the Dynamic Critical-Path (DCP) scheduling algorithm, is different from the previously proposed algorithms in a number of ways. First, it determines the critical path of the task graph and selects the next node to be scheduled in a dynamic fashion. Second, it rearranges the schedule on each processor dynamically in the sense that the positions of the nodes in the partial schedules are not fixed until all nodes have been considered. Third, it selects a suitable processor for a node by looking ahead the potential start times of the remaining nodes on that processor, and schedules relatively less important nodes to the processors already in use. A global as well as a pair-wise comparison is carried out for all seven algorithms under various scheduling conditions. The DCP algorithm outperforms the previous algorithms by a considerable margin. Despite having a number of new features, the DCP algorithm has admissible time complexity, is economical in terms of the number of processors used and is suitable for a wide range of graph structures.", "authors": ["Yu-Kwong Kwok", "I. Ahmad"], "related_topics": ["31689143", "107568181", "115874739"], "citation_count": "1125", "reference_count": "36", "references": ["2011039300", "1488422606", "2097911714", "2118396891", "2151038512", "2065689629", "2125412556", "1493749856", "2019356799", "1989582918"], "date": "1996"}, {"id": "1992069980", "title": "Interest and Self-Sustained Learning as Catalysts of Development: A Learning Ecology Perspective", "abstract": "Adolescents often pursue learning opportunities both in and outside school once they become interested in a topic. In this paper, a learning ecology framework and an associated empirical research agenda are described. This framework highlights the need to better understand how learning outside school relates to learning within schools or other formal organizations, and how learning in school can lead to learning activities outside school. Three portraits of adolescent learners are shared to illustrate different pathways to interest development. Five types of self-initiated learning processes are identified across these case portraits. These include the seeking out of text-based informational sources, the creation of new interactive activity contexts such as projects, the pursuit of structured learning opportunities such as courses, the exploration of media, and the development of mentoring or knowledge-sharing relationships. Implications for theories of human development and ideas for research are discussed.", "authors": ["Brigid Barron"], "related_topics": ["37228920", "26258499", "96427005"], "citation_count": "1179", "reference_count": "86", "references": ["1780382453", "2116199508", "10833075", "2085529605", "1495038747", "1761161266", "2135943618", "1539142549", "2033282520", "2057673348"], "date": "2006"}, {"id": "2081720252", "title": "Computer Solution of Linear Algebraic Systems", "abstract": "", "authors": ["George Elmer Forsythe", "Cleve B. Moler"], "related_topics": ["25971838", "94523830", "139352143"], "citation_count": "1410", "reference_count": "0", "references": ["2171219272", "1971129545", "3590961", "2028173473", "2132220437", "2111593426", "2104281151", "2166737459", "2165931309", "2078841894"], "date": "1967"}, {"id": "2100347631", "title": "Social Implications of the Internet", "abstract": "The Internet is a critically important research site for sociologists testing theories of technology diffusion and media effects, particularly because it is a medium uniquely capable of integrating modes of communication and forms of content. Current research tends to focus on the Internet's implications in five domains: 1) inequality (the \u201cdigital divide\u201d); 2) community and social capital; 3) political participation; 4) organizations and other economic institutions; and 5) cultural participation and cultural diversity. A recurrent theme across domains is that the Internet tends to complement rather than displace existing media and patterns of behavior. Thus in each domain, utopian claims and dystopic warnings based on extrapolations from technical possibilities have given way to more nuanced and circumscribed understandings of how Internet use adapts to existing patterns, permits certain innovations, and reinforces particular kinds of change. Moreover, in each domain the ultimate social implications of t...", "authors": ["Paul DiMaggio", "Eszter Hargittai", "W. Russell Neuman", "John P. Robinson"], "related_topics": ["110875604", "173655357", "86256295"], "citation_count": "3091", "reference_count": "104", "references": ["2147264455", "2798862961", "2147050295", "2500056419", "2116339812", "2160752569", "2340966270", "2170048845", "2062866147", "2501334522"], "date": "2001"}, {"id": "2133257461", "title": "Sparse deep belief net model for visual area V2", "abstract": "Motivated in part by the hierarchical organization of the cortex, a number of algorithms have recently been proposed that try to learn hierarchical, or \"deep,\" structure from unlabeled data. While several authors have formally or informally compared their algorithms to computations performed in visual area V1 (and the cochlea), little attempt has been made thus far to evaluate these algorithms in terms of their fidelity for mimicking computations at deeper levels in the cortical hierarchy. This paper presents an unsupervised learning model that faithfully mimics certain properties of visual area V2. Specifically, we develop a sparse variant of the deep belief networks of Hinton et al. (2006). We learn two layers of nodes in the network, and demonstrate that the first layer, similar to prior work on sparse coding and ICA, results in localized, oriented, edge filters, similar to the Gabor functions known to model V1 cell receptive fields. Further, the second layer in our model encodes correlations of the first layer responses in the data. Specifically, it picks up both colinear (\"contour\") features as well as corners and junctions. More interestingly, in a quantitative comparison, the encoding of these more complex \"corner\" features matches well with the results from the Ito & Komatsu's study of biological V2 responses. This suggests that our sparse variant of deep belief networks holds promise for modeling more higher-order features.", "authors": ["Honglak Lee", "Chaitanya Ekanadham", "Andrew Y. Ng"], "related_topics": ["97385483", "77637269", "8038995"], "citation_count": "1251", "reference_count": "27", "references": ["2136922672", "2100495367", "2116064496", "2110798204", "1994197834", "2113606819", "2145889472", "2122922389", "2172174689", "2137234026"], "date": "2007"}, {"id": "2088337190", "title": "Tangible User Interfaces: Past, Present and Future Directions", "abstract": "In the last two decades, Tangible User Interfaces (TUIs) have emerged as a new interface type that interlinks the digital and physical worlds. Drawing upon users' knowledge and skills of interaction with the real non-digital world, TUIs show a potential to enhance the way in which people interact with and leverage digital information. However, TUI research is still in its infancy and extensive research is required in order to fully understand the implications of tangible user interfaces, to develop technologies that further bridge the digital and the physical, and to guide TUI design with empirical knowledge. This monograph examines the existing body of work on Tangible User Interfaces. We start by sketching the history of tangible user interfaces, examining the intellectual origins of this field. We then present TUIs in a broader context, survey application domains, and review frameworks and taxonomies. We also discuss conceptual foundations of TUIs including perspectives from cognitive sciences, psychology, and philosophy. Methods and technologies for designing, building, and evaluating TUIs are also addressed. Finally, we discuss the strengths and limitations of TUIs and chart directions for future research.", "authors": ["Orit Shaer", "Eva Hornecker"], "related_topics": ["89505385", "2780049985", "107457646"], "citation_count": "696", "reference_count": "247", "references": ["2149891956", "2085529605", "2127972053", "1963949534", "2050896993", "2086928636", "2162514427", "1933657216", "2158707444", "2052417512"], "date": "2010"}, {"id": "1790954942", "title": "Concept Decompositions for Large Sparse Text Data Using Clustering", "abstract": "Unlabeled document collections are becoming increasingly common and availables mining such data sets represents a major contemporary challenge. Using words as features, text documents are often represented as high-dimensional and sparse vectors\u2013a few thousand dimensions and a sparsity of 95 to 99% is typical. In this paper, we study a certain spherical k-means algorithm for clustering such document vectors. The algorithm outputs k disjoint clusters each with a concept vector that is the centroid of the cluster normalized to have unit Euclidean norm. As our first contribution, we empirically demonstrate that, owing to the high-dimensionality and sparsity of the text data, the clusters produced by the algorithm have a certain \u201cfractal-like\u201d and \u201cself-similar\u201d behavior. As our second contribution, we introduce concept decompositions to approximate the matrix of document vectorss these decompositions are obtained by taking the least-squares approximation onto the linear subspace spanned by all the concept vectors. We empirically establish that the approximation errors of the concept decompositions are close to the best possible, namely, to truncated singular value decompositions. As our third contribution, we show that the concept vectors are localized in the word space, are sparse, and tend towards orthonormality. In contrast, the singular vectors are global in the word space and are dense. Nonetheless, we observe the surprising fact that the linear subspaces spanned by the concept vectors and the leading singular vectors are quite close in the sense of small principal angles between them. In conclusion, the concept vectors produced by the spherical k-means algorithm constitute a powerful sparse and localized \u201cbasis\u201d for text data sets.", "authors": ["Inderjit S. Dhillon", "Dharmendra S. Modha"], "related_topics": ["92951342", "184509293", "12426560"], "citation_count": "1797", "reference_count": "40", "references": ["2798909945", "2147152072", "2078206416", "2107743791", "2105818147", "1956559956", "2138745909", "1978394996", "3017143921", "2152565070"], "date": "2000"}, {"id": "2126151607", "title": "A guide to the literature on learning probabilistic networks from data", "abstract": "The literature review presented discusses different methods under the general rubric of learning Bayesian networks from data, and includes some overlapping work on more general probabilistic networks. Connections are drawn between the statistical, neural network, and uncertainty communities, and between the different methodological communities, such as Bayesian, description length, and classical statistics. Basic concepts for learning and Bayesian networks are introduced and methods are then reviewed. Methods are discussed for learning parameters of a probabilistic network, for learning the structure, and for learning hidden variables. The article avoids formal definitions and theorems, as these are plentiful in the literature, and instead illustrates key concepts with simplified examples.", "authors": ["W. Buntine"], "related_topics": ["155846161", "33724603", "77075516"], "citation_count": "742", "reference_count": "139", "references": ["2159080219", "1594031697", "1652505363", "2049633694", "1528905581", "2133671888", "1504694836", "1680392829", "2170112109", "1567512734"], "date": "1996"}, {"id": "2069562432", "title": "Using Canny's criteria to derive a recursively implemented optimal edge detector", "abstract": "A highly efficient recursive algorithm for edge detection is presented. Using Canny's design [1], we show that a solution to his precise formulation of detection and localization for an infinite extent filter leads to an optimal operator in one dimension, which can be efficiently implemented by two recursive filters moving in opposite directions. In addition to the noise truncature immunity which results, the recursive nature of the filtering operations leads, with sequential machines, to a substantial saving in computational effort (five multiplications and five additions for one pixel, independent of the size of the neighborhood). The extension to the two-dimensional case is considered and the resulting filtering structures are implemented as two-dimensional recursive filters. Hence, the filter size can be varied by simply changing the value of one parameter without affecting the time execution of the algorithm. Performance measures of this new edge detector are given and compared to Canny's filters. Various experimental results are shown.", "authors": ["Rachid Deriche"], "related_topics": ["14705441", "167074055", "193536780"], "citation_count": "1648", "reference_count": "12", "references": ["2109863423", "1622620102", "1756736144", "2113511941", "2038584908", "2081873601", "2050600304", "1488668339", "1982425027", "2082177474"], "date": "1987"}, {"id": "2108356231", "title": "Method and system for customizing marketing services on networks communicating with hypertext tagging conventions", "abstract": "The present server based communications system provides dynamic customization of hypertext tagged documents presented to clients accessing the system. The customization, which pertains to the content of the documents, is based on the specific requirements of a class to which the client belongs to. The class may be defined by the identity of the source which refers the client to the system. The system utilizes a database which dynamically retrieves stored data in response to a server software tool which configures the data into hypertext tagged documents. The system utilizes a dynamic token scheme to pass the identity of the referring network site from document to document to eventual purchase document accessed by the client through the hypertext tags.", "authors": ["William J. Tobin"], "related_topics": ["162215914", "93996380", "48145219"], "citation_count": "526", "reference_count": "85", "references": ["2161461831", "2128499373", "1648470663", "1927713140", "2126825876", "2101304210", "2139020969", "2160566752", "1847890984", "1770940718"], "date": "1998"}, {"id": "1533169541", "title": "Stochastic Complexity In Statistical Inquiry", "abstract": "", "authors": ["Jorma Rissanen"], "related_topics": ["194387892", "87465248", "80444323"], "citation_count": "2304", "reference_count": "0", "references": ["2072128103", "2132549764", "1501500081", "2125527601", "2135705692", "2153638435", "2154496743", "2098152234", "1993845689", "2114766824"], "date": "1989"}, {"id": "2162937730", "title": "Timing and computation in inner retinal circuitry.", "abstract": "In the vertebrate inner retina, the second stage of the visual system, different components of the visual scene are transformed, discarded, or selected before visual information is transmitted through the optic nerve. This review discusses the connections between higher-level functions of visual processing, mathematical descriptions of the neural code, inner retinal circuitry, and visual computations. In the inner plexiform layer, bipolar cells deliver spatially and temporally filtered input to approximately ten anatomical strata. These layers receive a unique combination of excitation and inhibition, causing cells in different layers to respond with different kinetics to visual input. These distinct temporal channels interact through amacrine cells, a diverse class of inhibitory interneurons, which transmit signals within and between layers. In particular, wide-field amacrine cells transmit transient inhibition over long distances within a layer. These mechanisms and properties are combined into computations to detect the presence of differential motion and suppress the visual effects of eye movements.", "authors": ["Stephen A. Baccus"], "related_topics": ["2781099447", "2777093970", "2778251979"], "citation_count": "98", "reference_count": "94", "references": ["2112455917", "2063640158", "2159659012", "1964374113", "1853085112", "2159198041", "2022186938", "2145356729", "1963597874", "1979275115"], "date": "2007"}, {"id": "2167081989", "title": "FastMap: a fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets", "abstract": "A very promising idea for fast searching in traditional and multimedia databases is to map objects into points in k-d space, using k feature-extraction functions, provided by a domain expert [25]. Thus, we can subsequently use highly fine-tuned spatial access methods (SAMs), to answer several types of queries, including the 'Query By Example' type (which translates to a range query); the 'all pairs' query (which translates to a spatial join [8]); the nearest-neighbor or best-match query, etc.However, designing feature extraction functions can be hard. It is relatively easier for a domain expert to assess the similarity/distance of two objects. Given only the distance information though, it is not obvious how to map objects into points.This is exactly the topic of this paper. We describe a fast algorithm to map objects into points in some k-dimensional space (k is user-defined), such that the dis-similarities are preserved. There are two benefits from this mapping: (a) efficient retrieval, in conjunction with a SAM, as discussed before and (b) visualization and data-mining: the objects can now be plotted as points in 2-d or 3-d space, revealing potential clusters, correlations among attributes and other regularities that data-mining is looking for.We introduce an older method from pattern recognition, namely, Multi-Dimensional Scaling (MDS) [51]; although unsuitable for indexing, we use it as yardstick for our method. Then, we propose a much faster algorithm to solve the problem in hand, while in addition it allows for indexing. Experiments on real and synthetic data indeed show that the proposed algorithm is significantly faster than MDS, (being linear, as opposed to quadratic, on the database size N), while it manages to preserve distances and the overall structure of the data-set.", "authors": ["Christos Faloutsos", "King-Ip Lin"], "related_topics": ["194222762", "110432227", "75165309"], "citation_count": "1566", "reference_count": "51", "references": ["2055043387", "2170120409", "2166559705", "2798909945", "1506285740", "1956559956", "3017143921", "2151135734", "1575476631", "1770825568"], "date": "1995"}, {"id": "2079441011", "title": "Process analysis, monitoring and diagnosis, using multivariate projection methods", "abstract": "Abstract Multivariate statistical methods for the analysis, monitoring and diagnosis of process operating performance are becoming more important because of the availability of on-line process computers which routinely collect measurements on large numbers of process variables. Traditional univariate control charts have been extended to multivariate quality control situations using the Hotelling T2 statistic. Recent approaches to multivariate statistical process control which utilize not only product quality data (Y), but also all of the available process variable data (X) are based on multivariate statistical projection methods (principal component analysis, (PCA), partial least squares, (PLS), multi-block PLS and multi-way PCA). An overview of these methods and their use in the statistical process control of multivariate continuous and batch processes is presented. Applications are provided on the analysis of historical data from the catalytic cracking section of a large petroleum refinery, on the monitoring and diagnosis of a continuous polymerization process and on the monitoring of an industrial batch process.", "authors": ["Theodora Kourti", "John F. MacGregor"], "related_topics": ["113644684", "199163554", "161584116"], "citation_count": "847", "reference_count": "34", "references": ["2148694408", "2152820192", "2158863190", "2089468765", "1978994389", "1966089218", "1990283595", "2141734529", "2015436473", "2005051528"], "date": "1995"}, {"id": "2133401839", "title": "Capacity Limits of Optical Fiber Networks", "abstract": "We describe a method to estimate the capacity limit of fiber-optic communication systems (or ?fiber channels?) based on information theory. This paper is divided into two parts. Part 1 reviews fundamental concepts of digital communications and information theory. We treat digitization and modulation followed by information theory for channels both without and with memory. We provide explicit relationships between the commonly used signal-to-noise ratio and the optical signal-to-noise ratio. We further evaluate the performance of modulation constellations such as quadrature-amplitude modulation, combinations of amplitude-shift keying and phase-shift keying, exotic constellations, and concentric rings for an additive white Gaussian noise channel using coherent detection. Part 2 is devoted specifically to the \"fiber channel.'' We review the physical phenomena present in transmission over optical fiber networks, including sources of noise, the need for optical filtering in optically-routed networks, and, most critically, the presence of fiber Kerr nonlinearity. We describe various transmission scenarios and impairment mitigation techniques, and define a fiber channel deemed to be the most relevant for communication over optically-routed networks. We proceed to evaluate a capacity limit estimate for this fiber channel using ring constellations. Several scenarios are considered, including uniform and optimized ring constellations, different fiber dispersion maps, and varying transmission distances. We further present evidences that point to the physical origin of the fiber capacity limitations and provide a comparison of recent record experiments with our capacity limit estimation.", "authors": ["R.-J. Essiambre", "G. Kramer", "P.J. Winzer", "G.J. Foschini", "B. Goebel"], "related_topics": ["97744766", "194232370", "32409245"], "citation_count": "2232", "reference_count": "200", "references": ["2610335499", "2798333393", "595252221", "1585641754", "3140968660", "2133475491", "1977733098", "1492221128", "2942228371", "2060807102"], "date": "2010"}, {"id": "2161633633", "title": "PLINK: A Tool Set for Whole-Genome Association and Population-Based Linkage Analyses", "abstract": "Whole-genome association studies (WGAS) bring new computational, as well as analytic, challenges to researchers. Many existing genetic-analysis tools are not designed to handle such large data sets in a convenient manner and do not necessarily exploit the new opportunities that whole-genome data bring. To address these issues, we developed PLINK, an open-source C/C++ WGAS tool set. With PLINK, large data sets comprising hundreds of thousands of markers genotyped for thousands of individuals can be rapidly manipulated and analyzed in their entirety. As well as providing tools to make the basic analytic steps computationally efficient, PLINK also supports some novel approaches to whole-genome data that take advantage of whole-genome coverage. We introduce PLINK and describe the five main domains of function: data management, summary statistics, population stratification, association analysis, and identity-by-descent estimation. In particular, we focus on the estimation and use of identity-by-state and identity-by-descent information in the context of population-based whole-genome studies. This information can be used to detect and correct for population stratification and to identify extended chromosomal segments that are shared identical by descent between very distantly related individuals. Analysis of the patterns of segmental sharing has the potential to map disease loci that contain multiple rare variants in a population-based linkage analysis.", "authors": ["Shaun Purcell", "", "Benjamin Neale", "", "Kathe Todd-Brown", "Lori Thomas", "Manuel A.R. Ferreira", "David Bender", "", "Julian Maller", "", "Pamela Sklar", "", "Paul I.W. de Bakker", "", "Mark J. Daly", "", "Pak C. Sham"], "related_topics": ["2908647359", "166976648", "31266012"], "citation_count": "23214", "reference_count": "43", "references": ["2110065044", "2098126593", "2162530578", "2157752701", "2076983043", "2048755332", "2313581450", "2042103448", "2066669827", "2008047653"], "date": "2007"}, {"id": "1977953443", "title": "Finding usability problems through heuristic evaluation", "abstract": "Usability specialists were better than non-specialists at performing heuristic evaluation, and \u201cdouble experts\u201d with specific expertise in the kind of interface being evaluated performed even better. Major usability problems have a higher probability than minor problems of being found in a heuristic evaluation, but more minor problems are found in absolute numbers. Usability heuristics relating to exits and user errors were more difficult to apply than the rest, and additional measures should be taken to find problems relating to these heuristics. Usability problems that relate to missing interface elements that ought to be introduced were more difficult to find by heuristic evaluation in interfaces implemented as paper prototypes but were as easy as other problems to find in running systems.", "authors": ["Jakob Nielsen"], "related_topics": ["3255780", "62993174", "23456302"], "citation_count": "1514", "reference_count": "17", "references": ["2342091124", "2162598207", "2109428365", "2027909523", "2155490532", "1550332727", "1972940641", "200023465", "2067099887", "1532472965"], "date": "1992"}, {"id": "2103430676", "title": "Semantic Integration of Verbal Information Into a Visual Memory.", "abstract": "A total of 1,242 subjects, in five experiments plus a pilot study, saw a series of slides depicting a single auto-pedestrian accident. The purpose of these experiments was to investigate how information supplied after an event influences a witness's memory for that event. Subjects were exposed to either consistent, misleading, or irrelevant information after the accident event. Misleading information produced less accurate responding on both a yes-no and a two-alternative forced-choice recognition test. Further, misleading information had a larger impact if introduced just prior to a final test rather than immediately after the initial event. The effects of misleading information cannot be accounted for by a simple demand-characteristics explanation. Overall, the results suggest that information to which a witness is exposed after an event, whether that information is consistent or misleading, is integrated into the witness's memory of the event.", "authors": ["Elizabeth F. Loftus", "David G. Miller", "Helen J. Burns"], "related_topics": ["35996082", "2780346924", "2779086471"], "citation_count": "2191", "reference_count": "10", "references": ["1989314580", "2016896363", "2141606903", "1442714200", "2035183219", "2068430037", "2045418753", "2475984269", "2049020839", "2151289144"], "date": "1977"}, {"id": "2145012779", "title": "Natural image statistics and efficient coding.", "abstract": "Natural images contain characteristic statistical regularities that set them apart from purely random images. Understanding what these regularities are can enable natural images to be coded more efficiently. In this paper, we describe some of the forms of structure that are contained in natural images, and we show how these are related to the response properties of neurons at early stages of the visual system. Many of the important forms of structure require higher-order (i.e. more than linear, pairwise) statistics to characterize, which makes models based on linear Hebbian learning, or principal components analysis, inappropriate for finding efficient codes for natural images. We suggest that a good objective for an efficient coding of natural scenes is to maximize the sparseness of the representation, and we show that a network that learns sparse codes of natural scenes succeeds in developing localized, oriented, bandpass receptive fields similar to those in the mammalian striate cortex.", "authors": ["B A Olshausen", "D J Field"], "related_topics": ["111437709", "179518139", "184898388"], "citation_count": "758", "reference_count": "15", "references": ["2108384452", "2180838288", "2167034998", "2120838001", "2122925692", "1914401667", "1993197592", "1971027050", "2117731089", "2135587681"], "date": "1996"}, {"id": "1981044874", "title": "Transmit beamforming for physical-layer multicasting", "abstract": "This paper considers the problem of downlink transmit beamforming for wireless transmission and downstream precoding for digital subscriber wireline transmission, in the context of common information broadcasting or multicasting applications wherein channel state information (CSI) is available at the transmitter. Unlike the usual \"blind\" isotropic broadcasting scenario, the availability of CSI allows transmit optimization. A minimum transmission power criterion is adopted, subject to prescribed minimum received signal-to-noise ratios (SNRs) at each of the intended receivers. A related max-min SNR \"fair\" problem formulation is also considered subject to a transmitted power constraint. It is proven that both problems are NP-hard; however, suitable reformulation allows the successful application of semidefinite relaxation (SDR) techniques. SDR yields an approximate solution plus a bound on the optimum value of the associated cost/reward. SDR is motivated from a Lagrangian duality perspective, and its performance is assessed via pertinent simulations for the case of Rayleigh fading wireless channels. We find that SDR typically yields solutions that are within 3-4 dB of the optimum, which is often good enough in practice. In several scenarios, SDR generates exact solutions that meet the associated bound on the optimum value. This is illustrated using measured very-high-bit-rate Digital Subscriber line (VDSL) channel data, and far-field beamforming for a uniform linear transmit antenna array.", "authors": ["N.D. Sidiropoulos", "T.N. Davidson", "Zhi-Quan Luo"], "related_topics": ["160562895", "148063708", "54197355"], "citation_count": "1200", "reference_count": "15", "references": ["2296319761", "2011039300", "1967073510", "2113168978", "2170898774", "1545861347", "1978666418", "2495457432", "2131086249", "2134376819"], "date": "2006"}, {"id": "2152520525", "title": "Stability of networked control systems", "abstract": "First, we review some previous work on networked control systems (NCSs) and offer some improvements. Then, we summarize the fundamental issues in NCSs and examine them with different underlying network-scheduling protocols. We present NCS models with network-induced delay and analyze their stability using stability regions and a hybrid systems technique. Following that, we discuss methods to compensate network-induced delay and present experimental results over a physical network. Then, we model NCSs with packet dropout and multiple-packet transmission as asynchronous dynamical systems and analyze their stability. Finally, we present our conclusions.", "authors": ["Wei Zhang", "M.S. Branicky", "S.M. Phillips"], "related_topics": ["1759631", "50897621", "79379906"], "citation_count": "4864", "reference_count": "19", "references": ["1981745143", "2099839128", "2128969277", "1801704802", "2170715240", "3013971696", "1513016807", "1589577058", "2056480661", "2151037467"], "date": "2001"}, {"id": "1996573126", "title": "VTrack: accurate, energy-aware road traffic delay estimation using mobile phones", "abstract": "Traffic delays and congestion are a major source of inefficiency, wasted fuel, and commuter frustration. Measuring and localizing these delays, and routing users around them, is an important step towards reducing the time people spend stuck in traffic. As others have noted, the proliferation of commodity smartphones that can provide location estimates using a variety of sensors---GPS, WiFi, and/or cellular triangulation---opens up the attractive possibility of using position samples from drivers' phones to monitor traffic delays at a fine spatiotemporal granularity. This paper presents VTrack, a system for travel time estimation using this sensor data that addresses two key challenges: energy consumption and sensor unreliability. While GPS provides highly accurate location estimates, it has several limitations: some phones don't have GPS at all, the GPS sensor doesn't work in \"urban canyons\" (tall buildings and tunnels) or when the phone is inside a pocket, and the GPS on many phones is power-hungry and drains the battery quickly. In these cases, VTrack can use alternative, less energy-hungry but noisier sensors like WiFi to estimate both a user's trajectory and travel time along the route. VTrack uses a hidden Markov model (HMM)-based map matching scheme and travel time estimation method that interpolates sparse data to identify the most probable road segments driven by the user and to attribute travel times to those segments. We present experimental results from real drive data and WiFi access point sightings gathered from a deployment on several cars. We show that VTrack can tolerate significant noise and outages in these location estimates, and still successfully identify delay-prone segments, and provide accurate enough delays for delay-aware routing algorithms. We also study the best sampling strategies for WiFi and GPS sensors for different energy cost regimes.", "authors": ["Arvind Thiagarajan", "Lenin Ravindranath", "Katrina LaCurts", "Samuel Madden", "Hari Balakrishnan", "Sivan Toledo", "Jakob Eriksson"], "related_topics": ["198613851", "2778559875", "60229501"], "citation_count": "1063", "reference_count": "19", "references": ["2159024459", "2056773559", "2144169341", "2170918595", "2127963147", "2096157747", "2162343230", "2141854027", "2126236329", "2045174117"], "date": "2009"}, {"id": "2101939036", "title": "Linearizability: a correctness condition for concurrent objects", "abstract": "A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable.", "authors": ["Maurice P. Herlihy", "Jeannette M. Wing"], "related_topics": ["20528329", "3701939", "203222032"], "citation_count": "3639", "reference_count": "43", "references": ["3144368627", "3146075203", "1991199257", "2054739713", "2132107743", "1542049623", "2166656159", "1603788080", "2086070079", "1964727056"], "date": "1990"}, {"id": "2001725958", "title": "The diploid genome sequence of an Asian individual.", "abstract": "Here we present the first diploid genome sequence of an Asian individual. The genome was sequenced to 36-fold average coverage using massively parallel sequencing technology. We aligned the short reads onto the NCBI human reference genome to 99.97% coverage, and guided by the reference genome, we used uniquely mapped reads to assemble a high-quality consensus sequence for 92% of the Asian individual's genome. We identified approximately 3 million single-nucleotide polymorphisms (SNPs) inside this region, of which 13.6% were not in the dbSNP database. Genotyping analysis showed that SNP identification had high accuracy and consistency, indicating the high sequence quality of this assembly. We also carried out heterozygote phasing and haplotype prediction against HapMap CHB and JPT haplotypes (Chinese and Japanese, respectively), sequence comparison with the two available individual genomes (J. D. Watson and J. C. Venter), and structural variation identification. These variations were considered for their potential biological impact. Our sequence data and analyses demonstrate the potential usefulness of next-generation sequencing technologies for personal genomics.", "authors": ["Jun Wang", "Wei Wang", "Ruiqiang Li", "", "Yingrui Li", "", "", "Geng Tian", "", "Laurie Goodman", "Wei Fan", "Junqing Zhang", "Jun Li", "Juanbin Zhang", "Yiran Guo", "", "Binxiao Feng", "Heng Li", "", "Yao Lu", "Xiaodong Fang", "Huiqing Liang", "Zhenglin Du", "Dong Li", "Yiqing Zhao", "", "Yujie Hu", "", "Zhenzhen Yang", "Hancheng Zheng", "Ines Hellmann", "Michael Inouye", "John Pool", "Xin Yi", "", "Jing Zhao", "Jinjie Duan", "Yan Zhou", "Junjie Qin", "", "Lijia Ma", "", "Guoqing Li", "Zhentao Yang", "Guojie Zhang", "", "Bin Yang", "Chang Yu", "Fang Liang", "", "Wenjie Li", "Shaochuan Li", "Dawei Li", "Peixiang Ni", "Jue Ruan", "", "Qibin Li", "", "Hongmei Zhu", "Dongyuan Liu", "Zhike Lu", "Ning Li", "", "Guangwu Guo", "", "Jianguo Zhang", "Jia Ye  +"], "related_topics": ["192953774", "89566754", "205270622"], "citation_count": "1107", "reference_count": "21", "references": ["2160969485", "2168909179", "2165460636", "2139760555", "2110755408", "2113649367", "2122732537", "2142642738", "2116753165", "2140869203"], "date": "2008"}, {"id": "1506281249", "title": "Pattern Classification (2nd ed.)", "abstract": "", "authors": ["Richard O. Duda", "Peter E. Hart", "David G. Stork"], "related_topics": ["41008148"], "citation_count": "5330", "reference_count": "13", "references": ["2752885492", "2798909945", "1669104078", "1655990431", "2752853835", "1496462336", "2751862591", "2796291475", "2577556340", "1570718080"], "date": "1998"}, {"id": "2136913207", "title": "Introduction to Econophysics: Correlations and Complexity in Finance", "abstract": "This book concerns the use of concepts from statistical physics in the description of financial systems. The authors illustrate the scaling concepts used in probability theory, critical phenomena, and fully developed turbulent fluids. These concepts are then applied to financial time series. The authors also present a stochastic model that displays several of the statistical properties observed in empirical data. Statistical physics concepts such as stochastic dynamics, short- and long-range correlations, self-similarity and scaling permit an understanding of the global behaviour of economic systems without first having to work out a detailed microscopic description of the system. Physicists will find the application of statistical physics concepts to economic systems interesting. Economists and workers in the financial world will find useful the presentation of empirical analysis methods and well-formulated theoretical tools that might help describe systems composed of a huge number of interacting subsystems.", "authors": ["Rosario N. Mantegna", "H. Eugene Stanley"], "related_topics": ["46224699", "29912722", "23925645"], "citation_count": "5335", "reference_count": "110", "references": ["1503295912", "2078206416", "1479863711", "2010997253", "1999996900", "2064978316", "1580561995", "2340149117", "2077791698", "2116988722"], "date": "1999"}, {"id": "2107790757", "title": "Shiftable multiscale transforms", "abstract": "One of the major drawbacks of orthogonal wavelet transforms is their lack of translation invariance: the content of wavelet subbands is unstable under translations of the input signal. Wavelet transforms are also unstable with respect to dilations of the input signal and, in two dimensions, rotations of the input signal. The authors formalize these problems by defining a type of translation invariance called shiftability. In the spatial domain, shiftability corresponds to a lack of aliasing; thus, the conditions under which the property holds are specified by the sampling theorem. Shiftability may also be applied in the context of other domains, particularly orientation and scale. Jointly shiftable transforms that are simultaneously shiftable in more than one domain are explored. Two examples of jointly shiftable transforms are designed and implemented: a 1-D transform that is jointly shiftable in position and scale, and a 2-D transform that is jointly shiftable in position and orientation. The usefulness of these image representations for scale-space analysis, stereo disparity measurement, and image enhancement is demonstrated. >", "authors": ["E.P. Simoncelli", "W.T. Freeman", "E.H. Adelson", "D.J. Heeger"], "related_topics": ["47432892", "2777451244", "196216189"], "citation_count": "1966", "reference_count": "47", "references": ["2170120409", "2132984323", "2098914003", "1996021349", "2103504761", "1991605728", "2118877769", "2109863423", "2166982406", "1627054999"], "date": "1992"}, {"id": "1983364832", "title": "3D Convolutional Neural Networks for Human Action Recognition", "abstract": "We consider the automated recognition of human actions in surveillance videos. Most current methods build classifiers based on complex handcrafted features computed from the raw inputs. Convolutional neural networks (CNNs) are a type of deep model that can act directly on the raw inputs. However, such models are currently limited to handling 2D inputs. In this paper, we develop a novel 3D CNN model for action recognition. This model extracts features from both the spatial and the temporal dimensions by performing 3D convolutions, thereby capturing the motion information encoded in multiple adjacent frames. The developed model generates multiple channels of information from the input frames, and the final feature representation combines information from all channels. To further boost the performance, we propose regularizing the outputs with high-level features and combining the predictions of a variety of different models. We apply the developed models to recognize human actions in the real-world environment of airport surveillance videos, and they achieve superior performance in comparison to baseline methods.", "authors": ["Shuiwang Ji", "Wei Xu", "Ming Yang", "Kai Yu"], "related_topics": ["108583219", "81363708", "50644808"], "citation_count": "9188", "reference_count": "59", "references": ["2151103935", "2136922672", "2310919327", "2100495367", "2162915993", "2072128103", "2546302380", "2912934387", "2117130368", "2130325614"], "date": "2012"}, {"id": "1987823709", "title": "Assessment of Color\u2010Measuring Instruments", "abstract": "The U.S. Army has undertaken a program to develop an instrumental method for assessing the acceptability of textiles for color difference from a standard. This article reports the results of the first phase of the program, an assessment of three commercial color-measuring instruments (Diano Match-Scan, Hunter D-54P-5, Macbeth MS-2000) for objective textile acceptability judgment. It is concluded that the three instruments are essentially equivalent in the precision and accuracy of the measurement of color and color difference using a wide variety of samples, at least over periods of up to seven weeks. All measures of repeatability lead to the conclusion that the uncertainties involved are well below the just-perceptible color difference. Levels of absolute accuracy achieved depend greatly on the details of operation, data treatment, and calibration, but are considered satisfactory for each of the instruments tested. With respect to certain other parameters, the performance of the instruments is less satisfactory. Rejection of the specular component differs significantly among the three, as does the selection of weights for tristimuus calculations. One instrument, as tested, exhibited significant sensitivity to weave orientation in textile samples. Finally, we find that the distributions of tristimulus values obtained with each of the instruments show large deviations from normality, severely limiting the significance of conventional statistical treatment of such data.", "authors": ["Fred W. Billmeyer", "Paula J. Alessi"], "related_topics": ["186991048", "154020017", "202799725"], "citation_count": "66", "reference_count": "23", "references": ["2325343629", "2072991569", "1990701202", "2118281922", "2138690710", "2024962637", "2052975780", "2142189009", "1969936609", "2002798393"], "date": "1981"}, {"id": "1965044325", "title": "Improving Consistency and Reducing Ambiguity in Stochastic Labeling: An Optimization Approach", "abstract": "We approach the problem of labeling a set of objects from a quantitative standpoint. We define a world model in terms of transition probabilities and propose a definition of a class of global criteria that combine both ambiguity and consistency. A projected gradient algorithm is developed to minimize the criterion. We show that the minimization procedure can be implemented in a highly parallel manner. Results are shown on several examples and comparisons are made with relaxation labeling techniques.", "authors": ["Olivier D. Faugeras", "Marc Berthod"], "related_topics": ["2780522230", "153258448", "2776232135"], "citation_count": "252", "reference_count": "11", "references": ["1979622972", "2136113379", "1530383550", "1736170383", "1990852520", "2143101939", "2012374219", "2066780173", "2053007711", "2002202571"], "date": "1981"}, {"id": "2099244020", "title": "Bilateral filtering for gray and color images", "abstract": "Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.", "authors": ["C. Tomasi", "R. Manduchi"], "related_topics": ["12043971", "159784718", "173752661"], "citation_count": "10324", "reference_count": "15", "references": ["2150134853", "1667165204", "2101248405", "2104763670", "2064347832", "2067681708", "2008014451", "1526351017", "2051826135", "1602550945"], "date": "1998"}, {"id": "2015391954", "title": "Essentials of psychological testing", "abstract": "I.BASIC CONCEPTS. 1.Who Uses Tests? And for What Purposes? 2.Varieties of Tests and Test Interpretations. 3.Administering Tests. 4.Scores and Score Conversions. 5.How to Judge Tests: Validation. 6.How to Judge Tests: Reliability and other Qualities. II.TESTS OF ABILITY. 7.General Ability: Appraisal Methods. 8.The Meanings of General Ability. 9.Influences on Intellectual Development. 10.Multiple Abilities and Their Role in Counseling. 11.Personnel Selection. III.MEASURES OF TYPICAL RESPONSE. 12.Interest Inventories. 13.General Problems in Studying Personality. 14.Personality Measurement through Self-Report. 15.Judgments and Systematic Observations. 16.Inferences from Performance.", "authors": ["Lee J. Cronbach"], "related_topics": ["163515075", "2776291627", "2778521920"], "citation_count": "6717", "reference_count": "0", "references": ["2030038103", "1746951143", "1125023678", "1655534105", "2100408980", "2001579773", "2063085086", "2067933440", "2163241745", "2018297215"], "date": "1983"}, {"id": "2077825289", "title": "Scholarly communication and the continuum of electronic publishing", "abstract": "Electronic publishing opportunities, manifested today in a variety of electronic journals and Web-based compendia, have captured the imagination of many scholars. These opportunities have also destabilized norms about the character of legitimate scholarly publishing in some fields. Unfortunately, much of the literature about scholarly e-publishing homogenizes the character of publishing. This article provides an analytical approach for evaluating disciplinary conventions and for proposing policies about scholarly e-publishing. We characterize three dimensions of scholarly publishing as a communicative practice\u2014publicity, access, and trustworthiness\u2014and examine several forms of paper and electronic publications in this framework. This analysis shows how the common claim that e-publishing \u201csubstantially expands access\u201d is oversimplified. It also indicates how peer reviewing (whether in paper or electronically) provides valuable functions for scholarly communication that are not effectively replaced by self-posting articles in electronic media.", "authors": ["Rob Kling", "Geoffrey McKim"], "related_topics": ["2777462167", "18599908", "117774814"], "citation_count": "208", "reference_count": "20", "references": ["2124431800", "43327620", "2173701363", "2030106179", "2087021579", "1552977625", "1508599645", "2137836165", "2007622462", "1541247549"], "date": "1999"}, {"id": "1587153270", "title": "Depth perception through motion", "abstract": "", "authors": ["Myron L. Braunstein"], "related_topics": ["52672216", "104114177", "31972630"], "citation_count": "489", "reference_count": "0", "references": ["1827848544", "1989701469", "2162550962", "2050830699", "2171322730", "2010450636", "2142581613", "2017392634", "2149365661", "2130368011"], "date": "1975"}, {"id": "2119539043", "title": "Particle filters for positioning, navigation, and tracking", "abstract": "A framework for positioning, navigation, and tracking problems using particle filters (sequential Monte Carlo methods) is developed. It consists of a class of motion models and a general nonlinear measurement equation in position. A general algorithm is presented, which is parsimonious with the particle dimension. It is based on marginalization, enabling a Kalman filter to estimate all position derivatives, and the particle filter becomes low dimensional. This is of utmost importance for high-performance real-time applications. Automotive and airborne applications illustrate numerically the advantage over classical Kalman filter-based algorithms. Here, the use of nonlinear models and non-Gaussian noise is the main explanation for the improvement in accuracy. More specifically, we describe how the technique of map matching is used to match an aircraft's elevation profile to a digital elevation map and a car's horizontal driven path to a street map. In both cases, real-time implementations are available, and tests have shown that the accuracy in both cases is comparable with satellite navigation (as GPS) but with higher integrity. Based on simulations, we also argue how the particle filter can be used for positioning based on cellular phone measurements, for integrated navigation in aircraft, and for target tracking in aircraft and cars. Finally, the particle filter enables a promising solution to the combined task of navigation and tracking, with possible application to airborne hunting and collision avoidance systems in cars.", "authors": ["F. Gustafsson", "F. Gunnarsson", "N. Bergman", "U. Forssell", "J. Jansson", "R. Karlsson", "P.-J. Nordlund"], "related_topics": ["206833254", "106480740", "2778559875"], "citation_count": "2215", "reference_count": "43", "references": ["1483307070", "2130416410", "1997063559", "2126736494", "2098613108", "1568122762", "2571050459", "2131598171", "10518661", "2128519721"], "date": "2002"}, {"id": "2139621418", "title": "Learning Accurate, Compact, and Interpretable Tree Annotation", "abstract": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank. Starting with a simple X-bar grammar, we learn a new grammar whose nonterminals are subsymbols of the original nonterminals. In contrast with previous work, we are able to split various terminals to different degrees, as appropriate to the actual complexity in the data. Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation. On the other hand, our grammars are much more compact and substantially more accurate than previous work on automatic annotation. Despite its simplicity, our best grammar achieves an F1 of 90.2% on the Penn Treebank, higher than fully lexicalized systems.", "authors": ["Slav Petrov", "Leon Barrett", "Romain Thibaux", "Dan Klein"], "related_topics": ["9432014", "206134035", "2777875368"], "citation_count": "997", "reference_count": "17", "references": ["2097606805", "1535015163", "2092654472", "2125712079", "2130337399", "1551104980", "2161204834", "2152561660", "2439178139", "2170716495"], "date": "2006"}, {"id": "3045462440", "title": "TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages", "abstract": "Confidently making progress on multilingual modeling requires challenging, trustworthy evaluations. We present TyDi QA\u2014a question answering dataset covering 11 typologically diverse languages with ...", "authors": ["Jonathan H. Clark", "Eunsol Choi", "Michael Collins", "Dan Garrette", "Tom Kwiatkowski", "Vitaly Nikolaev", "Jennimaria Palomaki"], "related_topics": ["44291984", "2776636917", "137955351"], "citation_count": "71", "reference_count": "69", "references": ["2963341956", "2963748441", "1840435438", "2963846996", "2963339397", "2889787757", "2963323070", "2171278097", "2579343286", "2251818205"], "date": "2020"}, {"id": "1850527962", "title": "An empirical evaluation of bagging and boosting", "abstract": "An ensemble consists of a set of independently trained classifiers (such as neural networks or decision trees) whose predictions are combined when classifying novel instances. Previous research has shown that an ensemble as a whole is often more accurate than any of the single classifiers in the ensemble. Bagging (Breiman 1996a) and Boosting (Freund & Schapire 1996) are two relatively new but popular methods for producing ensembles. In this paper we evaluate these methods using both neural networks and decision trees as our classification algorithms. Our results clearly show two important facts. The first is that even though Bagging almost always produces a better classifier than any of its individual component classifiers and is relatively impervious to overfitting, it does not generalize any better than a baseline neural-network ensemble method. The second is that Boosting is a powerful technique that can usually produce better ensembles than Bagging; however, it is more susceptible to noise and can quickly overfit a data set.", "authors": ["Richard Maclin", "David Opitz"], "related_topics": ["70153297", "169258074", "162040801"], "citation_count": "353", "reference_count": "17", "references": ["1995945562", "2912934387", "2112076978", "1966280301", "28412257", "2135293965", "2128073546", "2914369697", "2104364170", "1993387039"], "date": "1997"}, {"id": "2077791698", "title": "The Pricing of Options and Corporate Liabilities", "abstract": "If options are correctly priced in the market, it should not be possible to make sure profits by creating portfolios of long and short positions in options and their underlying stocks. Using this principle, a theoretical valuation formula for options is derived. Since almost all corporate liabilities can be viewed as combinations of options, the formula and the analysis that led to it are also applicable to corporate liabilities such as common stock, corporate bonds, and warrants. In particular, the formula can be used to derive the discount that should be applied to a corporate bond because of the possibility of default.", "authors": ["Fischer Black", "Myron S Scholes"], "related_topics": ["143969707", "194483076", "2778829522"], "citation_count": "42652", "reference_count": "16", "references": ["1503295912", "2029056003", "2083148578", "3094026675", "2124597406", "2052635514", "1990986169", "2123343520", "1971432209", "1591559241"], "date": "1973"}, {"id": "135942652", "title": "Engineering in K-12 Education: Understanding the Status and Improving the Prospects.", "abstract": "Engineering education in K-12 classrooms is a small but growing phenomenon that may have implications for engineering and also for the other STEM subjects--science, technology, and mathematics. Specifically, engineering education may improve student learning and achievement in science and mathematics, increase awareness of engineering and the work of engineers, boost youth interest in pursuing engineering as a career, and increase the technological literacy of all students. The teaching of STEM subjects in U.S. schools must be improved in order to retain U.S. competitiveness in the global economy and to develop a workforce with the knowledge and skills to address technical and technological issues. Engineering in K-12 Education reviews the scope and impact of engineering education today and makes several recommendations to address curriculum, policy, and funding issues. The book also analyzes a number of K-12 engineering curricula in depth and discusses what is known from the cognitive sciences about how children learn engineering-related concepts and skills. Engineering in K-12 Education will serve as a reference for science, technology, engineering, and math educators, policy makers, employers, and others concerned about the development of the country's technical workforce. The book will also prove useful to educational researchers, cognitive scientists, advocates for greater public understanding of engineering, and those working to boost technological and scientific literacy.", "authors": ["Linda Katehi", "Greg Pearson", "Michael Feder"], "related_topics": ["5041995", "87390875", "44877443"], "citation_count": "535", "reference_count": "136", "references": ["1562208008", "3134853862", "2423609147", "2153000380", "1927360298", "1938604699", "1574046838", "1883291571", "359704955", "3081949511"], "date": "2008"}, {"id": "1549739843", "title": "3D Model Acquisition from Extended Image Sequences", "abstract": "A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models. The method includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet; and a novel tracking algorithm in which corners and line segments are matched over image triplets in an integrated framework. The matching techniques are both robust (detecting and discarding mismatches) and fully automatic.", "authors": ["Paul A. Beardsley", "Philip H. S. Torr", "Andrew Zisserman"], "related_topics": ["133090833", "126422989", "147946207"], "citation_count": "633", "reference_count": "22", "references": ["2145023731", "2111308925", "2085261163", "2129249398", "2138835141", "1482517735", "1530454533", "1602748186", "1630235098", "1517576992"], "date": "1996"}, {"id": "1512018163", "title": "A METHOD FOR SYNTHESIS OF FACTOR ANALYSIS STUDIES", "abstract": "", "authors": ["Ledyard R. Tucker"], "related_topics": ["15744967", "2777880408", "70721500"], "citation_count": "969", "reference_count": "0", "references": ["2942810103", "1981222267", "2035128319", "2157066690", "2100992488", "2159230122", "2140006621", "2505361583", "1971467540", "2037401035"], "date": "1951"}, {"id": "2146842127", "title": "De-noising by soft-thresholding", "abstract": "Donoho and Johnstone (1994) proposed a method for reconstructing an unknown function f on [0,1] from noisy data d/sub i/=f(t/sub i/)+/spl sigma/z/sub i/, i=0, ..., n-1,t/sub i/=i/n, where the z/sub i/ are independent and identically distributed standard Gaussian random variables. The reconstruction f/spl circ/*/sub n/ is defined in the wavelet domain by translating all the empirical wavelet coefficients of d toward 0 by an amount /spl sigma//spl middot//spl radic/(2log (n)/n). The authors prove two results about this type of estimator. [Smooth]: with high probability f/spl circ/*/sub n/ is at least as smooth as f, in any of a wide variety of smoothness measures. [Adapt]: the estimator comes nearly as close in mean square to f as any measurable estimator can come, uniformly over balls in each of two broad scales of smoothness classes. These two properties are unprecedented in several ways. The present proof of these results develops new facts about abstract statistical inference and its connection with an optimal recovery model. >", "authors": ["D.L. Donoho"], "related_topics": ["141513077", "185429906", "2778500080"], "citation_count": "13464", "reference_count": "32", "references": ["2098914003", "2079724595", "2152328854", "191129667", "3005363104", "2107790757", "2109246257", "2050880896", "2033484654", "654435104"], "date": "1995"}, {"id": "2164278908", "title": "Distributed Optimization and Statistical Learning Via the Alternating Direction Method of Multipliers", "abstract": "Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas\u2013Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for l1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.", "authors": ["Stephen Boyd", "Neal Parikh", "Eric Chu", "Borja Peleato", "Jonathan Eckstein"], "related_topics": ["115903097", "2779915298", "157972887"], "citation_count": "15215", "reference_count": "175", "references": ["2296319761", "2173213060", "2156909104", "2296616510", "2145096794", "3029645440", "1554944419", "2100556411", "2129638195", "2135046866"], "date": "2011"}, {"id": "2140177165", "title": "A trie compaction algorithm for a large set of keys", "abstract": "A trie structure is frequently used for various applications, such as natural language dictionaries, database systems and compilers. However, the total number of states of a trie (and transitions between them) becomes large, so that the space cost may not be acceptable for a huge key set. In order to resolve this disadvantage, this paper presents a new scheme, called a \"two-trie\", that enables us to perform efficient retrievals, insertions and deletions for the key sets. The essential idea is to construct two tries for both front and rear compressions of keys, which is similar to a DAWG (directed acyclic word-graph). The approach differs from a DAWG in that the two-trie approach presented can uniquely determine information corresponding to keys while a DAWG cannot. For an efficient implementation of the two-trie, two types of data structures are introduced. Theoretical and experimental observations show that the method presented is more practical than existing ones considering the use of dynamic key sets, information storage of keys and compression of transitions.", "authors": ["J. Aoe", "K. Morimoto", "M. Shishibori", "Ki-Hong Park"], "related_topics": ["190290938", "177264268", "74197172"], "citation_count": "76", "reference_count": "27", "references": ["1491178396", "2753176400", "2099964107", "1600795850", "2110529160", "2165621523", "2087966340", "2051049045", "1976776761", "2088955004"], "date": "1996"}, {"id": "2902652978", "title": "Dimensionality reduction for visualizing single-cell data using UMAP.", "abstract": "Advances in single-cell technologies have enabled high-resolution dissection of tissue composition. Several tools for dimensionality reduction are available to analyze the large number of parameters generated in single-cell studies. Recently, a nonlinear dimensionality-reduction technique, uniform manifold approximation and projection (UMAP), was developed for the analysis of any type of high-dimensional data. Here we apply it to biological data, using three well-characterized mass cytometry and single-cell RNA sequencing datasets. Comparing the performance of UMAP with five other tools, we find that UMAP provides the fastest run times, highest reproducibility and the most meaningful organization of cell clusters. The work highlights the use of UMAP for improved visualization and interpretation of single-cell data.", "authors": ["Etienne Becht", "Leland McInnes", "John Healy", "Charles-Antoine Dutertre", "Immanuel W H Kwok", "Lai Guan Ng", "Florent Ginhoux", "Evan W Newell", ""], "related_topics": ["70518039", "201797286", "36464697"], "citation_count": "1170", "reference_count": "21", "references": ["2187089797", "2001141328", "2794480084", "2786672974", "1875842236", "2889326414", "1982729887", "2800392236", "1631320694", "2788348358"], "date": "2018"}, {"id": "2097606805", "title": "Accurate Unlexicalized Parsing", "abstract": "We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize.", "authors": ["Dan Klein", "Christopher D. Manning"], "related_topics": ["2777875368", "186644900", "206134035"], "citation_count": "3795", "reference_count": "18", "references": ["1535015163", "2092654472", "2110882317", "1567570606", "2153439141", "1551104980", "2155693943", "2161204834", "1859173823", "2170716495"], "date": "2003"}, {"id": "2520160253", "title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC while being simpler. We show competitive results in word error rate on the Librispeech corpus with MFCC features, and promising results from raw waveform.", "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "related_topics": ["155635449", "40969351", "151989614"], "citation_count": "247", "reference_count": "24", "references": ["2160815625", "2143612262", "2147880316", "1993882792", "2127141656", "1494198834", "2193413348", "1922655562", "2402146185", "2963211739"], "date": "2016"}, {"id": "2095739681", "title": "From machine learning to machine reasoning", "abstract": "A plausible definition of \"reasoning\" could be \"algebraically manipulating previously acquired knowledge in order to answer a new question\". This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated \"all-purpose\" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up.", "authors": ["L\u00e9on Bottou"], "related_topics": ["2776214188", "197963276", "11866591"], "citation_count": "264", "reference_count": "53", "references": ["2156909104", "2136922672", "2310919327", "2158899491", "2162915993", "2110764733", "2110798204", "2143891888", "1423339008", "2134557905"], "date": "2014"}, {"id": "2073252511", "title": "Analysis of Blockage Effects on Urban Cellular Networks", "abstract": "Large-scale blockages such as buildings affect the performance of urban cellular networks, especially at higher frequencies. Unfortunately, such blockage effects are either neglected or characterized by oversimplified models in the analysis of cellular networks. Leveraging concepts from random shape theory, this paper proposes a mathematical framework to model random blockages and analyze their impact on cellular network performance. Random buildings are modeled as a process of rectangles with random sizes and orientations whose centers form a Poisson point process on the plane. The distribution of the number of blockages in a link is proven to be a Poisson random variable with parameter dependent on the length of the link. Our analysis shows that the probability that a link is not intersected by any blockages decays exponentially with the link length. A path loss model that incorporates the blockage effects is also proposed, which matches experimental trends observed in prior work. The model is applied to analyze the performance of cellular networks in urban areas with the presence of buildings, in terms of connectivity, coverage probability, and average rate. Our results show that the base station density should scale superlinearly with the blockage density to maintain the network connectivity. Our analyses also show that while buildings may block the desired signal, they may still have a positive impact on the SIR coverage probability and achievable rate since they can block significantly more interference.", "authors": ["Tianyang Bai", "Rahul Vaze", "Robert W. Heath"], "related_topics": ["16757284", "122123141", "31243852"], "citation_count": "532", "reference_count": "28", "references": ["2610335499", "2150166076", "2095843437", "595252221", "2149170915", "1991567646", "2145873277", "2164741953", "2101121986", "2118166339"], "date": "2014"}, {"id": "2037430361", "title": "Matrix Analysis for Statistics", "abstract": "Preface. 1. A Review of Elementary Matrix Algebra. 2. Vector Spaces. 3. Eigenvalues and Eigenvectors. 4. Matrix Factorizations and Martrix Norms. 5. Generalized Inverses. 6. Systems of Linear Equations. 7. Partitioned Matrices. 8. Special Matrices and Matrix Operations. 9. Matrix Derivatives and Related Topics. 10. Some Special Topics Related to Quadratic Forms. References. Index.", "authors": ["James R. Schott"], "related_topics": ["137127113", "85817219", "62555958"], "citation_count": "1111", "reference_count": "0", "references": ["1579579143", "640156484", "2171963266", "1986326495", "2896388162", "2126432428", "2156782020", "2122666877", "2100107646", "1990885553"], "date": "2005"}, {"id": "2102182691", "title": "The Design and Implementation of FFTW3", "abstract": "FFTW is an implementation of the discrete Fourier transform (DFT) that adapts to the hardware in order to maximize performance. This paper shows that such an approach can yield an implementation that is competitive with hand-optimized libraries, and describes the software structure that makes our current FFTW3 version flexible and adaptive. We further discuss a new algorithm for real-data DFTs of prime size, a new way of implementing DFTs by means of machine-specific single-instruction, multiple-data (SIMD) instructions, and how a special-purpose compiler can derive optimized implementations of the discrete cosine and sine transforms automatically from a DFT algorithm.", "authors": ["M. Frigo", "S.G. Johnson"], "related_topics": ["2221639", "75172450", "21809047"], "citation_count": "5470", "reference_count": "64", "references": ["3145128584", "2752885492", "2432517183", "3145042860", "2096070062", "1916685473", "2136952590", "123426918", "2135653967", "2052196304"], "date": "2005"}, {"id": "2116148865", "title": "Greed is good: algorithmic results for sparse approximation", "abstract": "This article presents new results on using a greedy algorithm, orthogonal matching pursuit (OMP), to solve the sparse approximation problem over redundant dictionaries. It provides a sufficient condition under which both OMP and Donoho's basis pursuit (BP) paradigm can recover the optimal representation of an exactly sparse signal. It leverages this theory to show that both OMP and BP succeed for every sparse input signal from a wide class of dictionaries. These quasi-incoherent dictionaries offer a natural generalization of incoherent dictionaries, and the cumulative coherence function is introduced to quantify the level of incoherence. This analysis unifies all the recent results on BP and extends them to OMP. Furthermore, the paper develops a sufficient condition under which OMP can identify atoms from an optimal approximation of a nonsparse signal. From there, it argues that OMP is an approximation algorithm for the sparse problem over a quasi-incoherent dictionary. That is, for every input signal, OMP calculates a sparse approximant whose error is only a small factor worse than the minimal error that can be attained with the same number of terms.", "authors": ["J.A. Tropp"], "related_topics": ["124066611", "156872377", "99217422"], "citation_count": "4030", "reference_count": "30", "references": ["2078204800", "2610857016", "2099641086", "2151693816", "2154332973", "2136235822", "2156447271", "391578156", "1605417594", "2167839759"], "date": "2004"}, {"id": "2081797984", "title": "The impact of influenza epidemics on mortality: introducing a severity index.", "abstract": "Objectives The purpose of this study was to assess the impact of recent influenza epidemics on mortality in the United States and to develop an index for comparing the severity of individual epidemics. Methods A cyclical regression model was applied to weekly national vital statistics from 1972 through 1992 to estimate excesses in pneumonia and influenza mortality and all-cause mortality for each influenza season. Each season was categorized on the basis of increments of 2000 pneumonia and influenza excess deaths, and each of these severity categories was correlated with a range of all-cause excess mortality. Results Each of the 20 influenza seasons studied was associated with an average of 5600 pneumonia and influenza excess deaths (range, 0-11,800) and 21,300 all-cause excess deaths (range, 0-47,200). Most influenza A(H3N2) seasons fell into severity categories 4 to 6 (23,000-45,000 all-cause excess deaths), whereas most A(H1N1) and B seasons were ranked in categories 1 to 3 (0-23,000 such deaths). Conclusions From 1972 through 1992, influenza epidemics accounted for a total of 426,000 deaths in the United States, many times more than those associated with recent pandemics. The influenza epidemic severity index was useful for categorizing severity and provided improved seasonal estimates of the total number of influenza-related deaths.", "authors": ["L Simonsen", "M J Clarke", "G D Williamson", "D F Stroup", "N H Arden", "L B Schonberger"], "related_topics": ["2777546802", "2908647359", "89623803"], "citation_count": "748", "reference_count": "13", "references": ["2094615755", "1986797238", "1920907940", "2290494549", "2140241083", "2035672404", "2087798167", "2257675219", "2163448023", "1598756928"], "date": "1997"}, {"id": "2128672031", "title": "A Roadmap of Agent Research and Development", "abstract": "This paper provides an overview of research and development activities in the field of autonomous agents and multi-agent systems. It aims to identify key concepts and applications, and to indicate how they relate to one-another. Some historical context to the field of agent-based computing is given, and contemporary research directions are presented. Finally, a range of open issues and future challenges are highlighted.", "authors": ["Nicholas R. Jennings", "Katia Sycara", "Michael Wooldridge"], "related_topics": ["13687954", "74072328", "41550386"], "citation_count": "3728", "reference_count": "142", "references": ["2122410182", "2137079713", "2124344619", "2528268528", "175500210", "2340966270", "2106172458", "2096178388", "2162077280", "2088563966"], "date": "1997"}, {"id": "3123521572", "title": "Should we build more large dams? The actual costs of hydropower megaproject development \u2606", "abstract": "A brisk building boom of hydropower mega-dams is underway from China to Brazil. Whether benefits of new dams will outweigh costs remains unresolved despite contentious debates. We investigate this question with the \u201coutside view\u201d or \u201creference class forecasting\u201d based on literature on decision-making under uncertainty in psychology. We find overwhelming evidence that budgets are systematically biased below actual costs of large hydropower dams\u2014excluding inflation, substantial debt servicing, environmental, and social costs. Using the largest and most reliable reference data of its kind and multilevel statistical techniques applied to large dams for the first time, we were successful in fitting parsimonious models to predict cost and schedule overruns. The outside view suggests that in most countries large hydropower dams will be too costly in absolute terms and take too long to build to deliver a positive risk-adjusted return unless suitable risk management measures outlined in this paper can be affordably provided. Policymakers, particularly in developing countries, are advised to prefer agile energy alternatives that can be built over shorter time horizons to energy megaprojects.", "authors": ["Atif Ansar", "Bent Flyvbjerg", "Alexander Budzier", "Daniel Lunn"], "related_topics": ["40675005", "2777875442", "2777212580"], "citation_count": "961", "reference_count": "53", "references": ["2752099845", "1981457167", "2133469585", "1574089532", "1986721142", "2008942529", "3011865677", "3123664731", "158727920", "2082246284"], "date": "2014"}, {"id": "2112132489", "title": "Aligning Multiple Genomic Sequences With the Threaded Blockset Aligner", "abstract": "We define a \"threaded blockset,\" which is a novel generalization of the classic notion of a multiple alignment. A new computer program called TBA (for \"threaded blockset aligner\") builds a threaded blockset under the assumption that all matching segments occur in the same order and orientation in the given sequences; inversions and duplications are not addressed. TBA is designed to be appropriate for aligning many, but by no means all, megabase-sized regions of multiple mammalian genomes. The output of TBA can be projected onto any genome chosen as a reference, thus guaranteeing that different projections present consistent predictions of which genomic positions are orthologous. This capability is illustrated using a new visualization tool to view TBA-generated alignments of vertebrate Hox clusters from both the mammalian and fish perspectives. Experimental evaluation of alignment quality, using a program that simulates evolutionary change in genomic sequences, indicates that TBA is more accurate than earlier programs. To perform the dynamic-programming alignment step, TBA runs a stand-alone program called MULTIZ, which can be used to align highly rearranged or incompletely sequenced genomes. We describe our use of MULTIZ to produce the whole-genome multiple alignments at the Santa Cruz Genome Browser.", "authors": ["Mathieu Blanchette", "W. James Kent", "Cathy Riemer", "Laura Elnitski", "Arian F.A. Smit", "Krishna M. Roskin", "Robert Baertsch", "Kate Rosenbloom", "Hiram Clawson", "Eric D. Green", "David Haussler", "Webb Miller"], "related_topics": ["88031987", "2781148417", "141231307"], "citation_count": "2827", "reference_count": "28", "references": ["2106882534", "2168909179", "2165460636", "2128016314", "2151464048", "2097040991", "2057998009", "1994458586", "2129873761", "2155237411"], "date": "2004"}, {"id": "2130401121", "title": "Generalization of an Inequality by Talagrand and Links with the Logarithmic Sobolev Inequality", "abstract": "Abstract We show that transport inequalities, similar to the one derived by M. Talagrand (1996, Geom. Funct. Anal. 6 , 587\u2013600) for the Gaussian measure, are implied by logarithmic Sobolev inequalities. Conversely, Talagrand's inequality implies a logarithmic Sobolev inequality if the density of the measure is approximately log-concave, in a precise sense. All constants are independent of the dimension and optimal in certain cases. The proofs are based on partial differential equations and an interpolation inequality involving the Wasserstein distance, the entropy functional, and the Fisher information.", "authors": ["F. Otto", "C. Villani"], "related_topics": ["185644265", "2777675177", "206399364"], "citation_count": "1247", "reference_count": "28", "references": ["1593038947", "2054723044", "2105146991", "2071048859", "2127674094", "2132883347", "583356579", "2045535845", "2077070574", "88155604"], "date": "2000"}, {"id": "2138019504", "title": "Model selection and estimation in regression with grouped variables", "abstract": "Summary. We consider the problem of selecting grouped variables (factors) for accurate prediction in regression. Such a problem arises naturally in many practical situations with the multifactor analysis-of-variance problem as the most important and well-known example. Instead of selecting factors by stepwise backward elimination, we focus on the accuracy of estimation and consider extensions of the lasso, the LARS algorithm and the non-negative garrotte for factor selection. The lasso, the LARS algorithm and the non-negative garrotte are recently proposed regression methods that can be used to select individual variables. We study and propose efficient algorithms for the extensions of these methods for factor selection and show that these extensions give superior performance to the traditional stepwise backward elimination method in factor selection problems. We study the similarities and the differences between these methods. Simulations and real examples are used to illustrate the methods.", "authors": ["Ming Yuan", "Yi Lin"], "related_topics": ["2778060275", "203868755", "93959086"], "citation_count": "7072", "reference_count": "16", "references": ["2135046866", "1973948212", "2063978378", "2074682976", "2007069447", "2070094080", "3105120000", "2102760656", "2080726496", "2084089095"], "date": "2006"}, {"id": "2478175895", "title": "A truth maintenance system", "abstract": "Abstract : To choose their actions, reasoning programs must be able to make assumptions and subsequently revise their beliefs when discoveries contradict these assumtions. The Truth Maintenance System (TMS) is a problem solver subsystem for performing these functions by recording and maintaining the reasons for program beliefs. Such recorded reasons are useful in constructing explanations for program actions and in guiding the course of action of a problem solver. This paper describes (1) the representations and structure of the TMS, (2) the mechanisms used to revise the current set of beliefs, (3) how dependency-directed backtracking changes the current set of assumptions, (4) techniques for summarizing explanations of beliefs, (5) how to organize problem solvers into 'dialectically arguing' modules, (6) how to revise models of the belief systems of others, and (7) methods for embedding control structures in patterns of assumptions. We stress the need of problem solvers to choose between alternate systems of beliefs, and outline a mechanism by which a problem solver can employ rules guiding choices of what to believe, what to want, and what to do. (Author)", "authors": ["Jon Doyle"], "related_topics": ["151878182", "165120375", "191617201"], "citation_count": "2787", "reference_count": "47", "references": ["2121773050", "179611734", "1996347293", "2038118137", "2161531345", "1533070959", "1545815294", "1494027264", "1989483184", "1485983381"], "date": "1987"}, {"id": "2035159691", "title": "Neptune: a hypertext system for CAD applications", "abstract": "Even though many of the essential notions of hypertext were first contained in the description of a \u201cmemex,\u201d written by Vannevar Bush in 1945 [Bus45], there are today only a few scattered implementations of hypertext, let alone any serious use of it in a CAD environment. In what follows, we describe what hypertext is all about. We describe a prototype hypertext system, named Neptune, that we have built. We show how it is useful, especially its broad applicability to CAD.", "authors": ["Norman Delisle", "Mayer Schwartz"], "related_topics": ["2775884304", "162215914", "136764020"], "citation_count": "335", "reference_count": "17", "references": ["1587166076", "2087311398", "2025692333", "1688664186", "2019035718", "2341024331", "2044710750", "2023062025", "2200839525", "2059252897"], "date": "1986"}, {"id": "2062985118", "title": "Complex analytic dynamics on the Riemann sphere", "abstract": "Dichotomie dynamique de Fatou et Julia. Points periodiques. Consequences du theoreme de Montel. L'ensemble de Julia est la fermeture de l'ensemble des points periodiques repulseurs. Resultats classiques sur l'ensemble de Fatou. Classification de Sullivan de l'ensemble de Fatou. Une condition pour le developpement sur l'ensemble de Julia. La dynamique des polynomes. L'ensemble de Mandelbrot et le travail de Douady et Hubbard. Le theoreme d'application de Riemann mesurable et la dynamique analytique", "authors": ["Paul Blanchard"], "related_topics": ["29877031", "154483964", "95677049"], "citation_count": "711", "reference_count": "49", "references": ["2078206416", "1561974326", "1603340857", "2798922842", "1573241742", "1515452785", "2078755009", "1524565983", "2099572565", "184286686"], "date": "1984"}, {"id": "2900790966", "title": "Appraisal considered as a process of multilevel sequential checking.", "abstract": "", "authors": ["Klaus R. Scherer"], "related_topics": ["143299363", "4279774", "15744967"], "citation_count": "2402", "reference_count": "0", "references": ["2102998034", "2029334490", "2169365000", "2105931454", "1594610956", "2170298027", "2049423401", "2072206615", "2156848952", "2102639289"], "date": "2000"}, {"id": "2138290169", "title": "Identification of Causal Effects Using Instrumental Variables", "abstract": "Abstract We outline a framework for causal inference in settings where assignment to a binary treatment is ignorable, but compliance with the assignment is not perfect so that the receipt of treatment is nonignorable. To address the problems associated with comparing subjects by the ignorable assignment\u2014an \u201cintention-to-treat analysis\u201d\u2014we make use of instrumental variables, which have long been used by economists in the context of regression models with constant treatment effects. We show that the instrumental variables (IV) estimand can be embedded within the Rubin Causal Model (RCM) and that under some simple and easily interpretable assumptions, the IV estimand is the average causal effect for a subgroup of units, the compliers. Without these assumptions, the IV estimand is simply the ratio of intention-to-treat causal estimands with no interpretation as an average causal effect. The advantages of embedding the IV approach in the RCM are that it clarifies the nature of critical assumptions needed for a...", "authors": ["Joshua D. Angrist", "Guido W. Imbens", "Donald B. Rubin"], "related_topics": ["2776265769", "158600405", "64167355"], "citation_count": "7171", "reference_count": "51", "references": ["2098910318", "2138290169", "3121556564", "1978108654", "1989535774", "3122892498", "3122542817", "1967993709", "3140498024", "2590957573"], "date": "1996"}, {"id": "2138546372", "title": "Do the Asian drivers undermine export-oriented industrialization in SSA?", "abstract": "Summary An increase in outward orientation in general, and in export-oriented manufacturing in particular is widely indicated as a suitable developmental path for SSA. The logic for this is drawn both from the demonstration effect of China and the earlier generation of Asian NICs, and from theory. However, the entry of China (and to a lesser extent India) into the global economy as a significant exporter of manufactures poses severe problems for export-oriented growth in SSA. This can be seen from SSA\u2019s recent experience in the clothing and textile sectors, often considered to be the first step in export-oriented manufacturing growth. Without sustained trade preferences over Asian producers, SSA\u2019s clothing and textile industry will be largely excluded from global markets and face significant threats in its domestic market. This has generalizable implications for other sectors, and for other sets of low income producers.", "authors": ["Raphael Kaplinsky", "Mike Morris"], "related_topics": ["2776099877", "30455989", "193468729"], "citation_count": "243", "reference_count": "24", "references": ["3121398446", "2125918728", "1915384043", "1576605329", "2097790641", "1879296691", "1978413276", "2133733224", "2803419216", "2100600289"], "date": "2008"}, {"id": "1498502445", "title": "Artificial Intelligence: Foundations of Computational Agents", "abstract": "Recent decades have witnessed the emergence of artificial intelligence as a serious science and engineering discipline. Artificial Intelligence: Foundations of Computational Agents is a textbook aimed at junior to senior undergraduate students and first-year graduate students. It presents artificial intelligence (AI) using a coherent framework to study the design of intelligent computational agents. By showing how basic approaches fit into a multidimensional design space, readers can learn the fundamentals without losing sight of the bigger picture. The book balances theory and experiment, showing how to link them intimately together, and develops the science of AI together with its engineering applications. Although structured as a textbook, the book's straightforward, self-contained style will also appeal to a wide audience of professionals, researchers, and independent learners. AI is a rapidly developing field: this book encapsulates the latest results without being exhaustive and encyclopedic. It teaches the main principles and tools that will allow readers to explore and learn on their own. The text is supported by an online learning environment, AIspace, http://aispace.org, so that students can experiment with the main AI algorithms plus problems, animations, lecture slides, and a knowledge representation system, AIlog, for experimentation and problem solving.", "authors": ["L Poole David", "K Mackworth Alan"], "related_topics": ["207453521", "157170001", "26205005"], "citation_count": "373", "reference_count": "330", "references": ["2618530766", "2919115771", "2145339207", "1663973292", "3145128584", "2557283755", "2257979135", "1554944419", "1639032689", "2752099845"], "date": "2017"}, {"id": "2160454978", "title": "The MIT Alewife machine: architecture and performance", "abstract": "Alewife is a multiprocessor architecture that supports up to 512 processing nodes connected over a scalable and cost-effective mesh network at a constant cost per node. The MIT Alewife machine, a prototype implementation of the architecture, demonstrates that a parallel system can be both scalable and programmable. Four mechanisms combine to achieve these goals: software-extended coherent shared memory provides a global, linear address space; integrated message passing allows compiler and operating system designers to provide efficient communication and synchronization; support for fine-grain computation allows many processors to cooperate on small problem sizes; and latency tolerance mechanisms --- including block multithreading and prefetching --- mask unavoidable delays due to communication.Microbenchmarks, together with over a dozen complete applications running on the 32-node prototype, help to analyze the behavior of the system. Analysis shows that integrating message passing with shared memory enables a cost-efficient solution to the cache coherence problem and provides a rich set of programming primitives. Block multithreading and prefetching improve performance by up to 25% individually, and 35% together. Finally, language constructs that allow programmers to express fine-grain synchronization can improve performance by over a factor of two.", "authors": ["Anant Agarwal", "Ricardo Bianchini", "David Chaiken", "Kirk L. Johnson", "David Kranz", "John Kubiatowicz", "Beng-Hong Lim", "Kenneth Mackenzie", "Donald Yeung"], "related_topics": ["133875982", "201410400", "854659"], "citation_count": "543", "reference_count": "35", "references": ["2155066383", "2112121929", "1966285605", "2152056423", "2152496451", "2144430894", "1689272351", "2171432528", "2006090396", "2166034599"], "date": "1995"}, {"id": "2141224535", "title": "Fast and robust fixed-point algorithms for independent component analysis", "abstract": "Independent component analysis (ICA) is a statistical method for transforming an observed multidimensional random vector into components that are statistically as independent from each other as possible. We use a combination of two different approaches for linear ICA: Comon's information theoretic approach and the projection pursuit approach. Using maximum entropy approximations of differential entropy, we introduce a family of new contrast functions for ICA. These contrast functions enable both the estimation of the whole decomposition by minimizing mutual information, and estimation of individual independent components as projection pursuit directions. The statistical properties of the estimators based on such contrast functions are analyzed under the assumption of the linear mixture model, and it is shown how to choose contrast functions that are robust and/or of minimum variance. Finally, we introduce simple fixed-point algorithms for practical optimization of the contrast functions.", "authors": ["A. Hyvarinen"], "related_topics": ["118038509", "51432778", "158457486"], "citation_count": "7747", "reference_count": "35", "references": ["2099111195", "2099741732", "2108384452", "2145889472", "2019502123", "1996355918", "2133069808", "2137234026", "1977067929", "2101933716"], "date": "1999"}, {"id": "2294015730", "title": "Automated interpretation and/or translation of clinical encounters with cultural cues", "abstract": "A method, system and a computer program product for an automated interpretation and/or translation are disclosed. An automated interpretation and/or translation occurs by receiving language-based content from a user. The received language-based content is processed to interpret and/or translate the received language-based content into a target language. Also, a presence of a cultural sensitivity in the received language-based content is detected. Further, an appropriate guidance for dealing with the detected cultural sensitivity is provided.", "authors": ["Daniel T. Heinze"], "related_topics": ["527412718", "204321447", "41008148"], "citation_count": "19", "reference_count": "67", "references": ["1480124987", "2839138574", "1935556775", "1556174525", "317467376", "2133529723", "1911328612", "1924122251", "1859820048", "1605641357"], "date": "2013"}, {"id": "2100493403", "title": "The Strength of Weak Ties You Can Trust: The Mediating Role of Trust in Effective Knowledge Transfer", "abstract": "Research has demonstrated that relationships are critical to knowledge creation and transfer, yet findings have been mixed regarding the importance of relational and structural characteristics of social capital for the receipt of tacit and explicit knowledge. We propose and test a model of two-party (dyadic) knowledge exchange, with strong support in each of the three companies surveyed. First, the link between strong ties and receipt of useful knowledge (as reported by the knowledge seeker) was mediated by competence- and benevolence-based trust. Second, once we controlled for these two trustworthiness dimensions, the structural benefit ofweak ties emerged. This finding is consistent with prior research suggesting that weak ties provide access to nonredundant information. Third, competence-based trust was especially important for the receipt of tacit knowledge. We discuss implications for theory and practice.", "authors": ["Daniel Z. Levin", "Rob Cross"], "related_topics": ["2776960227", "2779561248", "191628500"], "citation_count": "3700", "reference_count": "92", "references": ["1495419098", "2116199508", "2061901927", "2324392187", "2132454116", "2108795964", "2085491458", "2129658695", "1592263067", "2142175015"], "date": "2004"}, {"id": "1584377288", "title": "DNA-drug interactions. The crystal structures of d(TGTACA) and d(TGATCA) complexed with daunomycin.", "abstract": "The anticancer drug daunomycin has been co-crystallized with the hexanucleotide duplex sequences d(TGTACA) and d(TGATCA) and single crystal X-ray diffraction studies of these two complexes have been carried out. Structure solution of the d(TGTACA) and d(TGATCA) complexes to 1.6 and 1.7 Angstrom resolution, respectively, shows two daunomycin molecules bound to the DNA hexamer. Binding occurs via intercalation of the drug chromophore at the d(TpG) step, and hydrogen bonding interactions involving the drug, DNA and solvent molecules. The daunomycin sugar is located in the minor groove of the DNA hexamer and is stabilized by hydrogen bonds between the amino group of the sugar and functional groups on the floor of the groove. The amino sugar of the d(TGATCA) duplex interacts directly with the DNA sequence, while in the d(TGTACA) duplex, the interaction is via solvent molecules. Two other complexes d(CGTACG)-daunomycin and d(CGATCG)-daunomycin have previously been structurally characterized. Comparison of the four structures with daunomycin bound to the triplet sequences 5'TGT, 5'TGA, 5'CGT and 5'CGA reveals changes in the conformation of both the DNA hexamer and the daunomycin upon complexation, as well as the hydrogen bonding and van der Waals' interactions.", "authors": ["Christine M. Nunn", "Luc Van Meervelt", "Shude Zhang", "Madeleine H. Moore", "Olga Kennard"], "related_topics": ["189754071", "112887158", "552990157"], "citation_count": "127", "reference_count": "55", "references": ["1969222787", "1985459186", "2013917043", "2016254453", "1966347067", "1515935592", "2162417581", "1969758655", "1882364029", "2048061554"], "date": "1991"}, {"id": "2005373714", "title": "Scale and performance in a distributed file system", "abstract": "The Andrew File System is a location-transparent distributed tile system that will eventually span more than 5000 workstations at Carnegie Mellon University. Large scale affects performance and complicates system operation. In this paper we present observations of a prototype implementation, motivate changes in the areas of cache validation, server process structure, name translation, and low-level storage representation, and quantitatively demonstrate Andrews ability to scale gracefully. We establish the importance of whole-file transfer and caching in Andrew by comparing its performance with that of Sun Microsystems NFS tile system. We also show how the aggregation of files into volumes improves the operability of the system.", "authors": ["John H. Howard", "Michael L. Kazar", "Sherri G. Menees", "David A. Nichols", "M. Satyanarayanan", "Robert N. Sidebotham", "Michael J. West"], "related_topics": ["13194111", "64448361", "2776422543"], "citation_count": "2478", "reference_count": "11", "references": ["2039179345", "1967141605", "2001438822", "2078775767", "2111223826", "1547343000", "2115294119", "1572516042", "1969383031", "1535615324"], "date": "1988"}, {"id": "3021212382", "title": "A novel algorithm for color constancy", "abstract": "Color constancy is the skill by which it is possible to tell the color of an object even under a colored light. I interpret the color of an object as its color under a fixed canonical light, rather than as a surface reflectance function. This leads to an analysis that shows two distinct sets of circumstances under which color constancy is possible. In this framework, color constancy requires estimating the illuminant under which the image was taken. The estimate is then used to choose one of a set of linear maps, which is applied to the image to yield a color descriptor at each point. This set of maps is computed in advance. The illuminant can be estimated using image measurements alone, because, given a number of weak assumptions detailed in the text, the color of the illuminant is constrained by the colors observed in the image. This constraint arises from the fact that surfaces can reflect no more light than is cast on them. For example, if one observes a patch that excites the red receptor strongly, the illuminant cannot have been deep blue. Two algorithms are possible using this constraint, corresponding to different assumptions about the world. The first algorithm, Crule will work for any surface reflectance. Crule corresponds to a form of coefficient rule, but obtains the coefficients by using constraints on illuminant color. The set of illuminants for which Crule will be successful depends strongly on the choice of photoreceptors: for narrowband photoreceptors, Crule will work in an unrestricted world. The second algorithm, Mwext, requires that both surface reflectances and illuminants be chosen from finite dimensional spaces; but under these restrictive conditions it can recover a large number of parameters in the illuminant, and is not an attractive model of human color constancy. Crule has been tested on real images of Mondriaans, and works well. I show results for Crule and for the Retinex algorithm of Land (Land 1971; Land 1983; Land 1985) operating on a number of real images. The experimental work shows that for good constancy, a color constancy system will need to adjust the gain of the receptors it employs in a fashion analagous to adaptation in humans.", "authors": ["D. A. Forsyth"], "related_topics": ["187888035", "129112856", "176258234"], "citation_count": "1045", "reference_count": "0", "references": ["2163945819", "2160835070", "1989811281", "2126629925", "2076019436", "52437429", "2013765095", "1966511606", "2161808755", "2150566186"], "date": "1992"}, {"id": "2108699731", "title": "VAGUE: a user interface to relational databases that permits vague queries", "abstract": "A specific query establishes a rigid qualification and is concerned only with data that match it precisely. A vague query establishes a target qualification and is concerned also with data that are close to this target. Most conventional database systems cannot handle vague queries directly, forcing their users to retry specific queries repeatedly with minor modifications until they match data that are satisfactory. This article describes a system called VAGUE that can handle vague queries directly. The principal concept behind VAGUE is its extension to the relational data model with data metrics, which are definitions of distances between values of the same domain. A problem with implementing data distances is that different users may have different interpretations for the notion of distance. VAGUE incorporates several features that enable it to adapt itself to the individual views and priorities of its users.", "authors": ["Amihai Motro"], "related_topics": ["5655090", "40207289", "89505385"], "citation_count": "431", "reference_count": "28", "references": ["1956559956", "2752853835", "2138709157", "2988119170", "2123858323", "2115822498", "2103219113", "2062168151", "1557757161", "2074622901"], "date": "1988"}, {"id": "2962739339", "title": "Deep contextualized word representations", "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.", "authors": ["Matthew E. Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer"], "related_topics": ["95318506", "2474386", "60048249"], "citation_count": "6539", "reference_count": "55", "references": ["2964121744", "2153579005", "2095705004", "2250539671", "2064675550", "2158899491", "2493916176", "2251939518", "2147880316", "2963748441"], "date": "2018"}, {"id": "1977948323", "title": "Stereo by Intra- and Inter-Scanline Search Using Dynamic Programming", "abstract": "This paper presents a stereo matching algorithm using the dynamic programming technique. The stereo matching problem, that is, obtaining a correspondence between right and left images, can be cast as a search problem. When a pair of stereo images is rectified, pairs of corresponding points can be searched for within the same scanlines. We call this search intra-scanline search. This intra-scanline search can be treated as the problem of finding a matching path on a two-dimensional (2D) search plane whose axes are the right and left scanlines. Vertically connected edges in the images provide consistency constraints across the 2D search planes. Inter-scanline search in a three-dimensional (3D) search space, which is a stack of the 2D search planes, is needed to utilize this constraint. Our stereo matching algorithm uses edge-delimited intervals as elements to be matched, and employs the above mentioned two searches: one is inter-scanline search for possible correspondences of connected edges in right and left images and the other is intra-scanline search for correspondences of edge-delimited intervals on each scanline pair. Dynamic programming is used for both searches which proceed simultaneously: the former supplies the consistency constraint to the latter while the latter supplies the matching score to the former. An interval-based similarity metric is used to compute the score. The algorithm has been tested with different types of images including urban aerial images, synthesized images, and block scenes, and its computational requirement has been discussed.", "authors": ["Yuichi Ohta", "Takeo Kanade"], "related_topics": ["125583679", "102315692", "831591"], "citation_count": "1531", "reference_count": "13", "references": ["1604766291", "2296589133", "1713915947", "2167965718", "2137095888", "2167558105", "2171896511", "1518920518", "136365859", "3015684618"], "date": "1985"}, {"id": "2046442873", "title": "OPPOSITE SUPERIORITIES OF THE RIGHT AND LEFT CEREBRAL HEMISPHERES IN DISCRIMINATIVE REACTION TIME TO PHYSIOGNOMICAL AND ALPHABETICAL MATERIAL", "abstract": "", "authors": ["G. Rizzolatti", "C. Umilt\u00e0", "G. Berlucchi"], "related_topics": ["2779486818", "97931131", "169760540"], "citation_count": "474", "reference_count": "0", "references": ["2030793689", "2099156632", "2026575723", "1998186877", "2034531899", "2128858699", "2122494609", "2782423995", "2061836270", "2021706204"], "date": "1970"}, {"id": "2162090451", "title": "A very brief measure of the Big-Five personality domains", "abstract": "When time is limited, researchers may be faced with the choice of using an extremely brief measure of the Big-Five personality dimensions or using no measure at all. To meet the need for a very brief measure, 5 and 10-item inventories were developed and evaluated. Although somewhat inferior to standard multi-item instruments, the instruments reached adequate levels in terms of: (a) convergence with widely used Big-Five measures in self, observer, and peer reports, (b) test\u2013retest reliability, (c) patterns of predicted external correlates, and (d) convergence between self and observer ratings. On the basis of these tests, a 10-item measure of the Big-Five dimensions is offered for situations where very short measures are needed, personality is not the primary topic of interest, or researchers can tolerate the somewhat diminished psychometric properties associated with very brief measures.", "authors": ["Samuel D. Gosling", "Peter J. Rentfrow", "William B. Swann"], "related_topics": ["187288502", "2865642", "2780840541"], "citation_count": "7834", "reference_count": "31", "references": ["1641003075", "2905327414", "3124068636", "1556033561", "2042962409", "2122644021", "2082352243", "2111621157", "2162831287", "2014833927"], "date": "2003"}, {"id": "2112306707", "title": "GPS Meteorology: Remote Sensing of Atmospheric Water Vapor Using the Global Positioning System", "abstract": "We present a new approach to remote sensing of water vapor based on the global positioning system (GPS). Geodesists and geophysicists have devised methods for estimating the extent to which signals propagating from GPS satellites to ground-based GPS receivers are delayed by atmospheric water vapor. This delay is parameterized in terms of a time-varying zenith wet delay (ZWD) which is retrieved by stochastic filtering of the GPS data. Given surface temperature and pressure readings at the GPS receiver, the retrieved ZWD can be transformed with very little additional uncertainty into an estimate of the integrated water vapor (IWV) overlying that receiver. Networks of continuously operating GPS receivers are being constructed by geodesists, geophysicists, government and military agencies, and others in order to implement a wide range of positioning capabilities. These emerging GPS networks offer the possibility of observing the horizontal distribution of IWV or, equivalently, precipitable water with unprecedented coverage and a temporal resolution of the order of 10 min. These measurements could be utilized in operational weather forecasting and in fundamental research into atmospheric storm systems, the hydrologic cycle, atmospheric chemistry, and global climate change. Specially designed, dense GPS networks could be used to sense the vertical distribution of water vapor in their immediate vicinity. Data from ground-based GPS networks could be analyzed in concert with observations of GPS satellite occultations by GPS receivers in low Earth orbit to characterize the atmosphere at planetary scale.", "authors": ["Michael Bevis", "Steven Businger", "Thomas A. Herring", "Christian Rocken", "Richard A. Anthes", "Randolph H. Ware"], "related_topics": ["2777683753", "60229501", "156008332"], "citation_count": "2599", "reference_count": "49", "references": ["1535176033", "1545923740", "304861154", "2119486063", "1971407695", "1974437027", "2019447407", "2139801633", "2002557257", "2169337892"], "date": "1992"}, {"id": "2253776861", "title": "Modality and topographic properties of single neurons of cat's somatic sensory cortex.", "abstract": "", "authors": ["Vernon B. Mountcastle"], "related_topics": ["94487597", "2775994972", "2780226545"], "citation_count": "3029", "reference_count": "0", "references": ["2138913040", "65738273", "2072522618", "2079810998", "2120079537", "2107635023", "2117940227", "2012265686", "2138704896", "1999055090"], "date": "1957"}, {"id": "2126554879", "title": "Swarm Intelligence: From Natural to Artificial Systems", "abstract": "1. Introduction 2. Ant Foraging Behavior, Combinatorial Optimization, and Routing in Communications Networks 3. Division of Labor and Task Allocation 4. Cemetery Organization, Brood Sorting, Data Analysis, and Graph Partitioning 5. Self-Organization and Templates: Application to Data Analysis and Graph Partitioning 6. Nest Building and Self-Assembling 7. Cooperative Transport by Insects and Robots 8. Epilogue", "authors": ["Eric Bonabeau", "Marco Dorigo", "Guy Theraulaz"], "related_topics": ["44832474", "169337768", "119487961"], "citation_count": "10261", "reference_count": "0", "references": ["2061438946", "1976744965", "2287814884", "1544329015", "2144317842", "1523741643", "2169064301", "2114652055", "2099019320", "2113188272"], "date": "1998"}, {"id": "1996931099", "title": "A methodology for implementing highly concurrent data objects", "abstract": "A concurrent object is a data structure shared by concurrent processes. Conventional techniques for implementing concurrent objects typically rely on critical sections; ensuring that only one process at a time can operate on the object. Nevertheless, critical sections are poorly suited for asynchronous systems: if one process is halted or delayed in a critical section, other, nonfaulty processes will be unable to progress. By contrast, a concurrent object implementation is lock free if it always guarantees that some process will complete an operation in a finite number of steps, and it is wait free if it guarantees that each process will complete an operation in a finite number of steps. This paper proposes a new methodology for constructing lock-free and wait-free implementations of concurrent objects. The object's representation and operations are written as stylized sequential programs, with no explicit synchronization. Each sequential operation is atutomatically transformed into a lock-free or wait-free operation using novel synchronization and memory management algorithms. These algorithms are presented for a multiple instruction/multiple data (MIMD) architecture in which n processes communicate by applying atomic read, write, load_linked, and store_conditional operations to a shared memory.", "authors": ["Maurice Herlihy"], "related_topics": ["20528329", "124343487", "101612960"], "citation_count": "735", "reference_count": "37", "references": ["2752885492", "2113751407", "2035362408", "2085407655", "109793532", "2611598995", "2003214215", "2137296754", "2069278684", "1555673550"], "date": "1993"}, {"id": "2014543370", "title": "A reliability coefficient for maximum likelihood factor analysis", "abstract": "Maximum likelihood factor analysis provides an effective method for estimation of factor matrices and a useful test statistic in the likelihood ratio for rejection of overly simple factor models. A reliability coefficient is proposed to indicate quality of representation of interrelations among attributes in a battery by a maximum likelihood factor analysis. Usually, for a large sample of individuals or objects, the likelihood ratio statistic could indicate that an otherwise acceptable factor model does not exactly represent the interrelations among the attributes for a population. The reliability coefficient could indicate a very close representation in this case and be a better indication as to whether to accept or reject the factor solution.", "authors": ["Ledyard R. Tucker", "Charles Lewis"], "related_topics": ["61420037", "9483764", "189559763"], "citation_count": "8372", "reference_count": "17", "references": ["2335487254", "2066306397", "2110818662", "2095917182", "1969502977", "2087962626", "1991186478", "1964946074", "2056652200", "1966986288"], "date": "1973"}, {"id": "1924000956", "title": "Database usage metering and protection system and method", "abstract": "A \"return on investment\" digital database usage metering, billing, and security system includes a hardware device which is plugged into a computer system bus (or into a serial or other functionally adequate connector) and a software program system resident in the hardware device. One or more databases are encrypted and stored on a non-volatile mass storage device (e.g., an optical disk). A tamper-proof decrypting device and associated controller decrypts selected portions of the stored database and measures the quantity of information which is decrypted. This measured quantity information is communicated to a remote centralized billing facility and used to charge the user a fee based on database usage. A system may include a \"self-destruct\" feature which .disables system operation upon occurrence of a predetermined event unless the user implements an \"antidote\"--instructions for implementing the antidote being given to him by the database owner only if the user pays his bill. Absolute database security and billing based on database usage are thus provided in a system environment wherein all database access tasks are performed at the user's site. Moreover, a free market competitive environment is supported because literary property royalties can be calculated based on actual data use.", "authors": ["Victor H. Shear"], "related_topics": ["78161392", "2778553114", "107535962"], "citation_count": "1829", "reference_count": "96", "references": ["1913149162", "2141976293", "3150037652", "2086800870", "2129401960", "1892463061", "2820932749", "2159609017", "2751183394", "2845715967"], "date": "1987"}, {"id": "2157654560", "title": "Potentiometric behavior of metalloporphyrin-based ion-selective electrodes: Use of silicone rubber matrix for serum chloride analysis", "abstract": "Abstract For the proper design of a miniaturized all-solid-state chloride-selective electrode for serum analysis with metalloporphyrin-based ionophores, the potentiometric behavior of four different metalloporphyrins, i.e., manganese(III) tetraphenylporphyrin chloride [Mn(TPP)Cl], manganese(III) octaethylporphyrin chloride [Mn(OEP)Cl], indium(III) tetraphenylporphyrin chloride [In(TPP)Cl] and indium(III) octaethylporphyrin chloride [In(OEP)Cl], doped in a one-component room temperature vulcanizing-type silicone rubber (SR) matrix were examined. Particular attention was paid to find a membrane formulation with minimal effect of salicylate because this interference is often the cause of a large positive error in serum chloride analysis. In general, the use of 10\u201320 wt% of plasticizer (e.g., o-nitrophenyl octyl ether (NPOE) and dibutyl sebacate (DBS)) was necessary for the ion carriers in SR to induce proper potentiometric response to chloride. On the other hand, In(TPP)Cl doped in SR matrix did not show any electrochemical activity regardless of the type of plasticizer employed. Mn(OEP)Cl or In(OEP)Cl doped in SR matrix with NPOE plasticizer exhibited super-Nernstian response (70.8 and 84.0 mV/pCl\u2212, respectively), while those with DBS plasticizer show sub-Nernstian behavior. Of the two octaethyl porphyrins, the In(OEP)Cl-based membrane exhibited higher slope, 53.7 mV/decade, to chloride with reduced salicylate interference ( log K POT Cl \u2212 ,sal \u2212 =1.1 with DBS). All-solid-state electrodes modified with In(OEP)Cl/SR/DBS membranes have been prepared and their utility for serum chloride measurement have been demonstrated.", "authors": ["In Jun Yoon", "Jae Ho Shin", "Insook Rhee Paeng", "Hakhyun Nam", "Geun Sig Cha", "Ki-Jung Paeng"], "related_topics": ["2778695967", "2908716831", "124614425"], "citation_count": "68", "reference_count": "30", "references": ["2075489519", "2038399456", "1896747810", "1569512084", "1965027713", "2059919815", "2015374222", "2062479140", "2066187495", "2073531379"], "date": "1998"}, {"id": "2116825644", "title": "Training restricted Boltzmann machines using approximations to the likelihood gradient", "abstract": "A new algorithm for training Restricted Boltzmann Machines is introduced. The algorithm, named Persistent Contrastive Divergence, is different from the standard Contrastive Divergence algorithms in that it aims to draw samples from almost exactly the model distribution. It is compared to some standard Contrastive Divergence and Pseudo-Likelihood algorithms on the tasks of modeling and classifying various types of data. The Persistent Contrastive Divergence algorithm outperforms the other algorithms, and is equally fast and simple.", "authors": ["Tijmen Tieleman"], "related_topics": ["192576344", "199354608", "11413529"], "citation_count": "1010", "reference_count": "20", "references": ["2136922672", "2100495367", "2116064496", "2110798204", "2099866409", "1994197834", "2096192494", "2120340025", "2124914669", "66838807"], "date": "2008"}, {"id": "2080267935", "title": "Graph-Based Algorithms for Boolean Function Manipulation", "abstract": "In this paper we present a new data structure for representing Boolean functions and an associated set of manipulation algorithms. Functions are represented by directed, acyclic graphs in a manner similar to the representations introduced by Lee [1] and Akers [2], but with further restrictions on the ordering of decision variables in the graph. Although a function requires, in the worst case, a graph of size exponential in the number of arguments, many of the functions encountered in typical applications have a more reasonable representation. Our algorithms have time complexity proportional to the sizes of the graphs being operated on, and hence are quite efficient as long as the graphs do not grow too large. We present experimental results from applying these algorithms to problems in logic design verification that demonstrate the practicality of our approach.", "authors": ["Bryant"], "related_topics": ["196836630", "43517604", "115625"], "citation_count": "12469", "reference_count": "17", "references": ["2011039300", "1655990431", "2002252750", "2105761964", "1994143452", "2133431834", "2165495918", "1983849809", "2054631220", "2080085596"], "date": "1986"}, {"id": "2096605459", "title": "Capacitive-type touch panel", "abstract": "A capacitive-type touch panel includes: a transparent substrate; a plurality of first conductors; a plurality of second conductors cooperating with the first conductors to form a matrix of capacitive regions; and a controller connected electrically to the first and second conductors for detecting the capacitance of each of the capacitive regions. Each of the first conductors is intersected and divided by the second conductors into a series of first electrode sections. Each of the second conductors is intersected and divided by the first conductors into a series of second electrode sections. Each of the first and second electrode sections of the first and second conductors has a fine conductor line-constructed structure which is constructed from a fine line-shaped conductor.", "authors": ["Yu-Huei Chang"], "related_topics": ["206755178", "34800285", "202374169"], "citation_count": "591", "reference_count": "12", "references": ["2849334407", "3142003516", "1555493939", "2020773174", "2820132077", "2843283563", "3147322653", "1500021796", "1863069858", "2827676067"], "date": "2008"}, {"id": "1853995153", "title": "On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration", "abstract": "In the last decade there has been an explosion of interest in mining time series data. Literally hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we make the following claim. Much of this work has very little utility because the contribution made (speed in the case of indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an amount of \u201cimprovement\u201d that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details. To illustrate our point, we have undertaken the most exhaustive set of time series experiments ever attempted, re-implementing the contribution of more than two dozen papers, and testing them on 50 real world, highly diverse datasets. Our empirical results strongly support our assertion, and suggest the need for a set of time series benchmarks and more careful empirical evaluation in the data mining community.", "authors": ["Eamonn Keogh", "Shruti Kasetty"], "related_topics": ["73555534", "151406439", "196083921"], "citation_count": "2098", "reference_count": "62", "references": ["1499049447", "2128061541", "2133184712", "2163336863", "2042591571", "1587157435", "2036557187", "1864972570", "151863654", "2101005720"], "date": "2003"}, {"id": "2318841949", "title": "A Textual Comparison of British and American Writing", "abstract": "M ANY AMERICANS REGARD BRITISH ENGLISH as more formal and proper than American English, while the British in turn consider American English to be markedly informal and relaxed. Observers commonly attribute these attitudes to differences in pronunciation, which are the most readily apparent distinctions between the two dialects. Correspondingly, nearly all linguistic comparisons of British and American English have focussed on phonological features and relatively idiosyncratic vocabulary differences. Syntactic differences between the two varieties have been largely ignored. The present study begins to fill this gap: it identifies systematic syntactic differences between British and American writing, and it suggests that these differences are associated with differing functional priorities. The study compares nine written genres (e.g., press reportage, academic prose, romantic fiction) in British and American English with respect to three underlying parameters of linguistic variation (identified in earlier studies). Based on their functional interpretations, these parameters have been tentatively labelled Dimension 1: INTERACTIVE versus EDITED TEXT; Dimension 2: ABSTRACT Versus SITUATED CONTENT; and Dimension 3: REPORTED versus IMMEDIATE STYLE. (These interpretations are described in section II.) The present study shows that there are systematic linguistic differences between British and American writing with respect to the first two of these dimensions. When the genres are compared along Dimension 1, it is found that the British genres are consistently more edited and less interactive than the corresponding American genres; along Dimension 2, the British genres are consistently less abstract than the corresponding American genres. Although these differences are not large, they are highly systematic across the different genres, indicating that they truly represent underlying linguistic differences between British and American written texts. The study suggests that the differences along both dimensions are associated with greater attention to grammatical and stylistic prescriptions in British than American writing. The discussion is organized as follows: in section I, some previous comparisons of British and American English are described; section II", "authors": ["Douglas Biber"], "related_topics": ["2779855358", "2777939226", "2781327548"], "citation_count": "140", "reference_count": "18", "references": ["2029315691", "87722466", "2009475852", "2061741899", "591184081", "2008485515", "340893908", "1975524236", "1601640437", "1972655027"], "date": "1987"}, {"id": "2069980026", "title": "Approximate frequency counts over data streams", "abstract": "Research in data stream algorithms has blossomed since late 90s. The talk will trace the history of the Approximate Frequency Counts paper, how it was conceptualized and how it influenced data stream research. The talk will also touch upon a recent development: analysis of personal data streams for improving our quality of lives.", "authors": ["Gurmeet Singh Manku", "Rajeev Motwani"], "related_topics": ["89198739", "2778484313", "75291252"], "citation_count": "1973", "reference_count": "31", "references": ["1484413656", "2064853889", "1506285740", "2295428206", "1978394996", "2030969394", "1597161471", "2080745194", "1977141583", "1493892051"], "date": "2012"}, {"id": "2156406284", "title": "Recognition-by-Components: A Theory of Human Image Understanding.", "abstract": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N \u00a3 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensiona l image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position an$ image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Representational power derives from an allowance of free combinations of the geons. A Principle of Componential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory. Any single object can project an infinity of image configurations to the retina. The orientation of the object to the viewer can vary continuously, each giving rise to a different two-dimensional projection. The object can be occluded by other objects or texture fields, as when viewed behind foliage. The object need not be presented as a full-colored textured image but instead can be a simplified line drawing. Moreover, the object can even be missing some of its parts or be a novel exemplar of its particular category. But it is only with rare exceptions that an image fails to be rapidly and readily classified, either as an instance of a familiar object category or as an instance that cannot be so classified (itself a form of classification).", "authors": ["Irving Biederman"], "related_topics": ["14551309", "139132820", "20894473"], "citation_count": "7661", "reference_count": "73", "references": ["2740373864", "2149095485", "2059975159", "2073257493", "1513966746", "2059799772", "2032533296", "2125756925", "1501418839", "2081519360"], "date": "1987"}, {"id": "2017271336", "title": "Principles of event segmentation in language: The case of motion events", "abstract": "We examine universals and crosslinguistic variation in constraints on event segmentation. Previous typological studies have focused on segmentation into syntactic (Pawley 1987) or intonational units (Givon 1991). We argue that the correlation between such units and semantic/conceptual event representations is language-specific. As an alternative, we introduce the MACRO-EVENT PROPERTY (MEP): a construction has the MEP if it packages event representations such that temporal operators necessarily have scope over all subevents. A case study on the segmentation of motion events into macro-event expressions in eighteen genetically and typologically diverse languages has produced evidence of two types of design principles that impact motion-event segmentation: language-specific lexicalization patterns and universal constraints on form-to-meaning mapping.", "authors": ["J\u00fcrgen Bohnemeyer", "Nicholas J. Enfield", "James Essegbey", "Iraide Ibarretxe-Antu\u00f1ano", "Sotaro Kita", "Friederike L\u00fcpke", "Felix K. Ameka"], "related_topics": ["2777532361", "89600930", "2776406365"], "citation_count": "268", "reference_count": "92", "references": ["1558866924", "2130041324", "1586060904", "1500718495", "1579929927", "1965696452", "2123987305", "2101196694", "2027972120", "2086461330"], "date": "2007"}, {"id": "2139047213", "title": "Incremental Learning for Robust Visual Tracking", "abstract": "Visual tracking, in essence, deals with non-stationary image streams that change over time. While most existing algorithms are able to track objects well in controlled environments, they usually fail in the presence of significant variation of the object's appearance or surrounding illumination. One reason for such failures is that many algorithms employ fixed appearance models of the target. Such models are trained using only appearance data available before tracking begins, which in practice limits the range of appearances that are modeled, and ignores the large volume of information (such as shape changes or specific lighting conditions) that becomes available during tracking. In this paper, we present a tracking method that incrementally learns a low-dimensional subspace representation, efficiently adapting online to changes in the appearance of the target. The model update, based on incremental algorithms for principal component analysis, includes two important features: a method for correctly updating the sample mean, and a forgetting factor to ensure less modeling power is expended fitting older observations. Both of these features contribute measurably to improving overall tracking performance. Numerous experiments demonstrate the effectiveness of the proposed tracking algorithm in indoor and outdoor environments where the target objects undergo large changes in pose, scale, and illumination.", "authors": ["David A. Ross", "Jongwoo Lim", "Ruei-Sung Lin", "Ming-Hsuan Yang"], "related_topics": ["83248878", "56461940", "10161872"], "citation_count": "3687", "reference_count": "36", "references": ["2798909945", "2132103241", "2152826865", "2148694408", "2159128898", "2123977795", "2125027820", "2613779721", "2118877769", "1481420047"], "date": "2008"}, {"id": "2165906949", "title": "Error-constrained COUNT query evaluation in relational databases", "abstract": "", "authors": ["Wen-Chi Hou", "Gultekin Ozsoyoglu", "Erdogan Dogdu"], "related_topics": ["192939062", "157692150", "194222762"], "citation_count": "93", "reference_count": "10", "references": ["1968829657", "1972223681", "1988144572", "2197881366", "2034401457", "1587364696", "2108717033", "2084787043", "2167770337", "2033457734"], "date": "1991"}, {"id": "1852082788", "title": "Mixed and hybrid finite element methods", "abstract": "Variational Formulations and Finite Element Methods. Approximation of Saddle Point Problems. Function Spaces and Finite Element Approximations. Various Examples. Complements on Mixed Methods for Elliptic Problems. Incompressible Materials and Flow Problems. Other Applications.", "authors": ["Franco Brezzi", "Michel Fortin"], "related_topics": ["144468803", "177605945", "92244383"], "citation_count": "9237", "reference_count": "0", "references": ["2130350269", "2141870784", "2168914934", "1998894128", "2138486270", "2006000775", "2052690618", "2102295719", "2039955529", "2022525937"], "date": "1991"}, {"id": "2408491755", "title": "LIMITS and Applications of Group Algebras for Parameterized Problems", "abstract": "The fastest known randomized algorithms for several parameterized problems use reductions to the k-MlD problem: detection of multilinear monomials of degree k in polynomials presented as circuits. The fastest known algorithm for k-MlD is based on 2k evaluations of the circuit over a suitable algebra. We use communication complexity to show that it is essentially optimal within this evaluation framework. On the positive side, we give additional applications of the method: finding a copy of a given tree on k nodes, a minimum set of nodes that dominate at least t nodes, and an m-dimensional k-matching. In each case, we achieve a faster algorithm than what was known before. We also apply the algebraic method to problems in exact counting. Among other results, we show that a variation of it can break the trivial upper bounds for the disjoint summation problem.", "authors": ["Ioannis Koutis", "Ryan Williams"], "related_topics": ["165464430", "84392682", "128669082"], "citation_count": "157", "reference_count": "32", "references": ["2913688336", "1606480398", "2340787257", "2296148711", "1575411448", "1596578766", "2120141762", "1852383912", "2408491755", "2102039892"], "date": "2016"}, {"id": "2158237121", "title": "Query evaluation techniques for large databases", "abstract": "Database management systems will continue to manage large data volumes. Thus, efficient algorithms for accessing and manipulating large sets and sequences will be required to provide acceptable performance. The advent of object-oriented and extensible database systems will not solve this problem. On the contrary, modern data models exacerbate the problem: In order to manipulate large sets of complex objects as efficiently as today's database systems manipulate simple records, query-processing algorithms and software will become more complex, and a solid understanding of algorithm and architectural issues is essential for the designer of database management software. This survey provides a foundation for the design and implementation of query execution facilities in new database management systems. It describes a wide array of practical query evaluation techniques for both relational and postrelational database systems, including iterative execution of complex query evaluation plans, the duality of sort- and hash-based set-matching algorithms, types of parallel query execution and their implementation, and special operators for emerging database application domains.", "authors": ["Goetz Graefe"], "related_topics": ["54239708", "157692150", "107535962"], "citation_count": "1981", "reference_count": "422", "references": ["2151135734", "1515932031", "2987803397", "2752853835", "2118269922", "2147504831", "1545155892", "2319794630", "2016758618", "2113427031"], "date": "1993"}, {"id": "2942228371", "title": "Probability, random variables, and stochastic processes", "abstract": "", "authors": ["Athanasios Papoulis", "S. Unnikrishna Pillai"], "related_topics": ["8272713", "122123141", "121864883"], "citation_count": "8629", "reference_count": "0", "references": ["2133401839", "2171501928", "2012445782", "2526144952", "2963294159", "2045343076", "1968560005", "2108324407", "2103632679", "2042620791"], "date": "2001"}, {"id": "91102539", "title": "Les Algebres d'Operateurs dans l'Espace Hilbertien", "abstract": "", "authors": ["J. L. B. Cooper", "J. Dixmier"], "related_topics": ["33923547", "202444582"], "citation_count": "1273", "reference_count": "0", "references": ["1985737977", "2015683881", "2000106536", "1964095328", "2077809943", "2963825935", "3103548895", "3004911475", "621792339", "2331274486"], "date": "1958"}, {"id": "2143426320", "title": "Gene Selection for Cancer Classification using Support Vector Machines", "abstract": "DNA micro-arrays now permit scientists to screen thousands of genes simultaneously and determine whether those genes are active, hyperactive or silent in normal or cancerous tissue. Because these new micro-array devices generate bewildering amounts of raw data, new analytical methods must be developed to sort out whether cancer tissues have distinctive signatures of gene expression over normal tissues or other types of cancer tissues. In this paper, we address the problem of selection of a small subset of genes from broad patterns of gene expression data, recorded on DNA micro-arrays. Using available training examples from cancer and normal patients, we build a classifier suitable for genetic diagnosis, as well as drug discovery. Previous attempts to address this problem select genes with correlation techniques. We propose a new method of gene selection utilizing Support Vector Machine methods based on Recursive Feature Elimination (RFE). We demonstrate experimentally that the genes selected by our techniques yield better classification performance and are biologically relevant to cancer. In contrast with the baseline method, our method eliminates gene redundancy automatically and yields better and more compact gene subsets. In patients with leukemia our method discovered 2 genes that yield zero leave-one-out error, while 64 genes are necessary for the baseline method to get the best result (one leave-one-out error). In the colon cancer database, using only 4 genes our method is 98% accurate, while the baseline method is only 86% accurate.", "authors": ["Isabelle Guyon", "Jason Weston", "Stephen Barnhill", "Vladimir Vapnik"], "related_topics": ["16811321", "2779017525", "148483581"], "citation_count": "9172", "reference_count": "42", "references": ["2148603752", "2119821739", "2150926065", "2109363337", "1563088657", "2147246240", "2140095548", "1601740268", "2087347434", "2017337590"], "date": "2002"}, {"id": "2148606196", "title": "The Structure and Function of Complex Networks", "abstract": "Inspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks.", "authors": ["Mark E. J. Newman"], "related_topics": ["34947359", "36647736", "137753397"], "citation_count": "21787", "reference_count": "393", "references": ["2112090702", "2008620264", "2124637492", "3013264884", "2138621811", "1854214752", "1992419399", "1971421925", "2097571405", "2164727176"], "date": "2002"}, {"id": "3000074734", "title": "The ecology of human development", "abstract": "", "authors": ["Urie Bronfenbrenner"], "related_topics": ["2781089502", "15744967", "18903297"], "citation_count": "18209", "reference_count": "0", "references": ["2147454772", "2107223217", "1984303969", "20725885", "1967609415", "2104630420", "2114088565", "2084716978", "2107428639", "2158089900"], "date": "1978"}, {"id": "2169213601", "title": "Relevance-Based Language Models", "abstract": "We explore the relation between classical probabilistic models of information retrieval and the emerging language modeling approaches. It has long been recognized that the primary obstacle to effective performance of classical models is the need to estimate a relevance model: probabilities of words in the relevant class. We propose a novel technique for estimating these probabilities using the query alone. We demonstrate that our technique can produce highly accurate relevance models, addressing important notions of synonymy and polysemy. Our experiments show relevance models outperforming baseline language modeling systems on TREC retrieval and TDT tracking tasks. The main contribution of this work is an effective formal method for estimating a relevance model with no training data.", "authors": ["Victor Lavrenko", "W. Bruce Croft"], "related_topics": ["143017306", "87546605", "137293760"], "citation_count": "1893", "reference_count": "24", "references": ["2006969979", "2093390569", "2158195707", "1482214997", "1586405805", "2062270497", "2014415866", "2131133093", "2064988570", "1557074680"], "date": "2001"}, {"id": "2003410902", "title": "Splines: a perfect fit for signal and image processing", "abstract": "The article provides arguments in favor of an alternative approach that uses splines, which is equally justifiable on a theoretical basis, and which offers many practical advantages. To reassure the reader who may be afraid to enter new territory, it is emphasized that one is not losing anything because the traditional theory is retained as a particular case (i.e., a spline of infinite degree). The basic computational tools are also familiar to a signal processing audience (filters and recursive algorithms), even though their use in the present context is less conventional. The article also brings out the connection with the multiresolution theory of the wavelet transform. This article attempts to fulfil three goals. The first is to provide a tutorial on splines that is geared to a signal processing audience. The second is to gather all their important properties and provide an overview of the mathematical and computational tools available; i.e., a road map for the practitioner with references to the appropriate literature. The third goal is to give a review of the primary applications of splines in signal and image processing.", "authors": ["M. Unser"], "related_topics": ["501101116", "9417928", "104317675"], "citation_count": "2154", "reference_count": "116", "references": ["2115755118", "2062024414", "2132984323", "2145023731", "2104095591", "2146842127", "2142276208", "2098914003", "2053691921", "1658679052"], "date": "1999"}, {"id": "2001564915", "title": "Reciprocal Teaching of Comprehension-Fostering and Comprehension-Monitoring Activities", "abstract": "Two instructional studies directed at the comprehension-fostering and comprehension-monitoring activities of seventh grade poor comprehenders are reported. The four study activities were summarizing (self-review), questioning, clarifying, and predicting. The training method was that of reciprocal teaching, where the tutor and students took turns leading a dialogue centered on pertinent features of the text. In Study 1, a comparison between the reciprocal teaching method and a second intervention modeled on typical classroom practice resulted in greater gains and maintenance over time for the reciprocal procedure. Reciprocal teaching, with an adult model guiding the student to interact with the text in more sophisticated ways, led to a significant improvement in the quality of the summaries and questions. It also led to sizable gains on criterion tests of comprehension, reliable maintenance over time, generalization to classroom comprehension tests, transfer to novel tasks that tapped the trained skills of...", "authors": ["Annemarie Sullivan Palincsar", "Ann L. Brown"], "related_topics": ["163933246", "511192102", "2776628384"], "citation_count": "10112", "reference_count": "51", "references": ["2135943618", "1569737621", "2039107287", "1998493215", "2498214524", "659306968", "3027269366", "655326068", "600881208", "1579456230"], "date": "1984"}, {"id": "2037621702", "title": "Assessing the effects of gamification in the classroom", "abstract": "Gamification, the application of game elements to non-game settings, continues to grow in popularity as a method to increase student engagement in the classroom. We tested students across two courses, measuring their motivation, social comparison, effort, satisfaction, learner empowerment, and academic performance at four points during a 16-week semester. One course received a gamified curriculum, featuring a leaderboard and badges, whereas the other course received the same curriculum without the gamified elements. Our results found that students in the gamified course showed less motivation, satisfaction, and empowerment over time than those in the non-gamified class. The effect of course type on students' final exam scores was mediated by students' levels of intrinsic motivation, with students in the gamified course showing less motivation and lower final exam scores than the non-gamified class. This suggests that some care should be taken when applying certain gamification mechanics to educational settings. Longitudinal study on effects of gamification in the classroom.71 students surveyed at four time points in gamified or non-gamified course.Over time, gamified students were less motivated, empowered, and satisfied.Gamified course negatively affected final exam grades through intrinsic motivation.Gamified systems strongly featuring rewards may have negative effects.", "authors": ["Michael D. Hanus", "Jesse Fox"], "related_topics": ["194519906", "47177190", "145420912"], "citation_count": "824", "reference_count": "51", "references": ["2141846678", "1980850924", "2122517769", "1527994979", "1998933811", "2170899200", "48268975", "2049080106", "2147489905", "2007851141"], "date": "2014"}, {"id": "2147283253", "title": "Multi-agent based information access services for condition monitoring in process automation", "abstract": "This paper studies issues concerning the application of goal-oriented information agents to condition monitoring tasks in process automation. In the presented approach, an agent-based information access layer is operating as a mediator for various types of process-related information. The agent system may be seen as an active partner for human users in this information intensive application domain. In the future, more and more automation related information will be available in electronic form. Physical sensors provide not only measurements but also reliability information, and numerous configuration details are available in electronic form. The challenge is to integrate as much of the available information as possible, and to automate the processing of this information to enable easy decision-making for end users.", "authors": ["T. Pirttioja", "A. Pakonen", "I. Seilonen", "A. Halme", "K. Koskinen"], "related_topics": ["180198813", "2776543384", "29848774"], "citation_count": "22", "reference_count": "24", "references": ["175500210", "2170756108", "2155272711", "2130766754", "2105656578", "2177007941", "2025366479", "1561662057", "2005781710", "2132892132"], "date": "2005"}, {"id": "1810943226", "title": "Generating Sequences With Recurrent Neural Networks", "abstract": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.", "authors": ["Alex Graves"], "related_topics": ["147168706", "2779386606", "37724570"], "citation_count": "3331", "reference_count": "30", "references": ["2064675550", "1554663460", "2143612262", "44815768", "1632114991", "2131462252", "196214544", "2108677974", "2120861206", "3023071679"], "date": "2013"}, {"id": "2982377460", "title": "A Platform based on HLS to Implement a Generic CNN on an FPGA", "abstract": "The fast progress in modern applications based on convolution neural network poses new challenges, such as higher precision and real-time response. On the other hand, advances of Field Programmable Gate Arrays tools allows designs based on High-Level Synthesis, allowing a faster and an easier implementation on hardware of solutions for complex problems. However, a significant amount of time and still some level of hardware design expertise are required to implement a convolution neural network on hardware. To solve this difficulty a platform to emulate a generic parameterizable-based convolution neural network on a programmable gate arrays is developed, giving the freedom to specify the network topology and tune the parameterization. This platform, developed in C language and synthetized through High-Level Synthesis, is prepared to configure a floating-point convolution neural network as a \u201clego\u201d. This approach became attractive because the designer focuses on the network topology, without in-depth understanding of the underlying hardware a requirement.", "authors": ["Dario Baptista", "F. Morgado-Dias", "Leonel Sousa"], "related_topics": ["199845137", "3270621", "42935608"], "citation_count": "0", "reference_count": "18", "references": ["2194775991", "2618530766", "2962835968", "2097117768", "2094756095", "2147800946", "2154579312", "2009832130", "1990315422", "2074772891"], "date": "2019"}, {"id": "2097246321", "title": "Three naive Bayes approaches for discrimination-free classification", "abstract": "In this paper, we investigate how to modify the naive Bayes classifier in order to perform classification that is restricted to be independent with respect to a given sensitive attribute. Such independency restrictions occur naturally when the decision process leading to the labels in the data-set was biased; e.g., due to gender or racial discrimination. This setting is motivated by many cases in which there exist laws that disallow a decision that is partly based on discrimination. Naive application of machine learning techniques would result in huge fines for companies. We present three approaches for making the naive Bayes classifier discrimination-free: (i) modifying the probability of the decision being positive, (ii) training one model for every sensitive attribute value and balancing them, and (iii) adding a latent variable to the Bayesian model that represents the unbiased label and optimizing the model parameters for likelihood using expectation maximization. We present experiments for the three approaches on both artificial and real-life data.", "authors": ["Toon Calders", "Sicco Verwer"], "related_topics": ["52001869", "185207860", "143809311"], "citation_count": "573", "reference_count": "13", "references": ["167016754", "2026019770", "2096335861", "2116666691", "2157928966", "1999380087", "145450961", "1593806347", "2145234462", "1593930037"], "date": "2010"}, {"id": "147723833", "title": "Digital image processing (2nd ed.)", "abstract": "", "authors": ["Rafael C. Gonzales", "Paul Wintz"], "related_topics": ["104317675", "31972630", "41008148"], "citation_count": "3007", "reference_count": "0", "references": ["2121601095", "2186428165", "1963623641", "2171759622", "2135463994", "2163344010", "2122374500", "2116973876", "2240798854", "2042629182"], "date": "1987"}, {"id": "2070834743", "title": "File system usage in Windows NT 4.0", "abstract": "We have performed a study of the usage of the Windows NT File System through long-term kernel tracing. Our goal was to provide a new data point with respect to the 1985 and 1991 trace-based File System studies, to investigate the usage details of the Windows NT file system architecture, and to study the overall statistical behavior of the usage data.In this paper we report on these issues through a detailed comparison with the older traces, through details on the operational characteristics and through a usage analysis of the file system and cache manager. Next to architectural insights we provide evidence for the pervasive presence of heavy-tail distribution characteristics in all aspect of file system usage. Extreme variances are found in session inter-arrival time, session holding times, read/write frequencies, read/write buffer sizes, etc., which is of importance to system engineering, tuning and benchmarking.", "authors": ["Werner Vogels"], "related_topics": ["180500224", "165121294", "95637964"], "citation_count": "351", "reference_count": "23", "references": ["2205436351", "196539227", "2007415020", "2171796885", "2107460938", "1967141605", "2068666958", "1650006494", "49087170", "2114226921"], "date": "1999"}, {"id": "1999410909", "title": "Economic Action and Social Structure: the Problem of Embeddedness", "abstract": "The paper deals with the problem of embeddedness of economic behavior in the social relations. This part of the text contains the theoretical definitions of embeddedness. The author analyzes over- and half-socialized concepts of human action in sociology and in economics. The issues of trust and fraud in economic life are in the focus.", "authors": ["Mark Granovetter"], "related_topics": ["63063934", "130064352", "2778032263"], "citation_count": "70147", "reference_count": "53", "references": ["2056621186", "3016265253", "1972698480", "155775238", "3124035573", "1511343964", "1970936211", "1480391747", "1655203505", "1977186326"], "date": "2008"}, {"id": "2019222286", "title": "Bandpass Channels, Zero-Crossings, and Early Visual Information Processing", "abstract": "Under appropriate conditions zero-crossings of a bandpass signal are very rich in information. The authors examine here the relevance of this result to the early stages of visual information processing, where zero-crossings in the output of independent spatial-frequency-tuned channels may contain sufficient information for much of the subsequent processing.", "authors": ["David Marr", "S. Ullman", "Tomaso Poggio"], "related_topics": ["87868495", "160086991", "178674793"], "citation_count": "170", "reference_count": "10", "references": ["2130355536", "2116360511", "1999908130", "1971082588", "1645522763", "2010814572", "2069726594", "2113192608", "2027620505", "1975080851"], "date": "1979"}, {"id": "1577906631", "title": "Principles of Communication Engineering", "abstract": "Textbook on communication engineering emphasizing random processes, information and detection theory, statistical communication theory, applications, etc", "authors": ["I. M. Jacobs", "J. M. Wozencraft"], "related_topics": ["3716254", "52622258", "122203268"], "citation_count": "1975", "reference_count": "0", "references": ["1667950888", "2133401839", "2161963928", "2112772743", "2170738062", "2109489513", "2143587067", "2165205968", "2111460811", "2129076435"], "date": "1964"}, {"id": "1935556775", "title": "Health care management system for comparing user-proposed and recommended resources required for treatment", "abstract": "A health care management system for use by hospitals, physicians, insurance companies, health maintenance organizations, and others in the health care field includes a processing unit and health condition guidelines. A user inputs information related to the health condition of an individual and guideline treatment options are identified. The user also inputs actual or proposed and final recommendation treatments for the same individual. The resulting comparative information can be used to modify the actual or proposed treatment, or provide explanatory information as to reasons for the difference between the final recommendation treatment and guideline treatment options. Also, the comparative information can be used by a reviewer for evaluation or utilization purposes.", "authors": ["Gary Thomas McIlroy", "Julie Ellen Kees", "Jacquelyn Ann Kalscheuer"], "related_topics": ["160735492", "147268084", "2780182762"], "citation_count": "829", "reference_count": "40", "references": ["3140998105", "2837533624", "1958094816", "2116933999", "1508780532", "2812251111", "1892798732", "1858703886", "1950862198", "1891233570"], "date": "1997"}, {"id": "2103749601", "title": "Sum capacity of the vector Gaussian broadcast channel and uplink-downlink duality", "abstract": "We characterize the sum capacity of the vector Gaussian broadcast channel by showing that the existing inner bound of Marton and the existing upper bound of Sato are tight for this channel. We exploit an intimate four-way connection between the vector broadcast channel, the corresponding point-to-point channel (where the receivers can cooperate), the multiple-access channel (MAC) (where the role of transmitters and receivers are reversed), and the corresponding point-to-point channel (where the transmitters can cooperate).", "authors": ["P. Viswanath", "D.N.C. Tse"], "related_topics": ["97744766", "2780186295", "156996364"], "citation_count": "1508", "reference_count": "20", "references": ["2130509920", "2151795416", "2145403270", "2121233130", "2139706615", "1976109068", "1922943911", "1919846929", "1537514565", "2154717086"], "date": "2003"}, {"id": "2094448442", "title": "Complementary DNA sequencing : expressed sequence tags and human genome project", "abstract": "Automated partial DNA sequencing was conducted on more than 600 randomly selected human brain complementary DNA (cDNA) clones to generate expressed sequence tags (ESTs). ESTs have applications in the discovery of new human genes, mapping of the human genome, and identification of coding regions in genomic sequences. Of the sequences generated, 337 represent new genes, including 48 with significant similarity to genes from other organisms, such as a yeast RNA polymerase II subunit; Drosophila kinesin, Notch, and Enhancer of split; and a murine tyrosine kinase receptor. Forty-six ESTs were mapped to chromosomes after amplification by the polymerase chain reaction. This fast approach to cDNA characterization will facilitate the tagging of most human genes in a few years at a fraction of the cost of complete genomic sequencing, provide new genetic markers, and serve as a resource in diverse biological research fields.", "authors": ["Adams", "JM Kelley", "JD Gocayne", "M Dubnick", "MH Polymeropoulos", "H Xiao", "CR Merril", "A Wu", "B Olde", "RF Moreno"], "related_topics": ["149034497", "89566754", "51679486"], "citation_count": "3464", "reference_count": "27", "references": ["2055043387", "2015292449", "2009310436", "2784619191", "2115149771", "2006698454", "2052503008", "2082631326", "2026710989", "2124620276"], "date": "1991"}, {"id": "1593793857", "title": "Local computations with probabilities on graphical structures and their application to expert systems", "abstract": "", "authors": ["S. L. Lauritzen", "D. J. Spiegelhalter"], "related_topics": ["58328972", "169272836", "49937458"], "citation_count": "5409", "reference_count": "130", "references": ["1498436455", "1997063559", "2797148637", "2155322595", "2138162238", "2143075689", "2143474538", "2166325326", "1516964807", "1549872659"], "date": "1990"}, {"id": "2125756925", "title": "Human image understanding : Recent research and a theory", "abstract": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into simple volumetric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of components [ N probably \u2264 36] can be derived from contrasts of five readily detectable properties of edges in a 2-dimensional image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position and image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. A principle of componential recovery can account for the major phenomena of object recognition: If an arrangement of two or three primitive components can be recovered from the input, objects can be quickly recognized even when they are occluded, rotated in depth, novel, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory.", "authors": ["Irving Biederman"], "related_topics": ["64876066", "55020928", "49209780"], "citation_count": "2031", "reference_count": "55", "references": ["2740373864", "2149095485", "2059975159", "2073257493", "1513966746", "2059799772", "2032533296", "1501418839", "1984314602", "2065343501"], "date": "1985"}, {"id": "2165290000", "title": "Shrinkability Maps for Content\u2010Aware Video Resizing", "abstract": "A novel method is given for content-aware video resizing, i.e. targeting video to a new resolution (which may involve aspect ratio change) from the original. We precompute a per-pixel cumulative shrinkability map which takes into account both the importance of each pixel and the need for continuity in the resized result. (If both x and y resizing are required, two separate shrinkability maps are used, otherwise one suffices). A random walk model is used for efficient offline computation of the shrinkability maps. The latter are stored with the video to create a multi-sized video, which permits arbitrarysized new versions of the video to be later very efficiently created in real-time, e.g. by a video-on-demand server supplying video streams to multiple devices with different resolutions. These shrinkability maps are highly compressible, so the resulting multi-sized videos are typically less than three times the size of the original compressed video. A scaling function operates on the multi-sized video, to give the new pixel locations in the result, giving a high-quality content-aware resized video. Despite the great efficiency and low storage requirements for our method, we produce results of comparable quality to state-of-the-art methods for content-aware image and video resizing.", "authors": ["Yi-Fei Zhang", "Shi-Min Hu", "Ralph Robert Martin"], "related_topics": ["65483669", "151211776", "202474056"], "citation_count": "123", "reference_count": "12", "references": ["2125637308", "2018377917", "2132610780", "2154118576", "3137241515", "1487563192", "2166554908", "2997945685", "1980852932", "2073895861"], "date": "2008"}, {"id": "2115022330", "title": "Measurement and analysis of online social networks", "abstract": "Online social networking sites like Orkut, YouTube, and Flickr are among the most popular sites on the Internet. Users of these sites form a social network, which provides a powerful means of sharing, organizing, and finding content and contacts. The popularity of these sites provides an opportunity to study the characteristics of online social network graphs at large scale. Understanding these graphs is important, both to improve current systems and to design new applications of online social networks.This paper presents a large-scale measurement study and analysis of the structure of multiple online social networks. We examine data gathered from four popular online social networks: Flickr, YouTube, LiveJournal, and Orkut. We crawled the publicly accessible user links on each site, obtaining a large portion of each social network's graph. Our data set contains over 11.3 million users and 328 million links. We believe that this is the first study to examine multiple online social networks at scale.Our results confirm the power-law, small-world, and scale-free properties of online social networks. We observe that the indegree of user nodes tends to match the outdegree; that the networks contain a densely connected core of high-degree nodes; and that this core links small groups of strongly clustered, low-degree nodes at the fringes of the network. Finally, we discuss the implications of these structural properties for the design of social network based systems.", "authors": ["Alan Mislove", "Massimiliano Marcon", "Krishna P. Gummadi", "Peter Druschel", "Bobby Bhattacharjee"], "related_topics": ["503923677", "36647736", "86256295"], "citation_count": "3920", "reference_count": "44", "references": ["2112090702", "2008620264", "2138621811", "1854214752", "1971421925", "2000042664", "2061901927", "1976969221", "3125161049", "2125315567"], "date": "2007"}, {"id": "1968560005", "title": "Stochastic properties of the random waypoint mobility model", "abstract": "The random waypoint model is a commonly used mobility model for simulations of wireless communication networks. By giving a formal description of this model in terms of a discrete-time stochastic process, we investigate some of its fundamental stochastic properties with respect to: (a) the transition length and time of a mobile node between two waypoints, (b) the spatial distribution of nodes, (c) the direction angle at the beginning of a movement transition, and (d) the cell change rate if the model is used in a cellular-structured system area. The results of this paper are of practical value for performance analysis of mobile networks and give a deeper understanding of the behavior of this mobility model. Such understanding is necessary to avoid misinterpretation of simulation results. The movement duration and the cell change rate enable us to make a statement about the \"degree of mobility\" of a certain simulation scenario. Knowledge of the spatial node distribution is essential for all investigations in which the relative location of the mobile nodes is important. Finally, the direction distribution explains in an analytical manner the effect that nodes tend to move back to the middle of the system area.", "authors": ["Christian Bettstetter", "Hannes Hartenstein", "Xavier P\u00e9rez-Costa"], "related_topics": ["2778763662", "191485582", "8272713"], "citation_count": "1072", "reference_count": "26", "references": ["2132932625", "2164192722", "2942228371", "2161457646", "2213553754", "2049176600", "2053694592", "1966415263", "2716117101", "1497763074"], "date": "2004"}, {"id": "2137073979", "title": "Performance analysis of generalized-faded coherent PSK channels with equal-gain combining and carrier phase error", "abstract": "A new method is developed to analyze the performance of partially coherent PSK systems in wireless channels with equal-gain combining diversity receiver. Two performance criteria are considered: the average bit error probability and the probability distribution of the combiner SNR (SNR reliability). Tikhonov-distributed phase error processes are assumed and generalized fading channels including Rayleigh, Rician, and Nakagami-m are investigated. We evaluate the detection loss suffered by the carrier recovery for different SNR reliability levels when BPSK and QPSK systems are used in wireless channels. The analysis is based on a convergent infinite series for the distribution of the sum of random variables. The convergence rate of the proposed series is investigated and the analytical results are presented along with providing results obtained by simulation.", "authors": ["M.A. Smadi", "V.K. Prabhu"], "related_topics": ["17877974", "60472773", "115098869"], "citation_count": "29", "reference_count": "13", "references": ["2506285684", "2108165364", "2041121275", "2108216492", "2104820507", "2157005274", "2098144684", "1999716262", "2130934944", "2096601244"], "date": "2006"}, {"id": "2162915993", "title": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories", "abstract": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u0092s \"gist\" and Lowe\u0092s SIFT descriptors.", "authors": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "related_topics": ["79284318", "69952321", "167611913"], "citation_count": "9939", "reference_count": "28", "references": ["1880262756", "2154422044", "2107034620", "1566135517", "2166049352", "2104978738", "2914885528", "2168002178", "2134731454", "2165828254"], "date": "2006"}, {"id": "3145506661", "title": "Introduction to Machine Learning", "abstract": "Machine learning is evolved from a collection of powerful techniques in AI areas and has been extensively used in data mining, which allows the system to learn the useful structural patterns and models from training data. Machine learning algorithms can be basically classified into four categories: supervised, unsupervised, semi-supervised and reinforcement learning. In this chapter, widely-used machine learning algorithms are introduced. Each algorithm is briefly explained with some examples.", "authors": ["F. Richard Yu", "Ying He"], "related_topics": ["97541855", "119857082", "41008148"], "citation_count": "9607", "reference_count": "43", "references": ["2618530766", "2919115771", "2911964244", "2140190241", "2148603752", "2124776405", "2076063813", "2064675550", "1480376833", "2125838338"], "date": "2018"}, {"id": "2119089847", "title": "Six-Month Prevalence of Psychiatric Disorders in Three Communities: 1980 to 1982", "abstract": "\u2022 Six-month prevalence rates for selected DSM-III psychiatric disorders are reported based on community surveys in New Haven, Conn, Baltimore, and St Louis. As part of the Epidemiologic Catchment Area program, data were gathered on more than 9,000 adults, employing the Diagnostic Interview Schedule to collect information to make a diagnosis. The most common disorders found were phobias, alcohol abuse and/or dependence, dysthymia, and major depression. The most common diagnoses for women were phobias and major depression, whereas for men, the most predominant disorder was alcohol abuse and/or dependence. Rates of psychiatric disorders dropped sharply after age 45 years.", "authors": ["Jerome K. Myers", "Myrna M. Weissman", "Gary L. Tischler", "Charles E. Holzer", "Philip J. Leaf", "Helen Orvaschel", "James C. Anthony", "Jeffrey H. Boyd", "Jack D. Burke", "Morton Kramer", "Roger Stoltzman"], "related_topics": ["140682164", "145734003", "2780931562"], "citation_count": "2333", "reference_count": "17", "references": ["1847168837", "2050768782", "2049165791", "1974702488", "2060200544", "2118532778", "2764362690", "2067342292", "1966236911", "2107267159"], "date": "1984"}, {"id": "1829379010", "title": "Lexical methods for managing variation in biomedical terminologies.", "abstract": "Abstract Access to biomedical terminologies is hampered by the high degree of variability inherent in natural language terms and in the terminologies themselves. The lexicon, lexical programs, databases, and indexes included with the 1994 release of the UMLS Knowledge Sources are designed to help users manage this variability. We describe these resources and illustrate their flexibility and usefulness in providing enhanced access to data in the UMLS Metathesaurus.", "authors": ["A. T. McCray", "S. Srinivasan", "A. C. Browne"], "related_topics": ["69505689", "2778121359", "195324797"], "citation_count": "373", "reference_count": "0", "references": ["1550258693", "2098201295", "2270018644", "2144001613", "2023736097", "2144949988", "2088561970", "2046747418", "2121244856", "1818857488"], "date": "1993"}, {"id": "1125023678", "title": "Education for Life and Work: Developing Transferable Knowledge and Skills in the 21st Century", "abstract": "Americans have long recognized that investments in public education contribute to the common good, enhancing national prosperity and supporting stable families, neighborhoods, and communities. Education is even more critical today, in the face of economic, environmental, and social challenges. Today's children can meet future challenges if their schooling and informal learning activities prepare them for adult roles as citizens, employees, managers, parents, volunteers, and entrepreneurs. To achieve their full potential as adults, young people need to develop a range of skills and knowledge that facilitate mastery and application of English, mathematics, and other school subjects. At the same time, business and political leaders are increasingly asking schools to develop skills such as problem solving, critical thinking, communication, collaboration, and self-management - often referred to as \"21st century skills.\" Education for Life and Work: Developing Transferable Knowledge and Skills in the 21st Century describes this important set of key skills that increase deeper learning, college and career readiness, student-centered learning, and higher order thinking. These labels include both cognitive and non-cognitive skills- such as critical thinking, problem solving, collaboration, effective communication, motivation, persistence, and learning to learn. 21st century skills also include creativity, innovation, and ethics that are important to later success and may be developed in formal or informal learning environments. This report also describes how these skills relate to each other and to more traditional academic skills and content in the key disciplines of reading, mathematics, and science. Education for Life and Work: Developing Transferable Knowledge and Skills in the 21st Century summarizes the findings of the research that investigates the importance of such skills to success in education, work, and other areas of adult responsibility and that demonstrates the importance of developing these skills in K-16 education. In this report, features related to learning these skills are identified, which include teacher professional development, curriculum, assessment, after-school and out-of-school programs, and informal learning centers such as exhibits and museums.", "authors": ["James W. Pellegrino", "Margaret L. Hilton", "st Century Skills"], "related_topics": ["2778308277", "97082442", "20574239"], "citation_count": "1118", "reference_count": "301", "references": ["2147264455", "2116199508", "2116817443", "1761828760", "2886409168", "2520660681", "2128689084", "2037124948", "1976637107", "1967555382"], "date": "2013"}, {"id": "2119217392", "title": "Multilevel analysis in public health research", "abstract": "Over the past few years there has been growing interest in considering factors defined at multiple levels in public health research. Multilevel analysis has emerged as one analytical strategy that may partly address this need, by allowing the simultaneous examination of group-level and individual-level factors. This paper reviews the rationale for using multilevel analysis in public health research, summarizes the statistical methodology, and highlights some of the research questions that have been addressed using these methods. The advantages and disadvantages of multilevel analysis compared with standard methods are reviewed. The use of multilevel analysis raises theoretical and methodological issues related to the theoretical model being tested, the conceptual distinction between group- and individual-level variables, the ability to differentiate \"independent\" effects, the reciprocal relationships between factors at different levels, and the increased complexity that these models imply. The potentialities and limitations of multilevel analysis, within the broader context of understanding the role of factors defined at multiple levels in shaping health outcomes, are discussed.", "authors": ["Ana V. Diez-Roux"], "related_topics": ["53059260", "29719523", "2780049985"], "citation_count": "1391", "reference_count": "101", "references": ["2324392187", "2145816995", "2082107925", "2082246284", "1976566530", "2030769837", "2070706581", "2103479150", "2058463674", "2797458901"], "date": "1999"}, {"id": "2103546861", "title": "A simple, fast, and accurate algorithm to estimate large phylogenies by maximum likelihood.", "abstract": "The increase in the number of large data sets and the complexity of current probabilistic sequence evolution models necessitates fast and reliable phylogeny reconstruction methods. We describe a new approach, based on the maximum- likelihood principle, which clearly satisfies these requirements. The core of this method is a simple hill-climbing algorithm that adjusts tree topology and branch lengths simultaneously. This algorithm starts from an initial tree built by a fast distance-based method and modifies this tree to improve its likelihood at each iteration. Due to this simultaneous adjustment of the topology and branch lengths, only a few iterations are sufficient to reach an optimum. We used extensive and realistic computer simulations to show that the topological accuracy of this new method is at least as high as that of the existing maximum-likelihood programs and much higher than the performance of distance-based and parsimony approaches. The reduction of computing time is dramatic in comparison with other maximum-likelihood packages, while the likelihood maximization ability tends to be higher. For example, only 12 min were required on a standard personal computer to analyze a data set consisting of 500 rbcL sequences with 1,428 base pairs from plant plastids, thus reaching a speed of the same order as some popular distance-based and parsimony algorithms. This new method is implemented in the PHYML program, which is freely available on our web page: http://www.lirmm.fr/w3ifa/MAAS/. (Algorithm; computer simulations; maximum likelihood; phylogeny; rbcL; RDPII project.) The size of homologous sequence data sets has in- creased dramatically in recent years, and many of these data sets now involve several hundreds of taxa. More- over, current probabilistic sequence evolution models (Swofford et al., 1996 ; Page and Holmes, 1998 ), notably those including rate variation among sites (Uzzell and Corbin, 1971 ; Jin and Nei, 1990 ; Yang, 1996 ), require an increasing number of calculations. Therefore, the speed of phylogeny reconstruction methods is becoming a sig- nificant requirement and good compromises between speed and accuracy must be found. The maximum likelihood (ML) approach is especially accurate for building molecular phylogenies. Felsenstein (1981) brought this framework to nucleotide-based phy- logenetic inference, and it was later also applied to amino acid sequences (Kishino et al., 1990). Several vari- ants were proposed, most notably the Bayesian meth- ods (Rannala and Yang 1996; and see below), and the discrete Fourier analysis of Hendy et al. (1994), for ex- ample. Numerous computer studies (Huelsenbeck and Hillis, 1993; Kuhner and Felsenstein, 1994; Huelsenbeck, 1995; Rosenberg and Kumar, 2001; Ranwez and Gascuel, 2002) have shown that ML programs can recover the cor- rect tree from simulated data sets more frequently than other methods can. Another important advantage of the ML approach is the ability to compare different trees and evolutionary models within a statistical framework (see Whelan et al., 2001, for a review). However, like all optimality criterion-based phylogenetic reconstruction approaches, ML is hampered by computational difficul- ties, making it impossible to obtain the optimal tree with certainty from even moderate data sets (Swofford et al., 1996). Therefore, all practical methods rely on heuristics that obtain near-optimal trees in reasonable computing time. Moreover, the computation problem is especially difficult with ML, because the tree likelihood not only depends on the tree topology but also on numerical pa- rameters, including branch lengths. Even computing the optimal values of these parameters on a single tree is not an easy task, particularly because of possible local optima (Chor et al., 2000). The usual heuristic method, implemented in the pop- ular PHYLIP (Felsenstein, 1993 ) and PAUP \u2217 (Swofford, 1999 ) packages, is based on hill climbing. It combines stepwise insertion of taxa in a growing tree and topolog- ical rearrangement. For each possible insertion position and rearrangement, the branch lengths of the resulting tree are optimized and the tree likelihood is computed. When the rearrangement improves the current tree or when the position insertion is the best among all pos- sible positions, the corresponding tree becomes the new current tree. Simple rearrangements are used during tree growing, namely \"nearest neighbor interchanges\" (see below), while more intense rearrangements can be used once all taxa have been inserted. The procedure stops when no rearrangement improves the current best tree. Despite significant decreases in computing times, no- tably in fastDNAml (Olsen et al., 1994 ), this heuristic becomes impracticable with several hundreds of taxa. This is mainly due to the two-level strategy, which sepa- rates branch lengths and tree topology optimization. In- deed, most calculations are done to optimize the branch lengths and evaluate the likelihood of trees that are finally rejected. New methods have thus been proposed. Strimmer and von Haeseler (1996) and others have assembled four- taxon (quartet) trees inferred by ML, in order to recon- struct a complete tree. However, the results of this ap- proach have not been very satisfactory to date (Ranwez and Gascuel, 2001 ). Ota and Li (2000, 2001) described", "authors": ["St\u00e9phane Guindon", "Olivier Gascuel"], "related_topics": ["53208351", "84927040", "68775195"], "citation_count": "17437", "reference_count": "48", "references": ["2170120409", "2164789250", "2097706568", "2161444534", "2030966943", "2994240441", "2144775551", "2065461553", "2105926960", "2017519756"], "date": "2003"}, {"id": "1528905581", "title": "Generalized Linear Models", "abstract": "The technique of iterative weighted linear regression can be used to obtain maximum likelihood estimates of the parameters with observations distributed according to some exponential family and systematic effects that can be made linear by a suitable transformation. A generalization of the analysis of variance is given for these models using log- likelihoods. These generalized linear models are illustrated by examples relating to four distributions; the Normal, Binomial (probit analysis, etc.), Poisson (contingency tables) and gamma (variance components).", "authors": ["Peter McCullagh", "John Ashworth Nelder"], "related_topics": ["41587187", "153720581", "91025261"], "citation_count": "28689", "reference_count": "42", "references": ["2611591252", "2995133996", "2074673068", "2796930440", "2556205749", "2102041666", "2798510847", "2082102453", "2801490189", "2123838014"], "date": "1982"}, {"id": "2075893676", "title": "How reliable are the results of large-scale information retrieval experiments?", "abstract": "Two stages in measurement of techniques for information retrieval are gathering of documents for relevance assessment and use of the assessments to numerically evaluate effectiveness. We consider both of these stages in the context of the TREC experiments, to determine whether they lead to measurements that are trustworthy and fair. Our detailed empirical investigation of the TREC results shows that the measured relative performance of systems appears to be reliable, but that recall is overestimated: it is likely that many relevant documents have not been found. We propose a new pooling strategy that can significantly in- crease the number of relevant documents found for given effort, without compromising fairness.", "authors": ["Justin Zobel"], "related_topics": ["87546605", "2780049985", "23123220"], "citation_count": "642", "reference_count": "15", "references": ["2032459394", "2141527751", "1975730959", "2141623655", "2151664495", "1967345182", "2077046902", "2117030594", "75771211", "2069820131"], "date": "1998"}, {"id": "2081155210", "title": "The need to belong: Desire for interpersonal attachments as a fundamental human motivation.", "abstract": "A hypothesized need to form and maintain strong, stable interpersonal relationships is evaluated in light of the empirical literature. The need is for frequent, nonaversive interactions within an ongoing relational bond. Consistent with the belongingness hypothesis, people form social attachments readily under most conditions and resist the dissolution of existing bonds. Belongingness appears to have multiple and strong effects on emotional patterns and on cognitive processes. Lack of attachments is linked to a variety of ill effects on health, adjustment, and well-being. Other evidence, such as that concerning satiation, substitution, and behavioral consequences, is likewise consistent with the hypothesized motivation. Several seeming counterexamples turned out not to disconfirm the hypothesis. Existing evidence supports the hypothesis that the need to belong is a powerful, fundamental, and extremely pervasive motivation.", "authors": ["Roy F. Baumeister", "Mark R. Leary"], "related_topics": ["74177177", "115085983", "2781296468"], "citation_count": "25297", "reference_count": "278", "references": ["2062663664", "2055461003", "2332321565", "1963794200", "1720881856", "2099365033", "2034235631", "2153155150", "2124668684", "2152938859"], "date": "1995"}, {"id": "2174298480", "title": "Significant-Loophole-Free Test of Bell's Theorem with Entangled Photons", "abstract": "Local realism is the worldview in which physical properties of objects exist independently of measurement and where physical influences cannot travel faster than the speed of light. Bell's theorem states that this worldview is incompatible with the predictions of quantum mechanics, as is expressed in Bell's inequalities. Previous experiments convincingly supported the quantum predictions. Yet, every experiment requires assumptions that provide loopholes for a local realist explanation. Here, we report a Bell test that closes the most significant of these loopholes simultaneously. Using a well-optimized source of entangled photons, rapid setting generation, and highly efficient superconducting detectors, we observe a violation of a Bell inequality with high statistical significance. The purely statistical probability of our results to occur under local realism does not exceed 3.74\u00d710^{-31}, corresponding to an 11.5 standard deviation effect.", "authors": ["Marissa Giustina", "", "Marijn A. M. Versteegh", "", "Soeren Wengerowsky", "", "Johannes Handsteiner", "", "Armin Hochrainer", "", "Kevin Phelan", "Fabian Steinlechner", "Johannes Kofler", "Jan-Ake Larsson", "Carlos Abellan", "Waldimar Amaya", "Valerio Pruneri", "", "Morgan W. Mitchell", "", "Joern Beyer", "Thomas Gerrits", "Adriana E. Lita", "Lynden K. Shalm", "Sae Woo Nam", "Thomas Scheidl", "", "Rupert Ursin", "Bernhard Wittmann", "", "Anton Zeilinger", ""], "related_topics": ["11511207", "36494176", "118704821"], "citation_count": "1047", "reference_count": "39", "references": ["1709784975", "2084883086", "2762179548", "1963898916", "2629854316", "2066592527", "2786198409", "1616015000", "2006166792", "1994712115"], "date": "2015"}, {"id": "2059334100", "title": "Structural Equations with Latent Variables", "abstract": "Model Notation, Covariances, and Path Analysis. Causality and Causal Models. Structural Equation Models with Observed Variables. The Consequences of Measurement Error. Measurement Models: The Relation Between Latent and Observed Variables. Confirmatory Factor Analysis. The General Model, Part I: Latent Variable and Measurement Models Combined. The General Model, Part II: Extensions. Appendices. Distribution Theory. References. Index.", "authors": ["Kenneth A. Bollen"], "related_topics": ["65965080", "51167844", "70727504"], "citation_count": "25897", "reference_count": "0", "references": ["2038702827", "2106096361", "1913957972", "1988050849", "2115988342", "2105846236", "2090330784", "2162437324", "2115217290", "2104057213"], "date": "1989"}, {"id": "2034147186", "title": "Imagine: media processing with streams", "abstract": "The power-efficient Imagine stream processor achieves performance densities comparable to those of special-purpose embedded processors. Executing programs mapped to streams and kernels, a single Imagine processor is expected to have a peak performance of 20 gflops and sustain 18.3 gops on mpeg-2 encoding.", "authors": ["B. Khailany", "W.J. Dally", "U.J. Kapasi", "P. Mattson", "J. Namkoong", "J.D. Owens", "B. Towles", "A. Chang", "S. Rixner"], "related_topics": ["52027705", "107027933", "107598950"], "citation_count": "497", "reference_count": "14", "references": ["2115172404", "2156413870", "2148051985", "2170879098", "2005128309", "2164909551", "1482960371", "1995186727", "2225811560", "2132587889"], "date": "2001"}, {"id": "73274768", "title": "Dependency-Based Evaluation of Minipar", "abstract": "In this paper, we first present a dependency-based method for parser evaluation. We then use the method to evaluate a broad-coverage parser, called MINIPAR, with the SUSANNE corpus. The method allows us to evaluate not only the overall performance of the parser, but also its performance with respect to different grammatical relationships and phenomena. The evaluation results show that MINIPAR is able to cover about 79% of the dependency relationships in the SUSANNE corpus with about 89% precision.", "authors": ["Dekang Lin"], "related_topics": ["19768560", "186644900", "2780428219"], "citation_count": "937", "reference_count": "18", "references": ["1632114991", "2102381086", "1996672843", "2110882317", "1986543644", "2153439141", "2087165009", "2142708806", "2109779030", "1984454122"], "date": "2002"}, {"id": "1523741643", "title": "Firefly algorithms for multimodal optimization", "abstract": "Nature-inspired algorithms are among the most powerful algorithms for optimization. This paper intends to provide a detailed description of a new Firefly Algorithm (FA) for multimodal optimization applications. We will compare the proposed firefly algorithm with other metaheuristic algorithms such as particle swarm optimization (PSO). Simulations and results indicate that the proposed firefly algorithm is superior to existing metaheuristic algorithms. Finally we will discuss its applications and implications for further research.", "authors": ["Xin-She Yang"], "related_topics": ["154982244", "28767586", "109718341"], "citation_count": "3721", "reference_count": "10", "references": ["2152195021", "2904250082", "1639032689", "1596914020", "2126554879", "2122122715", "1480600971", "2119899283", "2001471353", "2963434200"], "date": "2009"}, {"id": "2480934907", "title": "Glossary of transcript symbols with an introduction", "abstract": "", "authors": ["Gail Jefferson"], "related_topics": ["2780031656", "15744967", "41895202"], "citation_count": "3554", "reference_count": "0", "references": ["2560150188", "2083046848", "1509082030", "854457695", "3008466924", "2783092519", "1968344361", "2140349367", "2131138340", "2486097230"], "date": "2004"}, {"id": "2021142183", "title": "The Analysis of Variance", "abstract": "Originally published in 1959, this classic volume has had a major impact on generations of statisticians. Newly issued in the Wiley Classics Series, the book examines the basic theory of analysis of variance by considering several different mathematical models. Part I looks at the theory of fixed-effects models with independent observations of equal variance, while Part II begins to explore the analysis of variance in the case of other models.", "authors": ["Henry Scheff\u00e9"], "related_topics": ["196083921", "40486484", "76969082"], "citation_count": "10136", "reference_count": "0", "references": ["2087484885", "2141845152", "2164777277", "2047028564", "2116649573", "2126693856", "2023370307", "2141403362", "2113144077", "2125860227"], "date": "1960"}, {"id": "2151289144", "title": "An experimental study of the effect of language on the reproduction of visually perceived form.", "abstract": "The experiments reported in this paper are part of a study of the conditions which affect the reproduction of visually perceived form. Previous investigators such as G. E. Muller, F. Wulf, and J. J. Gibson 8 have pointed out various factors which are important in bringing about the changes that occur in reproduced forms when they are compared with the forms as originally presented. In the present study an effort has been made to control by experimental means the nature of the change in form. The directive agency used was language, or, more precisely, those processes of the organism that are initiated by language. Historically, Muller treats of the changes that take place after the passage of time in the reproduction of perceived forms in terms which include such concepts as 'convergence' or 'blurring' of the characteristic features of patterns. F. Wulf criticizes this view and proposes, on the basis of experimental study, to describe the observed changes in terms of such specific tendencies as 'sharpening,' 'levelling' and what may be termed the 'equilibrium tendency' in the structure. He remarks, however, that in some instances his subjects spontaneously identified the presented forms with 1 Muller, G. E., Zur Analyse der GedachtnistStigkeit und dee Vorstellungsverlaufes, III. Teil, Zeitsckriftfur Psyehologie, Erganzungsband, 1913, 8, 1-567. 1 Wulf, F., tJber die Veranderung von Vorstellungen (Gedachtnis und Gestalt) (Beitrage zur Psyehologie der Gestalt), Psychologische Forsckung, 1921, x, 333-373. * Gibson, J. J., The reproduction of visually perceived forms, / . Exper. Psychol.,", "authors": ["L. Carmichael", "H. P. Hogan", "A. A. Walter"], "related_topics": ["27362006", "193656293", "2776035688"], "citation_count": "553", "reference_count": "0", "references": ["2145998149", "2065808876", "2153310670", "1979104110", "2065003940", "2321152021", "1984314602", "2049324847", "1496523069", "2084636435"], "date": "1932"}, {"id": "2046294138", "title": "A Theory of Some Multiple Decision Problems. II", "abstract": "The theory of Part I is extended to problems in which it is permitted not to come to a definite conclusion regarding one or more of the questions under consideration. Some problems are also investigated in which, from a single set of observations, one wishes to answer a number of questions in sequence. Here the nature of the question at a later stage will depend on the answers obtained at the earlier stages.", "authors": ["E. L. Lehmann"], "related_topics": ["115988155", "165120375", "37724570"], "citation_count": "191", "reference_count": "15", "references": ["2092713296", "2025918513", "2076327797", "2037892350", "2326851176", "1996509535", "2024113512", "2034555244", "2010028868", "1972564458"], "date": "1957"}, {"id": "2116199508", "title": "Situated Learning: Legitimate Peripheral Participation", "abstract": "In this important theoretical treatist, Jean Lave, anthropologist, and Etienne Wenger, computer scientist, push forward the notion of situated learning - that learning is fundamentally a social process. The authors maintain that learning viewed as situated activity has as its central defining characteristic a process they call legitimate peripheral participation (LPP). Learners participate in communities of practitioners, moving toward full participation in the sociocultural practices of a community. LPP provides a way to speak about crucial relations between newcomers and old-timers and about their activities, identities, artefacts, knowledge and practice. The communities discussed in the book are midwives, tailors, quartermasters, butchers, and recovering alcoholics, however, the process by which participants in those communities learn can be generalised to other social groups.", "authors": ["Jeanne Lave", "Etienne Wenger"], "related_topics": ["200380349", "2777889970", "2776280689"], "citation_count": "84401", "reference_count": "0", "references": ["1980850924", "2164599981", "2130210496", "2147454772", "2120832154", "2149612368", "2163284576", "2139894798", "2086928636", "1565831494"], "date": "1990"}, {"id": "2116737258", "title": "Where should the bugs be fixed? - more accurate information retrieval-based bug localization based on bug reports", "abstract": "For a large and evolving software system, the project team could receive a large number of bug reports. Locating the source code files that need to be changed in order to fix the bugs is a challenging task. Once a bug report is received, it is desirable to automatically point out to the files that developers should change in order to fix the bug. In this paper, we propose BugLocator, an information retrieval based method for locating the relevant files for fixing a bug. BugLocator ranks all files based on the textual similarity between the initial bug report and the source code using a revised Vector Space Model (rVSM), taking into consideration information about similar bugs that have been fixed before. We perform large-scale experiments on four open source projects to localize more than 3,000 bugs. The results show that BugLocator can effectively locate the files where the bugs should be fixed. For example, relevant buggy files for 62.60% Eclipse 3.1 bugs are ranked in the top ten among 12,863 files. Our experiments also show that BugLocator outperforms existing state-of-the-art bug localization methods.", "authors": ["Jian Zhou", "Hongyu Zhang", "David Lo"], "related_topics": ["1009929", "43126263", "149091818"], "citation_count": "548", "reference_count": "36", "references": ["1880262756", "1532325895", "1574901103", "2148212498", "2079317829", "2101819268", "2162376048", "2162045655", "2170224888", "2160517961"], "date": "2012"}, {"id": "2064480843", "title": "Sequential Monte Carlo methods for dynamic systems", "abstract": "Abstract We provide a general framework for using Monte Carlo methods in dynamic systems and discuss its wide applications. Under this framework, several currently available techniques are studied and generalized to accommodate more complex features. All of these methods are partial combinations of three ingredients: importance sampling and resampling, rejection sampling, and Markov chain iterations. We provide guidelines on how they should be used and under what circumstance each method is most suitable. Through the analysis of differences and connections, we consolidate these methods into a generic algorithm by combining desirable features. In addition, we propose a general use of Rao-Blackwellization to improve performance. Examples from econometrics and engineering are presented to demonstrate the importance of Rao\u2013Blackwellization and to compare different Monte Carlo procedures.", "authors": ["Jun S. Liu", "Rong Chen"], "related_topics": ["111350023", "13153151", "187192777"], "citation_count": "2938", "reference_count": "36", "references": ["2125838338", "2098613108", "2118502261", "2083875149", "2136796925", "2131598171", "2077611006", "1481420047", "2102122585", "1521042556"], "date": "1996"}, {"id": "1974403130", "title": "PARAFAC: parallel factor analysis", "abstract": "We review the method of Parallel Factor Analysis, which simultaneously fits multiple two-way arrays or \u2018slices\u2019 of a three-way array in terms of a common set of factors with differing relative weights in each \u2018slice\u2019. Mathematically, it is a straightforward generalization of the bilinear model of factor (or component) analysis (xij = \u03a3Rr = 1airbjr) to a trilinear model (xijk = \u03a3Rr = 1airbjrckr). Despite this simplicity, it has an important property not possessed by the two-way model: if the latent factors show adequately distinct patterns of three-way variation, the model is fully identified; the orientation of factors is uniquely determined by minimizing residual error, eliminating the need for a separate \u2018rotation\u2019 phase of analysis. The model can be used several ways. It can be directly fit to a three-way array of observations with (possibly incomplete) factorial structure, or it can be indirectly fit to the original observations by fitting a set of covariance matrices computed from the observations, with each matrix corresponding to a two-way subset of the data. Even more generally, one can simultaneously analyze covariance matrices computed from different samples, perhaps corresponding to different treatment groups, different kinds of cases, data from different studies, etc. To demonstrate the method we analyze data from an experiment on right vs. left cerebral hemispheric control of the hands during various tasks. The factors found appear to correspond to the causal influences manipulated in the experiment, revealing their patterns of influence in all three ways of the data. Several generalizations of the parallel factor analysis model are currently under development, including ones that combine parallel factors with Tucker-like factor \u2018interactions\u2019. Of key importance is the need to increase the method's robustness against nonstationary factor structures and qualitative (nonproportional) factor change.", "authors": ["Richard A. Harshman", "Margaret E. Lundy"], "related_topics": ["178650346", "27438332", "177148314"], "citation_count": "581", "reference_count": "44", "references": ["2124181495", "1973967548", "2000215628", "3012395598", "2057503509", "137381930", "2238191081", "1986831759", "1963826206", "2041541191"], "date": "1994"}, {"id": "2165702945", "title": "The Struggle to Govern the Commons", "abstract": "Human institutions\u2014ways of organizing activities\u2014affect the resilience of the environment. Locally evolved institutional arrangements governed by stable communities and buffered from outside forces have sustained resources successfully for centuries, although they often fail when rapid change occurs. Ideal conditions for governance are increasingly rare. Critical problems, such as transboundary pollution, tropical deforestation, and climate change, are at larger scales and involve nonlocal influences. Promising strategies for addressing these problems include dialogue among interested parties, officials, and scientists; complex, redundant, and layered institutions; a mix of institutional types; and designs that facilitate experimentation, learning, and change.", "authors": ["Thomas Dietz", "Elinor Ostrom", "Paul C. Stern"], "related_topics": ["49427245", "137176749", "15517945"], "citation_count": "4975", "reference_count": "104", "references": ["2147264455", "2175723801", "91209090", "1731457293", "2048020255", "2077788593", "2031839214", "1974491836", "3122082991", "1560871399"], "date": "2003"}, {"id": "2086426947", "title": "A First Language: The Early Stages", "abstract": "For many years, Roger Brown and his colleagues have studied the developing language of pre-school children--the language that ultimately will permit them to understand themselves and the world around them. This longitudinal research project records the conversational performances of three children, studying both semantic and grammatical aspects of their language development. These core findings are related to recent work in psychology and linguistics--and especially to studies of the acquisition of languages other than English, including Finnish, German, Korean, and Samoan. Roger Brown has written the most exhaustive and searching analysis yet undertaken of the early stages of grammatical constructions and the meanings they convey. The five stages of linguistic development Brown establishes are measured not by chronological age-since children vary greatly in the speed at which their speech develops--but by mean length of utterance. This volume treats the first two stages. Stage I is the threshold of syntax, when children begin to combine words to make sentences. These sentences, Brown shows, are always limited to the same small set of semantic relations: nomination, recurrence, disappearance, attribution, possession, agency, and a few others. Stage II is concerned with the modulations of basic structural meanings--modulations for number, time, aspect, specificity--through the gradual acquisition of grammatical morphemes such as inflections, prepositions, articles, and case markers. Fourteen morphemes are studied in depth and it is shown that the order of their acquisition is almost identical across children and is predicted by their relative semantic and grammaticalcomplexity. It is, ultimately, the intent of this work to focus on the nature and development of knowledge: knowledge concerning grammar and the meanings coded by grammar; knowledge inferred from performance, from sentences and the settings in which they are spoken, and from signs of comprehension or incomprehension of sentences.", "authors": ["Roger William Brown"], "related_topics": ["95918357", "74672266", "26022165"], "citation_count": "6096", "reference_count": "0", "references": ["2106980598", "2569308312", "1593866988", "2152824855", "1546150263", "2501918302", "2101714982", "2165054306", "2396361046", "2099164611"], "date": "1972"}, {"id": "2152056423", "title": "The Stanford FLASH multiprocessor", "abstract": "The FLASH multiprocessor efficiently integrates support for cache-coherent shared memory and high-performance message passing, while minimizing both hardware and software overhead. Each node in FLASH contains a microprocessor, a portion of the machine's global memory, a port to the interconnection network, an I/O interface, and a custom node controller called MAGIC. The MAGIC chip handles all communication both within the node and among nodes, using hardwired data paths for efficient data movement and a programmable processor optimized for executing protocol operations. The use of the protocol processor makes FLASH very flexible --- it can support a variety of different communication mechanisms --- and simplifies the design and implementation.This paper presents the architecture of FLASH and MAGIC, and discusses the base cache-coherence and message-passing protocols. Latency and occupancy numbers, which are derived from our system-level simulator and our Verilog code, are given for several common protocol operations. The paper also describes our software strategy and FLASH's current status.", "authors": ["Jeffrey Kuskin", "David Ofelt", "Mark Heinrich", "John Heinlein", "Richard Simoni", "K. Gharachorloo", "J. Chapin", "D. Nakahira", "J. Baxter", "M. Horowitz", "A. Gupta", "M. Rosenblum", "J. Hennessy"], "related_topics": ["27670709", "96535780", "133875982"], "citation_count": "648", "reference_count": "16", "references": ["1555915743", "2155066383", "1966285605", "2127547524", "2153904572", "1545060479", "2012288359", "2006090396", "2145851359", "1582530102"], "date": "1994"}, {"id": "2080293785", "title": "Parts: A Study in Ontology", "abstract": "The relationship of part to whole is one of the most fundamental there is, yet until now there has been no full-length study of this concept. This book shows that mereology, the formal theory of part and whole, is essential to ontology. Peter Simons surveys and criticizes previous theories, especially the standard extensional view, and proposes a more adequate account which encompasses both temporal and modal considerations in detail. This has far-reaching consequences for our understanding of such classical philosophical concepts as identity, individual, class, substance and accident, matter, form, essence, dependence, and integral whole. It also enables the author to offer new solutions to longstanding problems surrounding these concepts, such as the Ship of Theseus Problem and the issue of mereological essentialism. The author shows by his use of formal techniques that classical philosophical problems are amenable to rigorous treatment, and the book represents a synthesis of issues and methods from the analytical tradition and from the older continental realist tradition of Brentano and the early Husserl. The book is aimed at philosophers, logicians, and linguists.", "authors": ["Peter M. Simons"], "related_topics": ["2777954218", "70530581", "2780648184"], "citation_count": "1534", "reference_count": "0", "references": ["2075123415", "1678959094", "2123171788", "2097395913", "1940888119", "2115902680", "1963354518", "2146871965", "1553976193", "1991183254"], "date": "1986"}, {"id": "2029491572", "title": "Introduction to Theoretical Linguistics", "abstract": "This is a comprehensive introduction to theoretical linguistics. It presupposes no previous knowledge and terms are defined as they are introduced; but it gives a rigorous and technical treatment of a wide range of topics, and brings the reader to an advanced level of understanding. Since its first publication in 1968 Introduction to Theoretical Linguistics has been one of the classic introductions to the discipline. In a field which is often seen as rapidly moving, it will continue to be used by students seeking an overview of the central areas of linguistics - phonetics and phonology, grammar and semantics - and to be of great value to anyone interested in the ways in which theory can help to explain the key problems of human language.", "authors": ["John Lyons"], "related_topics": ["153578388", "26022165", "148934300"], "citation_count": "2554", "reference_count": "0", "references": ["2171161819", "1966812932", "1973826788", "646297848", "2038542953", "2115867364", "2019529630", "2156539109", "2020026127", "2041818183"], "date": "1967"}, {"id": "2115706991", "title": "An Iterative Thresholding Algorithm for Linear Inverse Problems with a Sparsity Constraint", "abstract": "We consider linear inverse problems where the solution is assumed to have a sparse expansion on an arbitrary preassigned orthonormal basis. We prove that replacing the usual quadratic regularizing penalties by weighted p-penalties on the coefficients of such expansions, with 1 \u2264 p \u2264 2, still regularizes the problem. Use of such p-penalized problems with p < 2 is often advocated when one expects the underlying ideal noiseless solution to have a sparse expansion with respect to the basis under consideration. To compute the corresponding regularized solutions, we analyze an iterative algorithm that amounts to a Landweber iteration with thresholding (or nonlinear shrinkage) applied at each iteration step. We prove that this algorithm converges in norm. \u00a9 2004 Wiley Periodicals, Inc.", "authors": ["Ingrid Daubechies", "Michel Defrise", "Christine De Mol"], "related_topics": ["25484224", "159694833", "5806529"], "citation_count": "4858", "reference_count": "40", "references": ["2115755118", "2135046866", "1548802052", "2078204800", "2146842127", "2158940042", "1570089119", "2110505738", "191129667", "1514248469"], "date": "2004"}, {"id": "2149095485", "title": "A feature-integration theory of attention", "abstract": "Abstract A new hypothesis about the role of focused attention is proposed. The feature-integration theory of attention suggests that attention must be directed serially to each stimulus in a display whenever conjunctions of more than one separable feature are needed to characterize or distinguish the possible objects presented. A number of predictions were tested in a variety of paradigms including visual search, texture segregation, identification and localization, and using both separable dimensions (shape and color) and local elements or parts of figures (lines, curves, etc. in letters) as the features to be integrated into complex wholes. The results were in general consistent with the hypothesis. They offer a new set of criteria for distinguishing separable from integral features and a new rationale for predicting which tasks will show attention limits and which will not.", "authors": ["Anne M. Treisman", "Garry Gelade"], "related_topics": ["2776602268", "158495155", "2776310537"], "citation_count": "15991", "reference_count": "34", "references": ["2156046656", "1708089250", "2322677917", "1535782774", "2077763860", "1988660784", "1980429329", "2060032378", "2056101986", "2140403837"], "date": "1979"}, {"id": "2091574658", "title": "Seeing the invisible: the scope and limits of unconscious processing in binocular rivalry.", "abstract": "When an image is presented to one eye and a very different image is presented to the corresponding location of the other eye, the two images compete for conscious representations, such that only one image is visible at a time while the other is suppressed. Called binocular rivalry, this phenomenon and its deviants have been extensively exploited to study the mechanism and neural correlates of consciousness. In this paper, we propose a framework - the unconscious binding hypothesis - to distinguish unconscious processing from conscious processing. According to this framework, the unconscious mind not only encodes individual features but also temporally binds distributed features to give rise to cortical representations; unlike conscious binding, however, unconscious binding is fragile. Under this framework, we review evidence from psychophysical and neuroimaging studies and come to two important conclusions. First, processing of invisible features depends on the \"level\" of the features as defined by their neural mechanisms. For low-level simple features, prolonged exposure to visual patterns (e.g. tilt) and simple translational motion can alter the appearance of subsequent visible features (i.e. adaptation). For invisible high-level features, complex spiral motion cannot produce adaptation, nor can objects/words enhance subsequent processing of related stimuli (i.e. priming). Yet images of tools can activate the dorsal pathway. Second, processing of invisible features has functional significance. Although invisible central cues cannot orient attention, invisible erotic pictures in the periphery can nevertheless guide attention, likely through emotional arousal; reciprocally, the processing of invisible information can be modulated by attention.", "authors": ["Zhicheng Lin", "Sheng He"], "related_topics": ["198313034", "2781017021", "129564537"], "citation_count": "264", "reference_count": "225", "references": ["2019370496", "2158553737", "2123341385", "2098580305", "2232925767", "2109995759", "2164058388", "2113820953", "2160719354", "2133780491"], "date": "2009"}, {"id": "2101419153", "title": "The duality of technology: rethinking the concept of technology in organizations", "abstract": "This paper develops a new theoretical model with which to examine the interaction between technology and organizations. Early research studies assumed technology to be an objective, external force that would have deterministic impacts on organizational properties such as structure. Later researchers focused on the human aspect of technology, seeing it as the outcome of strategic choice and social action. This paper suggests that either view is incomplete, and proposes a reconceptualization of technology that takes both perspectives into account. A theoretical model\u2014the structurational model of technology\u2014is built on the basis of this new conceptualization, and its workings explored through discussion of a field study of information technology. The paper suggests that the reformulation of the technology concept and the structurational model of technology allow a deeper and more dialectical understanding of the interaction between technology and organizations. This understanding provides insight into the li...", "authors": ["Wanda J. Orlikowski"], "related_topics": ["59269818", "2778803364", "121017731"], "citation_count": "6581", "reference_count": "35", "references": ["1791587663", "1963608591", "1595891490", "2095654817", "2127148641", "2801912492", "2144124724", "2061276533", "2134173770", "2016202056"], "date": "2011"}, {"id": "2002557257", "title": "An introduction to the global positioning system and some geological applications", "abstract": "Receivers equipped to measure dual frequency carrier phase signals from satellites of the Global Positioning System (GPS) have been capable, under special conditions, of determining relative horizontal positions among stations separated by one to a few hundred kilometers with a precision of one to several millimeters since the early 1980s. The major obstacles to making this capability routine, extending it to all parts of the globe, and extending it to longer station separations, have been equipment cost, limitations in the GPS satellite constellation, arduous data analysis, uncertainties in satellite orbits, uncertainties in propagation delays associated with variable tropospheric water vapor, and difficulties in resolving carrier phase cycle ambiguities. Recent improvements have occurred in all these areas. The increasing ease and reduced cost of GPS data acquisition and analysis are having a significant impact on studies of near-fault crustal deformation and earthquake processes, until recently the province of conventional terrestrial geodetic techniques. The enhanced satellite constellation, improved models, and establishment of global tracking networks have extended several millimeters horizontal positioning capability to station separations of 1000 km or more in virtually all parts of the world. This enables study of new classes of tectonic problems that previously were difficult to attack with any geodetic technique. Examples include a complete kinematic description of ongoing crustal deformation in broad, complex continental plate boundary zones, and measurement of relative plate motion at convergent boundaries where global models may be poorly constrained.", "authors": ["Timothy H. Dixon"], "related_topics": ["60229501", "2779784338", "58754882"], "citation_count": "355", "reference_count": "115", "references": ["2135494568", "2075665712", "2003342124", "2119486063", "1984984876", "1974437027", "2169337892", "3014588700", "2085319862", "2001288097"], "date": "1991"}, {"id": "2221524898", "title": "Variations and extension of the convex\u2013concave procedure", "abstract": "We investigate the convex\u2013concave procedure, a local heuristic that utilizes the tools of convex optimization to find local optima of difference of convex (DC) programming problems. The class of DC problems includes many difficult problems such as the traveling salesman problem. We extend the standard procedure in two major ways and describe several variations. First, we allow for the algorithm to be initialized without a feasible point. Second, we generalize the algorithm to include vector inequalities. We then present several examples to demonstrate these algorithms.", "authors": ["Thomas Lipp", "Stephen Boyd"], "related_topics": ["12108790", "79187972", "50862404"], "citation_count": "455", "reference_count": "94", "references": ["3029645440", "2097308346", "2049633694", "2044758663", "1804110266", "2117853077", "2113642685", "3149604617", "2290452516", "2147196093"], "date": "2016"}, {"id": "2125975474", "title": "Achieving direct volume visualization with interactive semantic region selection", "abstract": "Interactive direct visualization of 3D data requires fast update rates and the ability to extract regions of interest from the surrounding data. Parallel volume rendering yields rates that make interactive control of image viewing possible for the first time. We have achieved rates as high as 15 frames per second by trading some function for speed. while volume rendering with a full complement of ramp classification capabilities is performed at 1.4 frames per second. These speeds have made the combination of region selection with volume rendering practical for the first time. Semantic driven selection, rather than geometric clipping, has proven to be a natural means of interacting with 3d data. Internal organs in medical data or other regions of interest can be built from preprocessed region primitives. We have applied the resulting combined system to real 3D medical data with encouraging results. The ideas presented are not just limited to our platform, but can be generalized to include most parallel architectures. We present lessons learned from writing fast volume renderers and from applying image processing techniques to viewing volumetric data.", "authors": ["Terry S. Yoo", "Ulrich Neumann", "Henry Fuchs", "Stephen M. Pizer", "Tim Cullip", "John Rhoades", "Ross Whitaker"], "related_topics": ["24498928", "30769735", "36464697"], "citation_count": "23", "reference_count": "16", "references": ["2229412420", "2119231080", "2295355433", "2177745862", "2126521141", "2122585444", "2004453135", "2997387466", "3000849327", "2026786095"], "date": "1991"}, {"id": "2110349823", "title": "Optimization over state feedback policies for robust control with constraints", "abstract": "This paper is concerned with the optimal control of linear discrete-time systems subject to unknown but bounded state disturbances and mixed polytopic constraints on the state and input. It is shown that the class of admissible affine state feedback control policies with knowledge of prior states is equivalent to the class of admissible feedback policies that are affine functions of the past disturbance sequence. This implies that a broad class of constrained finite horizon robust and optimal control problems, where the optimization is over affine state feedback policies, can be solved in a computationally efficient fashion using convex optimization methods. This equivalence result is used to design a robust receding horizon control (RHC) state feedback policy such that the closed-loop system is input-to-state stable (ISS) and the constraints are satisfied for all time and all allowable disturbance sequences. The cost to be minimized in the associated finite horizon optimal control problem is quadratic in the disturbance-free state and input sequences. The value of the receding horizon control law can be calculated at each sample instant using a single, tractable and convex quadratic program (QP) if the disturbance set is polytopic, or a tractable second-order cone program (SOCP) if the disturbance set is given by a 2-norm bound.", "authors": ["Paul J. Goulart", "Eric C. Kerrigan", "Jan M. Maciejowski"], "related_topics": ["91575142", "31531917", "157972887"], "citation_count": "538", "reference_count": "59", "references": ["2296319761", "3102923851", "2610857016", "1561941139", "1978956894", "1993170675", "1583497301", "2105235982", "1976410223", "1981723834"], "date": "2006"}, {"id": "1968865502", "title": "Instrumenting the planet", "abstract": "During the last 50 years, population growth, along with increasingly affluent societies, has resulted in a greater demand for our limited physical infrastructures and natural resources than ever before. In addition, the risks of climate change have heightened the need for more sophisticated ways of controlling carbon emissions. Today, numerous streams of data are being collected from sensors that monitor the environment. When used in conjunction with computational models, these streams can be important sources of data for understanding physical phenomena and human behavior. In this paper, we present a vision of a pervasively instrumented world in which these streams of real-world data are combined with mathematical models to improve the ability to manage the consumption of increasingly scarce resources. Such an instrumented world requires a class of information technology systems that combine very large numbers of sensors and actuators with computing platforms for capturing and analyzing such data streams. We provide details on the characteristics, requirements, and possible applications of such platforms and the key roles that they will play in addressing various societal challenges.", "authors": ["C.-H. Chen-Ritzo", "C. Harrison", "J. Paraszczak", "F. Parr"], "related_topics": ["109747225", "29985473", "121017731"], "citation_count": "69", "reference_count": "25", "references": ["2127949150", "2573715514", "1523248977", "2041137602", "2128217437", "2132082910", "2153453282", "1524622007", "1488160674", "2091739189"], "date": "2009"}, {"id": "2165878107", "title": "Time-frequency distributions-a review", "abstract": "A review and tutorial of the fundamental ideas and methods of joint time-frequency distributions is presented. The objective of the field is to describe how the spectral content of a signal changes in time and to develop the physical and mathematical ideas needed to understand what a time-varying spectrum is. The basic gal is to devise a distribution that represents the energy or intensity of a signal simultaneously in time and frequency. Although the basic notions have been developing steadily over the last 40 years, there have recently been significant advances. This review is intended to be understandable to the nonspecialist with emphasis on the diversity of concepts and motivations that have gone into the formation of the field. >", "authors": ["L. Cohen"], "related_topics": ["5297727", "116638312", "148773725"], "citation_count": "4864", "reference_count": "167", "references": ["2150391795", "1986608926", "2480086434", "2169525829", "1973119332", "2049588903", "2115144768", "1925346143", "1536990986", "2116776886"], "date": "1989"}, {"id": "2145713909", "title": "The Fundamental Matrix: Theory, Algorithms, and Stability Analysis", "abstract": "In this paper we analyze in some detail the geometry of a pair of cameras, i.e., a stereo rig. Contrarily to what has been done in the past and is still done currently, for example in stereo or motion analysis, we do not assume that the intrinsic parameters of the cameras are known (coordinates of the principal points, pixels aspect ratio and focal lengths). This is important for two reasons. First, it is more realistic in applications where these parameters may vary according to the task (active vision). Second, the general case considered here, captures all the relevant information that is necessary for establishing correspondences between two pairs of images. This information is fundamentally projective and is hidden in a confusing manner in the commonlyused formalism of the Essential matrix introduced by Longuet-Higgins (1981). This paper clarifies the projective nature of the correspondence problem in stereo and shows that the epipolar geometry can be summarized in one 3 x 3 matrix of rank 2 which we propose to call the Fundamental matrix. After this theoretical analysis, we embark on the task of estimating the Fundamental matrix from point corre- spondences, a task which is of practical importance. We analyze theoretically, and compare experimentally using synthetic and real data, several methods of estimation. The problem of the stability of the estimation is studied from two complementary viewpoints. First we show that there is an interesting relationship between the Fundamental matrix and three-dimensional planes which induce homographies between the images and create unstabilities in the estimation procedures. Second, we point to a deep relation between the unstability of the estimation procedure and the presence in the scene of so-called critical surfaces which have been studied in the context of motion analysis. Finally we conclude by stressing the fact that we believe that the Fundamental matrix will play a crucial role in future applications of three-dimensional Computer Vision by greatly increasing its versatility, robustness and hence applicability to real difficult problems.", "authors": ["Quang-Tuan Luong", "Olivier D. Faugeras"], "related_topics": ["147946207", "49996920", "56275529"], "citation_count": "1057", "reference_count": "70", "references": ["2028310195", "1598123022", "1482517735", "1943823759", "2115797648", "2065592949", "1530454533", "1602748186", "2134211982", "2025934818"], "date": "1995"}, {"id": "2019509999", "title": "Passage-level evidence in document retrieval", "abstract": "The increasing lengths of documents in full-text collections encourages renewed interest in the ranking and retrieval of document passages. Past research showed that evidence from passages can improve retrieval results, but it also raised questions about how passages are defined, how they can be ranked efficiently, and what is their proper role in long, structured documents.", "authors": ["James P. Callan"], "related_topics": ["87546605", "161156560", "177937566"], "citation_count": "689", "reference_count": "17", "references": ["2078875869", "1605873790", "2046983134", "2064579132", "1967907280", "2070811760", "2088004917", "2009716188", "1530211485", "1995461500"], "date": "1994"}, {"id": "2166087152", "title": "Image compression through wavelet transform coding", "abstract": "A novel theory is introduced for analyzing image compression methods that are based on compression of wavelet decompositions. This theory precisely relates (a) the rate of decay in the error between the original image and the compressed image as the size of the compressed image representation increases (i.e., as the amount of compression decreases) to (b) the smoothness of the image in certain smoothness classes called Besov spaces. Within this theory, the error incurred by the quantization of wavelet transform coefficients is explained. Several compression algorithms based on piecewise constant approximations are analyzed in some detail. It is shown that, if pictures can be characterized by their membership in the smoothness classes considered, then wavelet-based methods are near-optimal within a larger class of stable transform-based, nonlinear methods of image compression. Based on previous experimental research it is argued that in most instances the error incurred in image compression should be measured in the integral sense instead of the mean-square sense. >", "authors": ["R.A. DeVore", "B. Jawerth", "B.J. Lucier"], "related_topics": ["13481523", "94835093", "78548338"], "citation_count": "1419", "reference_count": "17", "references": ["2098914003", "2103504761", "1980149518", "2162870748", "574370508", "1975474302", "2019972422", "2088277224", "1987842033", "2020038074"], "date": "1992"}, {"id": "2113905985", "title": "Image coding based on mixture modeling of wavelet coefficients and a fast estimation-quantization framework", "abstract": "We introduce a new image compression paradigm that combines compression efficiency with speed, and is based on an independent \"infinite\" mixture model which accurately captures the space-frequency characterization of the wavelet image representation. Specifically, we model image wavelet coefficients as being drawn from an independent generalized Gaussian distribution field, of fixed unknown shape for each subband, having zero mean and unknown slowly spatially-varying variances. Based on this model, we develop a powerful \"on the fly\" estimation-quantization (EQ) framework that consists of: (i) first finding the maximum-likelihood estimate of the individual spatially-varying coefficient field variances based on causal and quantized spatial neighborhood contexts; and (ii) then applying an off-line rate-distortion (R-D) optimized quantization/entropy coding strategy, implemented as a fast lookup table, that is optimally matched to the derived variance estimates. A distinctive feature of our paradigm is the dynamic switching between forward and backward adaptation modes based on the reliability of causal prediction contexts. The performance of our coder is extremely competitive with the best published results in the literature across diverse classes of images and target bitrates of interest, in both compression efficiency and processing speed. For example, our coder exceeds the objective performance of the best zerotree-based wavelet coder based on space-frequency-quantization at all bit rates for all tested images at a fraction of its complexity.", "authors": ["S.M. LoPresto", "K. Ramchandran", "M.T. Orchard"], "related_topics": ["196216189", "47432892", "13481523"], "citation_count": "378", "reference_count": "13", "references": ["2142276208", "2053691921", "1634005169", "2611071497", "2054658115", "2163935396", "2067265395", "2157999599", "2117465325", "2132441534"], "date": "1997"}, {"id": "1998854584", "title": "SUPPLY CHAIN MANAGEMENT -- MORE THAN A NEW NAME FOR LOGISTICS", "abstract": "Practitioners and educators have variously addressed the concept of supply chain management (SCM) as an extension of logistics, the same as logistics, or as an all\u2010encompassing approach to business integration. Based on a review of the literature and management practice, it is clear that there is a need for some level of coordination of activities and processes within and between organizations in the supply chain that extends beyond logistics. We believe that this is what should be called SCM. This article proposes a conceptual model that provides guidance for future supply chain decision\u2010making and research.", "authors": ["Martha C. Cooper", "Douglas M. Lambert", "Janus D. Pagh"], "related_topics": ["44104985", "192639820", "108713360"], "citation_count": "4573", "reference_count": "0", "references": ["2070854196", "2113348250", "1990457952", "1965703329", "1997383668", "2117286234", "2029969606", "2142616543", "2738241474", "2139616932"], "date": "1996"}, {"id": "1511144591", "title": "Choice functions and the scopal semantics of indefinites", "abstract": "En prenant en compte le comportement exceptionnel de la portee des SN indefinis et les complications ajoutees par les effets de distributivite des indefinis pluriels, l'A. propose une revision des approches standard de la syntaxe et de la semantique des indefinis. En suivant l'article de Reinhart Quantifier scope (1997), il explique l'unique comportement de la portee des indefinis pluriels et singuliers par une semantique de la fonction du choix, et non par quelque operation de changement de portee. Mais, a la difference de Reinhart qui s'occupe aussi de la quantification standard, il considere que la quantification par les fonctions de choix est le mecanisme uniforme pour l'interpretation des indefinis. Il propose en outre une definition formelle linguistiquement adequate et exploitable dans un systeme compositionnel", "authors": ["Yoad Winter"], "related_topics": ["166553842", "124246873", "123556308"], "citation_count": "360", "reference_count": "35", "references": ["1491947308", "1687416839", "2097028840", "1519554123", "1496121670", "1491525124", "1593821722", "1594032094", "2078223914", "2039572733"], "date": "1997"}, {"id": "2006134838", "title": "Some results on uniformly high-order accurate essentially nonoscillatory schemes", "abstract": "We continue the construction and the analysis of essentially nonoscillatory shock capturing methods for the approximation of hyperbolic conservation laws. These schemes share many desirable properties with total variation diminishing schemes, but TVD schemes have at most first-order accuracy in the sense of truncation error, at extrema of the solution. In this paper we construct an hierarchy of uniformly high-order accurate approximations of any desired order of accuracy which are tailored to be essentially nonoscillatory. This means that, for piecewise smooth solutions, the variation of the numerical approximation is bounded by that of the true solution up to O(h^R^ ^-^ ^1), for 0", "authors": ["Ami Harten", "Stanley Osher", "Bj\u00f6rn Engquist", "Sukumar R. Chakravarthy"], "related_topics": ["20448624", "39177556", "152284280"], "citation_count": "378", "reference_count": "25", "references": ["2068056613", "1998830482", "2112548197", "2162357087", "2073945818", "1975706278", "2026073961", "2083659289", "1988634891", "2047612590"], "date": "1986"}, {"id": "1619226191", "title": "Irrelevant features and the subset selection problem", "abstract": "We address the problem of finding a subset of features that allows a supervised induction algorithm to induce small high-accuracy concepts. We examine notions of relevance and irrelevance, and show that the definitions used in the machine learning literature do not adequately partition the features into useful categories of relevance. We present definitions for irrelevance and for two degrees of relevance. These definitions improve our understanding of the behavior of previous subset selection algorithms, and help define the subset of features that should be sought. The features selected should depend not only on the features and the target concept, but also on the induction algorithm. We describe a method for feature subset selection using cross-validation that is applicable to any induction algorithm, and discuss experiments conducted with ID3 and C4.5 on artificial and real datasets.", "authors": ["George H. John", "Ron Kohavi", "Karl Pfleger"], "related_topics": ["2776012861", "16811321", "40608802"], "citation_count": "2668", "reference_count": "31", "references": ["2149706766", "2132166479", "1583700199", "1808644423", "2129113961", "190437827", "23418094", "2070902649", "1553244859", "1968908999"], "date": "1994"}, {"id": "1735617816", "title": "Discourse Analysis as Theory and Method", "abstract": "Discourse Analysis as Theory and Method is a systematic introduction to discourse analysis as a body of theories and methods for social research. It brings together three central approaches, Laclau and Mouffe's discourse theory, critical discourse analysis and discursive psychology, in order to establish a dialogue between different forms of discourse analysis often kept apart by disciplinary boundaries. The book introduces the three approaches in a clear and easily comprehensible manner, explaining the distinctive philosophical premises and theoretical perspectives of each approach as well as the methodological guidelines and tools they provide for empirical discourse analysis. The authors also demonstrate the possibilities for combining different discourse analytical and non-discourse analytical approaches in empirical study. Finally, they contextualize discourse analysis within the social constructionist debate about critical social research, rejecting the view that a critical stance is incompatible with social constructionist premises and arguing that critique must be an inherent part of social research.", "authors": ["Marianne Winther J\u00f8rgensen", "Louise Phillips"], "related_topics": ["99747519", "2779030433", "84389358"], "citation_count": "5556", "reference_count": "201", "references": ["1485995441", "2121393013", "2038600245", "2053501256", "2171148471", "2016634442", "2161586993", "2056879345", "1520944543", "2942733065"], "date": "2002"}, {"id": "2337770697", "title": "Automatic synthesis of fine-motion strategies for robots", "abstract": "Abstract : The use of active compliance enables robots to carry out tasks in the presence of significant sensing and control errors. Compliant motions are quite difficult for humans to specify, however. Furthermore, robot programs are quite sensitive to details of geometry and to error characteristics and must, therefore, be constructed anew for each task. These factors motivate the need for automatic synthesis tools for robot programming, especially for compliant motion. This paper describes formal approach to the synthesis of compliant motion strategies from geometric descriptions of assembly operations and explicit estimates of errors in sensing and control. A key aspect of the approach is that it provides correctness criteria for compliant motion strategies. (Author)", "authors": ["Tom\u00e1s Lozano-p\u00e9rez", "Matthew T. Mason", "Russell H. Taylor"], "related_topics": ["90509273", "34413123", "2777394884"], "citation_count": "1143", "reference_count": "0", "references": ["1969160376", "2088043683", "2128082316", "1999839266", "2095981630", "2141124675", "2023509699", "2171771720", "2112535044", "2116233534"], "date": "1991"}, {"id": "2522324076", "title": "Computer rendering of stochastic models", "abstract": "A recurrent problem in generating realistic pictures by computers is to represent natural irregular objects and phenomena without undue time or space overhead. We develop a new and powerful solution to this computer graphics problem by modeling objects as sample paths of stochastic processes. Of particular interest are those stochastic processes which previously have been found to be useful models of the natural phenomena to be represented. One such model applicable to the representation of terrains, known as \u201cfractional Brownian motion,\u201d has been developed by Mandelbrot.The value of a new approach to object modeling in computer graphics depends largely on the efficiency of the techniques used to implement the model. We introduce a new algorithm that computes a realistic, visually satisfactory approximation to fractional Brownian motion in faster time than with exact calculations. A major advantage of this technique is that it allows us to compute the surface to arbitrary levels of details without increasing the database. Thus objects with complex appearances can be displayed from a very small database. The character of the surface can be controlled by merely modifying a few parameters. A similar change allows complex motion to be created inexpensively.", "authors": ["A. Fournier", "D. Fussell", "L. Carpenter"], "related_topics": ["205711294", "77660652", "108819105"], "citation_count": "1019", "reference_count": "0", "references": ["2125833438", "2167003500", "2104314879", "2033854240", "2149792312", "2066864051", "2059753342", "2105835768", "1577524475", "2068677947"], "date": "1988"}, {"id": "2433940709", "title": "Parallel Sorting Algorithms", "abstract": "", "authors": ["Selim G. Akl"], "related_topics": ["57032618", "140086265", "64540648"], "citation_count": "534", "reference_count": "0", "references": ["2118558147", "2164215197", "2160204225", "2155119349", "2018915748", "241684218", "2166773527", "2057726682", "1996119065", "2963388231"], "date": "1984"}, {"id": "2049165791", "title": "Research diagnostic criteria: Rationale and reliability.", "abstract": "\u2022 A crucial problem in psychiatry, affecting clinical work as well as research, is the generally low reliability of current psychiatric diagnostic procedures. This article describes the development and initial reliability studies of a set of specific diagnostic criteria for a selected group of functional psychiatric disorders, the Research Diagnostic Criteria (RDC). The RDC are being widely used to study a variety of research issues, particularly those related to genetics, psychobiology of selected mental disorders, and treatment outcome. The data presented here indicate high reliability for diagnostic judgments made using these criteria.", "authors": ["Robert L. Spitzer", "Jean Endicott", "Eli Robins"], "related_topics": ["2778990124", "33459144", "108898314"], "citation_count": "10089", "reference_count": "27", "references": ["2150287316", "2109226331", "2012453547", "1972396225", "2133399371", "574768539", "2136936616", "1795726959", "2127412793", "2005290531"], "date": "1978"}, {"id": "2107202569", "title": "A revised European-American classification of lymphoid neoplasms : a proposal from the international lymphoma study group", "abstract": "", "authors": ["NL Harris", "ES Jaffe", "H Stein", "PM Banks", "JK Chan", "ML Cleary", "G Delsol", "C De Wolf Peeters", "B Falini", "KC Gatter"], "related_topics": ["2909944485", "2779526237", "2780039790"], "citation_count": "8318", "reference_count": "0", "references": ["2147246240", "2107398329", "2058015212", "2025383700", "2117291755", "2045399297", "2416844197", "2096638244", "1969582706", "2608724752"], "date": "1994"}, {"id": "2096710051", "title": "Detection of signals by information theoretic criteria", "abstract": "A new approach is presented to the problem of detecting the number of signals in a multichannel time-series, based on the application of the information theoretic criteria for model selection introduced by Akaike (AIC) and by Schwartz and Rissanen (MDL). Unlike the conventional hypothesis testing based approach, the new approach does not requite any subjective threshold settings; the number of signals is obtained merely by minimizing the AIC or the MDL criteria. Simulation results that illustrate the performance of the new method for the detection of the number of signals received by a sensor array are presented.", "authors": ["M. Wax", "T. Kailath"], "related_topics": ["126674687", "87007009", "93959086"], "citation_count": "4275", "reference_count": "24", "references": ["2168175751", "2142635246", "2113638573", "2058815839", "2054658115", "2106596127", "1974513581", "2019833178", "2165887549", "1500470240"], "date": "1985"}, {"id": "1563883302", "title": "Building Working Cells 'in Silico'", "abstract": "A computer scientist and biologist has come up with a scheme for exploring the effects that only emerge when a cell9s many processes interact: a simulation program called E-CELL that can reproduce, in simplified form, a cell9s biochemical symphony. Other computer models of the cell are being developed that reproduce individual cellular processes in detail; E-CELL, in contrast, is designed to paint a broad-brush picture of the cell as a whole.", "authors": ["Dennis Normile"], "related_topics": ["16277566", "2775905019", "2778250132"], "citation_count": "77", "reference_count": "0", "references": ["2162800060", "2121821841", "2117495845", "2042880070", "1997080758", "2100525485", "2148607448", "1977128600", "2139745270", "2148711543"], "date": "1999"}, {"id": "2044534358", "title": "Cluster-based scalable network services", "abstract": "We identify three fundamental requirements for scalable network services: incremental scalability and overflow growth provisioning, 24x7 availability through fault masking, and cost-effectiveness. We argue that clusters of commodity workstations interconnected by a high-speed SAN are exceptionally well-suited to meeting these challenges for Internet-server workloads, provided the software infrastructure for managing partial failures and administering a large cluster does not have to be reinvented for each new service. To this end, we propose a general, layered architecture for building cluster-based scalable network services that encapsulates the above requirements for reuse, and a service-programming model based on composable workers that perform transformation, aggregation, caching, and customization (TACC) of Internet content. For both performance and implementation simplicity, the architecture and TACC programming model exploit BASE, a weaker-than-ACID data semantics that results from trading consistency for availability and relying on soft state for robustness in failure management. Our architecture can be used as an off the shelf infrastructural platform for creating new network services, allowing authors to focus on the content of the service (by composing TACC building blocks) rather than its implementation. We discuss two real implementations of services based on this architecture: TranSend, a Web distillation proxy deployed to the UC Berkeley dialup IP population, and HotBot, the commercial implementation of the Inktomi search engine. We present detailed measurements of TranSend's performance based on substantial client traces, as well as anecdotal evidence from the TranSend and HotBot experience, to support the claims made for the architecture.", "authors": ["Armando Fox", "Steven D. Gribble", "Yatin Chawathe", "Eric A. Brewer", "Paul Gauthier"], "related_topics": ["98025372", "80445892", "48044578"], "citation_count": "911", "reference_count": "50", "references": ["3121531027", "1779735989", "2105818147", "2134342348", "2114728910", "1527961683", "2096322909", "2135131646", "2008793926", "2150048640"], "date": "1997"}, {"id": "2167667767", "title": "A flexible new technique for camera calibration", "abstract": "We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.", "authors": ["Z. Zhang"], "related_topics": ["110898773", "94816000", "199996500"], "citation_count": "15824", "reference_count": "27", "references": ["2798909945", "2028310195", "2176463832", "1977272108", "2167544683", "1943823759", "1660742177", "2138620157", "2065592949", "2118002377"], "date": "2000"}, {"id": "2560140854", "title": "The Power of Feedback", "abstract": "Feedback is one of the most powerful influences on learning and achievement, but this impact can be either positive or negative. Its power is frequently mentioned in articles about learning and teaching, but surprisingly few recent studies have systematically investigated its meaning. This article provides a conceptual analysis of feedback and reviews the evidence related to its impact on learning and achievement. This evidence shows that although feedback is among the major influences, the type of feedback and the way it is given can be differentially effective. A model of feedback is then proposed that identifies the particular properties and circumstances that make it effective, and some typically thorny issues are discussed, including the timing of feedback and the effects of positive and negative feedback. Finally, this analysis is used to suggest ways in which feedback can be used to enhance its effectiveness in classrooms.", "authors": ["John Hattie", "Helen Timperley"], "related_topics": ["42058189", "174988536", "93586867"], "citation_count": "13269", "reference_count": "133", "references": ["2888190061", "1967555382", "3019273456", "2007851141", "1678084289", "1982210139", "3149277062", "2030441548", "2045959487", "2095907159"], "date": "2007"}, {"id": "2168569455", "title": "A Theoretical Extension of the Technology Acceptance Model: Four Longitudinal Field Studies", "abstract": "The present research develops and tests a theoretical extension of the Technology Acceptance Model (TAM) that explains perceived usefulness and usage intentions in terms of social influence and cognitive instrumental processes. The extended model, referred to as TAM2, was tested using longitudinal data collected regarding four different systems at four organizations ( N = 156), two involving voluntary usage and two involving mandatory usage. Model constructs were measured at three points in time at each organization: preimplementation, one month postimplementation, and three months postimplementation. The extended model was strongly supported for all four organizations at all three points of measurement, accounting for 40%--60% of the variance in usefulness perceptions and 34%--52% of the variance in usage intentions. Both social influence processes (subjective norm, voluntariness, and image) and cognitive instrumental processes (job relevance, output quality, result demonstrability, and perceived ease of use) significantly influenced user acceptance. These findings advance theory and contribute to the foundation for future research aimed at improving our understanding of user adoption behavior.", "authors": ["Viswanath Venkatesh", "Fred D. Davis"], "related_topics": ["2780346085", "2776185967", "2779191989"], "citation_count": "22637", "reference_count": "58", "references": ["2099697766", "1791587663", "2888190061", "2033943395", "1987198869", "2130801612", "2100408980", "2036389121", "2045959487", "1980569376"], "date": "2000"}, {"id": "2319506195", "title": "Statistics, a new approach", "abstract": "", "authors": ["Wilson Allen Wallis", "Harry V. Roberts"], "related_topics": ["35591689", "176222170", "124101348"], "citation_count": "376", "reference_count": "0", "references": ["989915435", "2126101898", "1980054641", "1485474720", "2098076579", "1997648776", "2774401865", "2011897667", "2241732496", "2108380580"], "date": "1955"}, {"id": "1787564306", "title": "Knowledge Discovery in Databases: An Attribute-Oriented Approach", "abstract": "Knowledge discovery in databases, or data mining, is an important issue in the development of data- and knowledge-base systems. An attribute-oriented induction method has been developed for knowledge discovery in databases. The method integrates a machine learning paradigm, especially learning-from-examples techniques, with set-oriented database operations and extracts generalized data from actual data in databases. An attribute-oriented concept tree ascension technique is applied in generalization, which substantially reduces the computational complex@ of database learning processes. Different kinas of knowledge rules, including characteristic rules, discrimination rules, quantitative rules, and data evolution regularities can be discovered efficiently using the attribute-oriented approach. In addition to learning in relational databases, the approach can be applied to knowledge discovery in nested relational and deductive databases. Learning can also be performed with databases containing noisy data and exceptional cases using database statistics. Furthermore, the rules discovered can be used to query database knowledge, answer cooperative queries and facilitate semantic query optimization. Based upon these principles, a prototyped database learning system, DBLEARN, has been constructed for experimentation.", "authors": ["Jiawei Han", "Yandong Cai", "Nick Cercone"], "related_topics": ["12439846", "120567893", "148840519"], "citation_count": "593", "reference_count": "27", "references": ["1601529450", "2100176599", "1992810975", "2132513611", "2129150932", "2012170877", "2009207944", "2034956514", "2162621793", "2092842298"], "date": "1992"}, {"id": "2068632118", "title": "Extended Boolean information retrieval", "abstract": "In conventional information retrieval Boolean combinations of index terms are used to formulate the users'' information requests. While any document is in principle retrievable by a Boolean query, the amount of output obtainable by Boolean processing is difficult to control, and the retrieved items are not ranked in any presumed order of importance to the user population. In the vector processing model of retrieval, the retrieved items are easily ranked in decreasing order of the query-record similarity, but the queries themselves are unstructured and expressed as simple sets of weighted index terms. A new, extended Boolean information retrieval system is introduced which is intermediate between the Boolean system of query processing and the vector processing model. The query structure inherent in the Boolean system is preserved, while at the same time weighted terms may be incorporated into both queries and stored documents; the retrieved output can also be ranked in strict similarity order with the user queries. A conventional retrieval system can be modified to make use of the extended system. Laboratory tests indicate that the extended system produces better retrieval output than either the Boolean or the vector processing systems.", "authors": ["Gerard Salton", "Edward A. Fox", "Harry Wu"], "related_topics": ["2776635708", "68481662", "89686163"], "citation_count": "1553", "reference_count": "26", "references": ["2043909051", "3090556797", "2164547069", "1557757161", "1602667807", "1966365186", "1908696901", "2004436106", "2151433603", "2129094996"], "date": "1983"}, {"id": "2159024459", "title": "k -anonymity: a model for protecting privacy", "abstract": "Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k- anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, \u00b5-Argus and k-Similar provide guarantees of privacy protection.", "authors": ["Latanya Sweeney"], "related_topics": ["2777706471", "2776945810", "123201435"], "citation_count": "10891", "reference_count": "17", "references": ["1882297107", "1600806036", "1992810975", "1535505269", "2162621793", "627832951", "2072719872", "2163601424", "2008074667", "2066844014"], "date": "2002"}, {"id": "2164475575", "title": "A region based approach for human body motion analysis", "abstract": "Abstract Human body motion analysis can be roughly divided into three phases. In the first phase, moving body parts are separated from the background. In the second phase, these body parts are then labelled. In the third phase, the motion verbs are assigned to the movement. An earlier paper by the authors described a novel technique for segmenting the moving body parts from the background. In this paper, techniques developed for the second phase of the analysis are discussed. The notion of antiparallel lines is employed to abstract the regions into a higher level primitive which enables one to define and develop operations such as concatenation and deletion. A simple heuristic model is then used to map the detected regions into human body parts. Results of which are very encouraging. Future research in the proposed approach is warranted.", "authors": ["Maylor K. Leung", "Yee-Hong Yang"], "related_topics": ["89600930", "2777036941", "104114177"], "citation_count": "95", "reference_count": "24", "references": ["1655554306", "2117731089", "2095364258", "2026720449", "1994552597", "2109848675", "2038033160", "2083804944", "2131729179", "2122888449"], "date": "1987"}, {"id": "2300567117", "title": "Convergence Culture: Where Old and New Media Collide", "abstract": "Acknowledgments Introduction: \"Worship at the Altar of Convergence\": A New Paradigm for Understanding Media Change 1 Spoiling Survivor: The Anatomy of a Knowledge Community 2 Buying into American Idol: How We are Being Sold on Reality TV 3 Searching for the Origami Unicorn: The Matrix and Transmedia Storytelling 4 Quentin Tarantino's Star Wars? Grassroots Creativity Meets the Media Industry 5 Why Heather Can Write: Media Literacy and the Potter Wars 6 Photoshop for Democracy: The New Relationship between Politics and Popular CultureConclusion: Democratizing Television?The Politics of ParticipationNotes Glossary Index About the Author", "authors": ["Henry Jenkins"], "related_topics": ["2776530160", "99574664", "2777887517"], "citation_count": "8345", "reference_count": "0", "references": ["2969165671", "2129444086", "2097379719", "2970785670", "2171323324", "2101843697", "1673918140", "1991384030", "1463266149", "2515442686"], "date": "2005"}, {"id": "2070232376", "title": "A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs", "abstract": "Recently, a number of researchers have investigated a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partition for the original graph [Bui and Jones, Proc. of the 6th SIAM Conference on Parallel Processing for Scientific Computing, 1993, 445--452; Hendrickson and Leland, A Multilevel Algorithm for Partitioning Graphs, Tech. report SAND 93-1301, Sandia National Laboratories, Albuquerque, NM, 1993]. From the early work it was clear that multilevel techniques held great promise; however, it was not known if they can be made to consistently produce high quality partitions for graphs arising in a wide range of application domains. We investigate the effectiveness of many different choices for all three phases: coarsening, partition of the coarsest graph, and refinement. In particular, we present a new coarsening heuristic (called heavy-edge heuristic) for which the size of the partition of the coarse graph is within a small factor of the size of the final partition obtained after multilevel refinement. We also present a much faster variation of the Kernighan--Lin (KL) algorithm for refining during uncoarsening. We test our scheme on a large number of graphs arising in various domains including finite element methods, linear programming, VLSI, and transportation. Our experiments show that our scheme produces partitions that are consistently better than those produced by spectral partitioning schemes in substantially smaller time. Also, when our scheme is used to compute fill-reducing orderings for sparse matrices, it produces orderings that have substantially smaller fill than the widely used multiple minimum degree algorithm.", "authors": ["George Karypis", "Vipin Kumar"], "related_topics": ["48903430", "187407849", "19332903"], "citation_count": "6367", "reference_count": "43", "references": ["2340149117", "2114030927", "1509342228", "2118953734", "2059586807", "2095117703", "2143131337", "2161455936", "2082817855", "1981885118"], "date": "1998"}, {"id": "2064579132", "title": "Subtopic structuring for full-length document access", "abstract": "We argue that the advent of large volumes of full-length text, as opposed to short texts like abstracts and newswire, should be accompanied by corresponding new approaches to information access. Toward this end, we discuss the merits of imposing structure on full-length text documents; that is, a partition of the text into coherent multi-paragraph units that represent the pattern of subtopics that comprise the text. Using this structure, we can make a distinction between the main topics, which occur throughout the length of the text, and the subtopics, which are of only limited extent. We discuss why recognition of subtopic structure is important and how, to some degree of accuracy, it can be found. We describe a new way of specifying queries on full-length documents and then describe an experiment in which making use of the recognition of local structure achieves better results on a typical information retrieval task than does a standard IR measure.", "authors": ["Marti A. Hearst", "Christian Plaunt"], "related_topics": ["2776543384", "191617201", "23123220"], "citation_count": "545", "reference_count": "14", "references": ["1570542661", "2069501481", "2040004971", "2078875869", "2021325618", "1995461500", "2166806362", "156913501", "91776986", "1986307766"], "date": "1993"}, {"id": "2118269922", "title": "R-trees: a dynamic index structure for spatial searching", "abstract": "In order to handle spatial data efficiently, as required in computer aided design and geo-data applications, a database system needs an index mechanism that will help it retrieve data items quickly according to their spatial locations However, traditional indexing methods are not well suited to data objects of non-zero size located m multi-dimensional spaces In this paper we describe a dynamic index structure called an R-tree which meets this need, and give algorithms for searching and updating it. We present the results of a series of tests which indicate that the structure performs well, and conclude that it is useful for current database systems in spatial applications", "authors": ["Antonin Guttman"], "related_topics": ["203689450", "172722865", "159620131"], "citation_count": "11612", "reference_count": "16", "references": ["2165558283", "2116436709", "2161694911", "2066799613", "2008196645", "2092276439", "2002330922", "2145343598", "2172390267", "2050708115"], "date": "1984"}, {"id": "2122827492", "title": "Fourier Descriptors for Plane Closed Curves", "abstract": "A method for the analysis and synthesis of closed curves in the plane is developed using the Fourier descriptors FD's of Cosgriff [1]. A curve is represented parametrically as a function of arc length by the accumulated change in direction of the curve since the starting point. This function is expanded in a Fourier series and the coefficients are arranged in the amplitude/phase-angle form. It is shown that the amplitudes are pure form invariants as well as are certain simple functions of phase angles. Rotational and axial symmetry are related directly to simple properties of the Fourier descriptors. An analysis of shape similarity or symmetry can be based on these relationships; also closed symmetric curves can be synthesized from almost arbitrary Fourier descriptors. It is established that the Fourier series expansion is optimal and unique with respect to obtaining coefficients insensitive to starting point. Several examples are provided to indicate the usefulness of Fourier descriptors as features for shape discrimination and a number of interesting symmetric curves are generated by computer and plotted out.", "authors": ["Charles T. Zahn", "Ralph Z. Roskies"], "related_topics": ["175225751", "207864730", "203024314"], "citation_count": "2691", "reference_count": "11", "references": ["2116360511", "2133246412", "2808650095", "1972969203", "2118017998", "2122741244", "1982485672", "1528287150", "40044188", "50900203"], "date": "1972"}, {"id": "2162006472", "title": "Locality-sensitive hashing scheme based on p-stable distributions", "abstract": "We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p", "authors": ["Mayur Datar", "Nicole Immorlica", "Piotr Indyk", "Vahab S. Mirrokni"], "related_topics": ["74270461", "122907437", "116058348"], "citation_count": "3261", "reference_count": "29", "references": ["2147717514", "1502916507", "1541459201", "2520931985", "2165533158", "2045533739", "2169351022", "2109034006", "1595303882", "2048779798"], "date": "2004"}, {"id": "2097174014", "title": "Tamed Frequency Modulation, A Novel Method to Achieve Spectrum Economy in Digital Transmission", "abstract": "This paper describes a new type of frequency modulation, called Tamed Frequency Modulation (TFM), for digital transmission. The desired constraint of a constant envelope signal is combined with a maximum of spectrum economy which is of great importance, particularly in radio channels. The out-of-band radiation is substantially less as compared with other known constant envelope modulation techniques. With synchronous detection, a penalty of only 1 dB in error performance is encountered as compared with four-phase modulation. The idea behind TFM is the proper control of the frequency of the transmitter oscillator, such that the phase of the modulated signal becomes a smooth function of time with correlative properties. Simple and flexible implementation schemes are described.", "authors": ["F. Jager", "C. Dekker"], "related_topics": ["22676131", "201905106", "96834759"], "citation_count": "353", "reference_count": "10", "references": ["2798524847", "2134360027", "2120981061", "2150066920", "2140666569", "2162728536", "2059252900", "2025747047", "2107910749", "2134120396"], "date": "1978"}, {"id": "2149072817", "title": "Wavelets and filter banks: theory and design", "abstract": "The wavelet transform is compared with the more classical short-time Fourier transform approach to signal analysis. Then the relations between wavelets, filter banks, and multiresolution signal processing are explored. A brief review is given of perfect reconstruction filter banks, which can be used both for computing the discrete wavelet transform, and for deriving continuous wavelet bases, provided that the filters meet a constraint known as regularity. Given a low-pass filter, necessary and sufficient conditions for the existence of a complementary high-pass filter that will permit perfect reconstruction are derived. The perfect reconstruction condition is posed as a Bezout identity, and it is shown how it is possible to find all higher-degree complementary filters based on an analogy with the theory of Diophantine equations. An alternative approach based on the theory of continued fractions is also given. These results are used to design highly regular filter banks, which generate biorthogonal continuous wavelet bases with symmetries. >", "authors": ["M. Vetterli", "C. Herley"], "related_topics": ["46286280", "47432892", "22597639"], "citation_count": "2709", "reference_count": "34", "references": ["2132984323", "2098914003", "1996021349", "2103504761", "2798813531", "2166982406", "2096684483", "2116988482", "2041752335", "2093112233"], "date": "1992"}, {"id": "2057175746", "title": "Shape matching and object recognition using shape contexts", "abstract": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by: (1) solving for correspondences between points on the two shapes; (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.", "authors": ["S. Belongie", "J. Malik", "J. Puzicha"], "related_topics": ["155514235", "45089102", "2779662243"], "citation_count": "8348", "reference_count": "58", "references": ["2310919327", "2124386111", "2119821739", "2117812871", "2138451337", "2038952578", "2124087378", "2123977795", "2101522199", "2146766088"], "date": "2002"}, {"id": "2002062072", "title": "Egalitarianism in young children", "abstract": "Human social interaction is strongly shaped by other-regarding preferences, that is, a concern for the welfare of others. These preferences are important for a unique aspect of human sociality-large scale cooperation with genetic strangers-but little is known about their developmental roots. Here we show that young children's other-regarding preferences assume a particular form, inequality aversion that develops strongly between the ages of 3 and 8. At age 3-4, the overwhelming majority of children behave selfishly, whereas most children at age 7-8 prefer resource allocations that remove advantageous or disadvantageous inequality. Moreover, inequality aversion is strongly shaped by parochialism, a preference for favouring the members of one's own social group. These results indicate that human egalitarianism and parochialism have deep developmental roots, and the simultaneous emergence of altruistic sharing and parochialism during childhood is intriguing in view of recent evolutionary theories which predict that the same evolutionary process jointly drives both human altruism and parochialism.", "authors": ["Ernst Fehr", "", "Helen Bernhard", "Bettina Rockenbach"], "related_topics": ["204918333", "546784017", "194959371"], "citation_count": "1529", "reference_count": "49", "references": ["3022808291", "1542722502", "2129135549", "3126056200", "2157592153", "2119224589", "3122520279", "1825286732", "2125976408", "2026567452"], "date": "2008"}, {"id": "1999649023", "title": "Statistical Methods for Meta-Analysis", "abstract": "Preface. Introduction. Data Sets. Tests of Statistical Significance of Combined Results. Vote-Counting Methods. Estimation of a Single Effect Size: Parametric and Nonparametric Methods. Parametric Estimation of Effect Size from a Series of Experiments. Fitting Parametric Fixed Effect Models to Effect Sizes: Categorical Methods. Fitting Parametric Fixed Effect Models to Effect Sizes: General Linear Models. Random Effects Models for Effect Sizes. Multivariate Models for Effect Sizes. Combining Estimates of Correlation Coefficients. Diagnostic Procedures for Research Synthesis Models. Clustering Estimates of Effect Magnitude. Estimation of Effect Size When Not All Study Outcomes Are Observed. Meta-Analysis in the Physical and Biological Sciences. Appendix. References. Index.", "authors": ["Larry V. Hedges", "Ingram Olkin"], "related_topics": ["117251300", "102366305", "168743327"], "citation_count": "16758", "reference_count": "0", "references": ["1979423827", "2139168999", "2101316711", "1982471090", "2128689084", "2107328434", "2116153150", "150699103", "2057659248", "2144512297"], "date": "1984"}, {"id": "1977656351", "title": "Mobeyes: smart mobs for urban monitoring with a vehicular sensor network", "abstract": "Vehicular sensor networks are emerging as a new network paradigm of primary relevance, especially for proactively gathering monitoring information in urban environments. Vehicles typically have no strict constraints on processing power and storage capabilities. They can sense events (e.g., imaging from streets), process sensed data (e.g., recognizing license plates), and route messages to other vehicles (e.g., diffusing relevant notification to drivers or police agents). In this novel and challenging mobile environment, sensors can generate a sheer amount of data, and traditional sensor network approaches for data reporting become unfeasible. This article proposes MobEyes, an efficient lightweight support for proactive urban monitoring based on the primary idea of exploiting vehicle mobility to opportunistically diffuse summaries about sensed data. The reported experimental/analytic results show that MobEyes can harvest summaries and build a low-cost distributed index with reasonable completeness, good scalability, and limited overhead", "authors": ["Uichin Lee", "Biao Zhou", "M. Gerla", "E. Magistretti", "P. Bellavista", "A. Corradi"], "related_topics": ["24590314", "176563091", "48044578"], "citation_count": "458", "reference_count": "35", "references": ["2148251644", "2149959815", "2153422903", "1982002312", "2136420233", "2126540423", "2144381381", "2022318042", "1479991102", "2165491783"], "date": "2006"}, {"id": "2108138101", "title": "Efficient MATLAB Computations with Sparse and Factored Tensors", "abstract": "In this paper, the term tensor refers simply to a multidimensional or $N$-way array, and we consider how specially structured tensors allow for efficient storage and computation. First, we study sparse tensors, which have the property that the vast majority of the elements are zero. We propose storing sparse tensors using coordinate format and describe the computational efficiency of this scheme for various mathematical operations, including those typical to tensor decomposition algorithms. Second, we study factored tensors, which have the property that they can be assembled from more basic components. We consider two specific types: A Tucker tensor can be expressed as the product of a core tensor (which itself may be dense, sparse, or factored) and a matrix along each mode, and a Kruskal tensor can be expressed as the sum of rank-1 tensors. We are interested in the case where the storage of the components is less than the storage of the full tensor, and we demonstrate that many elementary operations can be computed using only the components. All of the efficiencies described in this paper are implemented in the Tensor Toolbox for MATLAB.", "authors": ["Brett W. Bader", "Tamara G. Kolda"], "related_topics": ["124007464", "64835786", "77608352"], "citation_count": "476", "reference_count": "45", "references": ["1506342804", "2013912476", "2113722075", "2027559251", "2119741678", "2113055885", "2135666716", "2042901969", "2037360998", "2111363262"], "date": "2007"}, {"id": "1984612928", "title": "Mobile Social Software: Facilitating Serendipity or Encouraging Homogeneity?", "abstract": "Mobile social systems can offer heterogeneous views of cities rather than encouraging users to socialize with people they already know and privileging consumption- and entertainment-based urban experiences.", "authors": ["J. Thom-Santelli"], "related_topics": ["74216064", "144543869", "2777381677"], "citation_count": "56", "reference_count": "11", "references": ["2164713644", "2124549791", "2111846364", "2325557374", "1554339076", "2104194999", "618545294", "2168141544", "2158283206", "2144245327"], "date": "2007"}, {"id": "2116339812", "title": "The Virtual Community: Homesteading on the Electronic Frontier", "abstract": "From the Publisher: Praised as \"one of the ten best books of the year\" by Business Week, this lively and provocative look inside the development, inner workings and future of the Internet is a must-read for anyone hoping to understand the next wave of human culture and communication.\"Read, learn, smile, weep, enjoy: managers, policy-makers, and fellow citizens, this book is worth your time.\" --Tom PetersA", "authors": ["Howard Rheingold"], "related_topics": ["2778571376", "29595303", "110875604"], "citation_count": "7038", "reference_count": "0", "references": ["2147050295", "2041711461", "1983895294", "2030144199", "2102411528", "2086235321", "2576297379", "2144336601", "1673918140", "1991384030"], "date": "1994"}, {"id": "2155054718", "title": "VITS-a vision system for autonomous land vehicle navigation", "abstract": "A description is given of VITS (for vision task sequencer), the vision system for the autonomous land vehicle (ALV) Alvin, addressing in particular the task of road-following. The ALV vision system builds symbolic descriptions of road and obstacle boundaries using both video and range sensors. The authors discuss various road segmentation methods for video-based road-following, along with approaches to boundary extraction and transformation of boundaries in the image plane into a vehicle-centered three-dimensional scene model. >", "authors": ["M.A. Turk", "D.G. Morgenthaler", "K.D. Gremban", "M. Marra"], "related_topics": ["5339829", "120515352", "34413123"], "citation_count": "545", "reference_count": "34", "references": ["2528268528", "3017143921", "1639227073", "2099034771", "1502820991", "2008791833", "2166967166", "100724795", "2160982455", "2156036475"], "date": "1988"}, {"id": "2118519969", "title": "I tube, you tube, everybody tubes: analyzing the world's largest user generated content video system", "abstract": "User Generated Content (UGC) is re-shaping the way people watch video and TV, with millions of video producers and consumers. In particular, UGC sites are creating new viewing patterns and social interactions, empowering users to be more creative, and developing new business opportunities. To better understand the impact of UGC systems, we have analyzed YouTube, the world's largest UGC VoD system. Based on a large amount of data collected, we provide an in-depth study of YouTube and other similar UGC systems. In particular, we study the popularity life-cycle of videos, the intrinsic statistical properties of requests and their relationship with video age, and the level of content aliasing or of illegal content in the system. We also provide insights on the potential for more efficient UGC VoD systems (e.g. utilizing P2P techniques or making better use of caching). Finally, we discuss the opportunities to leverage the latent demand for niche videos that are not reached today due to information filtering effects or other system scarcity distortions. Overall, we believe that the results presented in this paper are crucial in understanding UGC systems and can provide valuable information to ISPs, site administrators, and content owners with major commercial and technical implications.", "authors": ["Meeyoung Cha", "Haewoon Kwak", "Pablo Rodriguez", "Yong-Yeol Ahn", "Sue Moon"], "related_topics": ["101293273", "2780586970", "136764020"], "citation_count": "2074", "reference_count": "31", "references": ["2008620264", "2138899136", "2950627632", "2104085672", "2138543759", "2153527920", "2144256475", "1993803315", "2264709743", "2161012989"], "date": "2007"}, {"id": "1529930700", "title": "Views for Semistructured Data", "abstract": "Defining a view over a semistructured database introduces many new problems. In this paper we propose a view specification language and consider the problem of answering queries posed over views. The two main approaches, query rewriting and view materialization, are outlined with focus on the diffcult problems caused by the semistructured nature of the data.", "authors": ["S. Abiteboul", "R. Goldman", "J. McHugh", "V. Vassalos", "Y. Zhuge"], "related_topics": ["54239708", "201677973", "40140605"], "citation_count": "107", "reference_count": "17", "references": ["2087060113", "2123975697", "2149532506", "2117849706", "2134356404", "2100674109", "2290250680", "2162621793", "1528249715", "1512840853"], "date": "1996"}, {"id": "2208883602", "title": "Ontological Anti-Realism", "abstract": "The basic question of ontology is \u201cWhat exists?\u201d. The basic question of metaontology is: are there objective answers to the basic question of ontology? Here ontological realists say yes, and ontological anti-realists say no. (Compare: The basic question of ethics is \u201cWhat is right?\u201d. The basic question of metaethics is: are there objective answers to the basic question of ethics? Here moral realists say yes, and moral anti-realists say no.) For example, the ontologist may ask: Do numbers exist? The Platonist says yes, and the nominalist says no. The metaontologist may ask: is there an objective fact of the matter about whether numbers exist? The ontological realist says yes, and the ontological anti-realist says no. Likewise, the ontologist may ask: Given two distinct entities, when does a mereological sum of those entities exist? The universalist says always, while the nihilist says never. The metaontologist may ask: is there an objective fact of the matter about whether the mereological sum of two distinct entities exists? The ontological realist says yes, and the ontological anti-realist says no. Ontological realism is often traced to Quine (1948), who held that we can determine what exists by seeing which entities are endorsed by our best scientific theory of the world. In recent years, the practice of ontology has often presupposed an ever-stronger ontological realism, and strong versions of ontological realism have received explicit statements by Fine (this volume), Sider (2001; this volume), van Inwagen (1998; this volume), and others. Ontological anti-realism is often traced to Carnap (1950), who held that there are many different ontological frameworks, holding that different sorts of entities exist, and that while some INPCers: For a 30-page version, the most important sections to read are probably 1, 2, and 5-10. For those who have read the version of this paper posted in early January, the current version (early February) has only minor changes from that version.", "authors": ["David Chalmers"], "related_topics": ["2775961736", "193308744", "25810664"], "citation_count": "130", "reference_count": "24", "references": ["2094298389", "2498487088", "1570683606", "33925818", "1524765234", "2130706201", "2323071706", "2041342778", "2067582979", "1986922656"], "date": "2008"}, {"id": "1550769831", "title": "Semantic Interpretation and the Resolution of Ambiguity", "abstract": "Preface 1. Introduction 2. Semantic interpretation 3. The Absity semantic interpreter 4. Lexical disambiguation 5. Polaroid words 6. Structural disambiguation 7. The semantic enquiry desk 8. Conclusion 9. Speculations, partially baked ideas, and exercises for the reader References Index of names Index of subjects.", "authors": ["Graeme Hirst"], "related_topics": ["193125573", "44572571", "130318100"], "citation_count": "811", "reference_count": "0", "references": ["2436001372", "1572948005", "2130337399", "1731244441", "1710422233", "2040004971", "2140887277", "123527740", "1977182536", "2157025692"], "date": "1987"}, {"id": "2109059823", "title": "Predictive Reward Signal of Dopamine Neurons", "abstract": "Schultz, Wolfram. Predictive reward signal of dopamine neurons. J. Neurophysiol. 80: 1\u201327, 1998. The effects of lesions, receptor blocking, electrical self-stimulation, and drugs of abuse suggest t...", "authors": ["Wolfram Schultz"], "related_topics": ["513476851", "143661069", "2780936309"], "citation_count": "5028", "reference_count": "280", "references": ["2154642048", "2895674046", "2117726420", "1535810436", "2106862702", "2073787051", "1583833196", "2099652807", "1540136915", "2014793858"], "date": "1998"}, {"id": "2176206481", "title": "A weighted cepstral distance measure for speech recognition", "abstract": "A weighted cepstral distance measure is proposed and is tested in a speaker-independent isolated word recognition system using standard DTW (dynamic time warping) techniques. The measure is a statistically weighted distance measure with weights equal to the inverse variance of the cepstral coefficients. The experimental results show that the weighted cepstral distance measure works substantially better than both the Euclidean cepstral distance and the log likelihood ratio distance measures across two different databases. The recognition error rate obtained using the weighted cepstral distance measure was about 1 percent for digit recognition. This result was less than one-fourth of that obtained using the simple Euclidean cepstral distance measure and about one-third of the results using the log likelihood ratio distance measure. The most significant performance characteristic of the weighted cepstral distance was that it tended to equalize the performance of the recognizer across different talkers.", "authors": ["Y. Tohkura"], "related_topics": ["120174047", "40969351", "2639959"], "citation_count": "241", "reference_count": "16", "references": ["1966264494", "2137089646", "2112529238", "1989337816", "2057833190", "2123783347", "2069976350", "2050693797", "2102504831", "1920160043"], "date": "1987"}, {"id": "2021034890", "title": "Corpus, concordance, collocation", "abstract": "Designed for English language teachers and other educators, this study charts the emergence of a new view of language and the computer technology associated with it.", "authors": ["John McHardy Sinclair", "Ronald Carter"], "related_topics": ["532629269", "166007726", "2986193123"], "citation_count": "3571", "reference_count": "0", "references": ["2133518763", "2078906720", "1561412240", "574867956", "382421368", "2073552557", "2120409145", "2096116546", "2124819629", "2100729338"], "date": "1994"}, {"id": "2313004219", "title": "The sequencing of chemotherapy and radiation therapy after conservative surgery for early-stage breast cancer.", "abstract": "Background Patients with early-stage breast cancer who are at substantial risk for systemic metastases are increasingly treated with breast-conserving therapy and adjuvant chemotherapy. However, the optimal sequencing of chemotherapy and radiation therapy is not clear. Methods Two hundred forty-four patients with stage I or II breast cancer who were at substantial risk for distant metastases were randomly assigned to receive a 12-week course of chemotherapy either before or after radiation therapy. All had had breast-conserving surgery. The median length of follow-up in surviving patients was 58 months (range, 10 to 124). Results The five-year actuarial rates of cancer recurrence at any site and of distant metastases in the radiotherapy-first group and the chemotherapy-first group were 38 percent and 31 percent (P = 0.17) and 36 percent and 25 percent (P = 0.05), respectively. Overall survival was 73 percent and 81 percent (P = 0.11), respectively. The five-year crude rates of first recurrence according t...", "authors": ["A. Recht", "S. E. Come", "I. C. Henderson", "R. S. Gelman", "B. Silver", "D. F. Hayes", "L. N. Shulman", "J. R. Harris"], "related_topics": ["530470458", "509974204", "2779013556"], "citation_count": "600", "reference_count": "21", "references": ["1973948212", "2313308602", "2105365583", "2214029008", "2095349827", "2052577752", "2029902156", "1767955168", "111776290", "2046518833"], "date": "1996"}, {"id": "1495419098", "title": "The Knowledge Creating Company", "abstract": "Japanese companies, masters of manufacturing, have also been leaders in the creation, management, and use of knowledge-especially the tacit and often subjective insights, intuitions, and ideas of employees.", "authors": ["Ikujiro Nonaka"], "related_topics": ["2779561248", "187572123", "191628500"], "citation_count": "27020", "reference_count": "0", "references": ["2132454116", "2169667133", "2108183214", "2160449301", "1701471885", "2018514036", "1998800754", "1487531252", "2118020692", "2095848001"], "date": "2007"}, {"id": "2104820473", "title": "Supporting real-time applications in an Integrated Services Packet Network: architecture and mechanism", "abstract": "This paper considers the support of real-time applications in an Integrated Services Packet Network (ISPN). We first review the characteristics of real-time applications. We observe that, contrary to the popular view that real-time applications necessarily require a fixed delay bound, some real-time applications are more flexible and can adapt to current network conditions. We then propose an ISPN architecture that supports two distinct kinds of real-time service: guaranteed service, which is the traditional form of real-time service discussed in most of the literature and involves pre-computed worst-case delay bounds, and predicted service which uses the measure performance of the network in computing delay bounds. We then propose a packet scheduling mechanism that can support both of these real-time services as well as accommodate datagram traffic. We also discuss two other aspects of an overall ISPN architecture: the service interface and the admission control criteria.", "authors": ["David D. Clark", "Scott Shenker", "Lixia Zhang"], "related_topics": ["21434264", "193415008", "158379750"], "citation_count": "1478", "reference_count": "23", "references": ["2176566884", "3163287424", "2116142303", "2073440460", "2158283087", "2262960161", "2099440788", "1556522047", "2170009394", "2168697986"], "date": "1992"}, {"id": "2156283242", "title": "A NONITERATIVE MATRIX-METHOD FOR CONSTRAINT MOLECULAR-DYNAMICS SIMULATIONS", "abstract": "Abstract A non-iterative version of the matrix method which can be easily vectorised and parallelized is presented. The original matrix method, which is conceptually identical to the familiar SHAKE algorithm, is shown to be non-iterative when incorporated with the Verlet and leap-frog integration schemes with the same constraint error order as the (local) error order of the accompanying integration schemes. The method is checked by test simulations with n-butane and the liquid crystal moleculae 5CB (4-n-pentyl-4\u2032-cyanobiphenyl) in which its effectiveness is demonstrated.", "authors": ["Makoto Yoneya", "H. J. C. Berendsen", "Kootaro Hirasawa"], "related_topics": ["45600393", "86761442", "2776426709"], "citation_count": "66", "reference_count": "11", "references": ["2106140689", "1977482735", "2107572441", "2951352984", "2071214505", "2014570683", "2062092199", "2046299723", "2041669624", "2149421819"], "date": "1994"}, {"id": "31045409", "title": "The reflective practitioner", "abstract": "The reflection that accompanies the evidence a candidate presents in the performance-based product is a critical part of the candidate's development. Through reflection the candidate begins the ongoing process of blending the art and science of good teaching practice. Reflection requires thoughtful and careful reporting and analysis of teaching practice, philosophy, and experience. Understanding why an activity or practice was productive or nonproductive in the classroom is a key element in the progression from novice to master teacher. The reflection cycle and the guiding questions included in this packet are designed to assist licensure candidates in the reflection process. They will enable candidates to better understand the reflection process and address the question; \"How does this piece of evidence demonstrate my knowledge and skill level in this activity?\". The following reflection cycle offers a prescriptive structure while allowing the flexibility necessary for candidates to demonstrate their knowledge, skill, and ability in the unique context of their area and environment. The reflections of the novice teacher are also vital to the assessors charged with the responsibility for judging whether the teacher has met the required level of performance for each standard based activity. Through their responses to the guiding questions, candidates will better be able to put evidence into perspective for the review team members by explaining how the evidence or artifact addresses the standard through the activity.", "authors": ["D. Schoen"], "related_topics": ["132413290", "2780049985", "119957404"], "citation_count": "16565", "reference_count": "0", "references": ["2123184471", "2132454116", "2154563310", "1500842519", "2156435103", "2156665851", "2138984333", "2150587481", "2019147893", "2115925287"], "date": "1982"}, {"id": "2056115137", "title": "The perception of disoriented figures.", "abstract": "", "authors": ["Irvin Rock"], "related_topics": ["26760741", "180747234", "15744967"], "citation_count": "287", "reference_count": "0", "references": ["2093353037", "1501418839", "2022111034", "2117268255", "2094312809", "2087825138", "2122946915", "2122633888", "2967040615", "1998186877"], "date": "1973"}, {"id": "1980043035", "title": "A combined nonparametric approach to feature selection and binary decision tree design", "abstract": "Abstract An efficient procedure which integrates feature selection and binary decision tree construction is presented. The nonparametric approach is based on the Kolmogorov-Smirnov criterion which yields an optimal classification decision at each node. By combining the feature selection with the design of the classifier, only the most informative features are retained for classification.", "authors": ["E.M. Rounds"], "related_topics": ["10229987", "148483581", "5481197"], "citation_count": "132", "reference_count": "10", "references": ["193579291", "2017900294", "1970361289", "2143249365", "2034240861", "2086294262", "2000367563", "142755352", "2064048446", "296815042"], "date": "1979"}, {"id": "2018843280", "title": "A gene expression database for the molecular pharmacology of cancer", "abstract": "We used cDNA microarrays to assess gene expression profiles in 60 human cancer cell lines used in a drug discovery screen by the National Cancer Institute. Using these data, we linked bioinformatics and chemoinformatics by correlating gene expression and drug activity patterns in the NCI60 lines. Clustering the cell lines on the basis of gene expression yielded relationships very different from those obtained by clustering the cell lines on the basis of their response to drugs. Gene-drug relationships for the clinical agents 5-fluorouracil and L-asparaginase exemplify how variations in the transcript levels of particular genes relate to mechanisms of drug sensitivity and resistance. This is the first study to integrate large databases on gene expression and molecular pharmacology.", "authors": ["Uwe Scherf", "Douglas T. Ross", "Mark Waltham", "Lawrence H. Smith", "Jae K. Lee", "Lorraine Tanabe", "Kurt W. Kohn", "William C. Reinhold", "Timothy G. Myers", "Darren T. Andrews", "Dominic A. Scudiero", "Michael B. Eisen", "Edward A. Sausville", "Yves Pommier", "David Botstein", "Patrick O. Brown", "John N. Weinstein"], "related_topics": ["74187038", "150194340", "14314382"], "citation_count": "1784", "reference_count": "48", "references": ["2150926065", "1970156673", "1989076816", "238668910", "1967053372", "2030958510", "2161893150", "2167395325", "2155208683", "2120064876"], "date": "2000"}, {"id": "2062104878", "title": "Bayesian face recognition", "abstract": "Abstract We propose a new technique for direct visual matching of images for the purposes of face recognition and image retrieval, using a probabilistic measure of similarity, based primarily on a Bayesian (MAP) analysis of image differences. The performance advantage of this probabilistic matching technique over standard Euclidean nearest-neighbor eigenface matching was demonstrated using results from DARPA's 1996 \u201cFERET\u201d face recognition competition, in which this Bayesian matching alogrithm was found to be the top performer. In addition, we derive a simple method of replacing costly computation of nonlinear (on-line) Bayesian similarity measures by inexpensive linear (off-line) subspace projections and simple Euclidean norms, thus resulting in a significant computational speed-up for implementation with very large databases.", "authors": ["Baback Moghaddam", "Tony Jebara", "Alex Pentland"], "related_topics": ["104906051", "31510193", "165064840"], "citation_count": "859", "reference_count": "31", "references": ["2138451337", "2121647436", "2148694408", "2123977795", "2115689562", "2098947662", "2113341759", "2128716185", "2012352340", "2135463994"], "date": "2000"}, {"id": "2107922358", "title": "Rapid detection and quantification of RNA of Ebola and Marburg viruses, Lassa virus, Crimean-Congo hemorrhagic fever virus, Rift Valley fever virus, dengue virus, and yellow fever virus by real-time reverse transcription-PCR.", "abstract": "Viral hemorrhagic fevers (VHFs) are acute infections with high case fatality rates. Important VHF agents are Ebola and Marburg viruses (MBGV/EBOV), Lassa virus (LASV), Crimean-Congo hemorrhagic fever virus (CCHFV), Rift Valley fever virus (RVFV), dengue virus (DENV), and yellow fever virus (YFV). VHFs are clinically difficult to diagnose and to distinguish; a rapid and reliable laboratory diagnosis is required in suspected cases. We have established six one-step, real-time reverse transcription-PCR assays for these pathogens based on the Superscript reverse transcriptase-Platinum Taq polymerase enzyme mixture. Novel primers and/or 5\u2032-nuclease detection probes were designed for RVFV, DENV, YFV, and CCHFV by using the latest DNA database entries. PCR products were detected in real time on a LightCycler instrument by using 5\u2032-nuclease technology (RVFV, DENV, and YFV) or SybrGreen dye intercalation (MBGV/EBOV, LASV, and CCHFV). The inhibitory effect of SybrGreen on reverse transcription was overcome by initial immobilization of the dye in the reaction capillaries. Universal cycling conditions for SybrGreen and 5\u2032-nuclease probe detection were established. Thus, up to three assays could be performed in parallel, facilitating rapid testing for several pathogens. All assays were thoroughly optimized and validated in terms of analytical sensitivity by using in vitro-transcribed RNA. The \u226595% detection limits as determined by probit regression analysis ranged from 1,545 to 2,835 viral genome equivalents/ml of serum (8.6 to 16 RNA copies per assay). The suitability of the assays was exemplified by detection and quantification of viral RNA in serum samples of VHF patients.", "authors": ["Christian Drosten", "Stephan G\u00f6ttig", "Stefan Schilling", "Marcel Asper", "Marcus Panning", "Herbert Schmitz", "Stephan G\u00fcnther"], "related_topics": ["2777427142", "2776070282", "2779635636"], "citation_count": "784", "reference_count": "39", "references": ["2047480444", "1994091239", "2070721758", "2131589770", "2149579937", "2137089963", "2163760194", "2134971582", "2171308211", "2798078005"], "date": "2002"}, {"id": "33304535", "title": "The Assumptions Economists Make", "abstract": "Economists make confident assertions in op-ed columns and on cable news - so why are their explanations often at odds with equally confident assertions from other economists? And why are all economic predictions so rarely borne out? Harnessing his frustration with these contradictions, Jonathan Schlefer set out to investigate how economists arrive at their opinions. While economists cloak their views in the aura of science, what they actually do is make assumptions about the world, use those assumptions to build imaginary economies (known as models), and from those models generate conclusions. Their models can be useful or dangerous, and it is surprisingly difficult to tell which is which. Schlefer arms us with an understanding of rival assumptions and models reaching back to Adam Smith and forward to cutting-edge theorists today. Although abstract, mathematical thinking characterizes economists' work, Schlefer reminds us that economists are unavoidably human. They fall prey to fads and enthusiasms and subscribe to ideologies that shape their assumptions, sometimes in problematic ways. Schlefer takes up current controversies such as income inequality and the financial crisis, for which he holds economists in large part accountable. Although theorists won international acclaim for creating models that demonstrated the inherent instability of markets, ostensibly practical economists ignored those accepted theories and instead relied on their blind faith in the invisible hand of unregulated enterprise. Schlefer explains how the politics of economics allowed them to do so. \"The Assumptions Economists Make\" renders the behavior of economists much more comprehensible, if not less irrational.", "authors": ["Jonathan Schlefer"], "related_topics": ["2777605291", "118084267", "158071213"], "citation_count": "32", "reference_count": "81", "references": ["2050482467", "2148501506", "2252953284", "40048283", "2107497267", "2126988636", "2157509893", "2915892579", "70394360", "2069210188"], "date": "2012"}, {"id": "2056918046", "title": "Tree Systems for Syntactic Pattern Recognition", "abstract": "An approach of representing patterns by trees rather than by strings is described. A review of tree systems that include tree grammars, transformations, and mappings on trees and tree automata is briefly presented. The tree system is then applied to the problem of syntactic pattern recognition. Tree grammars are used for pattern description, and tree automata are used for classification. Illustrative examples include the application of the tree system to the classification of bubble chamber events and some English characters.", "authors": ["King-Sun Fu", "B.K. Bhargava"], "related_topics": ["100560664", "163797641", "207024777"], "citation_count": "179", "reference_count": "28", "references": ["2035020702", "2073663206", "2044909121", "2003442449", "1963587568", "2075795003", "2912299646", "1525462222", "1984256985", "2294348221"], "date": "1973"}, {"id": "1975900269", "title": "Sparse Principal Component Analysis", "abstract": "Principal component analysis (PCA) is widely used in data processing and dimensionality reduction. However, PCA suffers from the fact that each principal component is a linear combination of all the original variables, thus it is often difficult to interpret the results. We introduce a new method called sparse principal component analysis (SPCA) using the lasso (elastic net) to produce modified principal components with sparse loadings. We first show that PCA can be formulated as a regression-type optimization problem; sparse loadings are then obtained by imposing the lasso (elastic net) constraint on the regression coefficients. Efficient algorithms are proposed to fit our SPCA models for both regular multivariate data and gene expression arrays. We also give a new formula to compute the total variance of modified principal components. As illustrations, SPCA is applied to real and simulated data with encouraging results.", "authors": ["Hui Zou", "Trevor Hastie", "Robert Tibshirani"], "related_topics": ["24252448", "124066611", "27438332"], "citation_count": "3115", "reference_count": "17", "references": ["1554944419", "2135046866", "2122825543", "2063978378", "2148694408", "2138550913", "2137476312", "2148541040", "2062102668", "1774711529"], "date": "2006"}, {"id": "2037717074", "title": "Intelligent information-sharing systems", "abstract": "The Information Lens system is a prototype intelligent information-sharing system that is designed to include not only good user interfaces for supporting the problem-solving activity of individuals, but also good organizational interfaces for supporting the problem-solving activities of groups.", "authors": ["Thomas W Malone", "Kenneth R Grant", "Franklyn A Turbak", "Stephen A Brobst", "Michael D Cohen"], "related_topics": ["56397880", "89505385", "198809072"], "citation_count": "1022", "reference_count": "36", "references": ["1956559956", "1895273801", "1581423510", "1822534520", "2099305423", "2159525276", "2115164315", "2083605078", "1984543852", "1511343964"], "date": "1987"}, {"id": "2314833535", "title": "Statistical Methods for Research Workers", "abstract": "", "authors": ["John Tukey", "R. A. Fisher"], "related_topics": ["15744967"], "citation_count": "1491", "reference_count": "0", "references": ["2161520320", "2099915326", "2030360178", "2025651303", "2132853862", "1607441804", "1967542346", "2059356295", "2022619265", "2143512982"], "date": "1952"}, {"id": "2171308211", "title": "Detection and Molecular Characterization of Ebola Viruses Causing Disease in Human and Nonhuman Primates", "abstract": "Ebola (EBO) viruses were detected in specimens obtained during the hemorrhagic fever outbreak among humans in Kikwit, Democratic Republic of the Congo (DRC), in 1995 (subtype Zaire) and during an outbreak of disease in cynomolgus macaques in Alice, Texas, and the Philippines in 1996 (subtype Reston). Reverse transcriptase-polymerase chain reaction assays were developed and proven effective for detecting viral RNA in body fluids and tissues of infected individuals. Little change was seen in the nucleotide or deduced amino acid sequences of the glycoprotein (GP) of these EBO virus subtypes compared with those of their original representatives (i.e., the 1976 Yambuku, DRC, EBO isolate [subtype Zaire] and the 1989 Philippines and Reston, Virginia, isolates [subtype Reston]). The nonstructural secreted GP (SGP), the primary product of the GP gene, was more highly conserved than the structural GP, indicating different functional roles or evolutionary constraints for these proteins. Significant amounts of SGP were detected in acutely infected humans.", "authors": ["Anthony Sanchez", "Thomas G. Ksiazek", "Pierre E. Rollin", "Mary E. G. Miranda", "Sam G. Trappier", "Ali S. Khan", "Clarence J. Peters", "Stuart T. Nichol"], "related_topics": ["2777469322", "2777245867", "2780355102"], "citation_count": "254", "reference_count": "14", "references": ["2131706225", "2160047153", "1978996068", "2097378446", "1969661655", "1825594680", "1993048073", "1995116321", "2014418657", "2084944660"], "date": "1999"}, {"id": "2889277908", "title": "Generalize Symbolic Knowledge With Neural Rule Engine", "abstract": "As neural networks have dominated the state-of-the-art results in a wide range of NLP tasks, it attracts considerable attention to improve the performance of neural models by integrating symbolic knowledge. Different from existing works, this paper investigates the combination of these two powerful paradigms from the knowledge-driven side. We propose Neural Rule Engine (NRE), which can learn knowledge explicitly from logic rules and then generalize them implicitly with neural networks. NRE is implemented with neural module networks in which each module represents an action of a logic rule. The experiments show that NRE could greatly improve the generalization abilities of logic rules with a significant increase in recall. Meanwhile, the precision is still maintained at a high level.", "authors": ["Shen Li", "Hengru Xu", "Zhengdong Lu"], "related_topics": ["3746660", "50644808", "154945302"], "citation_count": "11", "reference_count": "29", "references": ["2964308564", "2158899491", "2493916176", "6908809", "2167839676", "2964118342", "2963143606", "2962772361", "2963687836", "2181042685"], "date": "2018"}, {"id": "1993549051", "title": "Connections with multiple congested gateways in packet-switched networks part 1: one-way traffic", "abstract": "In this paper we explore the bias in TCP/IP networks against connections with multiple congested gateways. We consider the interaction between the bias against connections with multiple congested gateways, the bias of the TCP window modification algorithm against connections with longer roundtrip times, and the bias of Drop Tail and Random Drop gateways against bursty traffic. Using simulations and a heuristic analysis, we show that in a network with the window modification algorithm in 4.3 tahoe BSD TCP and with Random Drop or Drop Tail gateways, a longer connection with multiple congested gateways can receive unacceptably low throughput. We show that in a network with no bias against connections with longer roundtrip times and with no bias against bursty traffic, a connection with multiple congested gateways can receive an acceptable level of throughput.We discuss the application of several current measures of fairness to networks with multiple congested gateways, and show that different measures of fairness have quite different implications. One view is that each connection should receive the same throughput in bytes/second, regardless of roundtrip times or numbers of congested gateways. Another view is that each connection should receive the same share of the network's scarce congested resources. In general, we believe that the fairness criteria for connections with multiple congested gateways requires further consideration.", "authors": ["Sally Floyd"], "related_topics": ["27143522", "157764524", "2778546251"], "citation_count": "575", "reference_count": "18", "references": ["2753542457", "3163287424", "3013767507", "2799087070", "2011730388", "2096597645", "2096812769", "1556522047", "2095000200", "2144410062"], "date": "1991"}, {"id": "2010348352", "title": "The job demands-resources model : state of the art", "abstract": "Purpose \u2013 The purpose of this paper is to give a state\u2010of\u2010the art overview of the Job Demands\u2010Resources (JD\u2010R) modelDesign/methodology/approach \u2013 The strengths and weaknesses of the demand\u2010control model and the effort\u2010reward imbalance model regarding their predictive value for employee well being are discussed. The paper then introduces the more flexible JD\u2010R model and discusses its basic premises.Findings \u2013 The paper provides an overview of the studies that have been conducted with the JD\u2010R model. It discusses evidence for each of the model's main propositions. The JD\u2010R model can be used as a tool for human resource management. A two\u2010stage approach can highlight the strengths and weaknesses of individuals, work groups, departments, and organizations at large.Originality/value \u2013 This paper challenges existing stress models, and focuses on both negative and positive indicators of employee well being. In addition, it outlines how the JD\u2010R model can be applied to a wide range of occupations, and be used to i...", "authors": ["Arnold B. Bakker", "Evangelia Demerouti"], "related_topics": ["2777442297", "63882131", "174954385"], "citation_count": "10082", "reference_count": "89", "references": ["2081155210", "2153610778", "3019273456", "2127625785", "2005673510", "2006906014", "2055461003", "2072544276", "1997858829", "2048385562"], "date": "2007"}, {"id": "2164591835", "title": "Utilization of the Internet for rapid community intensity maps", "abstract": "INTRODUCTION The most common information available immediately following a damaging earthquake is its magnitude and the epicentral location. However, it is also desirable to know the extent of the felt area, and, more important, the range of shaking experienced and the areal extent of strongest shaking. For most of the United States, there is insufficient seismic strong-motion station coverage to portray quickly and accurately the extent of strong shaking. Seismic intensity has been traditionally used worldwide as a method for quantifying the shaking pattern and the extent of damage for earthquakes. Though developed prior to the advent of today's modern seismometric instrumentation, seismic intensity scales nonetheless provide a useful framework to describe, in a simplified fashion, the complexity of ground motions and the extent and nature of the damage. A limitation of traditional intensity mapping has been the long time required to generate a detailed seismic intensity map, typically weeks...", "authors": ["David J. Wald", "Vincent Quitoriano", "Lori A. Dengler", "James W. Dewey"], "related_topics": ["2777967070", "61586570", "165205528"], "citation_count": "233", "reference_count": "0", "references": ["1731771962", "1968545881", "2118480788", "2169523845", "3123251390", "2109246136", "2025242548", "2980387713", "2162399577", "2148580977"], "date": "1999"}, {"id": "2964015378", "title": "Semi-Supervised Classification with Graph Convolutional Networks", "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.", "authors": ["Thomas N. Kipf", "Max Welling"], "related_topics": ["81363708", "48044578", "80444323"], "citation_count": "7582", "reference_count": "0", "references": ["2962711740", "2907492528", "3100848837", "2963224980", "2962883549", "2963184176", "3100278010", "2905224888", "2918342466", "2796426482"], "date": "2016"}, {"id": "2913677764", "title": "Mobile Computing", "abstract": "From the Publisher: The rapid development of wireless digital communication technology has created capabilities that software systems are only beginning to exploit. The falling cost of both communication and of mobile computing devices (laptop computers, hand-held computers, etc.) is making wireless computing affordable not only to business users but also to consumers. Mobile computing is not a \"scaled-down\" version of the established and well-studied field of distributed computing. The nature of wireless communication media and the mobility of computers combine to create fundamentally new problems in networking, operating systems, and information systems. Furthermore, many of the applications envisioned for mobile computing place novel demands on software systems. Although mobile computing is still in its infancy, some basic concepts have been identified and several seminal experimental systems developed. Mobile Computing contains chapters that describe these concepts and systems, and the book describes applications that are currently being deployed and tested. Mobile Computing serves as a valuable reference book and may also be used as a text for a course on the subject.", "authors": ["Tomasz Imielinski", "Henry F. Korth"], "related_topics": ["144543869", "149091818", "180198813"], "citation_count": "854", "reference_count": "0", "references": ["2108777122", "2128381560", "2115710963", "2121868539", "2156200189", "2082674813", "2072463110", "2122426592", "2040142992", "565292247"], "date": "1996"}]